<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>ÿπÿ®ÿØ ÿßŸÑŸÉÿ±ŸäŸÖ ÿßŸÑÿÆÿ∑Ÿäÿ® - Abdelkareem Elkhateb | AI Researcher &amp; Arabic NLP Specialist</title>
<link>https://kareemai.com/blog/feed.html</link>
<atom:link href="https://kareemai.com/blog/feed.xml" rel="self" type="application/rss+xml"/>
<description>Kareem Elkhateb personal site, a blog about machine learning, deep learning, Web development with Astro.js, FastAPI, also Arabic Natural Language Processing and Rust language.</description>
<image>
<url>https://kareemai.com/quarto.png</url>
<title>ÿπÿ®ÿØ ÿßŸÑŸÉÿ±ŸäŸÖ ÿßŸÑÿÆÿ∑Ÿäÿ® - Abdelkareem Elkhateb | AI Researcher &amp; Arabic NLP Specialist</title>
<link>https://kareemai.com/blog/feed.html</link>
<height>86</height>
<width>144</width>
</image>
<generator>quarto-1.8.25</generator>
<lastBuildDate>Thu, 06 Nov 2025 22:00:00 GMT</lastBuildDate>
<item>
  <title>Huawei FreeBuds 7i Review: Is It Worth Upgrading from FreeBuds 5i? (20 Days Testing)</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/products_reviews/Huawei freebuds 7i.html</link>
  <description><![CDATA[ 





<p><strong>Huawei FreeBuds 7i Review: Is It Worth Upgrading from FreeBuds 5i? (20 Days Testing)</strong></p>
<p>Hi, I‚Äôm Kareem, a college student working on machine learning and web technology projects. I previously reviewed the Huawei FreeBuds 5i after 2 months of daily use, and now I‚Äôve been testing the new FreeBuds 7i for 20 days. I don‚Äôt own a Huawei phone - I use a Realme Android device and MSI Linux laptop - so this is an honest review from someone using these earbuds outside the Huawei ecosystem.</p>
<p><strong>Unboxing and First Impressions</strong></p>
<p>The FreeBuds 7i comes in a neat package with the earbuds, charging case, four sizes of silicone ear tips (XS, S, M, L - one more than the 5i), a USB-C charging cable, and the usual documentation. The case is bigger than the 5i (57.8 x 57.8 x 27.8mm vs 61.8 x 48.2 x 26.9mm) and slightly heavier at 36.5g compared to 33.9g, but there‚Äôs a good reason: the battery capacity jumped from 410mAh to 510mAh.</p>
<p>Available in three Morandi colors - Pink, White, and Black - the design is understated and elegant, though I personally miss the Isle Blue option from the 5i.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/products_reviews/images/huawei_7i.jpg" class="img-fluid figure-img"></p>
<figcaption>Huawei 7i Review</figcaption>
</figure>
</div>
<p><strong>The Game-Changer: Microphone and Call Quality</strong></p>
<p>This is where the FreeBuds 7i truly shines. I don‚Äôt use these for regular mobile calls yet, but I rely on them daily for video meetings with my project partners. On the very first day, my friends noticed the difference immediately!</p>
<p>One partner said: <em>‚ÄúYour voice is now more clear, did you change anything?‚Äù</em></p>
<p>Another friend asked: ‚ÄúDo you have a mechanical keyboard?‚Äù The funny thing is, I‚Äôve always had a mechanical keyboard, but with the 5i my voice wasn‚Äôt clear enough for them to hear the typing sounds in the background. With the 7i, my voice comes through crystal clear while they can now actually hear my keyboard clicks.</p>
<p>The secret? The FreeBuds 7i features a bone conduction microphone working alongside three traditional microphones, with AI call noise cancellation that can handle noisy environments up to 90 dB. This combination delivers significantly better voice clarity compared to the standard mics on the 5i.</p>
<p>For anyone who does frequent video calls, online meetings, or even streaming, this upgrade alone justifies the purchase.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/products_reviews/images/5i_vs_7i.jpeg" class="img-fluid figure-img"></p>
<figcaption>Huawei Freebuds 7i</figcaption>
</figure>
</div>
<p><strong>Sound Quality and Audio Performance</strong></p>
<p>The FreeBuds 7i packs an 11mm quad-magnet dynamic driver (upgraded from the 5i‚Äôs 10mm dynamic driver) with a wide frequency response range of 20 Hz to 40 kHz. In real-world listening, the sound quality is similar to the 5i - both deliver excellent audio for the price point.</p>
<p>Music sounds clear with good separation, bass is punchy without being overwhelming, and podcasts come through crisp and detailed. The 7i also features Dynamic EQ that adjusts based on what you‚Äôre listening to, plus you can customize sound with 10 EQ bands through the AI Life app.</p>
<p>If you‚Äôre upgrading purely for music audio quality, you won‚Äôt notice a dramatic difference. The real improvements are in other areas.</p>
<p><strong>Active Noise Cancellation: Intelligent Dynamic ANC 4.0</strong></p>
<p>The noise cancelling performance is better by a good margin. Huawei‚Äôs new Intelligent Dynamic ANC 4.0 delivers an average noise cancellation depth of 28 dB with less than 0.5 second latency. In practical terms, this means faster adaptation to changing noise environments.</p>
<p>When I walk down the street at night, I don‚Äôt hear most of the ambient voices and traffic noise anymore. On the subway or bus, the engine noise is effectively blocked. In caf√©s, the background chatter fades away, letting me focus on my work.</p>
<p>Are you in complete silence? No - some sounds still get through, especially sudden loud noises. But the improvement over the 5i is noticeable and makes a real difference in noisy environments.</p>
<p><strong>Mode Switching: A Small Change That Matters</strong></p>
<p>One of my biggest frustrations with the 5i was the mode cycle order: Awareness ‚Üí Off ‚Üí Noise Cancelling. Since I primarily use ANC mode, I had to cycle through two modes every time I put them on.</p>
<p>The 7i finally fixes this! The new order is: Noise Cancelling ‚Üí Off ‚Üí Awareness. This might seem like a minor detail, but when you use these earbuds multiple times a day, it‚Äôs a quality-of-life improvement I genuinely appreciate.</p>
<p><strong>Multi-Device Connection and Bluetooth Performance</strong></p>
<p>The FreeBuds 7i runs on Bluetooth 5.4 (upgraded from 5.2 on the 5i) and supports simultaneous dual-device connection. It‚Äôs noticeably smarter at switching between my Linux laptop and Realme Android phone compared to the 5i.</p>
<p>The connection is stable, transitions are smooth, and it works seamlessly whether I‚Äôm using the Huawei AI Life app or not. This is impressive considering I don‚Äôt even own a Huawei phone. The improved Bluetooth version also means better range and more stable connectivity.</p>
<p>For the Linux users out there: yes, it connects via bluetoothctl, though you might need to restart Bluetooth occasionally for a clean connection - same as with the 5i.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/products_reviews/images/black_7i.jpeg" class="img-fluid figure-img"></p>
<figcaption>Huawei Freebuds 7i unboxing</figcaption>
</figure>
</div>
<p><strong>Battery Life: Longer and Faster</strong></p>
<p>This is where the larger case really pays off:</p>
<p><strong>FreeBuds 7i Battery Performance:</strong> - Single charge with ANC ON: 5 hours - Single charge with ANC OFF: 8 hours<br>
- Total with case (ANC ON): 20 hours - Total with case (ANC OFF): 35 hours - Earbud charging time: 40 minutes - Case charging time: 60 minutes (wired USB-C) - Fast charging: 10 minutes = 4 hours of playback</p>
<p><strong>FreeBuds 5i Battery Performance:</strong> - Single charge with ANC ON: 6 hours - Single charge with ANC OFF: 7.5 hours - Total with case (ANC ON): 18.5 hours - Total with case (ANC OFF): 28 hours - Earbud charging time: 60 minutes - Case charging time: 110 minutes (wired USB-C)</p>
<p>While the 5i offers slightly longer listening time on a single charge with ANC enabled (6h vs 5h), the 7i wins in total battery capacity and especially charging speed. Going from 110 minutes to 60 minutes for a full case charge is almost half the time! The earbuds also charge faster - 40 minutes vs 60 minutes.</p>
<p>The fast charging feature is genuinely useful: a quick 10-minute charge gives you 4 hours of playback when you‚Äôre in a hurry.</p>
<p><strong>Design, Build Quality, and Comfort</strong></p>
<p>I‚Äôll be honest here: the FreeBuds 5i case was more elegant and modern looking with its wider, flatter profile. The 7i‚Äôs case is more square-shaped and less stylish. However, the earbuds themselves are well-designed.</p>
<p>Each earbud weighs just 5.4g (vs 4.9g on the 5i), which is barely noticeable. The 7i includes four ear tip sizes (XS, S, M, L) compared to three on the 5i (S, M, L), giving you better options for a secure, comfortable fit. Both models have IP54 rating, meaning they‚Äôre dust-tight and splash-resistant - perfect for workouts or light rain.</p>
<p>The sound when closing the case is satisfying - a solid, premium click that I genuinely enjoy.</p>
<p><strong>Gesture Controls and Smart Features</strong></p>
<p>The touch controls are intuitive and responsive: - <strong>Double-tap:</strong> Play/pause music, answer/end calls - <strong>Triple-tap:</strong> Skip to next track (new feature vs 5i) - <strong>Swipe up/down:</strong> Volume control - <strong>Touch-and-hold:</strong> Switch between ANC modes or reject calls</p>
<p>New features on the 7i include: - <strong>Nod to pick up:</strong> Answer calls by nodding your head (needs to be enabled) - <strong>Unlimited Spatial Audio:</strong> 360¬∞ sound with head-tracking - <strong>Audio Sharing:</strong> Connect two pairs of FreeBuds to one device</p>
<p>The spatial audio feature works across different apps and devices, creating an immersive listening experience for movies and gaming. <img src="https://kareemai.com/blog/posts/products_reviews/images/overview_7i.jpeg" class="img-fluid" alt="Freebuds 7i"> <strong>Sensors and Technology</strong></p>
<p>The FreeBuds 7i is packed with sensors: - Infrared sensor (for wear detection) - Hall sensor (for case open/close detection) - Touch sensor (for gesture controls) - Gyroscope (for head-tracking in spatial audio) - Accelerometer - Bone voice sensor (for call quality)</p>
<p>These work together to provide smart features like auto-pause when you remove an earbud, and the improved call quality I mentioned earlier.</p>
<p><strong>Compatibility: Works Beyond Huawei Ecosystem</strong></p>
<p>One question I see often: ‚ÄúDo these work with non-Huawei phones?‚Äù Yes, absolutely! I‚Äôve been using them with: - Realme Android phone (works perfectly) - MSI Linux laptop (connects via bluetoothctl) - Huawei Mate Pad 11 tablet (seamless integration)</p>
<p>The AI Life app (available for both iOS and Android) unlocks additional features like EQ customization, firmware updates, and gesture configuration. But even without the app, the core functionality works great on any Bluetooth device.</p>
<p><strong>FreeBuds 7i vs FreeBuds 5i: Complete Comparison</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 37%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>FreeBuds 7i</th>
<th>FreeBuds 5i</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Driver Size</strong></td>
<td>11mm quad-magnet dynamic</td>
<td>10mm dynamic</td>
</tr>
<tr class="even">
<td><strong>Frequency Response</strong></td>
<td>20 Hz - 40 kHz</td>
<td>Standard</td>
</tr>
<tr class="odd">
<td><strong>ANC Technology</strong></td>
<td>Intelligent Dynamic ANC 4.0 (28dB)</td>
<td>Active noise cancellation</td>
</tr>
<tr class="even">
<td><strong>Microphone</strong></td>
<td>3 mics + bone conduction</td>
<td>Standard mics</td>
</tr>
<tr class="odd">
<td><strong>Call Quality</strong></td>
<td>Significantly clearer</td>
<td>Distant, unclear</td>
</tr>
<tr class="even">
<td><strong>Bluetooth</strong></td>
<td>5.4</td>
<td>5.2</td>
</tr>
<tr class="odd">
<td><strong>Battery (ANC ON)</strong></td>
<td>5h + 20h total</td>
<td>6h + 18.5h total</td>
</tr>
<tr class="even">
<td><strong>Battery (ANC OFF)</strong></td>
<td>8h + 35h total</td>
<td>7.5h + 28h total</td>
</tr>
<tr class="odd">
<td><strong>Case Battery</strong></td>
<td>510mAh</td>
<td>410mAh</td>
</tr>
<tr class="even">
<td><strong>Earbud Charging</strong></td>
<td>40 minutes</td>
<td>60 minutes</td>
</tr>
<tr class="odd">
<td><strong>Case Charging</strong></td>
<td>60 minutes</td>
<td>110 minutes</td>
</tr>
<tr class="even">
<td><strong>Fast Charging</strong></td>
<td>10min = 4h</td>
<td>Not available</td>
</tr>
<tr class="odd">
<td><strong>Weight (earbud)</strong></td>
<td>5.4g</td>
<td>4.9g</td>
</tr>
<tr class="even">
<td><strong>Weight (case)</strong></td>
<td>36.5g</td>
<td>33.9g</td>
</tr>
<tr class="odd">
<td><strong>Ear Tip Sizes</strong></td>
<td>4 sizes (XS, S, M, L)</td>
<td>3 sizes (S, M, L)</td>
</tr>
<tr class="even">
<td><strong>Mode Cycle Order</strong></td>
<td>NC ‚Üí Off ‚Üí Awareness</td>
<td>Awareness ‚Üí Off ‚Üí NC</td>
</tr>
<tr class="odd">
<td><strong>Spatial Audio</strong></td>
<td>Yes with head-tracking</td>
<td>No</td>
</tr>
<tr class="even">
<td><strong>Triple-tap Gesture</strong></td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="odd">
<td><strong>Nod to Answer</strong></td>
<td>Yes</td>
<td>No</td>
</tr>
<tr class="even">
<td><strong>IP Rating</strong></td>
<td>IP54</td>
<td>IP54</td>
</tr>
<tr class="odd">
<td><strong>Colors</strong></td>
<td>Pink, White, Black</td>
<td>Nebula Black, Isle Blue, Ceramic White</td>
</tr>
<tr class="even">
<td><strong>Price Range</strong></td>
<td>~$100</td>
<td>~$100</td>
</tr>
</tbody>
</table>
<p><strong>Who Should Buy the FreeBuds 7i?</strong></p>
<p><strong>Buy the 7i if you:</strong> - Do frequent video calls, online meetings, or streaming - Want the best call quality in this price range - Need better active noise cancellation - Value faster charging (60min vs 110min for case) - Switch between multiple devices regularly - Want spatial audio with head-tracking - Appreciate the extra ear tip size for better fit</p>
<p><strong>Stick with the 5i if you:</strong> - Need maximum single-charge battery life (6h vs 5h with ANC) - Prefer the more elegant case design and Isle Blue color - Rarely make calls or do video meetings - Are satisfied with current ANC performance - Want slightly lighter earbuds (4.9g vs 5.4g)</p>
<p><strong>Common Questions About FreeBuds 7i</strong></p>
<p><strong>Q: Do FreeBuds 7i work with iPhone?</strong> Yes, they work with any Bluetooth device including iPhones. Download the AI Life app for iOS to access advanced features.</p>
<p><strong>Q: How is the microphone quality for calls?</strong> Excellent. The bone conduction mic combined with AI noise cancellation delivers clear voice quality even in noisy environments up to 90 dB.</p>
<p><strong>Q: Can I use just one earbud?</strong> Yes, both earbuds work independently. You can use either the left or right earbud alone.</p>
<p><strong>Q: Are they good for working out?</strong> Yes, the IP54 rating makes them dust-tight and splash-resistant. Just wipe them dry after workouts.</p>
<p><strong>Q: How‚Äôs the latency for gaming?</strong> The Bluetooth 5.4 connection provides low latency suitable for casual mobile gaming, though dedicated gaming earbuds might perform better for competitive play.</p>
<p><strong>Final Verdict: Is the FreeBuds 7i Worth It?</strong></p>
<p>After 20 days of daily use, the Huawei FreeBuds 7i is a meaningful upgrade over the 5i. The microphone quality improvement is immediately noticeable - my colleagues commented on it the first day. The Intelligent Dynamic ANC 4.0 delivers genuinely better noise cancellation, and the faster charging is a game-changer (60 minutes vs 110 minutes for the case).</p>
<p>Yes, the case design is less elegant than the 5i, but the functional improvements more than compensate. For anyone who relies on earbuds for productivity - video calls, meetings, focused work in noisy environments - the FreeBuds 7i is the clear winner.</p>
<p>The sound quality remains excellent, the battery life is better overall, the device switching is smarter, and features like spatial audio and nod-to-answer add genuine value. At around $100, these are among the best budget noise-cancelling earbuds available, even for non-Huawei phone owners.</p>
<p><strong>Rating: 4.5/5</strong></p>
<p><strong>Pros:</strong> - Excellent call quality with bone conduction mic - Better ANC performance (28dB depth) - Much faster charging (60min vs 110min for case) - Smarter multi-device switching - Spatial audio with head-tracking - 4 ear tip sizes for better fit - Works great outside Huawei ecosystem</p>
<p><strong>Cons:</strong> - Case design less elegant than 5i - Slightly heavier earbuds (5.4g vs 4.9g) - Single-charge battery with ANC slightly shorter (5h vs 6h) - No Isle Blue color option</p>
<p>If you do video calls or need excellent ANC, the FreeBuds 7i is worth every penny. If you only listen to music casually, the 5i is still a great choice.</p>



 ]]></description>
  <guid>https://kareemai.com/blog/posts/products_reviews/Huawei freebuds 7i.html</guid>
  <pubDate>Thu, 06 Nov 2025 22:00:00 GMT</pubDate>
</item>
<item>
  <title>From $32,000 to $0 with Small Models and CTranslate2</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/minishlab/ctranslate_maswray.html</link>
  <description><![CDATA[ 





<section id="going-from-32000-to-0-cost-with-small-models" class="level2">
<h2 class="anchored" data-anchor-id="going-from-32000-to-0-cost-with-small-models">Going from $32,000 to 0 cost with small models</h2>
<p>It‚Äôs Friday and I have some time to continue working on open source tasks. I had an idea that requires translating a dataset. It‚Äôs not large - 2GB - and consists of some paragraphs from English. The average number of words is around 400 tokens per row from the 8 million rows :)</p>
<p>I looked into the OpenAI models to calculate how much this would cost me to translate all these with GPT-4.1 and GPT-4.1-mini, and the prices are the following: my total tokens =&gt; 8,000,000 rows * 400 tokens = 3,200,000,000. For the following calculations, I will assume input and output tokens are the same for ease of calculation. I will use the normal API, not the Batched API:</p>
<ul>
<li>total input tokens =&gt; 3,200,000,000</li>
<li>total output tokens =&gt; 3,200,000,000</li>
</ul>
<p><strong>The calculation based on this date 2025-10-03</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Cost</th>
<th>GPT4.1</th>
<th>GPT4.1-mini</th>
<th>GPT3.5 Turbo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Input tokens</td>
<td>3,200 * 2</td>
<td>3,200 * 0.40</td>
<td>3,200 * 0.50</td>
</tr>
<tr class="even">
<td>Output tokens</td>
<td>3,200 * 8</td>
<td>3,200 * 1.60</td>
<td>3,200 * 1.50</td>
</tr>
</tbody>
</table>
<table class="caption-top table">
<colgroup>
<col style="width: 70%">
<col style="width: 8%">
<col style="width: 10%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th>Cost</th>
<th>GPT4.1</th>
<th>GPT4.1-mini</th>
<th>GPT3.5 Turbo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Input tokens</td>
<td>6400</td>
<td>1280</td>
<td>1600</td>
</tr>
<tr class="even">
<td>Output tokens</td>
<td>25600</td>
<td>5120</td>
<td>4800</td>
</tr>
<tr class="odd">
<td>Total $ cost</td>
<td>32000</td>
<td>6400</td>
<td>6400</td>
</tr>
<tr class="even">
<td>Total EGP cost</td>
<td>1,527,680</td>
<td>305,536</td>
<td>305,536</td>
</tr>
<tr class="odd">
<td>it‚Äôs interesting that the cost of gpt4.1 mini is the same as gpt3.5 Turbo ^ ^</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Also, this is insane - I can afford only 1000 EGP or $50 at max :)</p>
</section>
<section id="how-poor-am-i-very-gpu-poor" class="level2">
<h2 class="anchored" data-anchor-id="how-poor-am-i-very-gpu-poor">How poor am I? Very GPU poor! üíª</h2>
<p>I wish I had a local GPU to be able to test open source LLMs like Cohere 70B and such strong models, and I would not care about time!</p>
<p>I remember there is amazing work that is not even an LLM for translation, created by <a href="https://www.linkedin.com/in/ahmedwasfy/">Ahmed Wasfy</a> from <a href="https://www.linkedin.com/company/namaa-community/posts/?feedView=all">NAMMA Community</a></p>
<p>It‚Äôs a 240M parameter small model trained to translate English into Egyptian. It was trained on more than <em><strong>150,000</strong></em> rows with more than <em><strong>10 Million tokens</strong></em> for Arabic language. It competes with closed LLMs like GPT-4o and Claude-3.5-Sonnet</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/minishlab/images/masrawy.png" class="img-fluid figure-img"></p>
<figcaption>masrawy results</figcaption>
</figure>
</div>
<p>I tested it with my local laptop GPU 1660Ti GTX mobile version with 6GB and CPU is Core i7 gen9 from Intel with 32GB DDR4. I tested the model and it worked with PyTorch very fast and very efficiently! The translations are very similar and this is enough for the task I want to build on this translated dataset! Let‚Äôs do the math for how much this will cost on my laptop :)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/minishlab/images/bojji.png" class="img-fluid figure-img"></p>
<figcaption>faster masrawy</figcaption>
</figure>
</div>
<hr>
</section>
<section id="pytorch-pipeline-with-hf-inference-through-transformers" class="level2">
<h2 class="anchored" data-anchor-id="pytorch-pipeline-with-hf-inference-through-transformers">PyTorch Pipeline with HF Inference through Transformers</h2>
<p>I created the translation pipeline and tested it with these batch sizes with these settings: float16 and batch sizes = [2,4,6,8,16]. I found that even though I have enough memory to load more batches, the optimal batch size was 4 and this is because of the RAM and CPU power. I was able to process 100 examples with these results:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 36%">
<col style="width: 0%">
<col style="width: 17%">
<col style="width: 9%">
<col style="width: 16%">
<col style="width: 8%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th></th>
<th>Number of Examples</th>
<th>Batch Size</th>
<th>GPU setup</th>
<th>Full time</th>
<th>Days need</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pytorch + float16</td>
<td></td>
<td>100</td>
<td>8</td>
<td>1660TI laptop GPU</td>
<td>60s</td>
<td>55.56 Days</td>
</tr>
<tr class="even">
<td>Pytorch + float16</td>
<td></td>
<td>100</td>
<td>4</td>
<td>1660TI laptop GPU</td>
<td>45s</td>
<td>41.67 Days</td>
</tr>
<tr class="odd">
<td>Pytorch + float16 + optimized version</td>
<td></td>
<td>100</td>
<td>4</td>
<td>1660TI laptop GPU</td>
<td>35s</td>
<td>32.41 Days</td>
</tr>
</tbody>
</table>
<p>optimized version here i mean</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(model, mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max-autotune"</span>, fullgraph<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-2"></span>
<span id="cb1-3">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span></code></pre></div></div>
<p>It‚Äôs a new feature in <a href="https://pytorch.org/get-started/pytorch-2-x/">PyTorch 2</a> to accelerate the model speeds. I tried multiple settings and also the different backends but there is no huge difference. Convert to ONNX? It‚Äôs a nightmare. I did it before and the results didn‚Äôt worth the headache! I may try it when I have time.</p>
</section>
<section id="lets-do-quantization" class="level2">
<h2 class="anchored" data-anchor-id="lets-do-quantization">Let‚Äôs Do Quantization</h2>
<p>I tried to use the <a href="https://docs.pytorch.org/ao/stable/serving.html">torchao</a> which enables performing quantization in more stable and easier ways. I tried it a lot with my GPU but due to CUDA version it always throws this error:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">1.</span> AssertionError: Float8 dynamic activation quantization is only supported on CUDA<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span>=8.9 and MI300+</span></code></pre></div></div>
<p>The library code is not straightforward and I don‚Äôt have time - I have just 2 days to finish this before I return to my main work.</p>
<p>I also faced some errors because the model I am trying to use is an old and not optimized one for these methods. It‚Äôs based on the <a href="https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-en-ar">OPUS-MT-en-ar</a> created with <a href="https://marian-nmt.github.io/">marianNMT</a> which is an efficient NMT implementation written in pure C++. The models have been converted to PyTorch using the Transformers library by Hugging Face</p>
</section>
<section id="vllms-and-sglang-for-hf-translation-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="vllms-and-sglang-for-hf-translation-pipeline">VLLMs and SGLang for HF translation pipeline</h2>
<p>I searched for SGLang solution with the model and I didn‚Äôt find any help. I tried the vLLM documentation also and found the following pages: <a href="https://docs.vllm.ai/en/latest/contributing/model/basic.html#1-bring-your-model-code">bring_your_own_model</a> and <a href="https://docs.vllm.ai/en/latest/models/supported_models.html#modelscope">this</a>. The model speed was worse than normal HF tensors - it was 5 seconds more. I think there is a better way to write the vLLM version better than mine.</p>
</section>
<section id="more-search-and-ctranslate-magic" class="level2">
<h2 class="anchored" data-anchor-id="more-search-and-ctranslate-magic">More search and Ctranslate magic üé©</h2>
<p>I wanted to give up, but let‚Äôs try a final search on how to serve Marian model. In an old forum answer I found what is called <a href="https://opennmt.net/CTranslate2/quickstart.html">CTranslate2</a>. They say it‚Äôs faster than HF Transformers for specific architectures by around 4-6x.</p>
<p><strong>Definition:</strong> CTranslate2 is a C++ and Python library for efficient inference with Transformer models. The following model types are currently supported:</p>
<ul>
<li>Encoder-decoder models: Transformer base/big, M2M-100, NLLB, BART, mBART, Pegasus, T5, Whisper</li>
<li>Decoder-only models: GPT-2, GPT-J, GPT-NeoX, OPT, BLOOM, MPT, Llama, Mistral, Gemma, CodeGen, GPTBigCode, Falcon, Qwen2</li>
<li>Encoder-only models: BERT, DistilBERT, XLM-RoBERTa</li>
</ul>
<p>Compatible models should be first converted into an optimized model format. The library includes converters for multiple frameworks:</p>
<ul>
<li><a href="https://opennmt.net/CTranslate2/guides/opennmt_py.html">OpenNMT-py</a></li>
<li><a href="https://opennmt.net/CTranslate2/guides/opennmt_tf.html">OpenNMT-tf</a></li>
<li><a href="https://opennmt.net/CTranslate2/guides/fairseq.html">Fairseq</a></li>
<li><a href="https://opennmt.net/CTranslate2/guides/marian.html">Marian</a></li>
<li><a href="https://opennmt.net/CTranslate2/guides/opus_mt.html">OPUS-MT</a></li>
<li><a href="https://opennmt.net/CTranslate2/guides/transformers.html">Transformers</a></li>
</ul>
<section id="key-features-of-ctranslate" class="level3">
<h3 class="anchored" data-anchor-id="key-features-of-ctranslate">Key features of Ctranslate</h3>
<p><strong>Fast and efficient execution on CPU and GPU</strong><br>
The execution&nbsp;<a href="https://github.com/OpenNMT/CTranslate2#benchmarks">is significantly faster and requires less resources</a>&nbsp;than general-purpose deep learning frameworks on supported models and tasks thanks to many advanced optimizations: layer fusion, padding removal, batch reordering, in-place operations, caching mechanism, etc.</p>
<ul>
<li><strong>Quantization and reduced precision</strong><br>
The model serialization and computation support weights with&nbsp;<a href="https://opennmt.net/CTranslate2/quantization.html">reduced precision</a>: 16-bit floating points (FP16), 16-bit brain floating points (BF16), 16-bit integers (INT16), 8-bit integers (INT8) and AWQ quantization (INT4).</li>
<li><strong>Multiple CPU architectures support</strong><br>
The project supports x86-64 and AArch64/ARM64 processors and integrates multiple backends that are optimized for these platforms:&nbsp;<a href="https://software.intel.com/content/www/us/en/develop/tools/oneapi/components/onemkl.html">Intel MKL</a>,&nbsp;<a href="https://github.com/oneapi-src/oneDNN">oneDNN</a>,&nbsp;<a href="https://www.openblas.net/">OpenBLAS</a>,&nbsp;<a href="https://github.com/google/ruy">Ruy</a>, and&nbsp;<a href="https://developer.apple.com/documentation/accelerate">Apple Accelerate</a>.</li>
<li><strong>Automatic CPU detection and code dispatch</strong><br>
One binary can include multiple backends (e.g.&nbsp;Intel MKL and oneDNN) and instruction set architectures (e.g.&nbsp;AVX, AVX2) that are automatically selected at runtime based on the CPU information.</li>
<li><strong>Parallel and asynchronous execution</strong><br>
Multiple batches can be processed in parallel and asynchronously using multiple GPUs or CPU cores.</li>
<li><strong>Dynamic memory usage</strong><br>
The memory usage changes dynamically depending on the request size while still meeting performance requirements thanks to caching allocators on both CPU and GPU.</li>
<li><strong>Lightweight on disk</strong><br>
Quantization can make the models 4 times smaller on disk with minimal accuracy loss.</li>
<li><strong>Simple integration</strong><br>
The project has few dependencies and exposes simple APIs in&nbsp;<a href="https://opennmt.net/CTranslate2/python/overview.html">Python</a>&nbsp;and C++ to cover most integration needs.</li>
<li><strong>Configurable and interactive decoding</strong><br>
<a href="https://opennmt.net/CTranslate2/decoding.html">Advanced decoding features</a>&nbsp;allow autocompleting a partial sequence and returning alternatives at a specific location in the sequence.</li>
<li><strong>Support tensor parallelism for distributed inference</strong><br>
Very large model can be split into multiple GPUs. Following this&nbsp;<a href="https://github.com/OpenNMT/CTranslate2/blob/master/docs/parallel.md#model-and-tensor-parallelism">documentation</a>&nbsp;to set up the required environment.</li>
</ul>
<p>Some of these features are difficult to achieve with standard deep learning frameworks and are the motivation for this project.</p>
</section>
<section id="lets-try-it" class="level3">
<h3 class="anchored" data-anchor-id="lets-try-it">Let‚Äôs try it!</h3>
<p>I used the following script to convert the HF version into CTranslate2 expected format:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">ct2-transformers-converter</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--model</span> NAMAA-Space/masrawy-english-to-egyptian-arabic-translator-v2.9 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--output_dir</span> ct2_model_masrawy</span></code></pre></div></div>
<p>then i used the model with this version</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">translator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ctranslate2.Translator(</span>
<span id="cb4-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ct2_model_masrawy"</span>,</span>
<span id="cb4-3">    device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>,</span>
<span id="cb4-4">    compute_type<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"float16"</span>,</span>
<span id="cb4-5">)</span></code></pre></div></div>
<p>It worked and was very fast - much, much faster!</p>
<hr>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 1%">
<col style="width: 21%">
<col style="width: 11%">
<col style="width: 20%">
<col style="width: 10%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th></th>
<th>Number of Examples</th>
<th>Batch Size</th>
<th>GPU setup</th>
<th>Full time</th>
<th>Days need</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Ctranslate + float16</td>
<td></td>
<td>100</td>
<td>8</td>
<td>1660TI laptop GPU</td>
<td>11s</td>
<td>10.19 days</td>
</tr>
<tr class="even">
<td>Ctranslate + float16</td>
<td></td>
<td>100</td>
<td>4</td>
<td>1660TI laptop GPU</td>
<td>16s</td>
<td>12.04 days</td>
</tr>
<tr class="odd">
<td>Ctranslate</td>
<td></td>
<td>100</td>
<td>6</td>
<td>1660TI laptop GPU</td>
<td>13s</td>
<td>14.81 days</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>We moved from 32.4 days to 10 days!!!</p>
</section>
</section>
<section id="getting-help-from-the-titan-rtx-24gb" class="level2">
<h2 class="anchored" data-anchor-id="getting-help-from-the-titan-rtx-24gb">Getting help from the Titan RTX 24GB</h2>
<p>One of my friends offered me access to his workstation which has dual GPU Titan RTX. It‚Äôs an old GPU but it‚Äôs far better than my little <a href="https://kareemai.com/blog/posts/mteb_encoding/my_little_dargon.html">kobo</a>.</p>
<p>I found that the optimal batch is 64 after some tries. Let‚Äôs use this and see the results. I will also increase the size from 100 samples to 1000.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 0%">
<col style="width: 14%">
<col style="width: 8%">
<col style="width: 11%">
<col style="width: 7%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th></th>
<th>Number of Examples</th>
<th>Batch Size</th>
<th>GPU setup</th>
<th>Full time</th>
<th>Days need</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Pytorch + float16 + optimized version</td>
<td></td>
<td>1000</td>
<td>64</td>
<td>Titan RTX</td>
<td>240s</td>
<td>22.22 days</td>
</tr>
<tr class="even">
<td>Ctranslate + int8 <br></td>
<td></td>
<td>1000</td>
<td>64</td>
<td>Titan RTX</td>
<td>7.89s</td>
<td>0.73&nbsp;days</td>
</tr>
<tr class="odd">
<td>Ctranslate + int8 + dual GPU</td>
<td></td>
<td>1000</td>
<td>64</td>
<td>Dual Titan RTX</td>
<td>4.42s</td>
<td>0.41 days</td>
</tr>
<tr class="even">
<td>Ctranslate + float16</td>
<td></td>
<td>1000</td>
<td>64</td>
<td>Titan RTX</td>
<td>6.46s</td>
<td>0.60 days</td>
</tr>
<tr class="odd">
<td>Ctranslate + float16 + dual GPU</td>
<td></td>
<td>1000</td>
<td>64</td>
<td>Dual Titan RTX</td>
<td>3.72</td>
<td>0.34 days</td>
</tr>
<tr class="even">
<td>Ctranslate + int8_float16</td>
<td></td>
<td>1000</td>
<td>64</td>
<td>Titan RTX</td>
<td>6.81s</td>
<td>0.63 days</td>
</tr>
<tr class="odd">
<td>Ctranslate + int8_float16 + dual GPU</td>
<td></td>
<td>1000</td>
<td>64</td>
<td>Dual Titan RTX</td>
<td>3.85s</td>
<td>0.36 days</td>
</tr>
<tr class="even">
<td>==We moved now from 22 days in single Titan RTX to 0.60 days!==</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<section id="why-float16-is-faster-than-int8" class="level4">
<h4 class="anchored" data-anchor-id="why-float16-is-faster-than-int8">Why float16 is faster than int8</h4>
<p><strong>Float16 Version (faster!):</strong></p>
<ul>
<li>Dual GPU: <strong>269.2 docs/sec</strong></li>
<li>Single GPU: 154.7 docs/sec</li>
<li>Time for 1000 docs: 3.72 seconds</li>
</ul>
<p><strong>Int8 Version (slower):</strong></p>
<ul>
<li>Dual GPU: <strong>225.8 docs/sec</strong></li>
<li>Single GPU: 126.7 docs/sec</li>
<li>Time for 1000 docs: 4.43 seconds</li>
</ul>
<p><strong>Result: Float16 is ~19% faster! (269.2 vs 225.8 docs/sec)</strong> <strong>Lower precision ‚â† Always faster!</strong> I need to increase the batch size for int8 and see which batch size will be better!</p>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps!</h2>
<p>This is just the start. I will search more and investigate how to make this faster because the 8 million rows are only 2GB and the next task is to translate 500GB :) Every second will make a huge difference!</p>
<ul>
<li>Use larger batch size with int8</li>
<li>Use different GPU with modern architecture and better CPU</li>
<li>Deep dive into vLLM</li>
<li>Try the ONNX version for GPU, not CPU</li>
<li>Try again with torchao</li>
</ul>
<p>Thanks for your time! Here is the converted version on Hugging Face: <a href="https://huggingface.co/Abdelkareem/faster_masrawy">ctranslate_masrawy</a>. Small models can save your life ^ ^</p>


</section>

 ]]></description>
  <category>machine-learning</category>
  <category>optimization</category>
  <category>translation</category>
  <category>ctranslate2</category>
  <category>cost-optimization</category>
  <guid>https://kareemai.com/blog/posts/minishlab/ctranslate_maswray.html</guid>
  <pubDate>Thu, 02 Oct 2025 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/minishlab/images/bojji.png" medium="image" type="image/png" height="216" width="144"/>
</item>
<item>
  <title>Getting Back to RSS</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/life_style/back_to_rss.html</link>
  <description><![CDATA[ 





<p>Hi!<br>
These are my thoughts on digital minimalism and staying ahead in AI without burning out.</p>
<section id="the-flood-of-information" class="level2">
<h2 class="anchored" data-anchor-id="the-flood-of-information">The Flood of Information</h2>
<p>I use <a href="https://github.com/yang991178/fluent-reader">Fluent Reader</a> to keep track of the feeds I love, covering topics like machine learning (ML), life, and more.<br>
<img src="https://kareemai.com/blog/posts/life_style/images/vision_read.png" class="img-fluid" alt="Fluent Reader"></p>
<p>Yesterday, I read an article from <a href="https://www.answer.ai/posts/2025-06-05-readbench.html">Answerdotai</a> about Vision Language Models (VLMs).</p>
<p>I spent about 15 minutes diving into the ideas and reflecting on how they relate to my recent projects using Colpali and DSE.</p>
<p>Today, I opened X.com and saw a thread by Benjamin about the same article.</p>
<p>I skimmed it but couldn‚Äôt recall anything meaningful! There was no real engagement‚Äîjust a fleeting sense of encountering new VLM updates.</p>
<p>I bookmarked the post, thinking I‚Äôd revisit it for my next project or research idea that could ‚Äúchange my life.‚Äù Spoiler: I probably won‚Äôt.</p>
</section>
<section id="is-twitter-the-best-for-ml-maybe" class="level2">
<h2 class="anchored" data-anchor-id="is-twitter-the-best-for-ml-maybe">Is Twitter the Best for ML? Maybe!</h2>
<p>My Twitter feed is highly customized, and I use an extension to block distractions.</p>
<p>Yet, every time I open it, I‚Äôm flooded with ideas and AI updates that feel overwhelming.</p>
<p>It‚Äôs one reason I struggle to finish projects. While X is great for staying updated and connecting with top minds in the field, it‚Äôs not the only way.</p>
<p>You can mention people like Jeremy Howard, Tom Arson, or the Hugging Face team and often get a response within an hour‚Äîpretty cool!</p>
<p>I deleted my Twitter account last year but created a new one, hoping to earn from the ad system and share my projects.</p>
<p>However, I haven‚Äôt completed a single project I‚Äôm proud to share. Everything‚Äôs still in the early stages.</p>
<p>I don‚Äôt need X! These feel like flimsy reasons to stay active there. There‚Äôs a way to get the benefits without harming my focus, health, or life.</p>
</section>
<section id="personal-branding-and-linkedin" class="level2">
<h2 class="anchored" data-anchor-id="personal-branding-and-linkedin">Personal Branding and LinkedIn</h2>
<p>What is LinkedIn? It‚Äôs supposed to be your portfolio for job opportunities and personal branding. I‚Äôve tried perfecting my profile, applying for jobs, and sharing work, but I‚Äôve had no offers through LinkedIn. This week, I landed two jobs‚Äîone through a friend‚Äôs referral and another via open-source connections‚Äîwithout LinkedIn‚Äôs help.</p>
<p>To me, LinkedIn feels fake. The algorithms are broken, and it‚Äôs become a waste of time. If you want to learn about me, check my CV and website at kareemai.com.</p>
<p>By focusing on deep, unique work, I believe I can create my own gravity to attract better opportunities aligned with my interests. Will this work for everyone? Probably not. These are just my thoughts and experiences.</p>
<p>By the way, a Hugging Face profile might be better for landing AI jobs if you‚Äôre creating real, impactful work.</p>
</section>
<section id="make-it-hard-for-people-to-reach-you" class="level2">
<h2 class="anchored" data-anchor-id="make-it-hard-for-people-to-reach-you">Make It Hard for People to Reach You</h2>
<p>Am I going to live in a cave? No! In a recent meeting, a friend jokingly called me ‚Äúour search engine.‚Äù</p>
<p>I want to stay connected to what matters and gain maximum benefits without fracturing my attention with short posts or inauthentic interactions.</p>
<p>There‚Äôs freedom in posting something without expecting comments or reactions. If you like it, great! If not, that‚Äôs fine too. Why didn‚Äôt you like it? Maybe it‚Äôs beginner-level or poorly written. I‚Äôll do better next time.</p>
<p>I‚Äôve set boundaries to manage interactions:</p>
<pre><code>Don‚Äôt send me voice notes‚Äîwrite instead. It‚Äôs quicker, and I don‚Äôt have to pause everything to listen.
Don‚Äôt call me‚Äîsend a message first.
Don‚Äôt leave comments‚Äîemail me instead.</code></pre>
<p>Tough? Sure. Some people might not like it, but it filters out noise and preserves what‚Äôs important. People may get annoyed initially, but they adapt quickly.</p>
</section>
<section id="back-to-rss-discord" class="level2">
<h2 class="anchored" data-anchor-id="back-to-rss-discord">Back to RSS + Discord</h2>
<p>After five years, I‚Äôve identified the sources I value and noticed a pattern. Why not collect them in one managed place, free from algorithms and ads? That‚Äôs where RSS comes in. I love it‚Äîit‚Äôs a superpower! When I first learned about RSS in college, I pictured an old Englishman in a garden reading about obscure topics. Now, I‚Äôve become that ‚Äúold man‚Äù who craves calm, minimal, and boring tools.</p>
<p>You can even follow YouTube channels via RSS without opening a browser! <img src="https://kareemai.com/blog/posts/life_style/images/fluent_reader.png" class="img-fluid" alt="Fluent Reader"></p>
<p>For interacting with people, Discord channels are better. I can still reach folks like Jeremy and Tom there.</p>
</section>
<section id="next-ideas" class="level2">
<h2 class="anchored" data-anchor-id="next-ideas">Next Ideas</h2>
<p>I have many changes I want to implement and thoughts to refine. I‚Äôm working on improving:</p>
<pre><code>Activity Watch
Todo Manager
Thoughts Logging
Media Manager</code></pre>
<p>I‚Äôm also focusing on better habits like sleeping, eating, and walking.</p>
<p>Want to find me? Visit my customized space at kareeai.com.</p>
<p>All my love,</p>
<p>Kareem</p>


</section>

 ]]></description>
  <category>blogging</category>
  <category>idea_Forge</category>
  <category>publish</category>
  <category>rough_thoughts</category>
  <category>life_style</category>
  <guid>https://kareemai.com/blog/posts/life_style/back_to_rss.html</guid>
  <pubDate>Mon, 09 Jun 2025 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/life_style/images/vision_read.png" medium="image" type="image/png" height="137" width="144"/>
</item>
<item>
  <title>Late Interaction and ColPali</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/nlp/embedding_world/late_interaction.html</link>
  <description><![CDATA[ 





<ul>
<li>what is early interaction</li>
<li>what is late interaction</li>
<li>Reasoning BERT</li>
<li>mvbert</li>
<li>ColPali</li>
<li>colbert</li>
<li>pylate</li>
<li>PLAID</li>
</ul>



 ]]></description>
  <category>blogging</category>
  <category>embedding</category>
  <category>minishlab</category>
  <category>model2vec</category>
  <category>arabic</category>
  <guid>https://kareemai.com/blog/posts/nlp/embedding_world/late_interaction.html</guid>
  <pubDate>Wed, 14 May 2025 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/nlp/embedding_world/images/minishlab.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Bojji &amp; Zarra Embedding models</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/minishlab/blog_zaraah.html</link>
  <description><![CDATA[ 





<section id="arabic-embedding-models" class="level2">
<h2 class="anchored" data-anchor-id="arabic-embedding-models">Arabic Embedding Models</h2>
<p>This blog post introduces the <strong>Bojji and Zarra</strong> family of static embedding models, designed for Arabic language tasks and built using the <strong>model2vec</strong> distillation technique from MinishLab.</p>
<p>These models distill knowledge from larger transformer models, such as SBERT, into compact, efficient embeddings.</p>
<p>This approach balances performance with speed and resource efficiency.</p>
<p>Below, I explore the Bojji models and their relationship to <strong>Potion</strong> models, their strengths and limitations, and their applications in Arabic embedding tasks.</p>
<section id="what-are-potion-models" class="level3">
<h3 class="anchored" data-anchor-id="what-are-potion-models">What are Potion Models?</h3>
<p><strong>Potion models</strong> combine innovative techniques to create high-performing, compact static embeddings.</p>
<p>I liken them to Bojji from <em>Ousama Ranking</em> small in size but capable of competing with giants like Jina AI and BGE models.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/minishlab/images/bojji.png" class="img-fluid figure-img"></p>
<figcaption>Bojji Embedding</figcaption>
</figure>
</div>
<p>Key features of Potion models include:</p>
<ul>
<li><p><strong>Superior Performance</strong>: They outperform traditional static embeddings like GloVe and FastText across various tasks, matching the performance of models like <strong>all-MiniLM-L6-v2</strong> in English.</p></li>
<li><p><strong>Compact Size</strong>: With approximately 2‚Äì4 million parameters, they are ~55 times smaller than GloVe, with model sizes ranging from 8 MB to 30 MB.</p></li>
<li><p><strong>Efficiency</strong>: Designed for CPU execution and browser-based applications, they are ideal for edge devices and low-resource environments.</p></li>
<li><p><strong>MTEB Performance</strong>: They achieve an average MTEB score above 50%, making them highly competitive for their size.</p></li>
</ul>
</section>
<section id="what-is-the-model2vec-distillation-method" class="level3">
<h3 class="anchored" data-anchor-id="what-is-the-model2vec-distillation-method">What is the model2vec Distillation Method?</h3>
<p>The <strong>model2vec</strong> distillation method addresses the challenge of creating fast, compact sentence transformers.</p>
<p>It transforms large sentence transformer models into static embeddings that are up to <strong>500x faster</strong> and <strong>15x smaller</strong>, with only a minor performance trade-off.</p>
<p>Unlike traditional methods like GloVe, model2vec captures knowledge from large sentence transformers, producing uncontextualized word vectors.</p>
<p>While this sacrifices some contextual nuance, it offers significant advantages in:</p>
<ul>
<li><p><strong>Speed</strong>: Up to 500x faster inference.</p></li>
<li><p><strong>Size</strong>: Models reduced by up to 50x, ranging from 8 MB to 30 MB.</p></li>
<li><p><strong>Versatility</strong>: Sufficient word representations for most NLP applications.</p></li>
</ul>
<p>For more details, refer to the <a href="https://minishlab.github.io/">MinishLab blog</a> and <a href="https://github.com/MinishLab/model2vec">GitHub repository</a>.</p>
</section>
</section>
<section id="jina-embeddings-v3-for-arabic" class="level2">
<h2 class="anchored" data-anchor-id="jina-embeddings-v3-for-arabic">Jina Embeddings v3 for Arabic</h2>
<p>The <strong>jina-embeddings-v3</strong> model is currently the top-performing open-source, zero-shot embedding model for Arabic on the MTEB leaderboard.</p>
<p>It excels across various tasks and has been validated in production for Arabic applications.</p>
<p>However, its large size and high memory requirements make it computationally expensive and slow compared to other embedding models.</p>
<p>To address this, I used model2vec to create a compact Arabic version, the <strong>Zarra</strong> and <strong>bojji</strong> with with another base model and different method, which retains strong performance while being significantly smaller and faster.</p>
</section>
<section id="bojji-and-zarra" class="level2">
<h2 class="anchored" data-anchor-id="bojji-and-zarra">Bojji and Zarra</h2>
<ul>
<li><p><a href="https://huggingface.co/NAMAA-Space/bojji">Bojji HuggingFace</a></p></li>
<li><p><a href="https://huggingface.co/NAMAA-Space/zarra">Zarra HuggingFace</a></p></li>
</ul>
<p>The <strong>Zarra</strong> models are the first static embedding models for Arabic trained with <strong>tokenlearn</strong> on the Arabic subset of the <a href="https://huggingface.co/datasets/allenai/c4">C4 dataset</a>.</p>
<p>They are optimized for Arabic-specific tasks and come in multiple sizes:</p>
<p>All variants support <strong>float32</strong> and <strong>int8</strong> quantization without performance loss, making them highly efficient for resource-constrained environments.</p>
</section>
<section id="bojji-model-vs-competitors" class="level2">
<h2 class="anchored" data-anchor-id="bojji-model-vs-competitors">Bojji Model vs Competitors</h2>
<p>To evaluate Bojji‚Äôs performance, I compared it against several multilingual and Arabic-specific sentence transformer models using MTEB tasks tailored for Arabic.</p>
<div id="e5c1683d" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-style: italic">                                            Model Evaluation Summary                                             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model                                 </span>‚îÉ<span style="font-weight: bold">    Avg </span>‚îÉ<span style="font-weight: bold">  MIRAC </span>‚îÉ<span style="font-weight: bold">  MLQAR </span>‚îÉ<span style="font-weight: bold">  Massi </span>‚îÉ<span style="font-weight: bold">  Multi </span>‚îÉ<span style="font-weight: bold">  STS17 </span>‚îÉ<span style="font-weight: bold">  STS22 </span>‚îÉ<span style="font-weight: bold">  XNLI_ </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ 0.6610 ‚îÇ 0.6262 ‚îÇ 0.5093 ‚îÇ 0.5577 ‚îÇ 0.5868 ‚îÇ 0.8531 ‚îÇ 0.6396 ‚îÇ 0.8542 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ 0.6494 ‚îÇ 0.6424 ‚îÇ 0.5267 ‚îÇ 0.5462 ‚îÇ 0.5943 ‚îÇ 0.8485 ‚îÇ 0.6291 ‚îÇ 0.7583 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ 0.6473 ‚îÇ 0.6159 ‚îÇ 0.5674 ‚îÇ 0.5832 ‚îÇ 0.5993 ‚îÇ 0.8002 ‚îÇ 0.6254 ‚îÇ 0.7393 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ 0.6444 ‚îÇ 0.5774 ‚îÇ 0.4808 ‚îÇ 0.5345 ‚îÇ 0.5847 ‚îÇ 0.8278 ‚îÇ 0.6310 ‚îÇ 0.8746 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ 0.6440 ‚îÇ 0.7177 ‚îÇ 0.5698 ‚îÇ 0.5071 ‚îÇ 0.5521 ‚îÇ 0.7881 ‚îÇ 0.6145 ‚îÇ 0.7584 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ 0.6413 ‚îÇ 0.5828 ‚îÇ 0.4840 ‚îÇ 0.5457 ‚îÇ 0.5494 ‚îÇ 0.8290 ‚îÇ 0.6242 ‚îÇ 0.8740 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ 0.6138 ‚îÇ 0.3799 ‚îÇ 0.5011 ‚îÇ 0.5600 ‚îÇ 0.5749 ‚îÇ 0.8559 ‚îÇ 0.6122 ‚îÇ 0.8125 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ 0.5431 ‚îÇ 0.2240 ‚îÇ 0.3612 ‚îÇ 0.4775 ‚îÇ 0.5698 ‚îÇ 0.8111 ‚îÇ 0.5540 ‚îÇ 0.8043 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ 0.5208 ‚îÇ 0.2191 ‚îÇ 0.3496 ‚îÇ 0.4515 ‚îÇ 0.5573 ‚îÇ 0.7916 ‚îÇ 0.4908 ‚îÇ 0.7859 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> bojji                                 </span>‚îÇ 0.5177 ‚îÇ 0.2941 ‚îÇ 0.3989 ‚îÇ 0.4667 ‚îÇ 0.5433 ‚îÇ 0.7233 ‚îÇ 0.5880 ‚îÇ 0.6094 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> zarra                                 </span>‚îÇ 0.4822 ‚îÇ 0.2295 ‚îÇ 0.3473 ‚îÇ 0.4119 ‚îÇ 0.5237 ‚îÇ 0.6469 ‚îÇ 0.6218 ‚îÇ 0.5942 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ 0.4699 ‚îÇ 0.1658 ‚îÇ 0.3150 ‚îÇ 0.4285 ‚îÇ 0.5338 ‚îÇ 0.6511 ‚îÇ 0.5951 ‚îÇ 0.5999 ‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ 0.2843 ‚îÇ 0.0005 ‚îÇ 0.0064 ‚îÇ 0.1905 ‚îÇ 0.4934 ‚îÇ 0.5089 ‚îÇ 0.2518 ‚îÇ 0.5384 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
</div>
<p>I filtered the most related MTEB tasks that supports Arabic-script only the evalution script is in the references blow. We can say that the average score for the Zarra are very low compared to the other models, but didn‚Äôt let the Average score fool you! Average is affected with the outliers so, if one task is the low the final answer with be low also.</p>
<p>But from the first look, we can see the peformance is similar to the Arabic versions of MiniLM-L12 in Average and if you looked at the Sentence similarity for STS22 it‚Äôs score are very good compared to static-embedding model.</p>
<section id="understanding-mteb-tasks-for-arabic" class="level3">
<h3 class="anchored" data-anchor-id="understanding-mteb-tasks-for-arabic">Understanding MTEB Tasks for Arabic</h3>
<p>The Massive Text Embedding Benchmark (MTEB) evaluates embedding models across various tasks. Here‚Äôs a breakdown of the tasks used :</p>
<ul>
<li><p>MIRACLRetrievalHardNegatives: Measures retrieval accuracy for hard negative examples, critical for search and question-answering systems. Zarra‚Äôs lower score here reflects its static embedding nature, which sacrifices some contextual nuance.</p></li>
<li><p>MLQARetrieval: Tests retrieval performance on multilingual question-answering datasets, where Zarra performs comparably to MiniLM models.</p></li>
<li><p>STS17 &amp; STS22: Evaluates semantic textual similarity, where Zarra excels, particularly in STS22, with scores rivaling larger models.</p></li>
<li><p>XNLI: Assesses natural language inference, where Zarra‚Äôs performance is competitive despite its compact size.</p></li>
</ul>
<p>These tasks highlight Zarra‚Äôs strengths in semantic similarity and efficiency, making it ideal for applications like chatbots and lightweight search systems</p>
<p>You can see the peformance for every task in MTEB here</p>
<div id="31238d0d" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">             Sorted by MIRACLRetrievalHardNegatives_main (Score)             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model Name                            </span>‚îÉ<span style="font-weight: bold"> MIRACLRetrievalHardNegatives_main </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">                             0.718 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">                             0.642 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">                             0.626 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">                             0.616 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                            0.583</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                            0.577</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                            0.380</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">bojji                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000; font-weight: bold">                            0.294</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">zarra                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000; font-weight: bold">                            0.230</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000">                            0.224</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000">                            0.219</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000">                            0.166</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000">                            0.001</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">             Sorted by MLQARetrieval_main (Score)             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model Name                            </span>‚îÉ<span style="font-weight: bold"> MLQARetrieval_main </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.570</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.567</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.527</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.509</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.501</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.484</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.481</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">bojji                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">             0.399</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.361</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.350</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">zarra                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">             0.347</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">             0.315</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000">             0.006</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">             Sorted by MassiveIntentClassification_main (Score)             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model Name                            </span>‚îÉ<span style="font-weight: bold"> MassiveIntentClassification_main </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.583</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.560</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.558</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.546</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.546</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.534</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.507</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.478</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">bojji                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">                           0.467</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>ÔøΩÔøΩ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.451</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                           0.428</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">zarra                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">                           0.412</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000">                           0.190</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">             Sorted by MultiHateClassification_main (Score)             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model Name                            </span>‚îÉ<span style="font-weight: bold"> MultiHateClassification_main </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.599</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.594</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.587</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.585</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.575</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.570</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.557</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.552</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.549</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">bojji                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">                       0.543</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.534</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">zarra                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">                       0.524</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">                       0.493</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">             Sorted by STS17_main (Score)             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model Name                            </span>‚îÉ<span style="font-weight: bold"> STS17_main </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.856 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.853 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.849 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.829 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.828 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.811 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.800 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.792 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.788 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">bojji                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">     0.723</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">      0.651 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">zarra                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">     0.647</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">     0.509</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">             Sorted by STS22.v2_main (Score)             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model Name                            </span>‚îÉ<span style="font-weight: bold"> STS22.v2_main </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">         0.640 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">         0.631 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">         0.629 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">         0.625 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">         0.624 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">zarra                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">        0.622</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">         0.615 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">         0.612 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">        0.595</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">bojji                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">        0.588</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">        0.554</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">        0.491</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #800000; text-decoration-color: #800000">        0.252</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">             Sorted by XNLI_main (Score)             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model Name                            </span>‚îÉ<span style="font-weight: bold"> XNLI_main </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> gate_arabert-v1                       </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.875 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_sts_matryoshka                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.874 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.854 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.813 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> Arabic-MiniLM-L12-v2-all-nli-triplet  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.804 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.786 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.758 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.758 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">     0.739 </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">bojji                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">    0.609</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">    0.600</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> </span><span style="color: #008000; text-decoration-color: #008000; font-weight: bold">zarra                                </span><span style="color: #008080; text-decoration-color: #008080"> </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000; font-weight: bold">    0.594</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> all_minilm_l6_v2                      </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> </span><span style="color: #808000; text-decoration-color: #808000">    0.538</span><span style="color: #008000; text-decoration-color: #008000"> </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
</div>
</section>
<section id="bojji-vs.-all-minilm" class="level3">
<h3 class="anchored" data-anchor-id="bojji-vs.-all-minilm">Bojji vs.&nbsp;all-MiniLM</h3>
<p>The Bojji model outperform the <strong>all-MiniLM</strong> family from SBERT in Arabic tasks while being significantly faster and capable of running on CPU.</p>
<p>This makes Bojji an excellent lightweight alternative for applications requiring efficient Arabic embeddings.</p>
<p>Also the models performance is most of the time better than the <strong>potion-multilingual-128M</strong> which indicates that techniques are working with any language not just English.</p>
</section>
<section id="arabic-rag-leaderboard" class="level3">
<h3 class="anchored" data-anchor-id="arabic-rag-leaderboard">Arabic RAG Leaderboard</h3>
<p>To complement MTEB evaluations, I tested Zarra on the <strong>Arabic-RAG Leaderboard</strong>, which provides a robust benchmark for Arabic-specific tasks. Zarra ranks 37 out of 45 models with an average score of <strong>36.84</strong>.</p>
<p>This is impressive, as Zarra is the smallest model in the leaderboard, highlighting its efficiency and competitive performance in resource-constrained settings.</p>
<section id="what-about-bojji-perfomrance-in-arabic-rag-leaderboard" class="level4">
<h4 class="anchored" data-anchor-id="what-about-bojji-perfomrance-in-arabic-rag-leaderboard">What about Bojji perfomrance in Arabic RAG Leaderboard?</h4>
<p>Actually the first model with Zarra and not bojji is the second release of Zarra with different updates but..i know that if i didn‚Äôt write the blog as it as, i will not publish it again!</p>
<p>Bojji will be test on the Arabic Rag soon.</p>
</section>
</section>
</section>
<section id="speed-comprsion" class="level2">
<h2 class="anchored" data-anchor-id="speed-comprsion">Speed comprsion</h2>
<div id="1409164c" class="cell" data-execution_count="5">
<div class="cell-output cell-output-stderr">
<pre><code>Some weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']
- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed zarra on cpu: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">26893.63</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed bojji on cpu: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">27478.15</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed potion-multilingual-128M on cpu: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">27145.31</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed paraphrase-multilingual-MiniLM-L12-v2 on cuda: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2363.24</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed silma_ai_embedding_sts_v0.<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1</span> on cuda: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">627.13</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed muffakir_embedding on cuda: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">621.77</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed get_multilingual_base on cuda: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">895.41</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed arabic_retrieval_v1.<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0</span> on cuda: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">618.56</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Completed arabic_triplet_matryoshka_v2 on cuda: <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">610.64</span> sentences/second
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-style: italic">                           Model Benchmark Results                           </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model                                 </span>‚îÉ<span style="font-weight: bold"> Speed (sentences/second) </span>‚îÉ<span style="font-weight: bold"> Device </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> zarra                                 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 26893.63                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cpu    </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> bojji                                 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 27478.15                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cpu    </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M              </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 27145.31                 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cpu    </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-L12-v2 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 2363.24                  </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cuda   </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1           </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 627.13                   </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cuda   </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding                    </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 621.77                   </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cuda   </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base                 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 895.41                   </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cuda   </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0                 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 618.56                   </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cuda   </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2          </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080"> 610.64                   </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000"> cuda   </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
</div>
<div id="44bcb016" class="cell" data-execution_count="7">
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>SafetensorsRepoMetadata(metadata=None, sharded=False, weight_map={'embeddings': 'model.safetensors'}, files_metadata={'model.safetensors': SafetensorsFileMetadata(metadata={}, tensors={'embeddings': TensorInfo(dtype='F32', shape=[249999, 256], data_offsets=(0, 255998976), parameter_count=63999744)}, parameter_count={'F32': 63999744})}, parameter_count={'F32': 63999744})</code></pre>
</div>
</div>
<div id="dd7c2361" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #008000; text-decoration-color: #008000">Results saved to model_info_results.csv</span>
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-style: italic">                                             Model Information Results                                             </span>
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ<span style="font-weight: bold"> Model                            </span>‚îÉ<span style="font-weight: bold"> Parameters (M) </span>‚îÉ<span style="font-weight: bold"> Size (MB) </span>‚îÉ<span style="font-weight: bold"> Relative to Largest (%) </span>‚îÉ<span style="font-weight: bold"> Less than Largest (x) </span>‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> zarra                            </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">          64.00 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    244.14 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   41.92 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  2.39 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> bojji                            </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         124.88 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    476.40 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   81.79 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.22 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> potion-multilingual-128M         </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         128.09 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    488.63 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   83.89 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.19 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> paraphrase-multilingual-MiniLM-‚Ä¶ </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         117.65 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    448.82 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   77.06 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.30 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> silma_ai_embedding_sts_v0.1      </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         135.19 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    515.72 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   88.54 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.13 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> muffakir_embedding               </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         135.19 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    515.72 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   88.54 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.13 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_retrieval_v1.0            </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         135.19 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    515.73 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   88.54 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.13 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> arabic_triplet_matryoshka_v2     </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         135.19 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    515.72 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                   88.54 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.13 </span>‚îÇ
‚îÇ<span style="color: #008080; text-decoration-color: #008080"> get_multilingual_base            </span>‚îÇ<span style="color: #808000; text-decoration-color: #808000">         305.37 </span>‚îÇ<span style="color: #008000; text-decoration-color: #008000">    582.45 </span>‚îÇ<span style="color: #800080; text-decoration-color: #800080">                  100.00 </span>‚îÇ<span style="color: #000080; text-decoration-color: #000080">                  1.00 </span>‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre>
</div>
</div>
<p>It‚Äôs very clear the main advantage of the static embedding models here:</p>
<p>They can process large number of samples on cpu which make them very useful for : 1. Clustring 2. Build classification pipelines on top of them 3. Use them in edge-devices 4. base models for chunking algorithms and dudplications..more to come soon ! ‚ù§Ô∏è</p>
<section id="whats-next-for-bojji" class="level3">
<h3 class="anchored" data-anchor-id="whats-next-for-bojji">What‚Äôs Next for Bojji?</h3>
<p>It‚Äôs just the start with initial tests, there is more to explore from the base models, datasets and the new features from minishlab which will try to narrow the gab between model2vec and sentence-transformers.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/minishlab/images/bojji_and_zarra.png" class="img-fluid figure-img"></p>
<figcaption>zarra and Bojji</figcaption>
</figure>
</div>
<p>Also thanks a lot for the minishlab team for their continous help to debug and update the models with me!</p>
</section>
<section id="bojji-model-references" class="level3">
<h3 class="anchored" data-anchor-id="bojji-model-references">Bojji model references</h3>
<ol type="1">
<li><a href="https://huggingface.co/blog/Navid-AI/arabic-rag-leaderboard">Arabic Leaderboard</a></li>
<li><a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB</a></li>
<li><a href="https://minishlab.github.io/">Minishlab</a></li>
<li><a href="">NAMAA-Space colleciton</a></li>
</ol>


</section>
</section>

 ]]></description>
  <category>blogging</category>
  <category>embedding</category>
  <category>minishlab</category>
  <category>model2vec</category>
  <category>arabic</category>
  <guid>https://kareemai.com/blog/posts/minishlab/blog_zaraah.html</guid>
  <pubDate>Wed, 14 May 2025 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/minishlab/images/minishlab.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Cloud GPU Pricing Comparsion in 2025</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/life_style/gpuvec.html</link>
  <description><![CDATA[ 





<section id="cloud-gpu-pricing-in-2025" class="level2">
<h2 class="anchored" data-anchor-id="cloud-gpu-pricing-in-2025"><a href="https://gpuvec.com">Cloud GPU Pricing in 2025</a></h2>
<p>In the fast-paced tech world of 2025, cloud GPUs drive AI breakthroughs, machine learning, and high-performance computing (HPC). Whether you‚Äôre training large language models (LLMs) or tackling vision tasks, finding the <strong>best cloud GPU providers</strong> at the right price is critical. With varied pricing from platforms like CoreWeave and Hyperstack, the landscape can feel overwhelming. That‚Äôs where <strong>GPUvec</strong> shines‚Äîyour go-to hub for <strong>cloud GPU pricing comparison</strong>, <strong>GPU benchmarks</strong>, and tools like our <strong>model size calculator</strong>.</p>
<section id="why-cloud-gpu-pricing-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-cloud-gpu-pricing-matters">Why Cloud GPU Pricing Matters</h3>
<p><strong>Cloud GPU pricing</strong> can define your project‚Äôs success. From startups to enterprises, demand for scalable, cost-effective GPUs is surging. Providers like Hyperstack offer NVIDIA H100s at $1.90/hr, while others compete with flexible rates for AI workloads. But it‚Äôs more than hourly costs‚ÄîVRAM, CUDA cores, and hidden fees (storage, networking) shape true value. GPUvec cuts through the noise, spotlighting the <strong>cheapest cloud GPUs</strong> and high-performance options tailored to you.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/gpuvec_snapshot.png" class="img-fluid figure-img"></p>
<figcaption>GPUvec Best Cloud GPU Providers</figcaption>
</figure>
</div>
</section>
</section>
<section id="gpuvec-your-cloud-gpu-companion" class="level2">
<h2 class="anchored" data-anchor-id="gpuvec-your-cloud-gpu-companion">GPUvec: Your Cloud GPU Companion</h2>
<p>GPUvec delivers real-time <strong>GPU pricing comparison</strong> from top <strong>GPU cloud providers</strong>. From the budget-friendly NVIDIA A4000 at $0.15/hr to the cutting-edge H200, we help you find the perfect fit. Explore these features:</p>
<ol type="1">
<li><a href="https://gpuvec.com/providers">Providers</a><br>
</li>
<li><a href="https://gpuvec.com/vector-db">Vector Database</a><br>
</li>
<li><a href="https://gpuvec.com/comparison-tool">Comparison Tool</a><br>
</li>
<li><a href="https://gpuvec.com/model-size-calculator">Model Size Calculator</a><br>
</li>
<li><a href="https://gpuvec.com/cost-estimator">Cost Estimator</a><br>
</li>
<li><a href="https://gpuvec.com/gpus">GPUs for AI</a>:
<ul>
<li><a href="https://gpuvec.com/gpus/h200">NVIDIA H200</a><br>
</li>
<li><a href="https://gpuvec.com/gpus/a100">NVIDIA A100</a><br>
</li>
<li><a href="https://gpuvec.com/gpus/a10">NVIDIA A10</a><br>
</li>
<li><a href="https://gpuvec.com/gpus/h100">NVIDIA H100</a><br>
</li>
<li><a href="https://gpuvec.com/gpus/rtx-6000-ada">NVIDIA A6000</a><br>
</li>
<li><a href="https://gpuvec.com/gpus/rtx-4090">NVIDIA RTX 4090</a><br>
</li>
<li><a href="https://gpuvec.com/gpus/rtx-5090">NVIDIA RTX 5090</a><br>
</li>
<li><a href="https://gpuvec.com/gpus/rtx-3090">NVIDIA RTX 3090</a></li>
</ul></li>
</ol>
<p>Filter by VRAM, CUDA cores, and more to <strong>optimize GPU costs</strong> effortlessly.</p>
</section>
<section id="best-cloud-providers" class="level2">
<h2 class="anchored" data-anchor-id="best-cloud-providers"><a href="https://gpuvec.com/providers">Best Cloud Providers</a></h2>
<p>Discover top <strong>GPU cloud providers</strong>:</p>
<ul>
<li><strong>CoreWeave</strong>: Cost-effective, AI-focused GPUs with unmatched scalability.<br>
</li>
<li><strong>Hyperstack</strong>: NVIDIA GPUs like the A100 at $0.50/hr, eco-friendly and powerful.<br>
</li>
<li><strong>Lambda Labs</strong>: Tailored for AI and deep learning with robust NVIDIA options.<br>
</li>
<li><strong>Paperspace</strong>: User-friendly <strong>cloud computing GPU</strong> solutions for all workloads.<br>
</li>
<li><strong>Google Cloud (GCP)</strong>: Comprehensive GPU offerings for machine learning.<br>
</li>
<li><strong>AWS</strong>: Wide-ranging GPU instances for AI and HPC.<br>
</li>
<li><strong>Azure</strong>: Robust cloud platform with GPU capabilities.<br>
</li>
<li><strong>Vast.ai</strong>: A marketplace for <strong>GPU rental pricing</strong> at competitive rates.<br>
</li>
<li><strong>RunPod</strong>: Affordable GPU instances for AI tasks.<br>
</li>
<li><strong>Modal</strong>: Competitive pricing with a sleek interface for AI workloads.</li>
</ul>
<p>GPUvec ranks them by price, performance, and specs like vCPUs and storage.</p>
</section>
<section id="weekly-update---gpuvec-newsletter" class="level2">
<h2 class="anchored" data-anchor-id="weekly-update---gpuvec-newsletter">Weekly Update - GPUvec Newsletter</h2>
<p>Stay ahead with our weekly newsletter‚Äîupdates on <strong>NVIDIA GPU pricing</strong>, new providers, and exclusive deals. Get insights to make smarter choices for your projects.</p>
<p><a href="https://open.substack.com/pub/gpuvec/p/coming-soon?r=5h4pn1&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false">Subscribe Now</a></p>
</section>
<section id="gpu-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="gpu-benchmarks">GPU Benchmarks</h2>
<p>Our <strong>GPU benchmarks</strong> target AI tasks‚ÄîLLMs, vision models, and libraries like Flash-Attention. Compare NVIDIA, AMD, TPUs, and Huawei inference chips to find the best performer for your workload.</p>
</section>
<section id="gpuvec-tools" class="level2">
<h2 class="anchored" data-anchor-id="gpuvec-tools">GPUvec Tools</h2>
<ul>
<li><strong>Model Size Calculator</strong>: Input your model (e.g., 7B, 9B) for compute recommendations.<br>
</li>
<li><strong>Cost Estimator</strong>: Forecast costs based on VRAM, runtime, and provider.<br>
</li>
<li><strong>Quantization</strong>: Optimize models for cost and performance.<br>
</li>
<li><strong>GPU Comparison</strong>: Analyze GPUs by VRAM, CUDA cores, and more.<br>
</li>
<li><strong>Spot Instance Finder</strong>: Snag the <strong>cheapest cloud GPUs</strong> with spot pricing.</li>
</ul>
</section>
<section id="cheapest-cloud-gpus" class="level2">
<h2 class="anchored" data-anchor-id="cheapest-cloud-gpus">Cheapest Cloud GPUs</h2>
<p>Need affordability? GPUvec tracks budget options like the A4000 at $0.15/hr and spot instances across providers, blending price with performance for <strong>AI GPU costs</strong>.</p>
</section>
<section id="compare-gpus-for-ai-tasks" class="level2">
<h2 class="anchored" data-anchor-id="compare-gpus-for-ai-tasks">Compare GPUs for AI Tasks</h2>
<p>GPUvec excels at comparing GPUs for AI. Dive into:</p>
<ul>
<li><strong>LLMs</strong>: Benchmarks for large language models.<br>
</li>
<li><strong>Vision Models</strong>: Performance for image tasks.<br>
</li>
<li><strong>Flash-Attention</strong>: GPUs optimized for advanced techniques.<br>
</li>
<li><strong>Hugging Face</strong>: Compatibility with popular libraries.<br>
</li>
<li><strong>VLLM</strong>: Tailored benchmarks for VLLM tasks.</li>
</ul>
<p>Bookmark favorites for later analysis.</p>
</section>
<section id="filter-based-on-vram-cuda-cores-and-more" class="level2">
<h2 class="anchored" data-anchor-id="filter-based-on-vram-cuda-cores-and-more">Filter Based on VRAM, CUDA Cores, and More</h2>
<p>Refine your search with filters:</p>
<ul>
<li>VRAM (e.g., 16GB, 80GB)<br>
</li>
<li>CUDA cores<br>
</li>
<li>System RAM<br>
</li>
<li>Local storage</li>
</ul>
<p>Find the ideal GPU fast.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>In 2025, cloud GPUs fuel AI and <strong>high-performance computing pricing</strong>. GPUvec simplifies your journey with real-time <strong>cloud GPU comparison</strong>, <strong>GPU benchmarks</strong>, and tools to <strong>optimize GPU costs</strong>. Whether you‚Äôre hunting the <strong>cheapest cloud GPUs</strong> or scaling for enterprise AI, GPUvec empowers you to save time and money. Visit <a href="https://gpuvec.com">GPUvec</a> today and master the cloud GPU landscape!</p>
<p>read also:</p>
<ol type="1">
<li><p><a href="https://kareemai.com/blog/posts/fl/what_is_federated_learning.html">what is federated Learning</a></p></li>
<li><p><a href="https://kareemai.com/blog/posts/life_style/kamcalorie.html">ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä</a></p></li>
</ol>


</section>

 ]]></description>
  <category>blogging</category>
  <category>idea_Forge</category>
  <category>publish</category>
  <category>rough_thoughts</category>
  <category>life_style</category>
  <guid>https://kareemai.com/blog/posts/life_style/gpuvec.html</guid>
  <pubDate>Thu, 03 Apr 2025 22:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/life_style/images/gpuvec.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>my dream job at Tarteel</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/speech_recognition/my_dream_job_at_tarteel.html</link>
  <description><![CDATA[ 





<section id="why-tarteel-not-fang" class="level2">
<h2 class="anchored" data-anchor-id="why-tarteel-not-fang">Why Tarteel, Not FANG?</h2>
<ul>
<li>As a Muslim, my ultimate goal isn‚Äôt just to accumulate wealth or knowledge for their own sake. I‚Äôm guided by broader concepts like taqwa (God-consciousness), righteous deeds, and sincere intentions. With only one short life to live, I want to make the most of it in the best way possible.</li>
<li>Working at big tech companies as a programmer offers good financial rewards and significant technical growth, along with practical experience‚Äîthough it comes with its fair share of challenges. However, it also means operating under the umbrella of foreign companies with their own agendas and ideologies. Take the major players like Google, Facebook, X, and Amazon, for example.</li>
<li>Their leaders, in one way or another, have supported the occupation of Gaza, contributed to the suffering of children, and restricted our freedom of expression.</li>
<li>Our accounts get banned, our voices silenced, and these companies provide both material and moral support to oppressive entities with every means at their disposal.</li>
<li>I‚Äôm not denying that working for such companies might be permissible under certain Islamic legal perspectives, but personally, I have no desire to be part of them. So, where do I want to go instead? Do I even have rules? After all, I haven‚Äôt worked at a ‚Äúreal‚Äù company yet‚Äîonly freelance gigs and open-source projects.</li>
<li>The truth is, I do have specific criteria for the kind of work environment I want to invest my time in. Here‚Äôs what I‚Äôm looking for:
<ul>
<li>A workplace that respects my faith, including what‚Äôs halal and haram, and honors religious practices.</li>
<li>A team working on meaningful projects with real humanitarian impact‚Äîprojects that benefit society without involving anything forbidden, even if they‚Äôre not explicitly religious.</li>
<li>A place that fosters my growth beyond just financial gain. As someone passionate about data science, I want to join a team grounded in strong scientific principles, up-to-date with advancements, and focused on innovation‚Äînot blind imitation or merely using what‚Äôs available.</li>
<li>A supportive, ambitious team led by kind and fair management.</li>
</ul></li>
<li>That‚Äôs when my eyes turned to Tarteel. I first came across it during high school, watching episodes featuring <a href="{{video <https://www.youtube.com/watch?app=desktop&amp;v=100Qq-mLDbMo}}>">Hazem Al-Siddiq and Abdul Latif</a> discussing the idea behind Tarteel and its early beginnings. Even now, after graduating, I‚Äôve kept up with the company‚Äôs progress.</li>
<li>From what I can see, it embodies everything I‚Äôm looking for‚Äîat least on the surface‚Äîand I assume the best of the people working there. My dream for the next two years is to join the Tarteel team.</li>
</ul>
</section>
<section id="tarteels-vision" class="level2">
<h2 class="anchored" data-anchor-id="tarteels-vision">Tarteel‚Äôs Vision</h2>
<p>Tarteel AI is the world‚Äôs leading app for Quran memorization and recitation. It‚Äôs a tool that supports millions of Muslims globally by providing features to help them memorize and connect with the Quran. When you read their application page, it‚Äôs genuinely inspiring:</p>
<ul>
<li>Fully remote work‚Äîwork anytime, anywhere.</li>
<li>A balance of dunya and akhira‚Äîan Islamic workweek, Islamic holidays, and a culture rooted in faith.</li>
<li>Unlimited time off (with manager approval).</li>
<li>Yearly team retreats and off-sites.</li>
<li>The freedom to work in your thobe, abaya, or traditional clothing from the comfort of home.</li>
<li>A chance to be part of a company leading AI and technology innovation in the Muslim community.</li>
<li>An opportunity to contribute to impactful projects that benefit Muslims worldwide.</li>
</ul>
</section>
<section id="machine-learning-engineer-at-tarteel" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-engineer-at-tarteel">Machine Learning Engineer at Tarteel</h2>
<p>Tarteel is always seeking talented individuals passionate about advancing the state of the Muslim ummah through their unique skills. They encourage applicants to share as much as possible about their interests and abilities.</p>
<p>So, here‚Äôs my story: I‚Äôve applied to Tarteel 4 times!</p>
<ul>
<li>The first time was during my second year of college, seeking an internship. My skills were basic‚ÄîI had just started learning about deep learning‚Äîbut the advice they gave me was encouraging and kind.</li>
<li>After graduation, I applied again but was rejected without explanation. I assume it‚Äôs because I was a fresh graduate, and they likely needed someone with experience in large-scale projects. That‚Äôs fair.</li>
<li>Seven months later, just before Ramadan 2026, Tarteel announced internship opportunities for the first time. I applied but wasn‚Äôt accepted. The competition was tough, and I don‚Äôt think I was the strongest candidate at the time‚Äîno hard feelings!</li>
<li>What now? I‚Äôm determined to prove I have the knowledge and skills to contribute. Here‚Äôs what I‚Äôm currently working on:
<ul>
<li>Arabic NLP, LLMs, and speech recognition with the Namma community, where I‚Äôm contributing to open-source projects and research papers.</li>
<li>A remote research lab in Russia, which is accelerating my technical growth.</li>
<li>Plans to join a company to learn about cloud deployment, model optimization, and GPU workloads.</li>
<li>Studying Quranic sciences and Tajweed to deepen my connection to the field.</li>
<li>Building small projects inspired by Tarteel‚Äôs vision to test my abilities and see where they take me.</li>
</ul></li>
</ul>
</section>
<section id="skills-i-need-to-master" class="level2">
<h2 class="anchored" data-anchor-id="skills-i-need-to-master">Skills I Need to Master</h2>
<p>To succeed, I‚Äôm focusing on these key areas:</p>
<ul>
<li>Speech recognition and audio processing.</li>
<li>Nvidia NeMo frameworks.</li>
<li>SLURM (for managing computing resources).</li>
<li>S5 (data storage and retrieval).</li>
<li>Monitoring and analyzing model performance for data-driven improvements.</li>
</ul>
</section>
<section id="my-current-plan" class="level2">
<h2 class="anchored" data-anchor-id="my-current-plan">My Current Plan</h2>
<p>I‚Äôve started mastering these skills by taking courses and reading books on state-of-the-art (SOTA) speech recognition models. Soon, I‚Äôll share my progress, publish my work, and apply what I‚Äôve learned to Tarteel‚Äôs vision. And, of course, I‚Äôm making duaa for guidance and success ‚ù§Ô∏è.</p>
</section>
<section id="other-resources" class="level2">
<h2 class="anchored" data-anchor-id="other-resources">Other Resources</h2>
<section id="my-blogs-related-to-tarteel" class="level3">
<h3 class="anchored" data-anchor-id="my-blogs-related-to-tarteel">My Blogs Related to Tarteel</h3>
<p>(To be added)</p>
</section>
<section id="social-media" class="level3">
<h3 class="anchored" data-anchor-id="social-media">Social Media</h3>
<ul>
<li><a href="https://huggingface.co/Abdelkareem">Hugging Face</a></li>
<li><a href="https://www.linkedin.com/in/kareemkobo/">LinkedIn</a></li>
<li><a href="https://x.com/AbdelkareemElk2">Twitter</a></li>
<li><a href="https://github.com/abdelkareemkobo">GitHub</a></li>
</ul>


</section>
</section>

 ]]></description>
  <category>blogging</category>
  <category>tarteel</category>
  <category>speech_recognition</category>
  <category>machine_learning</category>
  <category>quran</category>
  <category>job</category>
  <guid>https://kareemai.com/blog/posts/speech_recognition/my_dream_job_at_tarteel.html</guid>
  <pubDate>Mon, 17 Mar 2025 22:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/speech_recognition/images/tarteel_ai.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>ŸÅŸÜ ÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ© ÿßŸÑÿ±ŸÇŸÖŸäÿ©</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/life_style/digital_minimalisim_arabic.html</link>
  <description><![CDATA[ 





<ul>
<li><h1 id="ŸÑŸÖÿßÿ∞ÿß-ŸÜŸÖÿØ-ÿ£ŸäÿØŸäŸÜÿß-ÿ®ÿ¥ŸÉŸÑ-ÿ∫ÿ±Ÿäÿ≤Ÿä-ÿ•ŸÑŸâ-ŸáŸàÿßÿ™ŸÅŸÜÿß-ÿÆŸÑÿßŸÑ-ŸÑÿ≠ÿ∏ÿßÿ™-ÿßŸÑŸÖŸÑŸÑ-ÿ£Ÿà-ÿßŸÑŸÅÿ±ÿßÿ∫">ŸÑŸÖÿßÿ∞ÿß ŸÜŸÖÿØ ÿ£ŸäÿØŸäŸÜÿß ÿ®ÿ¥ŸÉŸÑ ÿ∫ÿ±Ÿäÿ≤Ÿä ÿ•ŸÑŸâ ŸáŸàÿßÿ™ŸÅŸÜÿß ÿÆŸÑÿßŸÑ ŸÑÿ≠ÿ∏ÿßÿ™ ÿßŸÑŸÖŸÑŸÑ ÿ£Ÿà ÿßŸÑŸÅÿ±ÿßÿ∫ÿü</h1>
<p>ŸÑŸäÿ≥ ŸÖŸÜ ŸÇÿ®ŸäŸÑ ÿßŸÑÿµÿØŸÅÿ©. ÿ™ŸÖ ÿ™ÿµŸÖŸäŸÖ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÑÿ¨ÿ∞ÿ®ŸÜÿß ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâÿå ŸàÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿßŸÜÿ™ÿ®ÿßŸáŸÜÿß Ÿàÿ™ŸÇÿØŸäŸÖ ÿØŸÅÿπÿßÿ™ ŸÖŸÜ ÿßŸÑÿØŸàÿ®ÿßŸÖŸäŸÜ ÿ£ÿ´ŸÜÿßÿ° ÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸáÿß.</p>
<p>ŸàŸÖÿπ ÿ∞ŸÑŸÉÿå ŸÅÿ•ŸÜ ŸÖÿ¨ÿ±ÿØ ŸÖÿπÿ±ŸÅÿ© ÿ∞ŸÑŸÉ ŸÑÿß ŸäŸÖŸÜÿπŸÜÿß ŸÖŸÜ ÿ™ÿ¥ÿ™Ÿäÿ™ ÿßŸÜÿ™ÿ®ÿßŸáŸÜÿß.</p>
<p>ŸÅŸä Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÇÿßŸÑÿ©ÿå ÿ≥ÿ£ÿ¥ÿßÿ±ŸÉ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖŸÅŸäÿØÿ© ŸàÿßŸÑŸÜÿµÿßÿ¶ÿ≠ ÿßŸÑÿπŸÖŸÑŸäÿ© ŸÑŸÑÿ™ÿÆŸÑÿµ ŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ£Ÿà ÿ™ŸÇŸÑŸäŸÑ ÿÆÿ∑ÿ±Ÿáÿß ÿ®ŸÇÿØÿ± ÿßŸÑÿ•ŸÖŸÉÿßŸÜ:</p></li>
<li><h2 id="ÿ£ŸàŸÇŸÅ-ÿ™ÿ¥ÿ∫ŸäŸÑ-ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™" class="anchored">1. ÿ£ŸàŸÇŸÅ ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™</h2>
<ul>
<li>ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸáŸä ÿ®Ÿàÿßÿ®ÿ© ÿßŸÑŸÖÿ¥ÿ™ÿ™ÿßÿ™.</li>
<li>ŸÖÿπÿ∏ŸÖ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ÿ∫Ÿäÿ± ŸÖŸáŸÖÿ© ŸàŸÑŸÉŸÜŸáÿß ÿ™ÿÆŸÑŸÇ ÿ¥ÿπŸàÿ±Ÿãÿß ÿ≤ÿßÿ¶ŸÅŸãÿß ÿ®ÿßŸÑÿ•ŸÑÿ≠ÿßÿ≠.</li>
<li>ÿ®ÿØŸÑÿßŸã ŸÖŸÜ ŸÖÿ±ÿßÿ¨ÿπÿ© ÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸÉŸÑ ÿ™ÿ∑ÿ®ŸäŸÇ ÿπŸÑŸâ ÿ≠ÿØÿ©ÿå ŸÖŸÜ ÿßŸÑÿ£ÿ≥ŸáŸÑ ÿ™ÿ®ŸÜŸä ÿπŸÇŸÑŸäÿ© ÿ£ŸÜ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ŸÉŸàŸÜ ŸÖÿ™ŸàŸÇŸÅÿ© ÿ®ÿ¥ŸÉŸÑ ÿßŸÅÿ™ÿ±ÿßÿ∂Ÿä.</li>
<li>ÿ£ŸàŸÇŸÅ ÿ™ÿ¥ÿ∫ŸäŸÑ ŸÉŸÑ ÿ¥Ÿäÿ° ÿ£ŸàŸÑÿßŸãÿå ÿ´ŸÖ ŸÇŸÖ ÿ®ÿ™ŸÖŸÉŸäŸÜ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸÅŸÇÿ∑ ŸÑŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÖÿ´ŸÑ ÿßŸÑŸÖÿ±ÿßÿ≥ŸÑÿ© ŸàÿßŸÑÿ™ŸÇŸàŸäŸÖ.</li>
</ul></li>
<li><h2 id="ÿßÿ≥ÿ™ÿÆÿØŸÖ-ÿ£ŸäŸÇŸàŸÜÿßÿ™-ÿ≥ŸàÿØÿßÿ°-ŸàŸÖÿµÿ∫ÿ±ÿ©" class="anchored">2. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ£ŸäŸÇŸàŸÜÿßÿ™ ÿ≥ŸàÿØÿßÿ° ŸàŸÖÿµÿ∫ÿ±ÿ©</h2>
<ul>
<li>ÿ™ÿ£ÿ™Ÿä ŸÉÿßŸÅÿ© ÿßŸÑŸàÿßÿ¨Ÿáÿßÿ™ ÿ®ÿ£ŸäŸÇŸàŸÜÿßÿ™ ŸÉÿ®Ÿäÿ±ÿ© ŸàŸÖŸÑŸàŸÜÿ©ÿå ŸäŸÖŸÉŸÜŸÉ ŸÖÿπÿ±ŸÅÿ© ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿ®ŸÖÿ¨ÿ±ÿØ ÿßŸÑŸÑŸàŸÜ ŸÅŸÇÿ∑ÿå ŸÅÿßŸÑŸÑŸàŸÜ ÿßŸÑÿ£ÿµŸÅÿ± ŸáŸà ÿ™ÿ∑ÿ®ŸäŸÇ ÿ≥ŸÜÿßÿ® ÿ¥ÿßÿ™ ŸàÿßŸÑŸÑŸàŸÜ ÿßŸÑÿ®ŸÜŸÅÿ≥ÿ¨Ÿä ŸáŸà ÿßŸÑÿ•ŸÜÿ≥ÿ™ÿ¨ÿ±ÿßŸÖ.</li>
<li>ŸäŸÖŸÉŸÜŸÉ ŸÅÿ™ÿ≠ ŸÖÿ™ÿ¨ÿ± ÿßŸÑÿ´ŸäŸÖÿßÿ™ ÿßŸÑÿÆÿßÿµ ÿ®ÿ¨Ÿáÿßÿ≤ŸÉ ÿßŸÑÿ¥ÿÆÿµŸä Ÿàÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ£ŸäŸÇŸàŸÜÿßÿ™ ŸÑŸÑŸàŸÜ ÿ´ÿßÿ®ÿ™ ŸàŸÖŸàÿ≠ÿØÿå ŸäŸÅÿ∂ŸÑ ÿ£ÿ≥ŸàÿØ ÿ£Ÿà ÿ±ŸÖÿßÿØŸä.</li>
</ul></li>
<li><h2 id="ÿ£ÿ≤ŸÑ-ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™-ŸÖŸÜ-ÿßŸÑÿ¥ÿßÿ¥ÿ©-ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©" class="anchored">3. ÿ£ÿ≤ŸÑ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÖŸÜ ÿßŸÑÿ¥ÿßÿ¥ÿ© ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©</h2>
<ul>
<li>ÿπŸÑŸâ ÿ∫ÿ±ÿßÿ± ÿ®Ÿäÿ¶ÿ™ŸÜÿß ÿßŸÑŸÖÿßÿØŸäÿ©ÿå ŸÅÿ•ŸÜ ŸÖÿß ŸáŸà ŸÖŸàÿ¨ŸàÿØ ÿπŸÑŸâ ÿ¥ÿßÿ¥ÿ™ŸÜÿß ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ© Ÿäÿµÿ®ÿ≠ ÿ•ÿ¥ÿßÿ±ÿßÿ™ ÿ™ÿ≠ŸÅÿ≤ ÿπÿßÿØÿßÿ™ŸÜÿß.</li>
<li>ÿπŸÜÿØŸÖÿß ÿ™ŸÉŸàŸÜ ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸàÿ≥ÿßÿ¶ÿ∑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿ© ŸÖÿ±ÿ¶Ÿäÿ© ÿ®ÿ¥ŸÉŸÑ ŸÉÿ®Ÿäÿ± ÿπŸÑŸâ ÿ¥ÿßÿ¥ÿ™ŸÉ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©ÿå ŸÅŸÖŸÜ ÿßŸÑŸÖÿ±ÿ¨ÿ≠ ÿ£ŸÜ ÿ™ŸÅÿ™ÿ≠Ÿáÿß.</li>
<li>ŸÜŸàÿµŸä ÿ®ŸÜŸÇŸÑ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖÿ¥ÿ™ÿ™ÿ© ŸÑŸÑÿßŸÜÿ™ÿ®ÿßŸá ÿ•ŸÑŸâ ‚ÄúÿßŸÑÿÆŸÑŸÅ‚Äù.</li>
<li>ŸäŸÖŸÉŸÜ ŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ£ŸäŸÅŸàŸÜ ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÖŸÜ ÿßŸÑÿ¥ÿßÿ¥ÿ© ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ© Ÿàÿ™ÿÆÿ≤ŸäŸÜŸáÿß ŸÅŸä ŸÖŸÉÿ™ÿ®ÿ© ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ÿå ÿ®ŸäŸÜŸÖÿß ŸäŸÖŸÉŸÜ ŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ£ŸÜÿØÿ±ŸàŸäÿØ ÿßŸÑÿßÿ≠ÿ™ŸÅÿßÿ∏ ÿ®ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ®ÿßŸÑŸÖÿ´ŸÑ ŸÅŸä ÿØÿ±ÿ¨ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™.</li>
</ul></li>
<li><h2 id="ÿ¥ÿ∫ŸÑ-ŸÅŸÑÿ™ÿ±-ÿßŸÑÿ™ÿØÿ±ÿ¨-ÿßŸÑÿ±ŸÖÿßÿØŸä" class="anchored">4. ÿ¥ÿ∫ŸëŸÑ ŸÅŸÑÿ™ÿ± ÿßŸÑÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸä</h2>
<ul>
<li>ŸäŸÖŸÉŸÜ ÿ£ŸÜ Ÿäÿ§ÿØŸä ÿ™ÿ≠ŸàŸäŸÑ Ÿáÿßÿ™ŸÅŸÉ ÿ•ŸÑŸâ ÿßŸÑÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸä ÿ•ŸÑŸâ ÿ¨ÿπŸÑ ÿßŸÑÿ™ŸÖÿ±Ÿäÿ± ÿπÿ®ÿ± ÿßŸÑŸàÿ≥ÿßÿ¶ÿ∑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿ© ÿ£ŸÇŸÑ ÿ™ÿ¥ÿ™Ÿäÿ™Ÿãÿß ÿπŸÑŸâ ÿßŸÑŸÅŸàÿ±.</li>
<li>ŸÑŸÉŸÜŸÉ ŸÑÿ≥ÿ™ ŸÖÿ∂ÿ∑ÿ±Ÿãÿß ŸÑÿ•ÿ®ŸÇÿßÿ¶Ÿá ŸÇŸäÿØ ÿßŸÑÿ™ÿ¥ÿ∫ŸäŸÑ ÿ∑ŸàÿßŸÑ ÿßŸÑŸàŸÇÿ™.</li>
<li>ŸÜÿ≠ŸÜ ŸÜÿπŸÑŸÖ ŸÖÿØŸâ ŸÇŸàÿ© Ÿáÿ∞Ÿá ÿßŸÑÿ£ÿ¨Ÿáÿ≤ÿ© ÿßŸÑÿµÿ∫Ÿäÿ±ÿ© ŸÑŸÑÿπŸÖŸÑ ÿßŸÑÿ•ÿ®ÿØÿßÿπŸä ŸàÿßŸÑÿ™ÿ±ŸÅŸäŸá.</li>
<li>ŸÖÿß ŸÜŸàÿµŸä ÿ®Ÿá ŸáŸà Ÿàÿ¨ŸàÿØ ÿ∑ÿ±ŸäŸÇÿ© ÿ®ÿ≥Ÿäÿ∑ÿ© ŸÑÿ™ÿ¥ÿ∫ŸäŸÑ Ÿàÿ•ŸäŸÇÿßŸÅ ŸÅŸÑÿ™ÿ± ÿßŸÑÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸäÿå ŸÖÿ´ŸÑ ÿ•ÿ∂ÿßŸÅÿ™Ÿá ÿ•ŸÑŸâ ŸÖÿ±ŸÉÿ≤ ÿßŸÑÿ™ÿ≠ŸÉŸÖ ÿπŸÑŸâ ÿ£ÿ¨Ÿáÿ≤ÿ© iPhone.</li>
</ul></li>
<li><h2 id="ÿÆÿØ-ŸÜŸÅÿ≥ŸÉ---ÿ£ÿÆÿ±-ŸÅÿ™ÿ≠-ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™" class="anchored">5. ÿÆÿØ ŸÜŸÅÿ≥ŸÉ - ÿ£ÿÆŸëÿ± ŸÅÿ™ÿ≠ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™</h2>
<ul>
<li>ŸÑÿ•ÿ∂ÿßŸÅÿ© ÿ™ÿ£ÿÆŸäÿ± ÿπŸÜÿØ ŸÅÿ™ÿ≠ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ÿå ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ™ÿ∑ÿ®ŸäŸÇ ŸÖÿ´ŸÑ: <a href="https://one-sec.app/">One Sec</a></li>
<li>ŸäŸÇÿØŸÖ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ŸàŸÇŸÅÿ© ŸÇÿµŸäÿ±ÿ© ŸÅŸä ŸÉŸÑ ŸÖÿ±ÿ© ÿ™ÿ≠ÿßŸàŸÑ ŸÅŸäŸáÿß ŸÅÿ™ÿ≠ ÿßŸÑŸàÿ≥ÿßÿ¶ÿ∑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿ© ÿ£Ÿà ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ£ÿÆÿ±Ÿâ ÿßŸÑŸÖÿ≠ÿØÿØÿ©.</li>
<li>ŸäÿπŸÖŸÑ ŸÉÿ≠ÿßÿ¨ÿ≤ ÿ¥ÿßÿ¥ÿ© ŸÖÿ§ŸÇÿ™ ÿ®ŸäŸÜŸÉ Ÿàÿ®ŸäŸÜ ÿßŸÑŸÖÿ¥ÿ™ÿ™ÿßÿ™ÿå ŸÖŸÖÿß Ÿäÿ≥ÿßÿπÿØŸÉ ÿπŸÑŸâ ÿ•ŸÖÿ≥ÿßŸÉ ŸÜŸÅÿ≥ŸÉ Ÿàÿ™ÿ≠ÿØŸäÿØ ŸÖÿß ÿ•ÿ∞ÿß ŸÉŸÜÿ™ ŸÖÿ¥ÿ™ÿ™Ÿãÿß ÿ£Ÿà ŸÖÿ™ÿπŸÖÿØŸãÿß.</li>
<li>ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿπŸÑŸâ ÿßŸÑŸÖŸàÿ®ÿßŸäŸÑ ÿ£Ÿà ÿπŸÑŸâ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ®.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/image_1738724671871_0.png" class="img-fluid figure-img"></p>
<figcaption>One Sec</figcaption>
</figure>
</div>
<ul>
<li><h2 id="ÿßÿ≠ÿ∞ŸÅ-ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™-ÿ∫Ÿäÿ±-ÿßŸÑÿ∂ÿ±Ÿàÿ±Ÿäÿ©" class="anchored">6. ÿßÿ≠ÿ∞ŸÅ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ∫Ÿäÿ± ÿßŸÑÿ∂ÿ±Ÿàÿ±Ÿäÿ©</h2>
<ul>
<li>ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿ¥ÿ™ÿ™ ŸÑŸÑÿßŸÜÿ™ÿ®ÿßŸá ŸÑÿß Ÿäÿ∂ŸäŸÅ ÿ£Ÿä ŸÇŸäŸÖÿ© ÿ≠ŸÇŸäŸÇŸäÿ©ÿå ŸÅÿ•ŸÜ ÿßŸÑÿ≠ŸÑ ÿßŸÑÿ£ÿ®ÿ≥ÿ∑ ÿ∫ÿßŸÑÿ®Ÿãÿß ŸÖÿß ŸäŸÉŸàŸÜ ÿßŸÑÿ£ŸÅÿ∂ŸÑ.</li>
<li>ÿßÿ≠ÿ∞ŸÅŸá ŸÖŸÜ ÿ¨Ÿáÿßÿ≤ŸÉ ÿ™ŸÖÿßŸÖŸãÿß.</li>
<li>ÿ´ŸÖÿå ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸàŸÇÿ™ŸÉ ÿßŸÑÿ∞Ÿä ÿ™ŸÖ ÿ™ÿ≠ÿ±Ÿäÿ±Ÿá ÿ≠ÿØŸäÿ´Ÿãÿß ŸÅŸä ÿ£ŸÜÿ¥ÿ∑ÿ© ŸÖŸÅŸäÿØÿ©.</li>
<li>ŸÖŸÜ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ® ÿßŸÑŸÖÿ´Ÿäÿ±ÿ© ŸáŸä ÿ≠ÿ∞ŸÅ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸäŸàÿ™ŸäŸàÿ® ŸÖŸÜ ÿßŸÑŸÖŸàÿ®ÿßŸäŸÑ Ÿàÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸá ŸÖŸÜ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ÿå ÿ≥ŸäŸÇŸÑŸÑ Ÿáÿ∞ÿß ŸÖŸÜ ÿßŸÑÿßŸÜÿ∫ŸÖÿßÿ≥ ŸàŸäŸÅÿ∂ŸÑ ÿ≠ÿ∞ŸÅ ŸÉŸÑÿß ŸÖŸÜ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ ŸàÿßŸÑŸäŸàÿ™ŸäŸàÿ®!!</li>
<li>ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ™ÿÆŸÑÿµ ŸÖŸÜ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸäŸàÿ™ŸäŸàÿ® ÿ®ÿßŸÑŸÉÿßŸÖŸÑ ÿπŸÑŸâ ŸÜÿ∏ÿßŸÖ ÿ£ŸÜÿØÿ±ŸàŸäÿØ ÿ®ÿØŸàŸÜ ÿπŸÖŸÑ ÿ±Ÿàÿ™ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Adb manager.</li>
<li>ŸàÿπŸÜÿØŸÖÿß ÿ™ÿ±ŸäÿØ ŸÖÿ¥ÿßŸáÿØÿ© ÿßŸÑŸäŸàÿ™ŸäŸàÿ® ÿ£Ÿà ÿ®ÿßŸÇŸä Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿå ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ® ŸÅŸáŸà ÿ£ŸÇŸÑ ÿπÿ±ÿ∂ÿ© ŸÑŸÑÿ™ÿ¥ÿ™ÿ™ ŸàÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÅŸä ÿ£ŸàŸÇÿßÿ™ ŸÖÿ´ŸÑ ŸÇÿ®ŸÑ ÿßŸÑŸÜŸàŸÖ ÿ£Ÿà ŸÅŸä ÿ£ÿ´ŸÜÿßÿ° ÿßŸÑŸÖÿ±ÿ≠ÿßÿ∂ ÿ£Ÿà ÿ™ŸÜÿßŸàŸÑ ÿßŸÑÿ∑ÿπÿßŸÖ ŸÅŸä ÿßŸÑŸÖÿ∑ÿ®ÿÆ ŸÖÿ´ŸÑÿßŸã!</li>
</ul></li>
<li><h2 id="ÿ£ÿπÿØ-ÿ™ÿ¥ŸÉŸäŸÑ-ÿπÿßŸÑŸÖŸÉ-ŸÉŸÖÿß-ÿ™ÿ±ŸäÿØ" class="anchored">7. ÿ£ÿπÿØ ÿ™ÿ¥ŸÉŸäŸÑ ÿπÿßŸÑŸÖŸÉ ŸÉŸÖÿß ÿ™ÿ±ŸäÿØ</h2>
<ul>
<li><p>ÿ•ÿ∞ÿß ŸÖÿß ÿ≤ŸÑÿ™ ÿ™ÿ±ŸäÿØ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ®ÿπÿ∂ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ÿå ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ™ÿ≠ŸÉŸÖ ŸÅŸä ŸÉŸäŸÅŸäÿ© ÿßŸÑÿπÿ±ÿ∂ ŸàŸÖÿßÿ∞ÿß ÿ™ÿ±ŸäÿØ ÿ£ŸÜ ÿ™ÿ±Ÿâ ŸàŸÖÿß ŸÑÿß ÿ™ÿ±ŸäÿØÿå ŸàÿßŸÑÿ™ŸàŸÇŸÅ ÿπŸÜ ÿßŸÑÿ™ÿ¥ÿ™ÿ™ ŸÖÿ´ŸÑÿßŸã.</p></li>
<li><p>ÿ®ÿπÿ∂ ÿ•ÿ∂ÿßŸÅÿßÿ™ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ ÿßŸÑÿ™Ÿä ÿ™ÿ≥ŸÖÿ≠ ŸÑŸÉ ÿ®ÿ™ÿπÿØŸäŸÑ ÿßŸÑŸÖŸàŸÇÿπ:</p>
<ul>
<li><a href="https://chromewebstore.google.com/detail/minimal-theme-for-twitter/pobhoodpcipjmedfenaigbeloiidbflp">Minimal theme for twitter</a>: ÿ™ÿ≥ŸÖÿ≠ ŸÑŸÉ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿ•ÿπÿØÿßÿØ ÿπÿ±ÿ∂ ÿ™ŸàŸäÿ™ÿ± ÿßŸÑÿÆÿßÿµ ÿ®ŸÉ.</li>
</ul></li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/image_1738724457971_0.png" class="img-fluid figure-img"></p>
<figcaption>Minimal Theme for Twitter</figcaption>
</figure>
</div>
<ul>
<li><a href="https://chromewebstore.google.com/detail/unhook-remove-youtube-rec/khncfooichmfjbepaaaebmommgaepoid">Unhook</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/image_1738724551148_0.png" class="img-fluid figure-img"></p>
<figcaption>Enhancer for Youtube - 1</figcaption>
</figure>
</div>
<ul>
<li><a href="https://chromewebstore.google.com/detail/enhancer-for-youtube/ponfpcnoihfmfllpaingbgckeeldkhle?hl=en-US">Enhancer for youtube</a></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/image_1738724511256_0.png" class="img-fluid figure-img"></p>
<figcaption>Enhancer for Youtube - 2</figcaption>
</figure>
</div>
<ul>
<li><h2 id="ŸÖÿ±ÿßŸÇÿ®ÿ©-ÿßŸÑŸàŸÇÿ™" class="anchored">8. ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸàŸÇÿ™</h2>
<ul>
<li>ŸÖŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖŸÅŸäÿØÿ© ŸÑŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸàŸÇÿ™ ÿπŸÑŸâ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ® ŸàÿßŸÑŸÖŸÅÿ™Ÿàÿ≠ÿ© ÿßŸÑŸÖÿµÿØÿ± ÿ£Ÿäÿ∂Ÿãÿß ŸáŸä: <a href="https://activitywatch.net/">ActivitWatch</a></li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://activitywatch.net/img/screenshots/screenshot-v0.9.3-activity.png" class="img-fluid figure-img"></p>
<figcaption>Activity Watch Example</figcaption>
</figure>
</div>
<ul>
<li><h2 id="Ÿáÿßÿ™ŸÅ-ÿ∫ÿ®Ÿä" class="anchored">Ÿáÿßÿ™ŸÅ ÿ∫ÿ®Ÿä</h2>
<ul>
<li><p>ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ™ÿ∑ÿ®ŸäŸÇ</p>
<ul>
<li><a href="https://dumbphone.so/">dumb phone</a></li>
</ul></li>
<li><p>Ÿäÿ≥ÿßÿπÿØŸÉ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿπŸÑŸä ÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ±ŸäÿØ ŸÅÿ™ÿ≠Ÿáÿß ŸÅŸÇÿ∑ ŸàŸäŸÇŸàŸÖ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿßŸäŸÇŸàŸÜÿ© ŸÑÿ™ÿµÿ®ÿ≠ ÿßÿ≥ŸÖ ŸÖÿ¨ÿ±ÿØ ŸÖŸÖÿß Ÿäÿ¨ÿπŸÑŸÉ ÿßŸÉÿ´ÿ± ŸàÿπŸäÿß ÿπŸÜÿØ ŸÖÿ≠ÿßŸàŸÑÿ™ŸÉ ŸÅÿ™ÿ≠ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ</p></li>
<li><p>ŸäŸÖŸÉŸÜŸÉ ÿ™ÿ¨ÿ±ÿ®ÿ©&nbsp;ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸáÿßÿ™ŸÅ ÿßŸÑÿ∫ÿ®Ÿä&nbsp;ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ™ŸÜÿ≤ŸäŸÑ ÿ£ÿØŸÜÿßŸá.</p></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/image_1738731874874_0.png" class="img-fluid figure-img"></p>
<figcaption>dumb phone</figcaption>
</figure>
</div></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/image_1738731869245_0.png" class="img-fluid figure-img"></p>
<figcaption>dumb phone example</figcaption>
</figure>
</div></li>
<li><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/image_1738731860670_0.png" class="img-fluid figure-img"></p>
<figcaption>review of dumb phone</figcaption>
</figure>
</div></li>
<li></li>
</ul></li>
<li><h2 id="ŸÖÿ±ÿßÿ¨ÿπ" class="anchored">ŸÖÿ±ÿßÿ¨ÿπ</h2>
<ul>
<li>ŸÖÿ≥ŸÑŸÉŸäÿßÿ™</li>
<li>ÿπŸÖŸÑ ÿπŸÖŸäŸÇ</li>
<li>ÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ© ÿßŸÑÿ±ŸÇŸÖŸäÿ©</li>
<li>ŸÅŸÜ ÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ©</li>
</ul></li>
</ul>



 ]]></description>
  <category>blogging</category>
  <category>idea_Forge</category>
  <category>publish</category>
  <category>rough_thoughts</category>
  <category>life_style</category>
  <guid>https://kareemai.com/blog/posts/life_style/digital_minimalisim_arabic.html</guid>
  <pubDate>Tue, 04 Feb 2025 22:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/life_style/images/fake_graviety.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Math Skills For AI</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/math/math_skills_for_AI.html</link>
  <description><![CDATA[ 





<section id="what-i-aim-to-achieve" class="level2">
<h2 class="anchored" data-anchor-id="what-i-aim-to-achieve">What I Aim to Achieve</h2>
<p>As a graduate with a Computer Science degree, my time has been primarily dedicated to three core areas:</p>
<ol type="1">
<li><strong>Programming:</strong>&nbsp;I‚Äôve worked extensively with Python, C++, JavaScript, and Rust.</li>
<li><strong>Mathematics:</strong>&nbsp;My studies have encompassed linear algebra, probability, calculus, and discrete mathematics.</li>
<li><strong>Core Computer Science:</strong>&nbsp;I‚Äôve explored topics like databases, networking, and data structures &amp; algorithms.</li>
</ol>
<p>During my final year, I realized there were significant gaps in my understanding, despite the courses and books I‚Äôd engaged with. I often wish I could start over, but real life doesn‚Äôt have a ‚Äúretry‚Äù button.</p>
<p>Currently, I‚Äôm involved in:</p>
<ol type="1">
<li><p><strong>AI Research:</strong>&nbsp;My focus is on medical image preprocessing and natural language processing. I‚Äôm also keenly interested in areas like:</p>
<ul>
<li>Federated Learning</li>
<li>Adversarial Neural Networks</li>
<li>Explainable AI (XAI)</li>
<li>Generative Art (specifically Stable Diffusion models, Flux, and ControlNet)</li>
</ul></li>
<li><p><strong>Web Development:</strong>&nbsp;I primarily use FastHTML and Astrojs for side projects. I enjoy building things and getting paid for them, as I don‚Äôt currently have a formal AI job.</p></li>
</ol>
</section>
<section id="the-centrality-of-math-in-ai-research" class="level2">
<h2 class="anchored" data-anchor-id="the-centrality-of-math-in-ai-research">The Centrality of Math in AI Research</h2>
<p>It‚Äôs true that in both engineering and research, you can be an excellent software engineer and earn a substantial income without deep mathematical knowledge, possibly more than many mathematicians. However, to be a&nbsp;good&nbsp;researcher, a strong mathematical foundation is crucial. By that, I don‚Äôt just mean a superficial understanding of numerous topics. You need a solid grasp of linear algebra and probability, both theoretically and practically. And by ‚Äúpractical,‚Äù I mean the ability to translate mathematical concepts into code.</p>
<p>Of course, other topics are relevant, depending on your specific field. For example:</p>
<ul>
<li><strong>Generative AI:</strong>&nbsp;You‚Äôll often encounter differential equations and advanced probability and statistical models.</li>
</ul>
<p>After reading research papers, you begin to see recurring concepts like conditional probability, Bayes‚Äô theorem, and matrix factorization. But you‚Äôll also find complex, novel, or sometimes even older, techniques that are hard to grasp initially.</p>
<hr>
<p>In my limited time exploring research, I‚Äôve observed that many papers lack significant contributions. Some seem to be primarily workarounds, comparisons of existing models, new data applied to established models, or minor observations. This isn‚Äôt inherently bad, but it‚Äôs not the kind of impact I‚Äôm aiming for. The researchers who are making substantial contributions are often very skilled in&nbsp;both&nbsp;math and coding. They create open-source projects, share their ideas, and actively contribute, like the authors of the Colbert papers in information retrieval. And these contributions are often enabled by math, such as PCA, LORA, and other optimization techniques.</p>
<p>While a strong coding background can certainly be beneficial for optimization and research, I strive for a deeper understanding and to reach a higher level of impact. After all, we only have one life.</p>
<p>I don‚Äôt consider myself a ‚Äúbookworm,‚Äù but I genuinely love reading and can become engrossed in books on diverse subjects and levels. I recall reading around four books on linear algebra, completing all the exercises, and summarizing the content. In deep learning, I‚Äôve tackled more than 30 books. For areas like networking, databases, and data structures, I‚Äôve read at least three books on each. When new topics like federated learning, XAI, and adversarial networks emerge, I always read at least one book on each.</p>
<p>If you were to examine my profile, CV, GitHub, or even this blog, you‚Äôd probably find that I‚Äôm below average for a recent graduate! What‚Äôs the problem?</p>
<p>I believe the core issue is that while I‚Äôve read extensively and sometimes coded along with the material, I haven‚Äôt committed to projects that demand more time and mental effort. I haven‚Äôt really allowed the knowledge to ‚Äúgrow.‚Äù For instance, I learned linear algebra theory and did the pen-and-paper exercises, but I didn‚Äôt experiment with coding it. And, I didn‚Äôt apply the concepts I studied to the fields that truly interested me. There‚Äôs also a gap between the libraries we use in deep learning and the underlying skills ‚Äì they don‚Äôt always feel directly connected.</p>
<p>It‚Äôs unrealistic to understand every library at a micro-level. But it‚Äôs crucial to try and bridge the gap between your fundamental skills and the high-level APIs you use. For example, challenge yourself to implement PCA from scratch with NumPy on a Kaggle dataset. Try coding the matrix components of LORA with PyTorch. Take probability concepts and apply them to datasets you care about ‚Äì for me, that might be datasets related to fitness or Arabic language processing. Build projects you love using these new tools, and consciously choose what skills to prioritize. For example, I might be okay with letting go of some discrete math knowledge, but not linear algebra.</p>
</section>
<section id="the-days-of-problem-solving" class="level2">
<h2 class="anchored" data-anchor-id="the-days-of-problem-solving">The Days of Problem Solving</h2>
<p>During my second year, I began exploring problem-solving but initially struggled with platforms like Codeforces. However, after two months of encouragement from friends, I decided to give it another shot.</p>
<p>I was using Edabit to practice Python problem-solving with easy problems and then moved to Codeforces without a solid grasp of C++. It took time and many hours struggling with error messages (I once learned a painful lesson that ‚Äú‚Äù and ‚Äô‚Äô are different in C++ unlike Python!).</p>
<p>After about two months of this, my skills in both thinking and implementation improved dramatically. I recall one of my earliest achievements was writing a 300-line C++ solution without relying on Google, and of course, LLMs weren‚Äôt around at that time. This feeling of self-sufficiency was incredibly rewarding. After four months, my problem-solving skills had improved considerably, and I had reached the next level. However, I then decided to shift my focus to web development to improve my financial situation, and I never went back. I also remember failing a technical interview in my third year because I struggled to solve linked list problems in Python, despite being able to do so in C++. I felt lost throughout my college years</p>
<p>But that feeling of deep understanding, of being able to solve problems independently, is amazing and builds confidence. It‚Äôs a virtuous cycle.</p>
</section>
<section id="things-i-remember" class="level2">
<h2 class="anchored" data-anchor-id="things-i-remember">Things I Remember</h2>
<p>I‚Äôm revisiting linear algebra and realized I‚Äôd forgotten how to calculate eigenvalues, though I understand their role. However, I haven‚Äôt forgotten how to calculate the determinant of a 2x2 or 3x3 matrix. Why? Because I solved countless exercises with determinants, but with eigenvalues, I had primarily read the solutions or tried simple examples. When using PCA in code, it‚Äôs easy to rely on a library and not think about the underlying operations. While that‚Äôs okay to some degree, we should occasionally revisit how things work behind the scenes.</p>
</section>
<section id="the-mbzuai-exam-in-two-days" class="level2">
<h2 class="anchored" data-anchor-id="the-mbzuai-exam-in-two-days">The MBZUAI Exam in Two Days</h2>
<p>A friend told me about a scholarship at MBZUAI with a deadline in three days. Although I didn‚Äôt have the necessary English test scores, I applied anyway. They‚Äôve scheduled an exam in 7 days from when I applied, and today was the first day I started preparing.</p>
<p>I completed the linear algebra and probability specializations on Coursera taught by Luis G. Serrano. While it was a good refresher, I dislike relearning the same concepts every year! The exam will cover probability, linear algebra, calculus, algorithms, trigonometry, optimization, and some NLP questions.</p>
<p>I honestly don‚Äôt remember much about trigonometry, and when I studied it before, it was in Arabic, not English, and the transition isn‚Äôt so simple. I also dislike cramming things for two days only to forget them immediately after ‚Äì that feels like a waste of time.</p>
<p>Despite the odds, I‚Äôm determined to apply, even if the acceptance rate for the scholarship is only 5%. Working with the people at MBZUAI would be a great experience. If I‚Äôm not accepted, I‚Äôll continue to focus on mastering math and keep moving forward.</p>
</section>
<section id="maslakiat" class="level2">
<h2 class="anchored" data-anchor-id="maslakiat">Maslakiat</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/math/images/Maslakiat.jpg" class="img-fluid figure-img"></p>
<figcaption>ŸÉÿ™ÿßÿ® ŸÖÿ≥ŸÑŸäŸÉÿßÿ™ ÿ•ÿ®ÿ±ÿßŸáŸäŸÖ ÿßŸÑÿ≥ŸÉÿ±ÿßŸÜ</figcaption>
</figure>
</div>
<p>when i have a stress and a lof of taskes i go to reading books I have final exams in the comming days, MBZUAI exam, research paper review comments needed to be corrected, open source problem i must finish this week, some websites and a lot of things. I start reading the first the page and the author was talking to me and the words touch my soul deeply for example some qoutes from the <a href="https://www.goodreads.com/book/show/22363984">book</a> I will write them in arabic and you can translate them with GPT.</p>
<p><strong>Translations of the Arabic Quotes (with slight interpretations for clarity):</strong></p>
<ol type="1">
<li><p><strong>‚ÄúŸàŸÑŸÉŸÜ ÿ´ŸÖÿ© ÿπÿßŸÖŸÑ ŸÑŸá ŸÅŸä ŸÜŸÅÿ≥Ÿä ÿ≠ŸÅÿßŸàÿ© ÿÆÿßÿµÿ© ÿå ÿπÿßŸÖŸÑ ŸäŸÅÿ≥ÿ± ŸÉÿ´Ÿäÿ±ÿß ŸÖŸÜ ŸÅÿ¥ŸÑ ÿßŸÑÿ∑ŸÖŸàÿ≠ÿßÿ™ Ÿà ÿßŸÑÿ£ÿ≠ŸÑÿßŸÖ ‚Ä¶ Ÿáÿ∞ÿß ÿßŸÑÿπÿßŸÖŸÑ ÿ®ŸÉŸÑ ÿßÿÆÿ™ÿµÿßÿ±: ŸáŸà ÿ£ŸÜ ÿßŸÑÿÆÿ∑ÿ∑ ŸÅŸàŸÇ ÿßŸÑÿµÿÆŸàÿ± Ÿà ÿßŸÑÿßÿ±ÿ¨ŸÑ ŸÖÿßÿ≤ÿßŸÑÿ™ ŸÜÿßÿπŸÖÿ© ŸÖÿß ÿ≠ŸÅŸäÿ™ ÿ®ÿπÿØ‚Ä¶‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúBut there is a factor that resonates deeply within me, a factor that explains much of the failure of ambitions and dreams‚Ä¶ This factor, in short, is that the plans are laid on rocks, but our feet are still tender, not yet calloused.‚Äù</li>
<li>Interpretation:&nbsp;This emphasizes the gap between grand plans and the lack of practical experience or the ‚Äúhard knocks‚Äù that build resilience and skill.</li>
</ul></li>
<li><p><strong>‚Äúÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÖÿ±ÿ° ŸäŸÜÿßŸÖ ÿ≠ÿ™Ÿä ÿ™ÿ¨Ÿáÿ±ŸÉ ÿ£ÿ¥ÿπÿ© ÿßŸÑÿ≠ŸÖÿ±ÿ© ŸÅŸä ÿπŸäŸÜŸäÿ© Ÿà Ÿäÿ®ÿ≥ÿ∑ ÿÆŸàÿßŸÜ ÿßŸÑÿ∑ÿπÿßŸÖ ŸÉŸÑŸÖÿß ÿßÿ¥ÿ™ŸáŸä ÿå ŸàŸäÿÆÿµÿµ ÿßŸÑÿ£ŸàŸÇÿßÿ™ ÿßŸÑÿ∑ŸàŸäŸÑÿ© ŸÑŸÑŸÇŸáŸàÿ© Ÿà ÿßŸÑÿ¥ÿßŸä Ÿà ÿßŸÑÿπÿµÿßÿ¶ÿ± Ÿà ÿßŸÑŸÅÿ∑ÿßÿ¶ÿ± ÿå ŸàŸÑÿß Ÿäÿ≥ŸÖÿ≠ ŸÑŸÜŸÅÿ≥Ÿá ÿ®ÿ£ŸÜ ÿ™ÿ™ŸÜÿßÿ≤ŸÑ ÿπŸÜ ÿ£Ÿä ŸÅÿ±ÿµÿ© ŸÅÿ≥ÿ≠ÿ© ÿ£Ÿà ŸÖÿ≥ÿßŸÖÿ±ÿßÿ™ ŸÖÿπ ÿ£ÿµÿ≠ÿßÿ®ÿ© ÿå Ÿà ŸÑÿß Ÿäÿ≥ÿ™ÿ∑Ÿäÿπ ŸÉÿ®ÿ≠ ÿ¨ŸÖÿßÿ≠ ÿ™ÿµŸÅÿ≠ ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿ£ŸÜ Ÿäÿ≥ÿ±ŸÇ ÿ≥ÿßÿπÿßÿ™Ÿá ÿå ÿßÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÖÿ±ÿ° ŸÉÿ∞ŸÑŸÉ .. ŸàŸÖÿß ÿ≤ÿßŸÑ Ÿäÿ±ÿ¨Ÿà ÿßŸÜ ÿ™ÿ™ÿ≠ŸÇŸÇ ŸäŸàŸÖÿß ŸÖÿß ÿÆÿ∑ÿ∑Ÿá ÿßŸÑÿπŸÑŸÖŸäÿ© Ÿà ÿßŸÑÿØÿπŸàŸäÿ© Ÿà ÿßŸÑÿ•ÿµŸÑÿßÿ≠Ÿäÿ© ÿå ŸÅŸÖÿ´ŸÑ Ÿáÿ∞ÿß ÿßŸÑÿ¥ÿÆÿµ ŸÇÿØ ÿßÿ≥ÿ™ÿ£ÿµŸÑ ÿπŸÇŸÑŸá ÿå Ÿà ÿ≤ÿ±ÿπ ÿ®ÿØŸÑÿß ŸÖŸÜŸá ŸÖÿµÿ®ÿßÿ≠ ÿπŸÑÿßÿ° ÿßŸÑÿØŸäŸÜ‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúIf a person sleeps until the red rays of the sun glare in their eyes, lays out a feast whenever they desire, dedicates long periods to coffee, tea, juices, and pastries, never allows themselves to miss an opportunity for leisure or socializing with friends, and cannot restrain themselves from internet browsing stealing their hours‚Äîif a person is like this and still hopes that their scientific, religious, or reformist plans will one day be realized, then such a person has removed their mind and planted Aladdin‚Äôs lamp in its place.‚Äù</li>
<li>Interpretation:&nbsp;This strongly condemns a life of indulgence and procrastination, suggesting that those who wish to achieve great things must sacrifice leisure and work diligently. They cannot expect to magically fulfill ambitions like Aladdin with his lamp.</li>
</ul></li>
<li><p><strong>‚ÄúŸÑÿß Ÿäÿ≥ÿ™ÿ∑ÿßÿπ ÿßŸÑÿπŸÑŸÖ ÿ®ÿ±ÿßÿ≠ÿ© ÿßŸÑÿ¨ÿ≥ŸÖ‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúKnowledge cannot be attained with bodily comfort.‚Äù</li>
<li>Interpretation:&nbsp;This is a concise statement emphasizing the necessity of effort and sacrifice in the pursuit of learning.</li>
</ul></li>
<li><p><strong>‚ÄúÿßŸÑŸÉŸÖÿßŸÑÿßÿ™ ŸÉŸÑŸáÿß ŸÑÿß ÿ™ŸÜÿßŸÑ ÿ•ŸÑÿß ÿ®ÿ≠ÿ∏ ŸÖŸÜ ÿßŸÑŸÖÿ¥ŸÇÿ© Ÿà ŸÑÿß Ÿäÿπÿ®ÿ± ÿ•ŸÑŸäŸáÿß ÿ•ŸÑÿß ÿπŸÑŸä ÿ¨ÿ≥ÿ± ŸÖŸÜ ÿßŸÑÿ™ÿπÿ®‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúAll perfections are not achieved except through a portion of hardship, and they cannot be crossed except on a bridge of fatigue.‚Äù</li>
<li>Interpretation:&nbsp;This highlights that excellence and mastery require sustained effort, difficulty, and resilience.</li>
</ul></li>
<li><p><strong>‚Äúÿ™ŸÑŸÖÿ≠ ŸÅÿ¨ÿ± ÿßŸÑÿ£ÿ¨ÿ± ŸäŸáŸÜ ÿ∏ŸÑÿßŸÖ ÿßŸÑÿ™ŸÉŸÑŸäŸÅ‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúYou perceive the dawn of reward makes the darkness of duty pale.‚Äù</li>
<li>Interpretation:&nbsp;This suggests that the hope of reward and the meaningful impact of your work make the hard work and sacrifice worthwhile.</li>
</ul></li>
<li><p><strong>‚Äúÿ®ŸÇÿØÿ± ŸÖÿß ÿ™ÿ™ÿπŸÜŸä ÿ™ŸÜÿßŸÑ ŸÖÿß ÿ™ÿ™ŸÖŸÜŸä‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúTo the extent that you exert yourself, to that extent you will achieve what you desire.‚Äù</li>
<li>Interpretation:&nbsp;This is a direct statement of the relationship between effort and achievement.</li>
</ul></li>
<li><p><strong>‚ÄúŸàŸÑŸÖ ÿ™ÿπÿ∑ŸÜŸä ÿßŸÑÿ£ŸäÿßŸÖ ŸÜŸàŸÖÿß ŸÖÿ≥ŸÉŸÜÿß ÿ£ŸÑÿ∞ ÿ®Ÿá ÿå ÿ•ŸÑÿß ÿ®ŸÜŸàŸÖ ŸÖÿ¥ÿ±ÿØ‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúThe days have not given me a comforting sleep more delicious than a scattered one.‚Äù</li>
<li>Interpretation:&nbsp;This beautifully evokes the idea that true rest is often earned by hard work and might not always be the most comfortable.</li>
</ul></li>
<li><p><strong>‚ÄúŸà ÿßÿ∞ÿß ŸÉÿßŸÜÿ™ ÿßŸÑŸÜŸÅŸàÿ≥ ŸÉÿ®ÿßÿ±ÿß ÿ™ÿπÿ®ÿ™ ŸÅŸä ŸÖÿ±ÿßÿØŸáÿß ÿßŸÑÿ£ÿ¨ÿ≥ÿßŸÖ‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúIf the souls are great, the bodies will toil in pursuit of their desires.‚Äù</li>
<li>Interpretation:&nbsp;This highlights that ambitious goals require a commitment to hard work that will test the physical body.</li>
</ul></li>
<li><p><strong>‚ÄúŸàŸÉÿ∞ŸÑŸÉ Ÿäÿ≠ÿ∞ÿ± ŸÖŸÜ ÿßŸÑÿ™ŸÜŸÇŸÑ ŸÖŸÜ ŸÉÿ™ÿßÿ® ÿßŸÑŸä ŸÉÿ™ÿßÿ® ŸÖŸÜ ÿ∫Ÿäÿ± ŸÖŸàÿ¨ÿ® ŸÅÿ•ŸÜŸá ÿπŸÑÿßŸÖÿ© ÿßŸÑÿ∂ÿ¨ÿ± ŸàÿπÿØŸÖ ÿßŸÑŸÅŸÑÿßÿ≠‚Äù</strong></p>
<ul>
<li>Translation:&nbsp;‚ÄúLikewise, he warns against moving from book to book without a valid reason, for it is a sign of boredom and lack of success.‚Äù</li>
<li>Interpretation:&nbsp;This advises against haphazardly abandoning study materials, highlighting that deep learning comes from thorough exploration.</li>
</ul></li>
<li><p><strong>‚ÄúŸàÿ•ŸÜ ŸÖŸÜ ÿßŸÑÿ≠ŸÉŸÖÿ© ÿ£ŸÜ ŸÖŸÜ ÿßÿ®ÿ™ÿØÿ£ ÿ®ÿπŸÖŸÑ Ÿàÿßÿ±ÿ™ÿßÿ≠ ŸÑŸá ŸÅŸÑŸäÿ≥ÿ™ŸÖÿ± ÿπŸÑŸäŸá ÿå ŸÅŸÖŸÜ ÿ®Ÿàÿ±ŸÉ ŸÑŸá ŸÅŸä ÿ¥ÿ¶ ŸÅŸÑŸäŸÑÿ≤ŸÖŸá ÿå Ÿàÿ®ÿπÿ∂ ÿßŸÑŸÜÿßÿ≥ Ÿäÿ®ÿØÿ£ ÿßŸÑÿ£ÿπŸÖÿßŸÑ Ÿà ŸÑÿß Ÿäÿ™ŸÖŸÖŸáÿß ÿå ŸÅŸäŸÖÿ∂Ÿä ÿπŸÑŸäŸá ÿßŸÑŸàŸÇÿ™ ÿ≥ÿ®ŸáŸÑŸÑÿß ŸÖŸÜ ÿ∫Ÿäÿ± ŸÅÿßÿ¶ÿØÿ© ŸÅŸÖÿ´ŸÑÿß ŸäŸÇÿ±ÿßÿ° ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑŸÉÿ™ÿßÿ® ÿßŸà Ÿáÿ∞ÿß ÿßŸÑŸÅŸÜ ÿå ÿ´ŸÖ ŸäÿØÿπŸá ŸÖŸÜ ÿ∫Ÿäÿ± ÿßŸÜ ŸäŸÉŸÖŸÑŸá ŸàŸäŸÜÿ™ŸÇŸÑ ÿßŸÑŸä ÿ∫Ÿäÿ±Ÿá ÿå ÿ´ŸÖ ÿßŸÑŸä ÿßÿÆÿ± ÿå ŸÖŸÜ ÿ∫Ÿäÿ± ÿ™ŸÉŸÖŸäŸÑ ÿßŸÑÿ£ŸàŸÑ ŸÅŸäÿ∂Ÿäÿπ ÿπŸÖŸÑŸá ŸàŸäŸÜŸÇÿ∂Ÿä ÿπŸÖÿ±Ÿá ÿ®ŸÑÿß ŸÅÿßÿ¶ÿØÿ© ÿå ŸàŸÉÿ∞ŸÑŸÉ ŸÅŸä ÿßŸÑÿ£ÿπŸÖÿßŸÑ ÿßŸÑÿßÿÆÿ±Ÿä ŸÉŸÑ ŸäŸàŸÖ ŸÑŸá ÿπŸÖŸÑ ŸàŸÉŸÑ ÿπŸÖŸÑ ŸÑŸá ÿ±ÿßŸä ŸÅŸäÿ∂Ÿäÿπ ÿßŸÑŸàŸÇÿ™ ÿπŸÑŸäŸá ŸÖŸÜ ÿ∫Ÿäÿ± ŸÅÿßÿ¶ÿØÿ©‚Äù</strong> - Translation:&nbsp;‚ÄúAnd it is wisdom that whoever begins a work and finds comfort in it should continue with it. For whoever is blessed in something should stick to it. And some people begin tasks and do not complete them, so their time passes in vain without benefit. For example, they read in this book or this discipline and then leave it without completing it and move on to another and then another without completing the first, so they waste their work and their lives pass without benefit. And likewise in other works, each day has a work and each work has its own approach, so they waste time on that without benefit.‚Äù</p></li>
</ol>
<p>For opensource project i have a lot of coold projects that i strated and will start soon but didn‚Äôt complete any one yet and i know when i finish one i will get a job easly but this is what happend.</p>
</section>
<section id="imam-al-nawawi" class="level2">
<h2 class="anchored" data-anchor-id="imam-al-nawawi">Imam Al-Nawawi</h2>
<p>Al-Nawawi began his pursuit of knowledge relatively late, in the year 649 AH. He was, as he himself stated, 19 years old at that time. This was considered a late start compared to the custom of their time, where people would begin seeking knowledge before reaching puberty. As Al-Nawawi himself said, ‚ÄúWhen I was nineteen years old, my father brought me to Damascus in the year forty-nine, and I resided in the Rawahiyya School.‚Äù</p>
<p>Al-Nawawi, may God have mercy on him, passed away in the year 676 AH, at the age of 45. Scholars in their forties typically begin to produce their most refined and meticulously researched scholarly work. Thus, the Sheikh, may God have mercy on him, did not live long.</p>
<p>Well then‚Ä¶ when did the Sheikh begin writing and authoring? The Sheikh himself stated that he spent six years in the pursuit of knowledge, and then began authoring, i.e., he began authoring at the age of 25.</p>
<p>Al-Nawawi also informed his student, Ibn al-Attar:</p>
<p>‚ÄúHe mentioned to me, may God have mercy on him, that he did not waste any time, night or day, except in a task of engaging with knowledge. Even while walking on the streets, he would engage in reviewing what he had memorized or studying. He remained engaged in acquiring knowledge in this manner for about six years, and then he began writing.‚Äù</p>
<p>This means that most of Al-Nawawi‚Äôs works that we circulate today were authored during his twenties and thirties!</p>
<p>Al-Isnawi explains: ‚ÄúThis phenomenon with Sheikh Muhi al-Din al-Nawawi was quite common. It is that, when he became qualified to study and acquire knowledge, he saw that it was part of his striving towards good deeds to make what he acquired and understood into an authorship, from which the reader could benefit. Thus, he made his authoring a means of acquiring knowledge, and his acquiring knowledge a means of authoring. Without this, he would not have been able to produce the amount of authorship he did. He entered Damascus to study when he was eighteen years old, and died before he reached forty-six.‚Äù</p>
<p>Al-Isnawi‚Äôs point is that Al-Nawawi made his authoring a way to acquire and seek knowledge. He immediately put his seeking and acquiring of knowledge into the form of authorship, i.e., his notes during his pursuit of knowledge, he would convert them into a form of authorship, rather than allowing the notes of his youth to be wasted.</p>
<p>Was this a coincidence for Al-Nawawi, or was it a conscious behavior? Meaning, did Al-Nawawi keep in mind the benefit of authorship in educating the author himself? In fact, there is a statement of Al-Nawawi in his other book,&nbsp;Sharh al-Muhadhab, which reveals that his early attention to authorship was for the purposes of self-learning. In his introduction, where he explained the etiquette of a seeker of knowledge, Al-Nawawi stated:</p>
<p>‚ÄúOne should pay attention to ‚Äòauthoring‚Äô when one is qualified for it, for through it one discovers the realities and subtleties of knowledge, and it becomes established in one‚Äôs mind. It forces one to engage in extensive searching, studying, investigating, and reviewing, and to become acquainted with the different opinions of the Imams, their agreements, what is clear, what is ambiguous, what is authentic, what is weak, what is eloquent, what is feeble, what is not subject to objection, and what is. Through this, a researcher takes on the qualities of a&nbsp;mujtahid&nbsp;(one who can exercise independent legal reasoning).‚Äù</p>
<p>Here, Al-Nawawi is not just encouraging authoring, but he is revealing the motivations that drive authoring and expands on the effect it has on the advancement of the student‚Äôs understanding by obliging them to delve deeply.</p>
<p>Also, Al-Khatib Al-Baghdadi said: ‚ÄúWhoever wants to benefit, let them break the pen of copying and take up the pen of research.‚Äù</p>
<hr>
<p>And I‚Äôve noticed that a lot of prominent figures in Deep Learning (DL) are doing this. For example:</p>
<ol type="1">
<li><p><strong>Michael Lanham</strong>&nbsp;(<a href="https://www.google.com/url?sa=E&amp;q=https%3A%2F%2Fwww.amazon.com%2Fstores%2Fauthor%2FB07BPS6WQL">https://www.amazon.com/stores/author/B07BPS6WQL</a>): The author of:</p>
<ul>
<li>Evolutionary Deep Learning</li>
<li>Practical AI on the Google Platform</li>
<li>Learn Python Game Development with ChatGPT</li>
<li>and many other books.</li>
</ul></li>
<li><p><strong>Christoph Molnar</strong>&nbsp;(<a href="https://www.google.com/url?sa=E&amp;q=https%3A%2F%2Fchristophm.github.io%2Finterpretable-ml-book%2F">https://christophm.github.io/interpretable-ml-book/</a>): The author of&nbsp;Interpretable Machine Learning.</p></li>
<li><p><strong>Christopher M. Bishop</strong>&nbsp;(<a href="https://www.google.com/url?sa=E&amp;q=https%3A%2F%2Fwww.amazon.com%2Fstores%2FChristopher-M.-Bishop%2Fauthor%2FB001IGLMNY%3Fref%3Dap_rdr%26isDramIntegrated%3Dtrue%26shoppingPortalEnabled%3Dtrue%23">https://www.amazon.com/stores/Christopher-M.-Bishop/author/B001IGLMNY?ref=ap_rdr&amp;isDramIntegrated=true&amp;shoppingPortalEnabled=true#</a>): The author of the famous book,&nbsp;Pattern Recognition and Machine Learning. He once mentioned that he wrote this book to ensure his own understanding of these concepts.</p></li>
</ol>
<p>‚Ä¶ and the list goes on.</p>
<p><strong>My Approach: Building, Not Just Reading</strong></p>
<p>I don‚Äôt necessarily aspire to write a book, but rather to&nbsp;recreate&nbsp;knowledge from the sources I‚Äôve studied (books, courses, and papers). I don‚Äôt advocate for simply ‚Äúwriting a book‚Äù as a goal. Instead, I aim to create accessible pieces of knowledge that I can iterate on and use to help others understand these concepts.</p>
<p>This is my intended approach, and I will start with:</p>
<ol type="1">
<li><strong>‚ÄúBuilding DL from Scratch‚Äù Series:</strong>&nbsp;Based on the fastai course and the&nbsp;Deep Learning from Scratch&nbsp;book.</li>
<li><strong>‚ÄúMath Level Up for DL‚Äù:</strong>&nbsp;Based on multiple books, courses, and some experiments I want to conduct.</li>
</ol>
<p>Then, I will expand on these approaches in blog posts and other materials on topics like federated learning and other areas I‚Äôm interested in. I‚Äôll try my best to do all of this effectively.</p>
</section>
<section id="not-just-the-math" class="level2">
<h2 class="anchored" data-anchor-id="not-just-the-math">NOT Just the Math</h2>
<p>This approach isn‚Äôt limited to math. It extends to every skill, including CSS, Deep Learning implementation with pure PyTorch code, and so on.</p>
<p>‚Ä¶to be continued.</p>
<p>you can read:</p>
<ol type="1">
<li><a href="https://kareemai.com/blog/posts/fl/what_is_federated_learning.html">What is federated learning</a></li>
<li><a href="https://kareemai.com/blog/posts/life_style/kamcalorie.html">kam calorie</a></li>
</ol>


</section>

 ]]></description>
  <category>blogging</category>
  <category>ai</category>
  <category>math</category>
  <category>linear_algebra</category>
  <category>calculus</category>
  <category>statistics</category>
  <category>probability</category>
  <guid>https://kareemai.com/blog/posts/math/math_skills_for_AI.html</guid>
  <pubDate>Sun, 26 Jan 2025 22:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/math/images/Maslakiat.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑÿ∑ÿπÿßŸÖ ÿü</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/life_style/kamcalorie.html</link>
  <description><![CDATA[ 





<section id="ŸÉŸÖ-ŸÉÿßŸÑŸàÿ±Ÿä" class="level2">
<h2 class="anchored" data-anchor-id="ŸÉŸÖ-ŸÉÿßŸÑŸàÿ±Ÿä"><a href="https://www.kamcalorie.com/">ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä</a></h2>
<p>ŸÖŸàŸÇÿπ ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸáŸà ÿØŸÑŸäŸÑ ÿßŸÑŸÇÿßÿ±ÿ¶ ÿßŸÑÿπÿ±ÿ®Ÿä ÿßŸÑŸä ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© ŸÅŸä ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿ∑ÿπŸÖÿ© ÿ®ŸÖÿÆÿ™ŸÑŸÅ ÿßŸÑÿ®ŸÑÿØÿßŸÜ ŸàÿßŸÑŸÑŸáÿ¨ÿßÿ™ ÿå ÿØŸÑŸäŸÑŸÉ ŸÑŸÖÿπÿ±ŸÅÿ© ÿßŸÑŸÇŸäŸÖÿ© ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ© ŸÑŸáÿß ŸÖÿ´ŸÑ ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© Ÿà ÿßŸÑŸÖÿπÿßÿØŸÜ ŸàŸÜÿ≥ÿ® ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ Ÿà ÿßŸÑÿ≥ŸÉÿ±Ÿäÿßÿ™ ŸÑÿ≠ŸÖŸäÿ© ÿµÿ≠Ÿäÿ© Ÿà ŸÜÿ∏ÿßŸÖ ÿ∫ÿ∞ÿßÿ¶Ÿä ÿ£ŸÅÿ∂ŸÑ ÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ° ŸÖŸÜÿµÿ© ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ÿ®ŸáÿØŸÅ ÿ™ŸàŸÅŸäÿ±ŸÖÿµÿØÿ± ŸÖŸàÿ´ŸàŸÇ Ÿà ÿØŸÇŸäŸÇ ŸÑŸÑŸÇÿßÿ±ÿ¶ ÿßŸÑÿπÿ±ÿ®Ÿä ÿ®ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä</p>
</section>
<section id="ŸÖŸÖŸäÿ≤ÿßÿ™-ÿßŸÑŸÖŸàŸÇÿπ" class="level2">
<h2 class="anchored" data-anchor-id="ŸÖŸÖŸäÿ≤ÿßÿ™-ÿßŸÑŸÖŸàŸÇÿπ">ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑŸÖŸàŸÇÿπ</h2>
<p>ÿßŸÑŸÖŸàŸÇÿπ ŸÖÿ®ŸÜŸä ÿ®ŸáÿØŸÅ ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ™ŸÇŸÜŸäÿßÿ™ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÑÿ∫ÿßÿ™ ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸàÿßŸÑŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸäÿ© ŸÑÿ™ŸàŸÅŸäÿ± ŸÉÿßŸÅÿ© ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™Ÿä ŸÇÿØ Ÿäÿ≠ÿ™ÿßÿ¨Ÿáÿß ÿßŸÑŸÅÿ±ÿØ ŸÖÿ´ŸÑ: 1. ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ∞ŸÉŸä : ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÖÿπŸÜŸä ÿ≥Ÿàÿßÿ° ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ£Ÿà ÿßŸÑÿ•ŸÜÿ¨ŸäŸÑŸäÿ≤Ÿäÿ© Ÿàÿ≠ÿ™Ÿä ŸÉÿßŸÅÿ© ÿßŸÑŸÑÿ∫ÿßÿ™ Ÿà ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿßŸä ÿ∑ÿ±ŸäŸÇÿ© ÿ≥Ÿàÿßÿ° ŸÑÿ∫ÿ© ÿπÿ±ÿ®Ÿäÿ© ŸÅÿµÿ≠Ÿäÿ© ÿßŸà ÿßŸÑÿπÿßŸÖŸäÿ© ÿßŸà ÿ≠ÿ™Ÿä ÿ£ÿÆÿ∑ÿßÿ° ÿ•ŸÖŸÑÿßÿ¶Ÿäÿ© 2. ÿ≥ÿ±ÿπÿ© ŸÅŸä ÿ•ÿ≥ÿ™ÿ±ÿßÿ¨ÿßÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ Ÿàÿπÿ±ÿ∂Ÿáÿß ŸÅŸä ÿ¥ŸÉŸÑ ÿ®ŸäÿßŸÜŸä ŸÖŸÖŸäÿ≤ Ÿäÿ≥ŸÖÿ≠ ŸÑŸÉ ÿ®ŸÖÿπÿ±ŸÅÿ© ÿßŸÑŸÖŸáŸÖ ŸÅŸä ŸàŸÇÿ™ ŸÅŸàÿ±Ÿä 3. ŸäŸÖŸÉŸÜŸÉ ÿ•ÿØÿÆÿßŸÑ ŸÖÿß ÿ£ŸÉŸÑ ÿ®ÿ¥ŸÉŸÑ ŸÉÿßŸÖŸÑ Ÿà ÿßŸÑŸÖŸàŸÇÿπ ŸäŸÇŸàŸÖ ÿ®ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿ™ŸÇÿØŸäÿ±ÿßÿ™ ÿßŸÑŸÑÿßÿ≤ŸÖÿ© ŸÑŸÉ</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/kcal.png" class="img-fluid figure-img"></p>
<figcaption>ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä</figcaption>
</figure>
</div>
<hr>
</section>
<section id="ÿÆÿßÿ™ŸÖÿ©" class="level2">
<h2 class="anchored" data-anchor-id="ÿÆÿßÿ™ŸÖÿ©">ÿÆÿßÿ™ŸÖÿ©</h2>
<p>Ÿäÿπÿ™ÿ®ÿ± ŸÖŸàŸÇÿπ ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ÿ®ÿØÿßŸäÿ© ÿßŸÑŸä ÿ≥ŸÑÿ≥ŸÑÿ© ŸÖŸÖŸÜ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ≥ŸáŸÑ ÿπŸÑŸä ÿßŸÑŸÜÿßÿ∑ŸÇŸäŸÜ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÖŸÖÿßÿ±ÿ≥ÿ© ÿßŸÑÿ±Ÿäÿßÿ∂ÿ© Ÿà ŸÑÿπŸäÿ¥ ÿ≠Ÿäÿßÿ© ÿ£ŸÅÿ∂ŸÑ Ÿà ŸáŸÜÿßŸÉ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÇÿßÿØŸÖ ŸÖÿ´ŸÑ : 1. ŸÉŸàÿ® ÿ®ÿ±Ÿàÿ™ŸäŸÜ 2. ÿπÿ∂ŸÑÿßÿ™Ÿä</p>
<p>ŸÇÿßŸÖ ÿ®ÿ™ÿ∑ŸàŸäÿ± Ÿà ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑŸÖŸàŸÇÿπ ÿπÿ®ÿØ ÿßŸÑŸÉÿ±ŸäŸÖ ÿßŸÑÿÆÿ∑Ÿäÿ® ÿ®ÿßÿ≠ÿ´ ŸÅŸä ÿπŸÑŸàŸÖ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä Ÿà ŸÖŸáÿ™ŸÖ ÿ®ÿßÿ´ÿ±ÿßÿ° ÿßŸÑŸÖÿ≠ÿ™ŸàŸä ÿßŸÑÿπÿ±ÿ®Ÿä</p>


</section>

 ]]></description>
  <category>blogging</category>
  <category>idea_Forge</category>
  <category>publish</category>
  <category>rough_thoughts</category>
  <category>life_style</category>
  <guid>https://kareemai.com/blog/posts/life_style/kamcalorie.html</guid>
  <pubDate>Tue, 07 Jan 2025 22:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/life_style/images/kcal.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>ÿßŸÅÿ∂ŸÑ ÿßŸÜŸàÿßÿπ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/life_style/protienai.html</link>
  <description><![CDATA[ 





<p><strong>ÿ£ŸÅÿ∂ŸÑ ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸàÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑŸÑÿ™ÿ∂ÿÆŸäŸÖ ŸÖŸÜ ŸÖŸàŸÇÿπ Proteinai</strong></p>
<p>ŸáŸÑ ÿ™ÿ®ÿ≠ÿ´ ÿπŸÜ ÿ£ŸÅÿ∂ŸÑ ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸàÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ Ÿàÿ™ÿ≠ŸÇŸäŸÇ ŸÜÿ™ÿßÿ¶ÿ¨ ŸÖÿ∞ŸáŸÑÿ© ŸÅŸä ÿßŸÑÿ™ÿ∂ÿÆŸäŸÖÿü ŸÖŸàŸÇÿπ <a href="https://www.protienai.com">ŸÖÿ≥ÿßÿ≠ŸäŸÇ ŸÉÿ±Ÿäÿßÿ™ŸäŸÜ Ÿà ÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ</a> ŸáŸà ÿßŸÑŸàÿ¨Ÿáÿ© ÿßŸÑŸÖÿ´ÿßŸÑŸäÿ© ÿßŸÑÿ™Ÿä ÿ™ŸàŸÅÿ± ŸÑŸÉ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖŸàÿßÿ±ÿØ ŸàÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÑÿßÿ≤ŸÖÿ© ŸÑÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑŸÖŸÉŸÖŸÑÿßÿ™ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ© ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ© ŸÑÿ™ÿ≠ŸÇŸäŸÇ ÿ£ŸáÿØÿßŸÅŸÉ.</p>
<section id="ŸÖÿß-ÿßŸÑÿ∞Ÿä-Ÿäÿ¨ÿπŸÑ-ŸÖŸàŸÇÿπ-proteinai-ŸÖŸÖŸäÿ≤ÿß" class="level2">
<h2 class="anchored" data-anchor-id="ŸÖÿß-ÿßŸÑÿ∞Ÿä-Ÿäÿ¨ÿπŸÑ-ŸÖŸàŸÇÿπ-proteinai-ŸÖŸÖŸäÿ≤ÿß"><strong>ŸÖÿß ÿßŸÑÿ∞Ÿä Ÿäÿ¨ÿπŸÑ ŸÖŸàŸÇÿπ Proteinai ŸÖŸÖŸäÿ≤Ÿãÿßÿü</strong></h2>
<section id="ŸÖÿ±ÿßÿ¨ÿπÿßÿ™-ŸÖÿ™ÿÆÿµÿµÿ©-ŸàŸÖŸÇÿßÿ±ŸÜÿßÿ™-ÿ¥ÿßŸÖŸÑÿ©" class="level3">
<h3 class="anchored" data-anchor-id="ŸÖÿ±ÿßÿ¨ÿπÿßÿ™-ŸÖÿ™ÿÆÿµÿµÿ©-ŸàŸÖŸÇÿßÿ±ŸÜÿßÿ™-ÿ¥ÿßŸÖŸÑÿ©"><strong>1. ŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ŸÖÿ™ÿÆÿµÿµÿ© ŸàŸÖŸÇÿßÿ±ŸÜÿßÿ™ ÿ¥ÿßŸÖŸÑÿ©</strong></h3>
<p>ŸäŸÇÿØŸÖ ŸÖŸàŸÇÿπ <a href="https://www.protienai.com">ŸÖÿ≥ÿßÿ≠ŸäŸÇ ŸÉÿ±Ÿäÿßÿ™ŸäŸÜ Ÿà ÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ</a> ŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ÿØŸÇŸäŸÇÿ© ŸàŸÖÿ≥ÿ™ŸÇŸÑÿ© ŸÑÿ£ÿ¥Ÿáÿ± ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸàÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÅŸä ÿßŸÑÿ≥ŸàŸÇ. ŸÖŸÜ ÿ®ŸäŸÜ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿßŸÑÿ™Ÿä Ÿäÿ∫ÿ∑ŸäŸáÿß ÿßŸÑŸÖŸàŸÇÿπ:</p>
<ul>
<li><strong>ÿ±ŸäÿØÿ±ŸäŸÉÿ≥ ÿ®Ÿäÿ¨ ÿ±ÿßŸÖŸä ŸÑÿßÿ®ÿ≥</strong></li>
<li><strong>Rival Nutrition - Rival Whey</strong></li>
<li><strong>MuscleTech - Nitro Tech Ripped</strong></li>
<li><strong>Dymatize - ISO100</strong></li>
</ul>
<p>ÿ™ÿ≥ÿßÿπÿØŸÉ ÿßŸÑŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ÿπŸÑŸâ ŸÅŸáŸÖ ÿßŸÑŸÖÿ≤ÿßŸäÿß ŸàÿßŸÑÿπŸäŸàÿ® ŸÑŸÉŸÑ ŸÖŸÜÿ™ÿ¨ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ≥ÿπÿ±ÿå ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿå ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™ÿå ŸàÿßŸÑŸÅÿπÿßŸÑŸäÿ©. ÿ®ÿßŸÑÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ ÿ∞ŸÑŸÉÿå ŸäŸàŸÅÿ± ÿßŸÑŸÖŸàŸÇÿπ ÿÆÿßÿµŸäÿ© ÿßŸÑŸÖŸÇÿßÿ±ŸÜÿßÿ™ ÿ¨ŸÜÿ®Ÿãÿß ÿ•ŸÑŸâ ÿ¨ŸÜÿ® ŸÑÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿ£ŸÜÿ≥ÿ®.</p>
</section>
<section id="ÿ™ÿµŸÜŸäŸÅÿßÿ™-ŸÖÿ®ÿ≥ÿ∑ÿ©-ŸÑÿ≥ŸáŸàŸÑÿ©-ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±" class="level3">
<h3 class="anchored" data-anchor-id="ÿ™ÿµŸÜŸäŸÅÿßÿ™-ŸÖÿ®ÿ≥ÿ∑ÿ©-ŸÑÿ≥ŸáŸàŸÑÿ©-ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±"><strong>2. ÿ™ÿµŸÜŸäŸÅÿßÿ™ ŸÖÿ®ÿ≥ÿ∑ÿ© ŸÑÿ≥ŸáŸàŸÑÿ© ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±</strong></h3>
<p>Ÿäÿ≥ŸáŸëŸÑ ÿßŸÑŸÖŸàŸÇÿπ ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´ ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ™ŸÜÿ∏ŸäŸÖ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿ∂ŸÖŸÜ ŸÅÿ¶ÿßÿ™ ŸÖÿ≠ÿØÿØÿ© ÿ™ŸÜÿßÿ≥ÿ® ÿßÿ≠ÿ™Ÿäÿßÿ¨ÿßÿ™ŸÉÿå ŸÖÿ´ŸÑ:</p>
<ul>
<li><strong>ÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ (ÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ)</strong></li>
<li><strong>ÿ•ŸÜŸÇÿßÿµ ÿßŸÑŸàÿ≤ŸÜ (ÿßŸÑÿ™ŸÜÿ¥ŸäŸÅ)</strong></li>
<li><strong>ÿßŸÑÿ™ÿπÿßŸÅŸä ÿßŸÑÿπÿ∂ŸÑŸä</strong></li>
<li><strong>ÿßÿ≥ÿ™ÿ®ÿØÿßŸÑ ÿßŸÑŸàÿ¨ÿ®ÿßÿ™</strong></li>
<li><strong>ÿÆÿßŸÑŸä ŸÖŸÜ ÿßŸÑÿ∫ŸÑŸàÿ™ŸäŸÜ</strong></li>
<li><strong>ŸÜÿ®ÿßÿ™Ÿä</strong></li>
<li><strong>ÿπÿ∂ŸàŸä</strong></li>
</ul>
</section>
<section id="ÿ£ÿØŸàÿßÿ™-ŸàŸÖŸàÿßÿ±ÿØ-ÿ™ÿπŸÑŸäŸÖŸäÿ©" class="level3">
<h3 class="anchored" data-anchor-id="ÿ£ÿØŸàÿßÿ™-ŸàŸÖŸàÿßÿ±ÿØ-ÿ™ÿπŸÑŸäŸÖŸäÿ©"><strong>3. ÿ£ÿØŸàÿßÿ™ ŸàŸÖŸàÿßÿ±ÿØ ÿ™ÿπŸÑŸäŸÖŸäÿ©</strong></h3>
<p>ÿ•ŸÑŸâ ÿ¨ÿßŸÜÿ® ÿßŸÑŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ŸàÿßŸÑŸÖŸÇÿßÿ±ŸÜÿßÿ™ÿå ŸäŸÇÿØŸÖ ÿßŸÑŸÖŸàŸÇÿπ ŸÖÿ¨ŸÖŸàÿπÿ© ŸÖŸÜ ÿßŸÑÿ£ÿØŸàÿßÿ™ ŸàÿßŸÑŸÖŸàÿßÿ±ÿØ ŸÑŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ÿπŸÑŸâ ÿßÿ™ÿÆÿßÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ŸÖÿØÿ±Ÿàÿ≥ÿ©:</p>
<ul>
<li><strong>ÿØŸÑŸäŸÑ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ:</strong> ŸäŸàŸÅÿ± ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ¥ÿßŸÖŸÑÿ© ÿ≠ŸàŸÑ ÿ£ŸÜŸàÿßÿπ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ©ÿå ŸÅŸàÿßÿ¶ÿØŸáÿßÿå ŸàŸÖÿ™Ÿâ Ÿäÿ¨ÿ® ÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸáÿß.</li>
<li><strong>ŸÇÿßÿπÿØÿ© ÿßŸÑŸÖÿπÿ±ŸÅÿ©:</strong> ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ¥ÿ±ÿ≠ ŸàÿßŸÅŸç ŸÑŸÑŸÖŸÉŸàŸÜÿßÿ™ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ŸÅŸä ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸàÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ.</li>
<li><strong>ÿ£ÿ≠ÿØÿ´ ÿßŸÑÿ£ÿÆÿ®ÿßÿ± ŸàÿßŸÑŸÖŸÇÿßŸÑÿßÿ™:</strong> ÿ™ÿ®ŸÇŸäŸÉ ÿπŸÑŸâ ÿßÿ∑ŸÑÿßÿπ ÿØÿßÿ¶ŸÖ ÿ®ÿ£ÿ≠ÿØÿ´ ÿßŸÑÿ™ÿ∑Ÿàÿ±ÿßÿ™ ŸÅŸä ŸÖÿ¨ÿßŸÑ ÿßŸÑŸÖŸÉŸÖŸÑÿßÿ™ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ©.</li>
</ul>
</section>
</section>
<section id="ŸÑŸÖÿßÿ∞ÿß-ÿ™ÿÆÿ™ÿßÿ±-proteinai" class="level2">
<h2 class="anchored" data-anchor-id="ŸÑŸÖÿßÿ∞ÿß-ÿ™ÿÆÿ™ÿßÿ±-proteinai"><strong>ŸÑŸÖÿßÿ∞ÿß ÿ™ÿÆÿ™ÿßÿ± Proteinaiÿü</strong></h2>
<ol type="1">
<li><strong>ÿ¥ŸÅÿßŸÅŸäÿ© ŸÉÿßŸÖŸÑÿ©:</strong> ŸäŸÇÿØŸÖ ÿßŸÑŸÖŸàŸÇÿπ ŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ÿØŸÇŸäŸÇÿ© ÿ∫Ÿäÿ± ŸÖÿ™ÿ≠Ÿäÿ≤ÿ©.</li>
<li><strong>ÿ≥ŸáŸàŸÑÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ:</strong> ÿ™ÿµŸÖŸäŸÖ ÿ®ÿ≥Ÿäÿ∑ ŸàŸàÿßÿ¨Ÿáÿ© ŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÖÿ±Ÿäÿ≠ÿ©.</li>
<li><strong>ÿ™ŸÜŸàÿπ ÿßŸÑÿÆŸäÿßÿ±ÿßÿ™:</strong> ÿ™ÿ∫ÿ∑Ÿäÿ© ÿ¥ÿßŸÖŸÑÿ© ŸÑÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ŸÅŸä ÿßŸÑÿ≥ŸàŸÇ.</li>
</ol>
<p>ÿßÿ≥ÿ™ŸÅÿØ ÿßŸÑÿ¢ŸÜ ŸÖŸÜ ŸÖŸàŸÇÿπ <a href="https://www.protienai.com">ŸÖÿ≥ÿßÿ≠ŸäŸÇ ŸÉÿ±Ÿäÿßÿ™ŸäŸÜ Ÿà ÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ</a> ŸÑÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑŸÖŸÉŸÖŸÑ ÿßŸÑŸÖÿ´ÿßŸÑŸä ŸÑÿ™ÿ≠ŸÇŸäŸÇ ÿ£ŸáÿØÿßŸÅŸÉ ÿßŸÑÿ±Ÿäÿßÿ∂Ÿäÿ© ŸàÿßŸÑÿµÿ≠Ÿäÿ©.</p>
<p>ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÖŸàŸÇÿπ ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÑŸÖÿπÿ±ŸÅÿ© ŸÉÿßŸÅÿ© ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© ÿßŸäÿ∂ÿß: 1. <a href="https://www.kamcalorie.com">ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ÿ®ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä</a></p>


</section>

 ]]></description>
  <category>blogging</category>
  <category>idea_Forge</category>
  <category>publish</category>
  <category>rough_thoughts</category>
  <category>life_style</category>
  <guid>https://kareemai.com/blog/posts/life_style/protienai.html</guid>
  <pubDate>Tue, 07 Jan 2025 22:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/life_style/images/proteinai.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>What is Federated Learning</title>
  <link>https://kareemai.com/blog/posts/fl/what_is_federated_learning.html</link>
  <description><![CDATA[ 





<p>You‚Äôre on a mission to create the purest, sweetest, and healthiest honey in the world. As a mad scientist, you want to improve your beehive‚Äôs efficiency and ensure no one can steal your secret recipe for magic honey.<br>
After researching how to set up your beehive system‚Äîhow the bees should communicate, and where to collect nectar in a protected way to guard against wasps that want to steal your honey and harm your beehive‚Äîyou discover that a Federated Beehive could meet all your needs. However, it adds complexity to your system and requires a new mindset.</p>
<section id="traditional-ml-systems-centralized" class="level2">
<h2 class="anchored" data-anchor-id="traditional-ml-systems-centralized">Traditional ML Systems (Centralized)</h2>
<p>In centralized systems, you collect flowers into your beehive and start processing them to create honey, which is not secure since people will know the type of flower on its way.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/fl/images/centralized_learning.png" class="img-fluid figure-img"></p>
<figcaption>centralized Learning</figcaption>
</figure>
</div>
<p>In centralized systems, we aggregate data from multiple sources into a specific center where training occurs, consuming significant bandwidth and moving user data off their devices.</p>
</section>
<section id="federated-learning-decentralized" class="level2">
<h2 class="anchored" data-anchor-id="federated-learning-decentralized">Federated Learning (Decentralized)</h2>
<p>In FL, your bees visit different types of flowers to collect nectar and bring it back to your beehive in a fast and efficient way. The nectar is covered in a protective container to prevent the scent from attracting dark wasps and others in the world. While this approach is secure and efficient, it requires more overhead in managing bee communication globally, combining diverse nectar, and handling potential issues like poisoned nectar that could harm your entire honey supply.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/fl/images/federate_learning.png" class="img-fluid figure-img"></p>
<figcaption>federated learning</figcaption>
</figure>
</div>
</section>
<section id="introduction-to-federated-learning" class="level2">
<h2 class="anchored" data-anchor-id="introduction-to-federated-learning">Introduction to Federated Learning</h2>
<p><strong>Definition:</strong> Federated Learning (FL) enables machine learning models on distributed data by moving the training to the data, instead of transferring data to the training center.</p>
<p>FL was first developed by Google in 2016 for their Gboard application, which uses a user‚Äôs typing history to suggest corrections and predict upcoming words while preserving user data privacy.</p>
<p>The idea is as follows: distribute our model across Android users‚Äô applications, train their data locally on their phones, and then aggregate the knowledge each user has learned using aggregation algorithms like FedAvg to combine the updates into a single global model.</p>
<p>This process must be repeated for multiple rounds to allow the model to learn from these small updates.</p>
</section>
<section id="honey-with-multiple-flavors" class="level2">
<h2 class="anchored" data-anchor-id="honey-with-multiple-flavors">Honey with Multiple Flavors</h2>
<p>We decided to offer honey jars with multiple flavors based on the flower types from which nectar was collected. We‚Äôll create a base flavor that everyone recognizes, plus special flavors with unique ingredients‚Äîsome containing vitamin C, others a dose of caffeine.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/fl/images/multiple_honey_flavors.png" class="img-fluid figure-img"></p>
<figcaption>Personalization in Federated Learning</figcaption>
</figure>
</div>
<p>In FL, this is called <strong>personalization</strong>. It can be seen as fine-tuning our global model (the base taste) with local data (special flowers) to meet specific needs.<br>
Since these unique flavors are likely to appeal only to certain local customers, they won‚Äôt be as popular with all customers compared to the base taste.</p>
<p>Our personalized model will excel on local data but may underperform on general data due to increased bias from fine-tuning.</p>
<p>An FL system allows us to manage the trade-off between user-specific preferences and generalization.</p>
</section>
<section id="horizontal-and-vertical-fl" class="level2">
<h2 class="anchored" data-anchor-id="horizontal-and-vertical-fl">Horizontal and Vertical FL</h2>
<p>There are two types of FL: Horizontal (homogeneous) FL and Vertical (heterogeneous) FL.</p>
<section id="horizontal-federated-learning" class="level3">
<h3 class="anchored" data-anchor-id="horizontal-federated-learning">Horizontal Federated Learning</h3>
<p>Imagine our bees extracting nectar from the same type of flower in different places and in various quantities.</p>
<p>An example of horizontal FL is the Gboard application, where local training on phones uses identical data formats with unique content reflecting the user‚Äôs typing history.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/fl/images/horizontal_fl.png" class="img-fluid figure-img"></p>
<figcaption>Horizontal Federated Learning</figcaption>
</figure>
</div>
</section>
<section id="vertical-federated-learning" class="level3">
<h3 class="anchored" data-anchor-id="vertical-federated-learning">Vertical Federated Learning</h3>
<p>For a new honey type, we instruct our bees to collect nectar from different plants with unique characteristics, creating a distinctive honey.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/fl/images/vertical_fl.png" class="img-fluid figure-img"></p>
<figcaption>Vertical Federated Learning</figcaption>
</figure>
</div>
</section>
</section>
<section id="why-fl-instead-of-centralized-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="why-fl-instead-of-centralized-machine-learning">Why FL instead of Centralized Machine Learning?</h2>
<ol type="1">
<li><strong>Centralized Learning</strong> lacks security, making FL essential for industries like banking and healthcare.</li>
<li><strong>Private data</strong> availability surpasses public data, offering more insights and patterns to uncover new abilities.</li>
<li><strong>User preference:</strong> Some users expect that no data will leave their device. For example, entering passwords or credit card information should not send those details to a keyboard app‚Äôs server. This use case led to FL‚Äôs development.</li>
<li><strong>Regulations:</strong> Various data privacy laws (GDPR, CCPA, etc.) protect sensitive data from being transferred. Regulations may even prohibit organizations from merging their users‚Äô data across different countries.</li>
<li><strong>Reduced Compute Costs:</strong> Centralized ML with large datasets demands high computational resources, limited by individual machine performance.</li>
<li><strong>Faster Training:</strong> With FL, models can train immediately after receiving data, providing users with faster, more responsive solutions.</li>
</ol>
</section>
<section id="are-we-running-out-of-training-data-for-genai" class="level2">
<h2 class="anchored" data-anchor-id="are-we-running-out-of-training-data-for-genai">Are We Running Out of Training Data for GenAI?</h2>
<p>Most LLMs are trained on publicly available web data, but there‚Äôs a need for diverse data across modalities (text, images, audio, video). LLM architectures are similar, but the data they are trained or fine-tuned on is crucial. FL can help by enabling training on:</p>
<ol type="1">
<li>Private data
<ul>
<li>Phones</li>
<li>Emails</li>
</ul></li>
<li>Regulated data
<ul>
<li>Financial</li>
<li>Legal</li>
</ul></li>
<li>Sensitive data
<ul>
<li>Doorbell camera images</li>
<li>Medical</li>
</ul></li>
<li>Isolated data
<ul>
<li>Manufacturing</li>
<li>Automotive</li>
</ul></li>
</ol>
</section>
<section id="wasps-attacking-your-data" class="level2">
<h2 class="anchored" data-anchor-id="wasps-attacking-your-data">Wasps Attacking Your Data</h2>
<p>Federated Learning minimizes data exposure, but gaps in federated systems still need secure solutions.</p>
<section id="privacy-attacks-on-federated-systems" class="level3">
<h3 class="anchored" data-anchor-id="privacy-attacks-on-federated-systems">Privacy Attacks on Federated Systems</h3>
<ul>
<li><strong>Membership Inference Attack:</strong> Identifies whether specific data samples were used in training.</li>
<li><strong>Attribute Inference Attack:</strong> Infers unseen attributes of training data.</li>
<li><strong>Reconstruction Attack:</strong> Reconstructs specific training data samples.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/fl/images/privacy_attack.png" class="img-fluid figure-img"></p>
<figcaption>Privacy Attacks on Federated Learning</figcaption>
</figure>
</div>
<p>We‚Äôll explore different types of FL attacks and create defenses in a future blog post.</p>
</section>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<p>In upcoming posts, I will explain the components of Federated Learning in greater detail, including math, code, and more beekeeping analogies.</p>
<ol type="1">
<li><a href="https://flower.ai/docs/framework/tutorial-series-what-is-federated-learning.html#Challenges-of-classical-machine-learning">Flower Framework</a></li>
</ol>


</section>
</section>

 ]]></description>
  <category>blogging</category>
  <category>publish</category>
  <category>fl</category>
  <guid>https://kareemai.com/blog/posts/fl/what_is_federated_learning.html</guid>
  <pubDate>Mon, 11 Nov 2024 22:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/fl/images/federate_learning.png" medium="image" type="image/png" height="151" width="144"/>
</item>
<item>
  <title>Google Ads Black Box</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/seo/google_ads_black_box.html</link>
  <description><![CDATA[ 





<section id="can-a-web-developer-creat-a-google-ad" class="level2">
<h2 class="anchored" data-anchor-id="can-a-web-developer-creat-a-google-ad">Can a web developer creat a google ad</h2>
<p>My cousin told me that he can‚Äôt create an ad for his work and he had a verified business profile, so i told him give you the website and i can do it in just few minutes. I opened google ads and created an account followed the instructions and added my visa then after one day the ad started to work.</p>
<p>Then i noticed that i want to change the ad to make it more advanced for mobile calls. I paused it and created a new one, then my account get suspended and the reason is because circumvengint systems policy! Okey, then what is the wrong? Submit an appeal and add the needed documents to get verfified and after 15 days there is no response and the account is still suspended, what about the money i give to the add and neither me or google is using it! It had fly with wind.</p>
</section>
<section id="another-try" class="level2">
<h2 class="anchored" data-anchor-id="another-try">Another try</h2>
<p>I toke my friend account, which is used for around 5 years on google ads and has spent a lot of money i create the ad with a different domain for the website and didn‚Äôt add the business profile and my identifiy is verified‚Ä¶etc my account get suspened immeditialy ? WTF!</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final thoughts</h2>
<ol type="1">
<li>Dont‚Äô add huge amount of money, add only 5$ with 5$ until everything is okey you can increase it abit for example 50$ per day.</li>
<li>Google Ads is a black box! What, why, when, how are irrelevant.: Go ahead and create a new account and do the advertiser verification before creating any campaign. You can try creating a new google ad account with same email ID first and same payment method. Google allows multiple ad accounts with single email. Yes I know they say that you cannot create new account but trust me they do not follow this. I have multiple stable accounts running under same email IDs which also have suspended accounts. Just get those ads live whatever it takesü•Ç <a href="https://www.reddit.com/r/googleads/comments/1fu5acv/suspended_account/">reddit answer</a></li>
</ol>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://kareemai.com/blog/posts/seo/how_i_use_nlp_for_seo.html">nlp for seo</a></li>
<li><a href="https://kareemai.com/blog/posts/seo/the_curse_of_seo.html">seo if overated</a></li>
<li><a href="https://support.google.com/adspolicy/answer/2375414?hl=en">google help</a></li>
<li><a href="https://oudhmotors.com/">ÿ≠ÿ¨ÿ≤ ŸÖŸàÿπÿØ ŸÅÿ≠ÿµ ÿßŸÑŸÖÿ±ŸÉÿ®ÿßÿ™ ÿ®ÿßŸÑÿØŸÖÿßŸÖ</a></li>
</ol>


</section>

 ]]></description>
  <category>blogging</category>
  <category>publish</category>
  <category>google</category>
  <category>seo</category>
  <category>ads</category>
  <guid>https://kareemai.com/blog/posts/seo/google_ads_black_box.html</guid>
  <pubDate>Fri, 04 Oct 2024 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/seo" medium="image"/>
</item>
<item>
  <title>Learning Data Structures and Algorithms as Machine Learning Engineer</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/ds_and_algo/master_ds.html</link>
  <description><![CDATA[ 





<section id="why-revisit-ds-and-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="why-revisit-ds-and-algorithms">Why revisit DS and algorithms</h2>
<ul>
<li><p>I am a fresh graduate from AI college, i spent the last 4 years learning about both Computer science and AI.</p></li>
<li><p>I was learning some math, machine learning , Deep learning and a lot of programming with python and C++, spent some a lot of time learning web also for freelance jobs.</p></li>
<li><p>a lot of time i had multiple interviews while i was a student in the summer and all the time the questions was about linkedlist, and some medium leetcode question and a few of them was about frameworks like pytorch or pandas.</p></li>
<li><p>I faced a strange fact when i started to work on life projects or some advanced books‚Ä¶etc they require a strong problem solving skills that i don‚Äôt have!!</p></li>
<li><p>I am revisiting these topics and will try to get out from the juypter notebook and kaggle world in software engineer with python and focus more on open source projects.</p></li>
<li><p>I want to reazlie the time/memeory order of the data structures i am using in my projects</p></li>
<li><p>I have read the algorithm book v3 and spent 6 months on codeforces with c++ i remember these days where i could spent around 10 hours per day solving problems with myself before the AI assistants like GPT..etc i am missing the good feeling after every problem i manage to solve and i was able to write around 90 lines of code without research or AI help..etc.</p></li>
<li><p>I will start learning again about this topics and make them a daily habit to solve a problem per day: - <a href="https://www.manning.com/books/grokking-data-structures">[grokking_ds]</a> - it‚Äôs a new book about data structure in python and explained with the grokking style</p></li>
<li><p><a href="https://www.udemy.com/course/python-ds-skills/">[DS with python]</a> - it‚Äôs a mostafa saad ibrhaim udemy course with python version with a lot of problems to solve</p></li>
<li><p><a href="https://neetcode.io/roadmap">[neetcode]</a> - a roadmap to focus on some problems selected from neetcode</p></li>
<li><p><a href="https://codingchallenges.fyi/">[coding challenges]</a> - A SE problems to help you focus more on how to build projects not just problem solving which will help me to start doing some open source</p></li>
</ul>
<section id="times-i-needed-ds" class="level3">
<h3 class="anchored" data-anchor-id="times-i-needed-ds">times i needed DS</h3>
<pre><code>- multiple time when i was trying to building some solutions related to NLP or graph neural network i know that this problem must solved with Linkedlist and this needs a type of tree then i struggle to continue....
- Learning about some NLP Algorithms or the new searching and matching techniques most of the time they are math equations with some optimizations you can't fully understand unless your skills in problem solving
- research in DL needs a huge skills in problem solving and how to understand the following architectures then update or utilize them to your needs more in this in the future but i think the better you are in SE the better you are in ML.</code></pre>
</section>
<section id="topics" class="level3">
<h3 class="anchored" data-anchor-id="topics">Topics</h3>
<ol type="1">
<li><a href="https://kareemai.com/blog/posts/ds_and_algo/Static_array.html">Arrays</a></li>
</ol>


</section>
</section>

 ]]></description>
  <guid>https://kareemai.com/blog/posts/ds_and_algo/master_ds.html</guid>
  <pubDate>Thu, 03 Oct 2024 21:00:00 GMT</pubDate>
</item>
<item>
  <title>Review of Huawei watch gt 4</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/products_reviews/Huawei_watch_gt_4_experience.html</link>
  <description><![CDATA[ 





<section id="buying-the-huawei-gt4" class="level2">
<h2 class="anchored" data-anchor-id="buying-the-huawei-gt4">Buying the Huawei GT4</h2>
<ul>
<li>I bought it from Amazon for 13,000 EGP. I opened it immediately, and it looked so nice; I was very happy with its design and feel.</li>
<li>I charged it with the wireless stand.</li>
<li>I wore it after an hour and took some time to download the Huawei Health app on my Realme6 mobile.</li>
</ul>
</section>
<section id="feeling-pain" class="level2">
<h2 class="anchored" data-anchor-id="feeling-pain">Feeling pain</h2>
<ul>
<li>I wore it, and after three days, my hand started to hurt, causing some discomfort because I was sleeping with it on without removing it.</li>
<li>I wore it on my right hand for four days, then switched it to my left hand, and my body felt more comfortable with it.</li>
</ul>
</section>
<section id="the-design-of-the-huawei-watch-gt4" class="level2">
<h2 class="anchored" data-anchor-id="the-design-of-the-huawei-watch-gt4">The Design of the Huawei watch gt4</h2>
<ul>
<li>The design is attractive, and many people who saw me wearing it didn‚Äôt notice that it was a smartwatch‚Äîthey thought it was a classic watch.</li>
<li>Others said that it looks better than the repetitive and dull design of the Apple Watch.</li>
<li>It looks very premium.</li>
<li>The brightness in sunlight is impressive.</li>
</ul>
</section>
<section id="sleeping-with-huawei-watch-gt4" class="level2">
<h2 class="anchored" data-anchor-id="sleeping-with-huawei-watch-gt4">Sleeping with Huawei watch gt4</h2>
<ul>
<li>The accuracy of the sleep detector is almost perfect. Sometimes, when you leave the watch near you for 6 hours, it detects that you are sleeping, but this has only happened maybe three times this year.</li>
<li>The accuracy of detecting sleep cycles and the time for each is spot on, and the graph analysis and statistics on this watch are easy to understand, creative, and full of information.</li>
<li>Why can‚Äôt I set an alarm based on the sleep cycle, like in the <a href="https://www.sleepcycle.com/">Sleep Cycle app</a>? This feature would be a game-changer!</li>
</ul>
</section>
<section id="calories-calculations-with-huawei-health" class="level2">
<h2 class="anchored" data-anchor-id="calories-calculations-with-huawei-health">Calories calculations with huawei health</h2>
<ul>
<li>You enter your information, like weight and height, and based on your vitals and activity, it detects the calories you burn every second. I like this estimation feature.</li>
<li>You can set a goal, for example, to go from 92 kg to 85 kg, but the problem is you need to calculate the calories and record it using the phone, not the watch. This is slow and inconvenient‚ÄîI don‚Äôt like having to open my phone often. Most of the time, my meals are repetitive, and recording them on the Huawei Health app is boring, so I usually just do a quick add.</li>
<li>In the future, I hope they let us add a list of meals to the app so we can select them directly from the watch.</li>
</ul>
</section>
<section id="activities-with-huawei-watch-gt4" class="level2">
<h2 class="anchored" data-anchor-id="activities-with-huawei-watch-gt4">Activities with Huawei Watch gt4</h2>
<ul>
<li>Heart rate tracking is a little slow compared to real-time detection, and sometimes when you are running and want to check your speed and heart rate, it takes around 3 seconds‚Äîquite a long time if you‚Äôre in the middle of a run!</li>
<li>The auto-detection of activities may only start after 20 minutes of walking!</li>
<li>SpO2‚Ä¶ and then what?</li>
<li>They claim there are more than 100 exercises to choose from, but do I really use all of these 100?</li>
<li>Let‚Äôs look at the ones that are useful to me:
<ul>
<li>Outdoor run</li>
<li>Elliptical</li>
<li><strong>Jump rope</strong>: My favorite! It‚Äôs accurate and very helpful.</li>
<li>Indoor run</li>
<li>Indoor walk</li>
</ul></li>
<li>Ones I don‚Äôt use:
<ul>
<li>Outdoor cycling</li>
<li>Indoor cycling</li>
<li>Pool swimming</li>
<li>Open-water swimming</li>
<li>Mountain hiking</li>
<li>Hiking</li>
<li>Trail running</li>
<li>Skiing</li>
<li>Snowboarding</li>
<li>Cross-country skiing</li>
<li>Triathlon</li>
<li>Rowing</li>
<li>Track running</li>
</ul></li>
<li>Are these really 100 exercises?</li>
<li>Where are the gym exercises like pull-ups, push-ups, squats, bench presses, etc.?</li>
</ul>
</section>
<section id="syncing-with-huawei-health" class="level2">
<h2 class="anchored" data-anchor-id="syncing-with-huawei-health">Syncing with huawei health</h2>
<ul>
<li>You must use one main device. I have both a Huawei Health and a Huawei MatePad, but I have to log in on just one of them to sync the information. What if I want to use both? You can‚Äôt.</li>
<li>Syncing with Linux or from the web? No, you can‚Äôt do that either.</li>
<li>However, syncing is very fast.</li>
</ul>
</section>
<section id="messages-with-huawei-gt4" class="level2">
<h2 class="anchored" data-anchor-id="messages-with-huawei-gt4">Messages with huawei gt4</h2>
<ul>
<li>I love the messaging feature. You can read messages in multiple languages without any problem and respond using preconfigured answers, but you can‚Äôt type on the watch.</li>
</ul>
</section>
<section id="music-with-huawei-gt4" class="level2">
<h2 class="anchored" data-anchor-id="music-with-huawei-gt4">Music with huawei gt4</h2>
<ul>
<li>The music quality and sound are great, especially if you want to listen to tracks before sleeping.</li>
</ul>
</section>
<section id="calls-with-huawei-gt4" class="level2">
<h2 class="anchored" data-anchor-id="calls-with-huawei-gt4">Calls with huawei gt4</h2>
<ul>
<li>Answering calls from the watch is really nice if you‚Äôre at home, but not so much if you‚Äôre outside on the street, for example.</li>
</ul>
</section>
<section id="battery-with-huawei-gt4" class="level2">
<h2 class="anchored" data-anchor-id="battery-with-huawei-gt4">Battery with huawei gt4</h2>
<ul>
<li>The best thing about the watch is the battery life. I don‚Äôt worry about it at all. I charge it for 30 minutes per week, and even when I use the always-on display, the battery doesn‚Äôt drain much.</li>
</ul>
</section>
<section id="apps-with-huawei-gt4" class="level2">
<h2 class="anchored" data-anchor-id="apps-with-huawei-gt4">Apps with huawei gt4</h2>
<ul>
<li>Camera Opus
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Photex
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Navigation - G maps
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>OneCalc
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>For Spotify Controller
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Calculator New
<ul>
<li>used it multiple times</li>
</ul></li>
<li>Events - G Calender
<ul>
<li>I use it alot</li>
</ul></li>
<li>Surfing Joe
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Mobcards
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>eSound music
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>petal maps
<ul>
<li>use it when walking and running</li>
</ul></li>
<li>navigation watch
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>easyCalenderGT
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>myTuner Radio
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>KeepStrong
<ul>
<li>The app has problem with login with google it‚Äôs focused more for Chinese people</li>
</ul></li>
<li>Compass navgation
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>TickTick
<ul>
<li>very useful can do/undo tasks from the watch but only tasks not the habbits</li>
</ul></li>
<li>Radarbot
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Fragola
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Salaat first
<ul>
<li>using it on daily basis</li>
</ul></li>
<li>home workout
<ul>
<li>not very useful</li>
</ul></li>
<li>2028 lite
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>wordpuz
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>love test
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>focus to-do
<ul>
<li>it‚Äôs not synced with cloud or the mobile app</li>
</ul></li>
<li>Dice
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Fitify workouts
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>RTL
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>hue essentials
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>FotMob
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Calories Counter
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>FilGoal
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>S7 Airlines
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Ÿáÿ≥ÿ®ÿ±Ÿäÿ≥
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li>Gold GPS Rangefinder
<ul>
<li>didn‚Äôt use it</li>
</ul></li>
<li></li>
</ul>
</section>
<section id="i-broked-the-glass-of-the-huawei-gt4" class="level2">
<h2 class="anchored" data-anchor-id="i-broked-the-glass-of-the-huawei-gt4">I broked the glass of the huawei gt4</h2>
<ul>
<li>The watch broke on the first day of college, probably because I pressed my hand too hard on a marble surface or something similar at the university.</li>
<li>I immediately contacted customer service, and a representative answered‚ÄîI can‚Äôt remember her name‚Äîbut she was incredibly polite, understanding, and helpful. I spoke to her again shortly after, and she asked me for specific information about the watch to check if it was under warranty or not. She followed up with me two days later, then again a day after that, and again two days later until I managed to get the invoice from Amazon. She tried to solve the issue by recommending an exchange and even told me which day to go when there would be discounts on the products.</li>
<li>Honestly, it was the best customer service experience I‚Äôve ever had. She was able to go beyond being just a robot to become someone who understands, values, and helps‚Äîa human experience that brings joy.</li>
<li>At the very least, I had to document and acknowledge that she is someone exceptional. I requested to give her a rating, and I did. I‚Äôm really happy about that.</li>
<li>But I haven‚Äôt fixed the watch yet because there are no spare parts available in Egypt.</li>
</ul>
<hr>
<p><img src="https://kareemai.com/blog/posts/products_reviews/images/back_gt4.jpg" class="img-fluid" alt="sensors of huawei watch gt4"> <img src="https://kareemai.com/blog/posts/products_reviews/images/broken_gt4.jpg" class="img-fluid" alt="screen of huawei watch gt4"> <img src="https://kareemai.com/blog/posts/products_reviews/images/gt4.jpg" class="img-fluid" alt="review of huawei watch gt4"> <img src="https://kareemai.com/blog/posts/products_reviews/images/face_gt4.jpg" class="img-fluid" alt="face of the huawei watch gt4"></p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><a href="https://kareemai.com/blog/posts/products_reviews/Huawei%20freebuds%205i.html">Huawei freebuds 5i review</a></li>
<li><a href="https://consumer.huawei.com/sa/wearables/watch-gt4/">Huawei watch gt4</a></li>
</ol>


</section>

 ]]></description>
  <category>huawei</category>
  <category>watch</category>
  <category>exp</category>
  <category>blogging</category>
  <category>publish</category>
  <guid>https://kareemai.com/blog/posts/products_reviews/Huawei_watch_gt_4_experience.html</guid>
  <pubDate>Thu, 03 Oct 2024 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/products_reviews/images/huawei-watch-gt4-14-day-battery-life.png" medium="image" type="image/png" height="104" width="144"/>
</item>
<item>
  <title>The curse of SEO</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/seo/the_curse_of_seo.html</link>
  <description><![CDATA[ 





<ul>
<li><strong>Definition:</strong> SEO is optimizing your website pages to appear in the top results of search engines like Google and Bing.
<ul>
<li>Why is this important? It makes you visible to more people who are interested in what you provide‚Äîproducts, services, news, etc.</li>
<li>Enough of the basics. I assume you already know what SEO is about. Now, let‚Äôs explore a darker side of being involved in SEO.</li>
</ul></li>
<li><strong>How to Track Your Changes</strong>
<ul>
<li>Since SEO revolves around ranking, how do you track your position?</li>
<li>There are multiple tools I enjoy using, such as:
<ul>
<li><strong>I love to manually search keywords and track their ranks myself! :)</strong>
<ul>
<li>I do this often when I need a break at the gym or during study breaks.</li>
</ul></li>
<li><a href="https://www.semrush.com/">SEMrush</a>
<ul>
<li>I use it to check domain authority, organic keywords, and traffic increase.</li>
<li>Seeing green in increased Ref. Domains and Authority Score brings joy.</li>
<li><em>I don‚Äôt use it for anything else! :)</em></li>
</ul></li>
<li><a href="https://rankmath.com/">Ranking Math</a>
<ul>
<li>Say hi to the overrated WordPress SEO plugin ‚ÄúRanking Math SEO‚Äù</li>
<li>It claims to simplify content optimization with built-in suggestions based on widely-accepted practices.</li>
<li>I use Rankmath Pro on a website I manage, showing impressions, total keywords, average position, and clicks. GSC offers all this for free!</li>
<li>This post isn‚Äôt about Rankmath; that‚Äôs for another time. In short:
<ul>
<li>AI tools</li>
<li>AMP</li>
<li>Analysis from Google Analytics</li>
<li>Instant indexing</li>
<li>Backlinks count</li>
<li>Local SEO</li>
<li>News sitemap</li>
<li>Podcasts</li>
<li>Schema</li>
<li>SEO analysis</li>
<li>Sitemap</li>
<li>Video Sitemap</li>
<li>WooCommerce</li>
<li>Google Web Stories</li>
</ul></li>
<li>None of these significantly impact SEO and ranking; there are other effective methods.</li>
<li>What matters most to me with Rankmath is:
<ul>
<li>Top 5 performing posts</li>
<li>Other keywords</li>
</ul></li>
<li>I mainly use Rankmath for its focus keyword section in each article.</li>
</ul></li>
<li><a href="https://mangools.com/">Mangools</a>
<ul>
<li>My preferred tool! Its UI/UX is excellent, and it‚Äôs fast and efficient unlike other tools.</li>
<li>With the free account, I get:
<ul>
<li>5 keyword researches daily</li>
<li>8 SERP checks</li>
<li>1,000 backlink analyses</li>
<li>Domain profile checks for 2 domains daily</li>
</ul></li>
<li>For Arabic, its keyword ideas aren‚Äôt as good.</li>
</ul></li>
<li><a href="https://search.google.com/search-console/about">Google Search Console</a>
<ul>
<li>A free tool by Google offering most SEO tools‚Äô functionalities for free and accurately.</li>
<li>You get:
<ul>
<li>Performance of your website for any keyword at any time in any region!</li>
<li>Page indexing status</li>
<li>Backlink analysis</li>
<li>Page experience and more</li>
</ul></li>
<li>You might notice a recurring theme:
<ul>
<li>Charts</li>
<li>Changing numbers everywhere, numbers galore!</li>
</ul></li>
</ul></li>
<li><a href="https://app.neilpatel.com/">Neil Patel</a>
<ul>
<li>Rank tracking</li>
<li>SEO opportunities</li>
<li>Site audit</li>
<li>Keyword research</li>
<li>Traffic estimation</li>
<li>Backlinks</li>
</ul></li>
<li><a href="https://keywordtool.io/">Keyword Tool</a>
<ul>
<li>For Arabic, it provides the most related suggested keywords, though many aren‚Äôt quite relevant.</li>
</ul></li>
<li><a href="https://www.guinrank.com/">GuinRank</a>
<ul>
<li>New and more tailored for Arabic, gaining power.</li>
<li>I use its content and keyword tools for Arabic, providing helpful recommendations and statistics for choosing useful keywords.</li>
</ul></li>
<li><a href="https://moz.com/">Moz</a>
<ul>
<li>They even blocked my IP -__-</li>
</ul></li>
</ul></li>
</ul></li>
<li><strong>Starting to Lose!</strong>
<ul>
<li>What‚Äôs going wrong? I hate losing after investing time, money, and mental health into something. If you‚Äôre like me, SEO can be crushing.</li>
<li>‚ÄúSEO is like gambling‚Äù ~ Kareem</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/seo/images/labtop_seo_increasing.jpeg" class="img-fluid figure-img"></p>
<figcaption>How to recover form SEO addiction</figcaption>
</figure>
</div>
<ul>
<li><strong>Losing Backlinks</strong>
<ul>
<li>Spam backlinks (like Khamsat, Fiverr, and Upwork)‚Äîmost are harmful.</li>
<li><a href="https://khamsat.com/marketing/backlinks-building/2836532-%D8%AE%D8%B7%D8%A9-%D8%A8%D8%A7%D9%83-%D9%84%D9%8A%D9%86%D9%83-pbn-%D8%A7%D9%84%D8%A3%D9%81%D8%B6%D9%84-%D8%AD%D8%A7%D9%84%D9%8A%D8%A7">PBN Network</a>
<ul>
<li>This service claims safe PBNs for backlinks from Web 2.0 blogs, profiles, social bookmarking, social likes/shares, etc. I tried it, and none appeared in GSC after 3 months; worse, my site‚Äôs rank dropped.</li>
</ul></li>
<li><a href="https://khamsat.com/marketing/backlinks-building/2191705-%D8%AD%D8%B2%D9%85%D8%A9-%D8%A8%D8%A7%D9%83%D9%84%D9%8A%D9%86%D9%83-%D9%85%D8%AA%D9%83%D8%A7%D9%85%D9%84%D8%A9-%D9%84%D9%85%D9%88%D9%82%D8%B9%D9%83-%D8%B9%D9%84%D9%89-%D9%85%D9%88%D8%A7%D9%82%D8%B9-%D8%B9%D8%A7%D9%84%D9%8A%D8%A9-%D8%A7%D9%84%D8%AF%D9%88%D9%85%D9%8A%D9%86-%D8%A7%D8%AB%D9%88%D8%B1%D8%AA%D9%8A">Manually Added Backlinks</a>
<ul>
<li>This package offers 70 PR10 backlinks from foreign websites, 60 Arabic guest posts, and 10 EDU backlinks, etc.</li>
<li>It worked to some extent, but the impact was minimal. Four backlinks from specific places helped more than these services.</li>
</ul></li>
<li>Other services are mostly spam backlinks; some guest posts might help, but aim for real backlinks spaced out from related sites.</li>
</ul></li>
<li><strong>Losing Ranking</strong>
<ul>
<li>This month, a home services website I manage improved from 65th to 9th in rankings, then disappeared, and later ranked 40th, etc.</li>
<li>This cycle repeats‚Äîa page gains rank, then drops.</li>
<li>It‚Äôs stressful; don‚Äôt check daily. Weekly (or every 2-3 weeks) is less stressful and gives fairer results, focusing on what‚Äôs important.</li>
</ul></li>
<li><strong>What‚Äôs Going Wrong?</strong>
<ul>
<li>Watching page changes from these tools is like social media‚Äôs new ‚Äúlike‚Äù button!</li>
<li>My mind loves the green and red numbers.</li>
<li>Ultimately, most analyses aren‚Äôt critical. Whether 23rd or 80th, if not in the top 5, what‚Äôs the use? Daily checks yield nothing; reaching top 5 goes unnoticed until notifications and calls confirm it.</li>
<li>If SEO is your sole income source, it‚Äôs a tough job‚Äîeven though it can make you a millionaire sometimes.</li>
</ul></li>
<li><strong>How to Recover</strong>
<ul>
<li>Here‚Äôs what helped me recover from this addiction:</li>
<li>Create barriers for easy access:
<ol type="1">
<li>Separate Google accounts/tabs into another browser profile. Using Brave or Bing makes this easy.</li>
<li>Remove bookmarked tabs for these tools and clear browsing history.</li>
<li>Use extensions to block these sites; Chrome Store has many offering motivational quotes.</li>
</ol></li>
<li>Delete Chrome and YouTube from mobile using <a href="https://askubuntu.com/questions/34702/how-do-i-set-up-android-adb">ADB</a>.</li>
<li>Move tool emails to spam except weekly updates from Mangools and GSC.</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/seo/images/laptop_google.jpeg" class="img-fluid figure-img"></p>
<figcaption>dark side of seo</figcaption>
</figure>
</div>
<ul>
<li><strong>Final Thoughts!</strong>
<ul>
<li><p>As a programmer, I initially thought a fast website and quality content were key in SEO. I later learned that choosing keywords and acquiring backlinks are crucial.</p></li>
<li><p>A nice Arabic book which will give you true information about SEO <a href="https://academy.hsoub.com/files/28-%D8%AF%D9%84%D9%8A%D9%84%D9%83-%D8%A5%D9%84%D9%89-%D8%AA%D8%AD%D8%B3%D9%8A%D9%86-%D9%85%D8%AD%D8%B1%D9%83%D8%A7%D8%AA-%D8%A7%D9%84%D8%A8%D8%AD%D8%AB-seo/">ÿØŸÑŸäŸÑŸÉ ÿ•ŸÑŸä ÿ™ÿ≠ÿ≥ŸäŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´</a></p></li>
<li><p>Feel free to DM on <a href="https://www.linkedin.com/in/abdelkareem-elkhateb-989a68294/">Linkedin</a></p></li>
<li><p>Ultimately, backlinks boil down to how many you buy and from whom.</p></li>
<li><p><a href="https://anwan.me/">ŸÖŸÜÿµÿ© ÿµŸÜÿßÿπÿ© ÿßŸÑŸÖÿ≠ÿ™ŸàŸä ÿßŸÑÿπÿ±ÿ®Ÿä</a></p></li>
<li><p><a href="https://kamcalorie.com">ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑŸÖŸàÿ≤</a></p></li>
<li><p><a href="https://www.tanorfix.com/">ÿµŸäÿßŸÜÿ© ÿßŸÅÿ±ÿßŸÜ ÿ∫ÿßÿ≤ ÿ®ÿßŸÑÿ±Ÿäÿßÿ∂</a></p></li>
<li><p><a href="https://www.smaagarden.com/">ÿ¥ÿ±ŸÉÿ© ÿ™ŸÜÿ≥ŸäŸÇ ÿ≠ÿØÿßÿ¶ŸÇ ÿ®ÿßŸÑŸÖÿØŸäŸÜÿ© ÿßŸÑŸÖŸÜŸàÿ±ÿ©</a></p></li>
<li><p><a href="https://www.alainclean.com/">ÿ¥ÿ±ŸÉÿ© ÿ™ŸÜÿ∏ŸäŸÅ ŸÖŸÜÿßÿ≤ŸÑ ŸÅŸä ÿßŸÑÿπŸäŸÜ</a></p></li>
<li></li>
</ul></li>
</ul>



 ]]></description>
  <category>blogging</category>
  <category>seo</category>
  <guid>https://kareemai.com/blog/posts/seo/the_curse_of_seo.html</guid>
  <pubDate>Tue, 30 Jul 2024 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/seo/images/labtop.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/life_style/fake_graviety.html</link>
  <description><![CDATA[ 





<section id="ÿßŸÑÿ®ÿØÿßŸäÿ©" class="level2">
<h2 class="anchored" data-anchor-id="ÿßŸÑÿ®ÿØÿßŸäÿ©">ÿßŸÑÿ®ÿØÿßŸäÿ©</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/burn_out.png" class="img-fluid figure-img"></p>
<figcaption>target</figcaption>
</figure>
</div>
<p>ÿ£ÿ≠ÿØ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ£ŸÇŸàŸÖ ÿ®Ÿáÿß ŸÅŸä ÿ®ÿπÿ∂ ÿßŸÑÿ£ÿ≠ŸäÿßŸÜ ŸáŸä ŸÖÿ±ÿßŸÇÿ®ÿ© ŸÖÿµÿßÿØÿ± ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿßŸÑÿ™Ÿä ÿ™ÿ£ÿ™ŸäŸÜŸä ŸàÿßŸÑŸÖÿ≠ŸÅÿ≤ÿßÿ™ ŸÑŸáÿß Ÿàÿ™ÿ™ÿ®ÿπ ÿ£ÿ´ÿ± ÿ™ŸÑŸÉ ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿπŸÑŸä ÿ£ŸÅÿπÿßŸÑŸä ŸàŸÖÿ¥ÿßÿπÿ±Ÿä ÿå Ÿäÿπÿ™ÿ®ÿ±Ÿáÿß ÿßŸÑÿ®ÿπÿ∂ ÿ™ŸÅŸÉŸäÿ± ÿ≤ÿßÿ¶ÿØ Ÿàÿ£ÿπÿ™ÿ®ÿ±Ÿáÿß ÿ£ŸÜÿß ŸÜÿπŸÖÿ© ÿ™ŸÜŸÇÿ∞ŸÜŸä ÿ£ÿ≠ŸäÿßŸÜÿß ŸÖŸÜ ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÅ ŸÅŸä ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖŸáÿßŸÖ ŸàÿßŸÑÿ•ÿ≥ÿ™ŸäŸÇÿßÿ∏ ŸÖÿ™ÿßÿÆÿ±ÿß ŸÜÿ≥ÿ®Ÿäÿß.</p>
<p>ÿ®ÿØÿ£ÿ™ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÅŸä ÿßŸÑÿ∏ŸáŸàÿ± ŸÅŸä ÿßŸÑÿ≥ŸÜÿ© ÿßŸÑÿ£ŸàŸÑŸä ÿßŸÑÿ¨ÿßŸÖÿπŸäÿ© ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿ®ÿØÿßŸäÿ© ÿßŸÑÿ™Ÿä Ÿäÿ≠ÿßŸàŸÑ ŸÉŸÑ ÿ¥ÿÆÿµ ÿ£ŸÜ Ÿäÿ∏Ÿáÿ± ŸÖŸáÿßÿ±ÿßÿ™Ÿá ŸàŸÇÿØÿ±ÿßÿ™Ÿá ŸàŸäÿ´ÿ®ÿ™ ŸÜŸÅÿ≥Ÿá ŸàŸäÿ≠ÿßŸàŸÑ ÿ•ÿ´ÿßÿ±ÿ© ÿ•ÿπÿ¨ÿßÿ® ÿßŸÑÿ£ÿÆÿ±ŸäŸÜ Ÿàÿ™ŸÜÿ¥ÿßÿ°ÿ© ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ŸÖÿπ ÿ£ŸÜÿßÿ≥ ŸÖŸÜ ŸÉÿßŸÅÿ© ÿßŸÑŸÖÿ≠ÿßŸÅÿ∏ÿßÿ™ ÿ∞ŸÑŸÉ ÿßŸÑÿØÿÆŸàŸÑ ÿßŸÑŸÖŸÅÿßÿ¨ÿ¶ ŸàÿßŸÑŸÉÿ´ŸäŸÅ ŸÉÿßŸÜ ŸÑŸá ÿ£ÿ´ÿ± ŸÜŸÅÿ≥Ÿä ÿ≥ÿ¶.</p>
<p>ŸÖÿ´ŸÑ ÿ™ÿ∫Ÿäÿ± ÿßŸÑÿßŸáÿ™ŸÖÿßŸÖÿßÿ™ ÿπŸÑŸä ÿßŸÑŸÖÿ≥ÿ™ŸàŸä ÿßŸÑÿ¥ÿÆÿµ ŸàÿßŸÑŸÖÿπÿ±ŸÅŸä Ÿà ÿßŸÑÿØÿÆŸàŸÑ ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ÿßŸÑŸÉÿ´Ÿäÿ±Ÿá ÿ®ÿØÿ£ÿ™ ÿßŸÑÿ£ŸáÿØÿßŸÅ ÿßŸÑŸÖÿ±ŸÉÿ≤Ÿäÿ© ÿßŸÑÿ™Ÿä ŸÉŸÜÿ™ ÿ£ÿ≠ŸÑŸÖ ÿ®Ÿáÿß Ÿà ÿ£ŸÅŸÉÿßÿ±Ÿä ŸàŸÖÿ®ÿßÿØÿ¶ ÿ®ÿßŸÑÿ™ÿ¥ÿ™ÿ™ ŸàÿßŸÑÿ™ÿ£ÿ´ÿ± ÿ®ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÉŸÑ ÿ¥ÿÆÿµ ÿ™ÿπÿ±ŸÅÿ™ ÿπŸÑŸäŸá Ÿàÿµÿßÿ± ÿ®ŸäŸÜŸä Ÿàÿ®ŸäŸÜŸá ÿπŸÑÿßŸÇÿ© ÿ≤ŸÖÿßŸÑÿ© ÿ®ŸÑ Ÿàÿ≠ÿ™Ÿä ŸÖÿ¨ÿ±ÿØ ÿ±ÿ§Ÿäÿ© ÿµŸÅÿ≠ÿ™Ÿá ÿπŸÑŸä Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ŸÉŸÑ Ÿáÿ∞ÿß ÿ∑ÿ®ŸäÿπŸä Ÿà ŸÖŸÅŸáŸàŸÖ.</p>
<p>ÿ®ÿπÿØ ŸÖÿ≠ÿßŸàŸÑ ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸäŸàŸÖŸä ŸàÿßŸäŸÜ Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ŸÜÿßŸÅÿ≤Ÿá Ÿàÿ£ŸäŸÜ ÿ™ÿ≥ŸÜÿ≤ŸÅ ÿ£ŸÅŸÉÿßÿ±Ÿä Ÿà ŸÖÿÆÿ≤ŸàŸÜ ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ŸÑÿØŸä Ÿàÿ¨ÿØÿ™ ÿ£ŸÜŸä ÿ£ÿ∞Ÿáÿ® ŸÑŸÜÿ¥ÿ± ÿ®Ÿäÿ™ ÿßŸÑÿ¥ÿπÿ± Ÿáÿ∞ÿß Ÿàÿ™ŸÑŸäÿÆÿµ ÿßŸÑŸÉÿ™ÿßÿ® ÿ∞ÿßŸÉ ŸÑÿ£ŸÜÿ™ÿ∏ÿ± ÿ±ÿØ ŸÅÿπŸÑ ŸÅŸÑÿßŸÜ ŸàÿπŸÑÿßŸÜ Ÿà ÿßŸÜÿ∫ŸÖÿßÿ≥Ÿä ŸÅŸä ÿßŸÑÿ±ÿØŸàÿØ ÿπŸÑŸä ŸÖŸÜÿ¥Ÿàÿ±ÿßÿ™ŸáŸÖ Ÿàÿ™ÿ™ÿ®ÿπ ÿ£ÿÆÿ®ÿßÿ±ŸáŸÖ Ÿà ÿ™ÿ∂ÿÆŸÖ ÿ∑ŸÅŸäŸÑŸäŸä ÿßŸÑŸÅÿ∂ŸàŸÑ ÿπŸÜÿØŸä ÿ®ÿ¥ŸÉŸÑ ŸÖÿ®ÿßŸÑÿ∫ ŸÅŸäŸá ŸÖŸÖÿß ÿ£ÿµÿ®ÿ≠ Ÿäÿ≥ÿ®ÿ® ŸÇŸÑŸÇ Ÿàÿ≠Ÿäÿ±ÿ© Ÿàÿ™ÿ¥ÿ™ÿ™ ŸàŸÖŸÇÿßÿ±ÿßŸÜÿßÿ™ Ÿà Ÿàÿ∂Ÿäÿßÿπ ÿ£ÿπŸÖÿßÿ±.</p>
</section>
<section id="ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ±" class="level2">
<h2 class="anchored" data-anchor-id="ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ±">ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ±</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/effect_of_other_people.jpg" class="img-fluid figure-img"></p>
<figcaption>target</figcaption>
</figure>
</div>
<p>ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ± ÿßŸÑÿ≥ÿ±Ÿäÿπ ÿ®ÿßŸä ÿ¥ÿÆÿµ Ÿäÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿ¥ÿ¶ ŸÑÿß ÿ£ÿπÿ±ŸÅŸá ŸÖÿ±ÿ™ 6 ÿ¥ŸáŸàÿ± ÿ™ŸÇÿ±Ÿäÿ®ÿß Ÿàÿ£ŸÜÿß ŸÖÿ™ÿßÿ´ÿ± ÿ®ÿ®ÿπÿ∂ ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ÿßŸÑÿ∞ŸäŸÜ ŸÉŸÜÿ™ ÿ£ÿπÿ™ŸÇÿØ ÿßŸÜ ŸÑÿØŸäŸáŸÖ ŸÇÿØÿ± ŸÖŸÜ ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑÿµÿØŸÇ ŸàÿßŸÑÿßÿ¥ÿ™ÿ±ÿßŸÉ ŸÅŸä ŸÉŸàÿ±ÿ≥ÿßÿ™ŸáŸÖ ÿßŸÑÿ™Ÿä ÿ≥ÿ™ÿ¨ÿπŸÑŸÜŸä ŸÖÿ®ÿ±ŸÖÿ¨ ŸÑÿ£ÿ≠ÿµŸÑ ÿπŸÑŸä ÿØÿÆŸÑ ÿ®ÿßŸÑÿØŸàŸÑÿßÿ± ŸÅŸä ŸÜŸáÿßŸäÿ© ÿßŸÑÿ¥Ÿáÿ± ÿßŸÑŸÇÿßÿØŸÖ <strong>ÿ∞ŸÑŸÉ ÿßŸÑÿ¥Ÿáÿ± ÿßŸÑÿ∞Ÿä ÿ£ŸÖÿ™ÿØ 4 ÿ≥ŸÜŸàÿßÿ™ ÿØÿ±ÿßÿ≥Ÿäÿ© !!!</strong> ÿ¥Ÿáÿ± ÿ£ÿ≥ÿ®ŸàÿπŸá ÿ®ŸÖŸÇÿØÿßÿ± ÿπÿßŸÖ!</p>
<p>ŸÑŸÜÿ±ŸÖÿ≤ ŸÑÿ™ŸÑŸÉ ÿßŸÑŸÅÿ¶ÿ© ŸÖŸÜ ÿßŸÑŸÖÿ§ÿ´ÿ±ŸäŸÜ ÿ®ÿßŸÑÿ±ŸÖÿ≤ ÿ≥ ŸàŸáŸà ÿ•ÿÆÿ™ÿµÿßÿ± ŸÑŸÉŸÑŸÖÿ© ÿ≥ÿ®Ÿàÿ®ÿ© ŸäŸÜÿ™ÿ¥ÿ± ŸáŸàŸÑÿßÿ° ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ŸÅŸä ÿ£ŸÖÿßŸÉŸÜ ÿµŸäÿØ ÿßŸÑŸÖÿ®ÿ™ÿØÿßÿ¶ŸäŸÜ Ÿäÿ®Ÿäÿπ ŸÑŸÉ ŸáŸàŸÑÿßÿ° ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ÿßŸÑŸàÿπŸàÿØ ÿßŸÑÿ®ÿ±ÿßŸÇÿ© ŸÉŸàÿ±ÿ≥ ŸÑÿ™ÿπŸÑŸÖ ÿßŸÑÿ≥ÿßŸäÿ®ÿ± ÿ≥ŸäŸÉŸàÿ±ÿ™Ÿä ŸÅŸä ÿÆŸÑÿßŸÑ 3 ÿ¥ŸáŸàÿ± ÿ£Ÿà ÿ™ÿπŸÑŸÖ ÿØÿ®ŸÑŸàŸÖÿ© ÿπŸÑŸÖ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸàÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿ¥Ÿáÿ±ŸäŸÜ ÿ™ŸÜÿ®Ÿáÿ± ŸÉÿ´Ÿäÿ±ÿß ÿ®ÿßŸÑŸÉÿßÿ±ÿ≤ŸäŸÖÿß Ÿàÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑÿßŸÑŸÇÿßÿ° ŸàŸÜÿ∏ÿßŸÅÿ© ÿßŸÑŸÖŸÉÿßŸÜ ŸàÿßŸÑŸÖÿ≠ÿ™ŸàŸä ÿßŸÑÿ∞Ÿä ŸäÿπÿØ ŸÖÿ®Ÿáÿ± ÿ®ÿßŸÑŸÜÿ≥ÿ®ÿ© ŸÑŸÉ ŸÅŸÑÿ®ÿ≥ ŸÑÿØŸäŸÉ ÿ£Ÿä ÿ¢ŸÑŸäÿßÿ™ ŸÑŸÑÿ≠ŸÉŸÖ ÿπŸÑŸä ÿßŸÑÿ¥ÿÆÿµ ÿ£Ÿà ÿßŸÑŸÖÿ≠ÿ™ŸàŸä ŸÅŸÉŸÑ ŸÖÿπÿ±ŸÅÿ™ŸÉ ŸÅŸä ÿßŸÑÿπŸÑŸÖ ŸáŸä ÿ™ÿπÿßŸÑ ŸÜÿ¨ÿ±ÿ® ÿ≠ÿµÿ© ÿπŸÜÿØ ÿ£ÿ≥ÿ™ÿßÿ∞ ÿ¥ŸÉÿ±Ÿä</p>
<p>ÿ∑ÿßŸÑÿ® ŸÑÿß ÿ≠ŸàŸÑ ŸÑŸá ŸàŸÑÿß ŸÇŸàÿ© ŸÑÿß Ÿäÿπÿ±ŸÅ ÿ£Ÿä ÿ¥ÿ¶ ŸÅŸä ÿπŸÇŸÑÿ© ÿ∫Ÿäÿ± ŸÖŸÑÿÆÿµ ÿßŸÑÿØÿ±ÿ≥ ÿßŸÑÿ∞Ÿä Ÿäÿ≠ŸÅÿ∏ÿ© ÿπŸÜ ÿ∏Ÿáÿ± ŸÇŸÑÿ® ŸàŸäÿ∞Ÿáÿ® ŸÑŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ ŸÑŸäÿ≥ŸÉÿ® ÿ™ŸÑŸÉ ÿßŸÑÿßÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ¨ÿßŸáÿ≤Ÿá ŸÅŸä Ÿàÿ±ŸÇÿ© ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ ÿßŸÑÿßÿ®ŸÑŸá ŸÑŸäÿ™ŸÅÿßÿ¨ÿ¶ ÿ∞ŸÑŸÉ ÿßŸÑŸÖÿ≥ŸÉŸäŸÜ ÿ£ŸÜ ŸÑÿß ŸäŸàÿ¨ÿØ ÿ™ÿπŸÑŸäŸÖ ÿ¨ÿßŸÖÿπŸä ÿ≠ŸÇŸäŸÇŸä ŸàÿßŸÜŸáÿß ŸÉÿßŸÜÿ™ ŸÉÿ∞ÿ®ÿ© ÿßŸÑÿπŸÖÿ± ÿßŸÑÿ∂ÿßÿ¶ÿπ ŸÅŸä ŸÉŸÑ ÿ™ŸÑŸÉ ÿßŸÑÿ≥ŸÜŸàÿßÿ™ ŸÖŸÜ ÿßŸÑÿßÿ®ÿ™ÿØÿßÿ¶Ÿäÿ© ŸàŸáŸà Ÿäÿ≥ÿ£ŸÑ ŸÖÿ™Ÿä ÿßŸÑÿ±ÿßÿ≠ÿ© ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑÿ™ŸÑŸÇŸäŸÜ ÿßŸÑŸÅÿßÿ¥ŸÑ Ÿàÿ™ŸÉŸàŸÜ ÿßŸÑÿßÿ¨ÿßÿ®ÿ© ÿßŸÑŸÉŸÑÿßÿ¥ŸÉŸäÿ© ŸáŸä ÿ£ÿ™ÿπÿ® ÿßŸÑŸàŸÇÿ™Ÿä ÿπŸÑÿ¥ÿßŸÜ ÿ™ÿ≥ÿ™ÿ±Ÿäÿ≠ ÿ®ÿπÿØŸäŸÜ ÿ®ÿπÿØŸäŸÜ ÿßŸÖÿ™Ÿá!</p>
<p>ŸÅŸä ÿßŸÑÿ¨ÿßŸÖÿπÿ© ÿπŸÜÿØŸÖÿß ÿ™ŸÜÿ™ŸáŸä ŸÖŸÜ ÿßŸÑ3 ÿßŸÑÿ´ÿßŸÜŸàŸä ŸÑÿ™ÿµŸäÿ± ÿØŸÉÿ™Ÿàÿ± ŸÖÿÆ Ÿàÿ£ÿπÿµÿßÿ® ÿ£Ÿà ŸÖŸáŸÜÿØÿ≥ ÿ®ÿ™ÿ±ŸàŸÑ</p>
</section>
<section id="ÿßŸÑŸÉŸáŸÜÿ©-Ÿà-ÿßŸÑŸÖÿπÿ®ÿØ" class="level2">
<h2 class="anchored" data-anchor-id="ÿßŸÑŸÉŸáŸÜÿ©-Ÿà-ÿßŸÑŸÖÿπÿ®ÿØ">ÿßŸÑŸÉŸáŸÜÿ© Ÿà ÿßŸÑŸÖÿπÿ®ÿØ</h2>
<p>ÿ≥Ÿàÿßÿ° ŸÉÿßŸÜÿ™ ŸÜÿ™Ÿäÿ¨ÿ© ÿßŸÑÿ´ÿßŸÜŸàŸäÿ© ŸÖÿ±ÿ∂Ÿäÿ© Ÿà ÿ£ÿ±ÿ∂Ÿäÿ™ ŸàÿßŸÑÿØŸäŸÉ ÿ£ŸÖ ŸÖÿ≠ÿ≤ŸÜÿ© Ÿàÿ£ÿµÿßÿ®ŸÉ ÿßŸÉÿ™ÿßÿ¶ÿ® ŸàÿßŸÖÿ™ŸÑÿ¶ÿ™ ÿ®ÿßŸÑÿ≠ÿ≤ŸÜ ŸÅŸÑÿß ÿ™ÿ®ÿ™ÿ£ÿ≥ ŸÅÿßŸÑŸÇÿßÿØŸÖ ÿ£ÿ≥Ÿàÿ° ÿπŸÑŸäŸÉŸÖÿß ŸàŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉ ŸÅŸä ÿπÿµÿ± ÿßŸÑŸÉŸáŸÜÿ© ÿßŸÑÿ¨ÿßŸÖÿπŸäÿ© ÿ®ÿπÿØ ŸÖÿ±ÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿπÿØŸäÿØÿ© Ÿàÿ≥ŸÖÿßÿπ ÿßŸÑÿ£ÿ±ÿßÿ° ŸáŸÜÿß ŸàŸáŸÜÿßŸÉ ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÅŸäÿØŸàŸáÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ∞ŸÉÿ± ŸÑŸÉ ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ¨ÿßŸÖÿπÿ© ÿßŸÑŸÅŸÑÿßŸÜŸäÿ© Ÿàÿ£ŸÇÿ≥ÿßŸÖŸáÿß ŸàŸÜÿπŸäŸÖŸáÿß Ÿàÿ™ÿ∞ŸÉÿ±ŸÉ ÿ®ÿßŸÑÿßÿ®ÿ™ÿπÿßÿØ ÿπŸÜ ÿßŸÑŸáŸÜÿØÿ≥ÿ© ŸàÿßŸÑÿ¨ÿßŸÖÿπÿßÿ™ ÿßŸÑÿ™ŸÇŸÑŸäÿØŸäÿ© ŸàÿßŸÑÿ∞Ÿáÿßÿ® ÿßŸÑŸä ŸÉŸÑŸäÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ© ŸÖÿ´ŸÑ:</p>
<ol type="1">
<li>ŸÉŸÑŸäÿ© ÿßŸÑŸÖŸÑÿßÿ≠ÿ© ŸàÿßŸÑŸÅÿ∂ÿßÿ°</li>
<li>ŸÉŸÑŸäÿ© ÿßŸÑÿ´ÿ±Ÿàÿ© ÿßŸÑÿ≥ŸÖŸÉŸäÿ©</li>
<li>ŸàÿßŸÑÿ≠ÿ®Ÿäÿ®ÿ© ÿßŸÑÿÆÿ®Ÿäÿ´ÿ© ŸÉŸÑŸäÿ© ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÉŸÑŸäÿ© ÿßŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ŸàÿµŸÜÿßÿπÿ© ÿßŸÑÿ±ŸäŸÖŸàÿ™ÿßÿ™ ŸàŸÖŸÉŸÜ ÿßŸÑÿÆŸäÿßÿ∑ÿ©</li>
<li>ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÉŸÑŸäÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ© ÿ£Ÿà ÿßŸÑŸÇÿ≥ÿßŸÖ ÿ∞ÿßÿ™ ÿßŸÑÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑÿ®ÿ±ÿßŸÇÿ© ‚ÄúŸÑŸäÿ≥ ÿπŸÜÿØŸä ÿ£Ÿä ÿ•ÿπÿ™ÿ±ÿßÿ∂ ÿπŸÜ ÿ£Ÿä ŸÉŸÑŸäÿ© ÿ£Ÿà ÿ™ÿÆÿµÿµ ÿ®ŸÑ ÿ£ÿ™ŸÖŸÜŸä ÿ£ŸÜ ŸäŸÉŸàŸÜ ÿπŸÜÿØŸä ÿπŸÖÿ± ŸÑŸÉŸÑ ÿ™ÿÆÿµÿµ ŸÅÿ¥ÿ±ŸÅ ÿßŸÑÿπŸÑŸÖ ŸÉÿßŸÅŸä‚Äù</li>
</ol>
<p>ŸÑŸÉŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÅŸä ÿ£ŸÜŸáÿß ŸÖÿ≥ÿ±ÿ≠Ÿäÿ© Ÿàÿ≥ÿ®Ÿàÿ®ÿ© ÿπÿßŸÖÿ© ŸàŸÉŸÑ ŸÅÿ±ÿØ ŸÖÿ¥ÿßÿ±ŸÉ ŸÅŸäŸáÿß ÿ®ÿØÿßŸäÿ© ŸÖŸÜ ÿßŸÑŸÖÿØÿ±ÿ≥ŸäŸÜ ŸàÿßŸÑÿ£ŸáŸÑ Ÿà ÿßŸÑŸÖŸáÿßÿ∑ŸäŸÑ ÿßŸÑÿ¨ÿßŸÖÿπŸäŸäŸÜ</p>
<p>ÿ∞ŸÑŸÉ ÿßŸÑŸÖÿπÿ®ÿØ ÿßŸÑŸÖŸÑÿ¶ ÿ®ÿßŸÑÿßŸÑŸáÿ© ŸàÿßŸÑŸÉŸáŸÜÿ© ŸàÿßŸÑŸÖÿ≠ÿ±ŸÖÿßÿ™ ŸàÿßŸÑÿ∞Ÿä ÿ®ŸÖÿ¨ÿ±ÿØ ÿØÿÆŸàŸÑŸÉ ŸÑÿ®Ÿàÿßÿ®ÿ© ÿ∞ŸÑŸÉ ÿßŸÑŸÖÿπÿ®ÿØ Ÿàÿ™ŸÇÿØŸäŸÖŸÉ ŸÑÿ£Ÿàÿ±ÿßŸÇ ÿßŸÑÿßŸÑÿ™ÿ≠ÿßŸÇ ŸÅŸÇÿØ ÿ™ŸÖÿ™ ÿπŸÑŸäŸÉ ÿßŸÑŸÑÿπŸÜÿ© ÿßŸÑÿ£ÿ®ÿØŸäÿ© ŸàŸÉŸÖÿß ÿØÿÆŸÑÿ™ ÿ¨ÿ≥ÿØ ŸÖŸÖÿ™ŸÑÿ¶ ÿ®ÿßŸÑÿ£ŸÖŸÑ ÿ£Ÿà ÿ≠ÿ™Ÿä ÿ¨ÿ≥ÿØ ŸÖŸÖÿ™ŸÑÿ¶ ÿ®ÿßŸÑÿ≠ÿ≤ŸÜ ŸàÿßŸÑŸÜÿØŸÖ ŸÅÿ≥ÿ±ÿπÿß ŸÖÿß ÿ≥ÿ™ÿÆÿ±ÿ¨ ÿ¨ÿ´ÿ© ŸáÿßŸÖÿØÿ© ŸÅÿßŸÇÿØÿ© ÿßŸÑÿ±ÿ∫ÿ®ÿ© ÿπŸÑŸä ÿßŸÑÿπŸäÿ¥ ÿ®ŸÑ ÿ™ŸÅŸÇÿØ ŸÅŸä ŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖÿ±ÿßÿ™ ÿ•ŸÜÿ≥ÿßŸÜÿ™ŸäŸÉ</p>
</section>
<section id="ŸáŸäŸÉŸÑŸäÿ©-ÿßŸÑŸÖÿπÿ®ÿØ" class="level2">
<h2 class="anchored" data-anchor-id="ŸáŸäŸÉŸÑŸäÿ©-ÿßŸÑŸÖÿπÿ®ÿØ">ŸáŸäŸÉŸÑŸäÿ© ÿßŸÑŸÖÿπÿ®ÿØ</h2>
<p>ÿ®ÿπÿØŸÖÿß ŸÇÿØÿ±ÿ™ ÿπŸÑŸä ÿßŸÑŸÜÿ¨ÿßÿ© ŸàŸÑÿ≠ÿßŸÇ ÿ£Ÿä Ÿàÿ≥ŸäŸÑÿ© ŸÖŸàÿßÿµŸÑÿßÿ™ ÿ≥Ÿàÿßÿ° ŸÖŸÜ ÿ®Ÿäÿ™ŸÉ ŸÑŸÑÿ¨ÿßŸÖÿπÿ© ÿ£Ÿà ŸÑŸÑŸÖŸàŸÇŸÅ ÿßŸÑÿπÿßŸÖ ÿßŸà ŸÖŸÜ ŸÖŸàŸÇŸÅ ÿßŸÑÿπÿßŸÖ ŸÑŸÑÿ¨ÿßŸÖÿπÿ© ŸáŸÜŸäÿßÿ¶ÿß ŸÑŸÉ ŸÅŸÇÿØ ÿßÿ≥ÿ™ŸÜŸÅÿ≤ÿ™ 20% ŸÖŸÜ ŸÇÿØÿ±ÿ™ŸÉ ÿπŸÑŸä ÿßŸÑÿµŸÖŸàÿØ</p>
<p>ÿ≥ÿ™ÿØÿÆŸÑ Ÿáÿ∞ÿß ÿßŸÑÿµÿ±ÿ≠ ÿßŸÑŸáÿßÿ¶ŸÑ ÿßŸÑŸÖÿ®Ÿáÿ± ŸÅŸä ÿ®ÿØÿßŸäÿ™Ÿá Ÿàÿ™ÿ™Ÿàÿ¨Ÿá ÿßŸÑŸä ÿßŸÑŸÖÿπÿ®ÿØ ÿßŸÑÿ∞Ÿä ŸÑÿπŸÜÿ™ ÿ®Ÿá ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿÆÿØŸÖ ÿßŸÑÿ£ŸÉÿ®ÿ± ŸÖŸÜŸÉ Ÿäÿ™ŸÜÿµŸÑŸàŸÜ ŸÑŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑŸÅÿ™Ÿäÿßÿ™ ÿßŸÑÿ≥ÿßÿ∞ÿ¨ÿßÿ™ ŸÑÿ•ÿ¥ÿ®ÿßÿπ ÿ¥ŸáŸàÿßÿ™ŸáŸÖ.</p>
</section>
<section id="ÿßŸÑÿ∑ÿßŸÇÿ©-ÿßŸÑÿ≥ŸàÿØÿßÿ°" class="level2">
<h2 class="anchored" data-anchor-id="ÿßŸÑÿ∑ÿßŸÇÿ©-ÿßŸÑÿ≥ŸàÿØÿßÿ°">ÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑÿ≥ŸàÿØÿßÿ°</h2>
<p>ŸÉÿßŸÜ ÿßŸÑÿ™ŸÅÿ≥Ÿäÿ± ÿßŸÑŸàÿ≠ŸäÿØ ŸÑŸÉŸÑ Ÿáÿ∞ÿß ÿßŸÑÿπÿ®ÿ´ ŸáŸà Ÿàÿ¨ŸàÿØ ÿÆÿ∑ÿ© ÿ¥ÿ± ŸÉÿ®ÿ±Ÿä ŸÖŸÜ ÿßŸÑŸÅÿ±ÿßÿπŸÜÿ© ÿßŸÑŸÇÿØŸÖÿßÿ° ŸÑÿ™ŸàŸÑŸäÿØ ÿ£ŸÉÿ®ÿ± ŸÇÿØÿ± ŸÖŸÜ ÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑÿ≥ŸÑÿ®Ÿäÿ© ŸàÿßŸÑÿ•ÿ≠ÿ®ÿßÿ∑ ŸÅŸä ŸÉŸÑ ŸÖŸÉÿßŸÜ Ÿäÿ¨ÿ™ŸÖÿπ ŸÅŸäŸá ÿßŸÑÿ®ÿ¥ÿ± ÿßŸà ŸÉÿßŸÜ ŸäŸÅÿ™ÿ±ÿ∂ ÿßŸÜ ŸäŸÉŸàŸÜ ŸàŸÑÿßÿØÿ© ÿ¨ÿØŸäÿØÿ© ŸÑÿ£ÿ±Ÿàÿßÿ≠ ŸÖÿ™ÿπÿ®ÿ©.</p>
<p>Ÿäÿ™ŸÖ ÿ•ÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ™ŸÑŸÉ ÿßŸÑÿ∑ÿßŸÇÿ© Ÿàÿ•ŸÖÿ™ÿµÿßÿµŸáÿß ŸÅŸáŸä ÿ™ÿπŸÜŸä ŸÑŸáŸÖ ÿßŸÑÿÆŸÑŸàÿØ ŸÅÿ™ŸÑŸÉ ÿßŸÑŸÖŸÜÿ∑ŸÇÿ© ÿ≠ŸÑÿ™ ÿπŸÑŸäŸáÿß ŸÑÿπŸÜÿ© ŸÑÿß ŸäŸÖŸÉŸÜ ÿ≠ŸÑŸáÿß ÿ•ŸÑÿß ÿ®ÿßŸÑŸÇÿ∂ÿßÿ° ÿπŸÑŸä ÿßŸÑŸÅÿ±ÿßÿπŸÜÿ© Ÿà ÿ•ÿπÿßÿØÿ© ÿßŸÑÿßÿ±Ÿàÿßÿ≠ ÿßŸÑÿ™Ÿä ÿ£ÿ∫ÿ™ÿµÿ®ÿ™ ŸàÿßŸÑÿ£ÿ≠ŸÑÿßŸÖ ÿßŸÑŸÖŸÅŸÇŸàÿØÿ© ÿ£ÿ≠ŸÑÿßŸÖ ÿßŸÑÿ®ÿ≥ÿ∑ÿßÿ° ŸàŸÑŸÑÿ≠ÿØŸäÿ´ ŸáŸÜÿß ÿ®ŸÇŸäÿ© ŸÅŸä ŸÖŸÉÿßŸÜ Ÿàÿ≤ŸÖÿßŸÜ ÿ£ÿÆÿ±Ÿä.</p>
</section>
<section id="ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©" class="level2">
<h2 class="anchored" data-anchor-id="ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©">ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/graviety.jpg" class="img-fluid figure-img"></p>
<figcaption>target</figcaption>
</figure>
</div>
<p><a href="https://ar.wikipedia.org/wiki/%D8%AC%D8%A7%D8%B0%D8%A8%D9%8A%D8%A9">ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©</a> (ŸÖŸÜ ŸÅÿπŸÑ ÿ¨Ÿéÿ∞Ÿéÿ®Ÿé) Ÿàÿ™ÿπÿ±ŸÅ ÿ£Ÿäÿ∂ÿßŸã ÿ®ÿßÿ≥ŸÖ ÿßŸÑÿ´ŸéŸÇÿßŸÑÿ© (ŸÖŸÜ ŸÅÿπŸÑ ÿ´ŸéŸÇŸèŸÑŸé) ŸáŸä ÿ∏ÿßŸáÿ±ÿ© ÿ∑ÿ®ŸäÿπŸäÿ© Ÿäÿ™ŸÖ ÿ®Ÿàÿßÿ≥ÿ∑ÿ™Ÿáÿß ÿ™ÿ≠ÿ±ŸäŸÉ ŸàÿßŸÜÿ¨ÿ∞ÿßÿ® ŸÉŸÑ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ŸÖŸÜ ÿßŸÑŸÉÿ™ŸÑÿ© ÿ£Ÿà ÿßŸÑÿ∑ÿßŸÇÿ© -ÿ®ŸÖÿß ŸÅŸä ÿ∞ŸÑŸÉ ÿßŸÑŸÉŸàÿßŸÉÿ® ŸàÿßŸÑŸÜÿ¨ŸàŸÖ ŸàÿßŸÑŸÖÿ¨ÿ±ÿßÿ™ Ÿàÿ≠ÿ™Ÿâ ÿßŸÑÿ∂Ÿàÿ°- ŸÜÿ≠Ÿà ÿ®ÿπÿ∂Ÿáÿß ÿßŸÑÿ®ÿπÿ∂.</p>
<p>ÿπŸÑŸâ ÿßŸÑÿ£ÿ±ÿ∂ÿå ÿ™ÿπÿ∑Ÿä ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿ´ŸÇŸÑÿßŸã ŸÑŸÑÿ£ÿ¨ÿ≥ÿßŸÖ ÿßŸÑŸÖÿßÿØŸäÿ© (ÿßŸÑŸàÿ≤ŸÜ)ÿå Ÿàÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑŸÇŸÖÿ± ÿ™ÿ≥ÿ®ÿ® ÿßŸÑŸÖÿØ ŸàÿßŸÑÿ¨ÿ≤ÿ± ŸÅŸä ÿßŸÑŸÖÿ≠Ÿäÿ∑. ÿ™ÿ≥ÿ®ÿ® ÿßŸÑÿßŸÜÿ¨ÿ∞ÿßÿ® ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿä ŸÑŸÑŸÖÿßÿØÿ© ÿßŸÑÿ∫ÿßÿ≤Ÿäÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ© ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ÿßŸÑŸÉŸàŸÜ ŸÅŸä ÿßŸÑÿ®ÿØÿ° ŸÅŸä ÿßŸÑÿßŸÜÿØŸÖÿßÿ¨ ÿßŸÑŸÜŸàŸàŸäÿå Ÿàÿ™ŸÉŸàŸäŸÜ ÿßŸÑŸÜÿ¨ŸàŸÖ -Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑŸÜÿ¨ŸàŸÖ ŸÖÿπŸãÿß ŸÅŸä ŸÖÿ¨ÿ±ÿßÿ™- ŸÑÿ∞ÿß ŸÅÿ•ŸÜ ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≥ÿ§ŸàŸÑÿ© ÿπŸÜ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ÿßŸÑŸáŸäÿßŸÉŸÑ ÿßŸÑŸàÿßÿ≥ÿπÿ© ÿßŸÑŸÜÿ∑ÿßŸÇ ŸÅŸä ÿßŸÑŸÉŸàŸÜ.</p>
<p>ÿπŸÑŸâ ÿßŸÑÿ±ÿ∫ŸÖ ŸÖŸÜ ÿ∞ŸÑŸÉ ŸÅÿ•ŸÜ ÿ¢ÿ´ÿßÿ± ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿ™ÿµÿ®ÿ≠ ÿ£ÿ∂ÿπŸÅ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ™ÿ≤ÿßŸäÿØ ÿπŸÑŸâ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ®ÿπŸäÿØÿ©.</p>
</section>
<section id="ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°" class="level2">
<h2 class="anchored" data-anchor-id="ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°">ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°</h2>
<p>ŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ÿ£ŸÜ ÿ™ŸÅŸÉÿ± ŸÉÿ´Ÿäÿ±ÿß ŸÅŸä ŸÉÿßŸÅÿ© ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ™Ÿä ÿ™ÿ¨ÿ∞ÿ®ŸÉ ŸÑŸáÿß ŸÖŸÜ ÿ≠ŸàŸÑŸÉ ÿπŸÑŸä ŸÖÿ≥ÿ™ŸàŸä ÿßŸÑŸàŸÇÿ™ Ÿà ÿßŸÑÿ£ŸÅŸÉÿßÿ± ŸàÿßŸÑŸÖÿ¥ÿßÿπÿ± ŸàŸÇŸàÿ© ÿßŸÑÿ•ÿ±ÿßÿØÿ©!</p>
<ol type="1">
<li>ÿ™ÿßÿ´Ÿäÿ± ÿ£ÿµÿØŸÇÿßÿ¶ŸÉ ÿπŸÑŸäŸÉ</li>
<li>ŸÖŸÉÿßŸÜ ÿ≥ŸÉŸÜŸÉ</li>
<li>ÿ£ÿ≥ÿ±ÿ™ŸÉ</li>
<li>Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ</li>
</ol>
<p><strong>ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤</strong> ŸÑŸäÿ≥ ŸáŸà ŸÇÿ∂ÿßÿ° ÿ£ŸÉÿ´ÿ± ŸàŸÇÿ™ ŸÅŸä ÿ£ŸÖÿ± ŸÖÿß ŸÑŸÉŸÜŸá ŸÇÿØÿ±ÿ™ŸÉ ÿπŸÑŸä ÿ•ÿ®ÿπÿßÿØ ÿßŸÑŸÖÿ¥ÿ™ÿßÿ™ ÿπŸÜ ÿ™ŸÑŸÉ ÿßŸÑŸÖŸáŸÖÿ© ŸàÿßŸÑŸÇÿØÿ±ÿ© ÿπŸÑŸä ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ÿßŸÑŸÉÿßŸÖŸÑ ŸÅŸäŸáÿß. ŸÅŸÖÿ´ŸÑÿß: ŸÅŸÖÿ´ŸÑÿß ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ŸáŸà ÿßŸÜ ÿ™ÿ∞ÿßŸÉÿ± 4 ÿ≥ÿßÿπÿßÿ™ ÿ®ÿ±ŸÖÿ¨ÿ© ŸÅŸÇÿ∑ ŸàŸÑŸäÿ≥ ÿßŸÜ ÿ™ÿ±ŸÉÿ≤ ÿπŸÑŸä ÿ≥ÿßÿπÿ™ŸäŸÜ ÿ®ÿ±ŸÖÿ¨ÿ© ŸàŸäÿ® Ÿàÿ≥ÿßÿπÿ© ŸÖÿßÿ±ŸÉÿ™ŸÜŸäÿ¨ Ÿàÿ≥ÿßÿπÿ© ŸÖÿ∞ÿßŸÉÿ±ÿ© ŸÑŸÑÿ¨ÿßŸÖÿπÿ© ŸàŸÖÿ≠ÿßŸàŸÑ ÿßŸÑÿ™ŸÜŸÇŸÑ ÿ®ŸäŸÜŸáŸÖ ÿπŸÑŸä= ŸÖÿØÿßÿ± ÿßŸÑŸäŸàŸÖ ÿßŸà ŸÉŸÖÿß ÿßÿ≠ÿ® ÿßŸÜ ÿßŸÇŸàŸÑ ÿπŸÑŸä ŸÖÿØÿßÿ± ŸÜŸàŸÖ!</p>
<hr>
<p>ŸÑŸäÿ≥ÿ™ ÿßŸÑŸÇÿ∂Ÿäÿ© ŸÉŸÖ ŸÑÿØŸä ŸÖŸÜ ÿßŸÑŸàŸÇÿ™ ŸÑÿ£ÿπŸÖŸÑ ŸÉÿ∞ÿß ÿ®ŸÑ ŸÉŸÖ ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑŸàŸÇÿ™ ŸÑÿØŸä ÿßŸÑŸÇÿØÿ±ÿ© ÿπŸÑŸä ÿπŸÖŸÑ Ÿáÿ∞ÿß ŸÅŸàÿ¨ŸàÿØ 10 ÿ≥ÿßÿπÿßÿ™ ŸÅÿ±ÿßÿ∫ ŸÑŸäÿ≥ ŸÖÿπŸÜÿßŸá ÿßŸÜŸÉ ÿ™ÿ≥ÿ™ÿ∑Ÿäÿπ ÿ•ÿ≥ÿ™ÿÆÿØÿßŸÖŸáŸÖ ÿ¨ŸÖŸäÿπÿß ÿ®ŸÑ ŸäŸàÿ¨ÿØ ŸÖŸÜŸáŸÖ ŸÖÿ´ŸÑÿß 4 ÿ≥ÿßÿπÿßÿ™ ŸÅŸÇÿ∑ ŸàŸáÿ∞Ÿá ÿ±ÿ≠ŸÑÿ© ÿ∑ŸàŸäŸÑÿ© Ÿàÿ™ÿ≠ÿ™ÿßÿ¨ ŸÑÿ™ŸÜÿ∏ŸäŸÖ ÿπÿßŸÑŸä ŸàŸÖÿ≠ÿßŸàŸÑ ŸàÿÆÿ∑ÿßÿ° ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÜÿµÿßÿ¶ÿ≠ ŸÑŸäÿ≥ Ÿáÿ∞ÿß ŸàŸÇÿ™ ÿ∞ŸÉÿ±Ÿáÿß.</p>
<p>ŸÅŸÑŸáÿ∞ÿß ŸäŸÜÿµÿ≠ ÿ®ÿßŸÑÿßÿ®ÿ™ÿπÿßÿØ ÿπŸÜ Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ Ÿà ÿ™ÿØŸÅŸÇ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ¥ÿ∫ŸÑ ÿπŸÇŸÑŸÉ ŸàŸÇŸÑÿ®ŸÉ ŸÅŸä ÿ®ÿØÿßŸäÿ© ÿßŸÑŸäŸàŸÖ ŸÅÿ®ÿπÿØ ÿ≥ÿßÿπÿ™ŸäŸÜ ÿ™ÿ¥ÿπÿ± ÿ®ÿßŸÑÿµÿØÿßÿπ ŸàÿßŸÑÿ±ÿ∫ÿ®ÿ© ÿπŸÑŸä ÿßŸÑŸÜŸàŸÖ ŸàŸÉÿ£ŸÜ ÿπŸÇŸÑŸÉ ÿ™ŸàŸÇŸÅ ÿπŸÜ ÿßŸÑÿπŸÖŸÑ.</p>
</section>
<section id="ÿ≠ÿØŸäÿ´-ÿ™ÿÆÿ±ÿ¨" class="level2">
<h2 class="anchored" data-anchor-id="ÿ≠ÿØŸäÿ´-ÿ™ÿÆÿ±ÿ¨">ÿ≠ÿØŸäÿ´ ÿ™ÿÆÿ±ÿ¨</h2>
<p><img src="https://kareemai.com/blog/posts/life_style/images/chocies.png" class="img-fluid" alt="target"> ŸÖÿØŸä ÿπŸÑŸä ÿ™ÿÆÿ±ÿ¨Ÿä ŸÖŸÜ ÿßŸÑÿ¨ÿßŸÖÿπÿ© ÿ®ÿ™ŸÇÿØŸäÿ± ÿ¨ŸäÿØ ÿ¨ÿØÿß +B ŸÖÿ™ÿ±ŸÅÿπ ÿ®ÿ∂ÿπÿ© ÿ£ŸäÿßŸÖ ÿ™ÿ™ŸÖŸÑŸÉŸÜŸä ŸÅÿ±ÿ≠ÿ© ÿπÿßÿ±ŸÖÿ© ÿ£ŸÜŸÜŸä ŸÇÿØÿ™ Ÿáÿ±ÿ®ÿ™ ŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑÿ≥ÿ¨ŸàŸÜ ÿßŸÑÿ™Ÿä Ÿàÿ∂ÿπÿ™ ÿπŸÑŸäÿß ÿ∑ŸàÿßŸÑÿ© Ÿáÿ∞Ÿá ÿßŸÑÿ£ÿπŸàÿßŸÖ ÿ¥ÿπŸàÿ± ŸÖÿ±Ÿäÿ≠ ÿ¨ÿØÿß ÿ™ÿ®ŸÇŸä ÿ≥ÿ¨ŸÜ ÿßŸÑÿÆÿØŸÖÿ© ÿßŸÑÿπÿ≥ŸÉÿ±Ÿäÿ© ÿßŸÑŸÑŸáŸÖ ÿ•ŸÜŸä ÿ£ÿ≥ÿßŸÑŸÉ ÿßŸÑÿ•ÿπŸÅÿßÿ° ŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ŸàŸÖŸÜ ÿ¥ÿ±Ÿáÿß Ÿàÿ¥ÿ± ŸÖŸÜ ŸÅŸäŸáÿß.</p>
<p>ÿ≠ÿØŸäÿ´ ÿ™ÿÆÿ±ÿ¨ ŸÅŸä ŸÖÿØÿßÿ± ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ∞Ÿä ŸÑŸÖ Ÿäÿ™ŸÖ ÿ™ÿ≠ÿØŸäÿØŸá ÿ®ÿßŸÑŸÉÿßŸÖŸÑ ŸáŸà ŸÅŸäŸÖÿß ÿ≥ŸàŸÅ ÿ£ÿ™ÿÆÿµÿµ ÿßŸÑÿ¢ŸÜ ÿ£ŸÅŸÉÿ± ŸÅŸä ÿ•ÿ¨ÿßÿ®ÿ© ŸÖŸÜÿ∞ 3 ÿ≥ŸÜŸàÿßÿ™ ŸàŸÉŸÑ ÿ¥Ÿáÿ±ŸäŸÜ ÿ™ÿ≤ÿØÿßÿØ ŸÖÿπÿ±ŸÅÿ™Ÿä ŸàÿÆÿ®ÿ±ÿ™Ÿä Ÿàÿ£ÿ¨ÿØ ÿ£ŸÜŸÜŸä ŸÑŸäÿ≥ ŸÑÿØŸä ÿ•ÿ¨ÿßÿ®ÿ© ÿ≠ŸÇŸäŸÇÿ© ÿ≠ÿ™Ÿä ÿßŸÑÿ¢ŸÜ. ŸáŸÜÿßŸÉ 3 ÿ™ÿÆÿµÿµÿßÿ™ ÿ£ÿ≥ÿ™ÿ∑Ÿäÿπ ÿßŸÜ ÿ£ÿ®ÿØÿß ÿ®Ÿáÿß:</p>
<ol type="1">
<li>ŸÖŸáŸÜÿØÿ≥ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ (ŸàŸÖŸÜ ÿÆŸÑÿßŸÑŸá ÿ£ÿÆÿ™ÿßÿ± ŸÅÿ±ÿπ ŸÖÿ´ŸÑ ÿ®ÿ±ŸÖÿ¨ÿ© ÿßŸÑŸàÿßÿ¨Ÿáÿßÿ™ ÿßŸà ÿßŸÑÿ®ÿßŸÉ ÿ•ŸÜÿØ)</li>
<li>ŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿπŸÑŸàŸÖ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ( ŸÖŸÜ ÿÆŸÑÿßŸÑŸá ÿ£ÿÆÿ™ÿßÿ± ŸÅÿ±ÿπ ŸÖÿ´ŸÑ ÿ™ÿπŸÑŸÖ ÿßŸÑÿπŸÖŸäŸÇ ŸàÿßŸÑŸÖÿ¨ÿßŸÑÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´Ÿäÿ© ÿßŸÑÿ¥ŸäŸÇÿ© ÿßŸÑÿ£ÿÆÿ±Ÿä)</li>
<li>ÿßŸÑŸÖÿßÿ±ŸÉÿ™ŸäŸÜÿ¨ + ÿßŸÑÿ≥ŸäŸà + ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑŸÖÿ≠ÿ™ŸàŸä (ŸÖŸÜ ÿÆŸÑÿßŸÑ ŸáŸà ÿ£ŸÇÿ±ÿ® ŸÅÿ±ÿµÿ© ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸä ÿßŸÑŸÖÿßŸÑ ŸÑÿ≥ÿ®ÿ® ÿ∫Ÿäÿ± ŸÖÿπŸÑŸàŸÖ ŸÑŸÜ ÿ£ÿµÿ±ÿ≠ ÿπŸÜŸá) ÿ£ŸäŸÜ ŸáŸä ÿßŸÑÿµÿπŸàÿ®ÿ©! ÿßŸÑÿµÿπŸàÿ®ÿ© ÿ™ŸÉŸÖŸÜ ŸÅŸä ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÉŸÑ ŸÅÿ±ÿπ ŸÖŸÜ ÿ™ŸÑŸÉ ÿßŸÑŸÅÿ±Ÿàÿπ Ÿà ÿ£ÿ´ÿ± ÿ£ÿÆÿ™Ÿäÿßÿ± ÿ£ÿ≠ÿØŸáŸÖ ÿπŸÜ ÿßŸÑÿ£ÿÆÿ± ŸÖŸÜ ŸÜÿßÿ≠Ÿäÿ© ÿßŸÑÿ£Ÿäÿ¨ÿßÿ®Ÿäÿßÿ™ ŸàÿßŸÑÿ≥ŸÑÿ®Ÿäÿßÿ™ ŸÑŸÉŸÑÿß ŸÖŸÜŸáŸÖÿß ŸàŸÑŸäÿ≥ Ÿáÿ∞ÿß ŸÖŸÉÿßŸÜ ÿßŸÑŸÜŸÇÿßÿ¥ ŸàŸÑŸÉŸÜ ŸÖÿß ÿ£ÿ±ŸäÿØ ÿ£ŸÜ ÿ£ÿ¥Ÿäÿ± ŸÑŸá ŸáŸà ÿ™ÿ£ÿ´Ÿäÿ± ÿßŸÑÿ•ÿÆÿ™Ÿäÿßÿ±ÿßÿ™ ÿπŸÑŸäŸÉ Ÿà ÿ£ÿ´ÿ±Ÿáÿß ÿπŸÑŸä ÿ≠Ÿäÿßÿ™ŸÉ Ÿà ŸàŸÖÿßŸáŸä ÿ£ÿ≥ÿ®ÿßÿ® ŸÖŸäŸàŸÑŸÉ ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÑÿ•ÿÆÿ™Ÿäÿßÿ± ŸÖÿ≠ÿØÿØ.</li>
</ol>
<p>ŸÉŸäŸÅ ÿ≥ÿ£ÿÆÿ™ÿßÿ± ÿßŸÑÿ¢ŸÜ ŸÅŸä ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÇÿØ ÿ£ÿÆÿ±ÿ™ ÿßŸÜ ÿ£ÿ≠ÿ¨ŸÖ ÿ¨ÿ∞ÿ® ŸÉŸÑ ÿ™ÿÆÿµÿµ ŸÖŸÜŸáŸÖ ŸÑŸä ŸÅŸä ÿßŸÑŸÅÿ™ÿ±ÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ© ÿ®ÿßŸÑŸÇÿØÿ± ÿßŸÑÿ∞Ÿä ÿ£ÿ±ÿ≥ŸÖŸá ŸÑŸÜŸÅÿ≥Ÿä ŸàŸÖÿ≠ÿßŸàŸÑ ÿßŸÑÿ•ŸÑÿ™ÿ≤ÿßŸÖ ÿ®ÿ∞ŸÑŸÉ ŸàÿßŸÑÿ¨ŸÖÿπ ÿ®ŸäŸÜŸáŸÖ ŸÑŸÑÿÆÿ±Ÿàÿ¨ ÿ®ÿ£ŸÅÿ∂ŸÑ ÿ•ÿ≥ÿ™ŸÅÿßÿØÿ© ŸÖŸÖŸÉŸÜÿ©.</p>
</section>
<section id="ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑŸÖÿ¥ÿßÿπÿ±-ÿßŸÑÿ∞ÿßÿ™Ÿäÿ©" class="level2">
<h2 class="anchored" data-anchor-id="ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑŸÖÿ¥ÿßÿπÿ±-ÿßŸÑÿ∞ÿßÿ™Ÿäÿ©">ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑŸÖÿ¥ÿßÿπÿ± ÿßŸÑÿ∞ÿßÿ™Ÿäÿ©</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/groot.png" class="img-fluid figure-img"></p>
<figcaption>target</figcaption>
</figure>
</div>
<p>ÿ®ÿπÿ∂ ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© ÿßŸÑÿ™Ÿä ÿ£ÿ™ÿ∞ŸÉÿ±Ÿáÿß Ÿà ÿ£ÿ¨ÿØ ŸÅŸäŸáÿß ÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÇ ÿ£ÿµÿ≠ÿßÿ®Ÿáÿß ŸÅŸä ŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿ£ŸàŸÇÿßÿ™ ÿ®ÿ∫Ÿäÿ± ŸÇÿµÿØ ŸàŸÜŸÉÿ±ÿßŸÜ ÿ¥ÿØŸäÿØ ŸÑŸÖÿß ŸäŸÅÿπŸÑŸàŸÜ ŸàŸáÿ∞ÿß ŸÖÿß ÿ£ÿÆÿßŸÅ Ÿà ÿ£ÿ≠ÿßÿ∞ÿ± ŸÖŸÜŸá.</p>
<section id="ÿßŸÑÿ¨ŸäŸÖ" class="level3">
<h3 class="anchored" data-anchor-id="ÿßŸÑÿ¨ŸäŸÖ">ÿßŸÑÿ¨ŸäŸÖ</h3>
<p>ŸÅŸä ÿµÿ®ÿßÿ≠ ÿßŸÑŸäŸàŸÖ ÿØÿÆŸÑ ÿ¥ÿÆÿµ ÿ£ŸàŸÑ ŸÖÿ±Ÿá ÿ£ÿ±ÿßŸá ŸÅŸä ÿßŸÑÿ¨ŸäŸÖ Ÿäÿ®ÿØŸà ŸÖÿ™ŸÖÿ±ÿ≥ ŸÅŸä ŸÉŸÖÿßŸÑ ÿßŸÑÿ£ÿ¨ÿ≥ÿßŸÖ ŸÑŸá ŸÜŸÅÿ≥Ÿä ÿπŸÖÿ±Ÿä ÿ™ŸÇÿ±Ÿäÿ®ÿß ŸäŸÖÿ¥Ÿä ŸÖÿ´ŸÑ ÿßŸÑÿ≠ÿµÿßŸÜ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ±Ÿäÿ® ÿ™ÿ¥ÿπÿ± ŸÉÿ£ŸÜ Ÿäÿ±ŸäÿØ ÿ£ŸÜ ŸäÿÆÿ®ÿ∑ ŸÅŸä ÿ£Ÿä ÿ¥ÿ¶ ÿ£ŸÖÿßŸÖŸá ŸàŸÑÿØŸäŸá ÿ•ÿ®ÿ™ÿ≥ÿßŸÖÿ© ÿπÿ±Ÿäÿ∂Ÿá ÿ∑ŸàÿßŸÑ ÿßŸÑŸàŸÇÿ™ ŸàÿπŸäŸÜŸäŸá ÿ™ŸÜÿ∏ÿ± ŸÑŸÉŸÑ ŸÖŸÜ ÿ≠ŸàŸÑŸá ÿ®ÿ¥ŸÉŸÑ ŸÖÿ±Ÿäÿ® ŸàŸÉÿ£ŸÜŸá ÿ™ŸÇŸàŸÑ ŸáŸÑ ÿ™ÿ±ÿßŸÜŸä! ÿ£Ÿà ŸáŸà ŸÉÿ∞ÿß ŸÇÿ±ÿßÿ¶Ÿáÿß ÿπŸÇŸÑŸä ÿ∑ŸàÿßŸÑ ÿßŸÑÿ≥ÿßÿπÿ™ŸäŸÜ ÿßŸÑÿ™Ÿä ŸÇÿ∂ÿßŸáŸÖ ÿ®ÿ¨ÿßŸÜÿ®Ÿä Ÿäÿµÿ±ÿÆ ÿ®ÿµŸàÿ™ ÿπÿßŸÑŸä ÿ£ÿπŸÑŸä ŸÖŸÜ ÿ±ŸàŸÜŸä ŸÉŸàŸÑŸÖÿßŸÜ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ±Ÿäÿ® ÿ®ÿ±ÿ∫ŸÖ ÿ£ŸÜ ÿßŸÑÿßÿ´ŸÇÿßŸÑ ÿßŸÑÿ™Ÿä Ÿäÿ™ŸÖÿ±ŸÜ ÿ®Ÿáÿß ŸÇÿ±Ÿäÿ®ÿ© ÿ¨ÿØÿß Ÿàÿ£ÿ≠ŸäÿßŸÜÿß ÿ£ŸÇŸÑ ŸÖŸÜ ÿßŸÑÿ™Ÿä ÿ£ÿ™ŸÖÿ±ŸÜ ÿ®Ÿáÿß Ÿà ÿ™ÿπÿßŸÖŸÑŸá ŸÖÿπ ÿßŸÑÿ£Ÿàÿ≤ÿßŸÜ ÿ∫ÿ±Ÿäÿ® ÿ®ÿ≠ŸÇ Ÿäÿ±ŸÅÿπ ÿßŸÑÿ®ÿßÿ± ÿßŸÑÿ≠ÿØŸäÿØŸä ŸÑÿ£ÿπŸÑŸä ŸàŸäÿ≥ŸÇÿ∑Ÿá ÿπŸÑŸä ÿßŸÑÿ£ÿ±ÿ∂ ÿ®ŸÇŸàŸá ŸàŸÑÿØŸäŸá ŸáŸàÿ≥ ÿ®ÿßŸÑÿµÿ±ÿßÿÆ ŸàÿßŸÑÿ™ŸÉÿ≥Ÿäÿ± ÿ≠ÿ™Ÿä ÿ£ŸÜ ŸÖŸÜ Ÿäÿ®ÿπÿØŸá ÿØŸàÿ±ŸäŸÜ Ÿäÿ≥ÿ™Ÿäÿ∑ÿπ ÿ≥ŸÖÿßÿπÿ© ŸàŸÖŸÜ Ÿäÿ≥ŸÉŸÜ ŸÅŸä ÿßŸÑÿØŸàÿ± ÿßŸà ŸäŸÖÿ¥Ÿä ŸÅŸä ÿßŸÑÿ¥ÿßÿ±ÿπ ŸàŸÜÿ≠ŸÜ ŸÅŸä ÿßŸÑÿØŸàÿ± ÿßŸÑ3 Ÿäÿ≥ÿ™ÿ∑Ÿäÿπ ÿ≥ŸÖÿßÿπÿ© ÿ®ÿµŸàÿ™ Ÿàÿßÿ∂ÿ≠ ŸÅŸäÿßÿ™ÿ±Ÿä ŸÖÿßŸáŸà ŸÖÿµÿØÿ± ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸàÿßŸÑŸÖÿ≠ÿ±ŸÉ ŸÑŸáÿ∞Ÿá ÿßŸÑÿ£ŸÅÿπÿßŸÑ ÿßŸÑÿ™Ÿä ŸÑŸÖ ÿ™ÿ≥ÿ™ÿ∑Ÿäÿπ ŸÉŸÑŸÖÿßÿ™Ÿä ŸàÿµŸÅ ÿßŸÑŸáŸÖÿ¨Ÿäÿ© Ÿà ÿßŸÑÿ•ÿ≤ÿπÿßÿ¨ ÿßŸÑŸÖÿ®ÿ™ÿ∞ŸÑ ÿßŸÑŸäŸàŸÖ</p>
</section>
<section id="ÿßŸÑÿ¨ÿßŸÖÿπÿ©" class="level3">
<h3 class="anchored" data-anchor-id="ÿßŸÑÿ¨ÿßŸÖÿπÿ©">ÿßŸÑÿ¨ÿßŸÖÿπÿ©</h3>
<p>Ÿäÿ≠ÿ∂ÿ±ŸÜŸä ÿ∞ŸÉÿ± ŸÖÿ´ÿßŸÑŸäŸÜ ŸÖŸÜÿ™ÿ¥ÿ±ŸäŸÜ ÿ∑ÿßŸÑÿ® ÿßŸÑÿ•ÿ™ÿ≠ÿßÿØ ÿßŸà ÿßŸÑÿ£ŸÜÿ¥ÿ∑ÿ© ÿßŸÑÿ∑ÿßŸÑÿ®Ÿäÿ© ÿßŸÑŸÉÿ´Ÿäÿ±Ÿá</p>
<section id="ÿ•ÿ™ÿ≠ÿßÿØ-ÿßŸÑÿ∑ŸÑÿ®ÿ©-ŸàÿßŸÑÿ£ŸÜÿ¥ÿ∑ÿ©-ÿßŸÑÿ∑ŸÑÿßÿ®Ÿäÿ©" class="level4">
<h4 class="anchored" data-anchor-id="ÿ•ÿ™ÿ≠ÿßÿØ-ÿßŸÑÿ∑ŸÑÿ®ÿ©-ŸàÿßŸÑÿ£ŸÜÿ¥ÿ∑ÿ©-ÿßŸÑÿ∑ŸÑÿßÿ®Ÿäÿ©">ÿ•ÿ™ÿ≠ÿßÿØ ÿßŸÑÿ∑ŸÑÿ®ÿ© ŸàÿßŸÑÿ£ŸÜÿ¥ÿ∑ÿ© ÿßŸÑÿ∑ŸÑÿßÿ®Ÿäÿ©</h4>
<p>ÿ∞ŸÑŸÉ ÿßŸÑÿ∑ŸÑÿßÿ® ÿµÿßÿ≠ÿ® ÿßŸÑÿ®ÿØŸÑÿ© ÿßŸÑÿ£ŸÜŸäŸÇÿ© ŸàÿßŸÑÿ•ÿ®ÿ™ÿ≥ÿßŸÖÿ© ÿßŸÑÿπÿ±Ÿäÿ∂ÿ© ÿßŸÑÿ∞Ÿä Ÿäÿ¥ÿ∫ŸÑ ŸÜŸÅÿ≥Ÿá ŸÅŸä ÿßŸÑÿ•ÿ≠ÿ™ŸÅÿßŸÑÿßÿ™ ŸàÿßŸÑÿ™ŸÜÿ∏ŸäŸÖÿßÿ™ ŸàÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ ÿßŸÑÿ•ÿ¨ÿ™ŸÖÿßÿπŸäÿ© ÿßŸÑŸÉÿ´Ÿäÿ± Ÿàÿ™ŸÜÿ∏ŸäŸÖ ÿßŸÑŸÜÿØŸàÿßÿ™ ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑŸÜŸÅÿßŸÇ (ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿßŸÑŸàÿßŸÇÿπ ÿßŸÑÿ¨ÿßŸÖÿπŸä ŸÑÿπÿßŸÖ 2024) ÿßŸÑÿ£ŸÖÿ± Ÿäÿ¥ÿ®Ÿá ŸÖÿ≥ÿ±ÿ≠Ÿäÿ© ÿ≥ÿÆŸäŸÅÿ© Ÿäÿµÿ®ÿ≠ ŸÅŸäŸáÿß Ÿáÿ∞ÿß ÿßŸÑÿ∑ÿßŸÑÿ® ÿßŸÑÿ®ÿßÿ¶ÿ≥ Ÿäÿ±ŸÇÿµ ÿπŸÑŸä Ÿáÿ∞ÿß ÿßŸÑŸÖÿ≥ÿ±ÿ≠ ÿßŸÑŸÖÿ≤ŸäŸÅ ŸàŸäÿ∏ŸÜ ÿ£ŸÜŸá ÿ®ÿ∑ŸÑ ÿßŸÑŸÅŸäŸÑŸÖ Ÿàÿ≥ŸàŸÅ ŸäŸÜÿ™ÿµÿ± ŸÅŸä ÿßŸÑŸÜŸáÿßŸäÿ© ŸàŸÑŸÉŸÜ ŸÉŸÑ ÿßŸÑŸÖÿπÿ™ÿ∑Ÿäÿßÿ™ ÿ™ÿµÿ±ÿ≠ ÿ®ÿ£ŸÜŸá ŸÖŸáÿ±ÿ¨ ÿ®ÿ•ŸÖÿ™Ÿäÿßÿ≤ ŸàŸäÿÆÿßÿØÿπ ŸÜŸÅÿ≥Ÿá.</p>
</section>
<section id="ÿ£ÿ∞ŸÉŸä-ÿ¥ÿÆÿµ-ŸÅŸä-ÿπÿßŸÑŸÖŸá" class="level4">
<h4 class="anchored" data-anchor-id="ÿ£ÿ∞ŸÉŸä-ÿ¥ÿÆÿµ-ŸÅŸä-ÿπÿßŸÑŸÖŸá">ÿ£ÿ∞ŸÉŸä ÿ¥ÿÆÿµ ŸÅŸä ÿπÿßŸÑŸÖŸá</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/life_style/images/fake_graviety.jpg" class="img-fluid figure-img"></p>
<figcaption>target</figcaption>
</figure>
</div>
<p>ÿ∞ŸÑŸÉ ÿßŸÑÿ≤ŸÖŸäŸÑ ÿßŸÑÿ∞Ÿä ÿ™ÿ¨ÿØÿ© Ÿäÿ≠ÿßŸàŸÑ ÿ®ÿ•ÿ≥ÿ™ŸÖÿ±ÿßÿ± ÿ£ŸÜ Ÿäÿ´ÿ®ÿ™ ŸÑŸÉ ÿ£ŸÜŸá ÿ£ÿ∞ŸÉŸä ŸÖŸÜŸÉ Ÿàÿ£ÿ∞ŸÉŸä ŸÖŸÜ ÿ£Ÿä ÿ£ÿ≠ÿØ ŸÅŸä ÿßŸÑÿ∫ÿ±ŸÅÿ© ŸàÿπŸÑŸä ÿ®ÿπÿØ 100 ŸÉŸäŸÑŸà ŸÖÿ™ÿ± ŸÖŸÜ ŸÖÿ±ŸÉÿ≤ ŸàŸÇŸàŸÅŸá.</p>
<p>ÿ∞ŸÑŸÉ ÿßŸÑÿ≤ŸÖŸäŸÑ ŸäŸÜÿπŸÖÿ≥ ŸÅŸä ÿµŸàÿ™ ÿßŸÑÿ£Ÿäÿ¨Ÿà ÿßŸÑÿ∞Ÿä ÿ®ÿØÿßÿÆŸÑŸá ŸÅÿ™ÿ¨ÿØŸá ŸäŸÜÿπÿ±ŸÅ ÿπŸÜ ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿµÿ≠Ÿäÿ≠Ÿá ŸÑÿ™ÿ≠ÿµŸäŸÑ ÿßŸÑÿπŸÑŸÖ ÿ®ÿ¥ŸÉŸÑ ÿ±ÿ£ÿ≥Ÿä Ÿàÿ£ŸÅŸÇŸä ÿ®ÿ™Ÿàÿßÿ≤ŸÜ ÿ≠ŸÇŸäŸÇŸä ŸÑŸäÿµŸÑ ÿßŸÑŸä ŸÖÿ±ÿ≠ŸÑÿ© ŸÖŸÜ ÿ•ÿ™ŸÇÿßŸÜ ÿßŸÑÿπŸÑŸÖ Ÿà ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸä Ÿàÿ∏ŸäŸÅÿ© ŸÖÿ±Ÿäÿ≠ÿ© ŸÉŸÖ ÿ£ÿ¥ÿπÿ± ÿ®ÿßŸÑÿ≠ÿ≤ŸÜ ÿπŸÑŸäŸá ŸÅŸÑÿØŸäŸá ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿ∑ÿßŸÇÿ© ŸàŸÑŸÉŸÜŸá Ÿäÿ≥ÿ™ÿ∫ŸÑŸáÿß ÿ®ÿ¥ŸÉŸÑ ÿ±ÿ®ŸÖÿß ŸäŸÉŸàŸÜ ÿÆÿßÿ∑ÿ¶ Ÿà ŸÖÿ§ŸÉÿØ ÿ£ŸÜŸá ŸÖÿ≤ÿπÿ¨ ÿ£Ÿäÿ∂ÿß!</p>
<p>ÿßŸÑŸÖÿ§ÿ≥ŸÅ ÿßŸÜŸá ÿ®ÿπÿØ ŸÖÿ±Ÿàÿ± ÿ®ÿπÿØ ÿßŸÑŸàŸÇÿ™ Ÿäÿ®ÿØÿß ŸÉŸÑ ÿ¥ÿÆÿµ ŸÖŸÜÿß ŸÅŸä ÿ¨ŸÖÿπ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÅŸä ÿßŸÑÿ™ÿÆÿµÿµ ÿßŸÑÿ∞Ÿä Ÿäÿπÿ¨ÿ®Ÿá ŸàÿßŸÑÿ•ŸÑÿ™ÿ≠ÿßŸÇ ÿ®Ÿàÿ∏ÿßÿ¶ŸÅ ŸàÿµÿØŸäŸÇŸÜÿß ŸÑÿß Ÿäÿ≤ÿßŸÑ ŸÅŸä ÿ≥ÿ±ÿßÿ® ÿ£ÿ∞ŸÉŸä ÿ¥ÿÆÿµ ŸÅŸä ÿßŸÑÿπÿßŸÑŸÖ ŸàŸÖÿ≠ÿßŸàŸÑÿßÿ™Ÿá ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ±Ÿá ÿ®ÿØŸàŸÜ ŸÇÿµÿØ ŸÑÿ™ÿ®ŸäÿßŸÜ ÿ∞ŸÑŸÉ ÿ£ÿµÿ®ÿ≠ÿ™ ŸÖÿ≤ÿπÿ¨ÿ© Ÿàÿ£ÿµÿ®ÿ≠ÿ™ ŸÖÿπÿ±ŸÅÿ™Ÿá ÿßŸÑÿ™Ÿä ÿ£ŸÉÿ´ÿ±Ÿáÿß ÿ£ŸÅŸÇŸäÿ© ŸÖÿµÿØÿ± ÿ•ÿ≤ÿπÿßÿ¨ ŸàŸÜŸàÿπ ŸÖŸÜ ÿ£ŸÜŸàÿßÿπ ÿßŸÑÿ™ÿ®ÿßŸáŸä ÿßŸÑŸÖÿ´Ÿäÿ± ŸÑŸÑÿ¥ŸÅŸÇÿ© ŸàÿßŸÑÿ∫ÿ∂ÿ® ÿ£ÿ≠ŸäÿßŸÜÿß! ŸäŸÖŸÉŸÜ ÿßŸÑÿ™ŸÅŸÉŸäÿ± ŸÅŸä ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ•Ÿäÿ¨Ÿà ÿπŸÑŸäŸÉ ŸàÿÆÿØÿßÿπŸÉ ŸÑŸÜŸÅÿ≥ŸÉ ŸÅŸä ÿßŸÑÿ≠ÿßŸÑŸäÿ™ŸÜ ŸàÿßŸÑÿ™ŸÅÿµŸäŸÑ ŸÉÿ´Ÿäÿ± ŸàŸÑŸäÿ≥ ÿßŸÑÿ∫ÿ±ÿ∂ ÿßŸÑÿ™ÿπŸÖŸäŸÖ.</p>
<p><strong>ŸÖŸÇÿ™ÿ±ÿ≠ÿßÿ™ ŸÑŸÑÿÆÿ±Ÿàÿ¨ ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑŸÅÿÆ</strong></p>
<ol type="1">
<li><p>ÿ±ÿßŸÇÿ® ŸàŸÇÿ™ŸÉ ÿπŸÑŸä Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿ£ÿ¨ÿ™ŸÖÿßÿπŸä ŸàŸÑŸäÿ≥ ÿßŸÑŸÖŸÇÿµÿØ ŸÉŸÖ ÿ™ÿ¨ŸÑÿ≥ ÿπŸÑŸä Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÜÿµÿßÿ™ ŸàŸÑŸÉŸÜ ÿ£ŸÜÿ∏ÿ± ÿßŸÑŸä ÿ™ÿπŸÑŸÇŸäÿßÿ™ŸÉ Ÿà ŸÖŸÜÿ¥Ÿàÿ±ÿßÿ™ŸÉ ÿ≥ÿ™ÿ¨ÿØ ÿ£ŸÜ ÿ£ŸÉÿ´ÿ± ÿ¥ÿÆÿµ ÿ™ÿ™ÿ≠ÿØÿ´ ÿπŸÜŸá ÿ®ÿ¥ŸÉŸÑ ÿµÿ±Ÿäÿ≠ ÿ£Ÿà ÿÆŸÅŸä ŸáŸà ŸÉŸÖ ÿ£ŸÜÿ™ ÿπÿ®ŸÇÿ±Ÿä Ÿàÿ™ŸÅŸáŸÖ ŸÖÿß ŸÑÿßŸäŸÅŸáŸÖŸá ÿßŸÑÿ£ÿÆÿ±ŸäŸÜ! ŸÉŸÖ ÿ£ŸÜÿ™ ÿ∞ŸÉŸä! ÿ≥ÿ™ÿ¨ÿØŸÉ ŸÖÿ™ŸÇŸàŸÇÿπ ÿπŸÑŸä ÿ∞ÿßÿ™ŸÉ!</p></li>
<li><p>ÿßŸÑÿ•ŸÜÿ≥ÿ≠ÿßÿ® ŸÖŸÜ ŸÖÿ±ÿßŸÇÿ®ÿ© Ÿà ÿ£ÿπŸäŸÜ ÿßŸÑŸÜÿßÿ≥ Ÿà ŸÖÿ≠ÿßÿ≥ÿ®ÿ© ÿßŸÑŸÜŸÅÿ≥ ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÉÿ´ÿ± ÿ≠ÿ≤ŸÖ Ÿà ÿßŸÑÿ£ŸÜÿ≥ÿ≠ÿßÿ® ŸáŸÜÿß ŸÖŸÇÿµŸàÿØ ÿ®Ÿá Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ Ÿà ÿßŸÑÿ™ÿ¨ŸÖÿπÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ∏Ÿáÿ± ŸÅŸäŸá ÿ™ŸÑŸÉ ÿßŸÑÿ£ŸÅÿπÿßŸÑ ŸÖÿ´ŸÑ ŸÖÿ∞ÿßŸÉÿ±ÿ™ŸÉ ŸÅŸä ŸÜŸÅÿ≥ ÿ∫ÿ±ŸÅÿ© ÿßŸÑÿ≥ŸÉŸÜ ÿßŸÑÿ¨ÿßŸÖÿπŸä ÿ£ŸÖÿßŸÖ ÿ£ÿµÿØŸÇÿßÿ¶ŸÉ Ÿà ÿ≥ÿ§ÿßŸÑŸÉ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ± ŸÑŸÑÿ£ÿÆÿ±ŸäŸÜ ŸáŸÑ ÿ™ÿπÿ±ŸÅ ŸÖÿßŸáŸä ŸÜÿ∏ÿ±Ÿäÿ© ÿßŸÑŸáÿ™ŸàÿßŸÜÿß ŸÖÿ∑ÿßÿ∑ÿß ! Ÿà ÿØÿπŸÜŸä ÿ£ÿ¥ÿ±ÿ≠ ŸÑŸÉ ŸÉŸÖ ÿµÿπŸàÿ®ÿ© Ÿáÿ∞Ÿá ÿßŸÑŸÜÿ∏ÿ±Ÿäÿ© Ÿàÿπÿ®ŸÇÿ±Ÿäÿ™Ÿáÿß ..ÿßŸÑÿÆ</p></li>
<li><p>ŸÑÿß ÿ™ÿ™ÿ±ŸÉ ÿ•ÿ¥ÿßÿ±ÿßÿ™ ŸÑŸÑÿßÿÆÿ±ŸäŸÜ ŸÖÿ´ŸÑ ÿßŸÑÿßŸáÿ™ŸÖÿßŸÖ ÿßŸÑÿ≤ÿßÿ¶ÿØ ÿ®ÿ≠ÿßŸÑÿßÿ™ ÿßŸÑŸàÿßÿ™ÿ≥ ŸàÿßŸÑÿ™ŸäŸÑŸäÿ¨ÿ±ÿßŸÖ Ÿàÿ•ÿ∏Ÿáÿßÿ± ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ± ŸÑŸÖÿßÿ∞ÿß ÿ™ŸÅÿπŸÑ ŸÖÿ´ŸÑ ÿØŸäÿ≥ŸÉŸàÿ±ÿØ ŸàÿßŸÑÿ£ÿ∫ÿßŸÜŸä ÿßŸÑÿ™Ÿä ÿ™ÿ≥ÿ™ŸÖÿπ ŸÑŸáÿß</p></li>
</ol>
</section>
</section>
<section id="ŸáŸàÿ≥-ÿßŸÑÿ¨ŸÖÿßŸÑ" class="level3">
<h3 class="anchored" data-anchor-id="ŸáŸàÿ≥-ÿßŸÑÿ¨ŸÖÿßŸÑ">ŸáŸàÿ≥ ÿßŸÑÿ¨ŸÖÿßŸÑ</h3>
<p>ŸáŸàÿ≥ ÿßŸÑÿ¨ŸÖÿßŸÑ ÿ™ŸÑŸÉ ÿßŸÑŸÅÿ™ÿßÿ© ÿßŸÑÿ™Ÿä ŸÉŸÑ ÿ•Ÿáÿ™ŸÖÿßŸÖŸáÿß ŸáŸà ÿ¨ŸÖÿßŸÑŸáÿß ŸàÿßŸÑÿ¨ŸÖÿßŸÑ ŸàÿßŸÑÿ´ÿ±Ÿàÿ© ŸàÿßŸÑŸÖÿßŸÑ ÿ™ÿ¨ÿØ ÿ£ŸÜŸá ŸÖŸáŸàÿ≥ÿ© ÿ®ÿßŸÑÿ¨ÿßŸÜÿ® ÿßŸÑÿ®ÿµÿ±Ÿä ÿπŸÜÿØŸáÿß ÿ®ÿ¥ŸÉŸÑ Ÿäÿ¨ÿπŸÑŸÉ ÿ™ÿ∏ŸÜŸáÿß ŸÖÿßŸÉŸäÿ™ ŸÖÿÆŸäŸÅ ŸÖŸÜ ÿßŸÑÿ•ŸÜÿ¨ÿ∞ÿßÿ® ŸÑŸÑŸÖÿßÿØŸäÿßÿ™ ÿ®ÿ¥ŸÉŸÑ Ÿäÿ∑ÿ∫Ÿä ÿπŸÑŸä ÿ¨ŸÖÿßŸÑŸáÿß ŸÉÿ£ŸÜÿ´Ÿä ŸäÿµŸÑ ÿßŸÑÿ£ŸÖÿ± ÿßŸÑŸä ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑŸáÿßŸÑÿ© ÿßŸÑŸÖÿ≠Ÿäÿ∑ÿ© ÿ®Ÿáÿß ŸÉÿ£ŸÖ ÿ£Ÿà ÿ≤Ÿàÿ¨ÿ© ÿ£Ÿà ŸÅÿ™ÿßÿ© ÿπŸÖŸàŸÖÿß ÿ™ÿ¥ÿπÿ±.</p>
<p>ŸÖÿ¥ÿßŸáÿØÿ© ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÖ ŸàÿßŸÑÿ™ŸäŸÉ ÿ™ŸàŸÉ ÿ®ÿ¥ŸÉŸÑ ŸÖŸÉÿ´ŸÅ ŸàŸÖÿ≠ÿßŸàŸÑÿ© ÿ™ŸÇŸÑŸäÿØ ÿßŸÑÿ™ÿ±ŸÜÿØÿßÿ™ ŸàÿßŸÑŸÖÿ¥ÿßŸáŸäÿ± ŸàÿßŸÑÿ•ŸÜÿ∫ŸÖÿßÿ≥ ŸÅŸä ÿ£ÿÆÿ®ÿßÿ±ŸáŸÖ‚Ä¶ ÿ®ÿπÿØ ŸÖÿ±Ÿàÿ± ÿ®ÿπÿ∂ ÿßŸÑŸàŸÇÿ™ ÿ™ÿ¨ÿØ ÿ£ŸÜŸÉ ÿßŸÖÿßŸÖ ŸÅÿ™ÿßÿ© ŸÑÿß ÿ™ÿØÿ±Ÿä ÿ£Ÿä ÿ¥ÿ¶ ÿπŸÜ ŸÉŸàŸÜŸáÿß ŸÅÿ™ÿßÿ© ÿ∫Ÿäÿ± ÿ¨ÿ≥ÿØŸáÿß Ÿàÿ¨ŸÖÿßŸÑŸáÿß ÿ≠ÿ™Ÿä Ÿáÿ∞ÿß ŸäÿµŸÑ ÿ®ÿ¥ŸÉŸÑ ÿÆÿßÿ∑ÿ¶Ÿä.</p>
</section>
<section id="ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÇ-ÿßŸÑÿ≥Ÿäÿßÿ≥Ÿä-ŸàÿßŸÑŸÖÿ¨ÿßÿ±Ÿäÿßÿ™" class="level3">
<h3 class="anchored" data-anchor-id="ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÇ-ÿßŸÑÿ≥Ÿäÿßÿ≥Ÿä-ŸàÿßŸÑŸÖÿ¨ÿßÿ±Ÿäÿßÿ™">ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÇ ÿßŸÑÿ≥Ÿäÿßÿ≥Ÿä ŸàÿßŸÑŸÖÿ¨ÿßÿ±Ÿäÿßÿ™</h3>
<p>ŸäŸÉÿ´ÿ± ŸÅÿÆ ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸáŸÜÿß ŸÅŸä ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÅ ÿßŸÑÿ≥Ÿäÿßÿ≥Ÿä ŸÑŸÉ ŸÉÿ£ÿ® Ÿàÿ™ŸÇÿµŸäÿ±ŸÉ ŸÅŸä ÿ™ÿ±ÿ®Ÿäÿ© ÿ£ŸàŸÑÿßÿØŸÉ ÿßŸà ÿ≤ŸäÿßÿØÿ© ÿØÿÆŸÑŸÉ Ÿà ÿ≥ÿØ ÿ±ŸÖŸÇ ÿ®Ÿäÿ™ŸÉ!</p>
</section>
</section>
<section id="ÿ£ŸäŸÜ-ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©" class="level2">
<h2 class="anchored" data-anchor-id="ÿ£ŸäŸÜ-ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©">ÿ£ŸäŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©ÿü</h2>
<p>ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÑŸäÿ≥ÿ™ ŸÅŸä ÿßŸÑÿ£ŸÜÿ¨ÿ∞ÿßÿ® ŸÑÿ¥ÿ¶ ŸÅŸáÿ∞ÿß ŸÖÿ≥ÿ™ÿ≠ŸäŸÑ ÿ≠ÿØŸàÿ´Ÿá ŸÑŸÉŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸáŸÑ ÿ£ŸÜÿß ŸÅÿπŸÑÿß ÿ£ÿ≥Ÿäÿ± ŸÅŸä ÿßŸÑŸÖÿØÿßÿ± ÿßŸÑÿµÿ≠Ÿäÿ≠ ÿßŸÑÿ∞Ÿä Ÿäÿ™ŸÅŸÇ ŸÖÿπ ÿßŸÑÿ∫ÿßŸäÿ© ÿßŸÑŸÉÿ®ÿ±Ÿä ÿ®ÿ£ŸÅÿ∂ŸÑ ÿ¥ŸÉŸÑ ŸÖŸÖŸÉŸÜ ŸàŸáŸÑ ÿ™Ÿàÿ¨ÿØ ŸÖÿ≠ÿßŸàŸÑÿ© ÿßŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ± ÿ£ŸÖ ÿ£ŸÜŸÉ ÿ™ÿ™ÿ±ŸÉŸáÿß ŸÑŸÑÿ∏ÿ±ŸàŸÅ Ÿàÿ™ŸÑÿπÿ® ÿØŸàÿ± ÿßŸÑŸÖŸÅÿπŸàŸÑ ÿ®Ÿá! ŸáŸÑ ŸÅÿπŸÑÿß ÿ®ÿπÿØ ÿ∞Ÿáÿßÿ® ÿßŸÑÿπŸÖÿ± ŸáŸÑ Ÿáÿ∞ÿß ŸáŸà ŸÖÿß ŸÉŸÜÿ™ ÿ™ŸàÿØ ÿ£ŸÜŸÉ ÿ£ŸÖÿ∂Ÿäÿ™ ŸÅŸäŸá ÿπŸÖÿ±ŸÉ! ÿßŸÑÿÆÿ∑ÿ± ŸäŸÉŸÖŸÜ ÿ£ŸÜ Ÿáÿ∞ÿß ŸÉŸÑŸá Ÿäÿ≠ÿØÿ´ ŸÖŸÜ ÿ¥ÿØ Ÿàÿ¨ÿ∞ÿ® ÿ®ÿØŸàŸÜ ÿ£ŸÜ ÿ™ÿ™ÿØÿ±ŸÉ ŸÅŸä ÿ£Ÿä ŸÅÿ∂ÿßÿ° ÿµÿßÿ± ŸÇŸÖÿ±ŸÉ.</p>
</section>
<section id="ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ≠Ÿäÿßÿ©-ÿπŸÑŸä-ÿßŸÑÿ£ÿ±ÿ∂" class="level2">
<h2 class="anchored" data-anchor-id="ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ≠Ÿäÿßÿ©-ÿπŸÑŸä-ÿßŸÑÿ£ÿ±ÿ∂">ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ≠Ÿäÿßÿ© ÿπŸÑŸä ÿßŸÑÿ£ÿ±ÿ∂</h2>
<p><strong>ÿ∑ÿπÿßŸÖ ÿßŸÑÿ±Ÿàÿ≠</strong> : ŸÉŸÖÿß ÿ£ŸÜ ÿßŸÑÿ¨ÿ≥ÿØ ŸÑŸá ÿ∫ÿ∞ÿßÿ°ÿ© ŸÅÿßŸÑÿ¨ÿ≥ÿØ ÿÆŸÑŸÇ ŸÖŸÜ ÿ∑ŸäŸÜ ÿ™ÿ¨ÿØ ÿ£ŸÜ ÿ±Ÿàÿ≠ŸÉ ÿ™ÿ´ŸÇŸÑ Ÿàÿ™ÿ≤ÿØÿßÿØ ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿØŸÜŸäÿß Ÿàÿ¥ŸáŸàÿßÿ™Ÿáÿß ŸÑŸÉ Ÿà ŸÉÿ∞ŸÑŸÉ ŸÅÿ±Ÿàÿ≠ŸÉ ŸÑŸáÿß ÿ∫ÿ∞ÿßÿ° ŸàŸáŸà ÿßŸÑÿ∞ŸÉÿ± ŸÅÿßŸÑÿ∞ŸÉÿ± ÿ∫ÿ∞ÿßÿ° ÿ±Ÿàÿ≠ŸÉ ŸÉŸÑŸÖÿß ÿ£ŸÉÿ´ÿ±ÿ™ ŸÖŸÜŸá ÿßÿ±ÿ™ŸÅÿπÿ™ ÿ±Ÿàÿ≠ŸÉ ÿßŸÑŸä ÿßŸÑÿ£ÿπŸÑŸä ŸàÿÆŸÅÿ© ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿ±ÿ∂ ŸÑŸÉ.</p>
<p><strong>ÿßŸÑŸáÿØŸÅ ÿßŸÑÿ≠ŸÇŸäŸÇŸä</strong>: ÿßŸÑŸáÿØŸÅ ÿ£ŸÜ ÿ™ÿØŸàÿ± ŸÅŸä ÿßŸÑŸÖÿØÿßÿ± ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸàÿßŸÑÿ£ŸÖŸÜ ŸàŸÑÿß ÿ™ÿ∫ÿ±ŸäŸÉ ÿßŸÑŸÖŸÖÿ±ÿßÿ™ ÿßŸÑŸÇÿµŸäÿ±ÿ© ÿßŸÑÿ≥ÿ±Ÿäÿπÿ© ÿßŸÑÿ™Ÿä ÿ™ŸÜÿ≠ÿ±ŸÅ ÿ®ŸÉ ŸäŸäŸÖŸäŸÜ ŸàŸäŸäÿ≥ÿßÿ± ÿßŸÑŸáÿØŸÅ ÿ£ŸÜ ŸäŸÉŸàŸÜ ÿ≥Ÿäÿ±ŸÉ ÿßŸÑŸä ÿßŸÑŸÖŸàŸÑŸä ÿπÿ≤Ÿàÿ¨ŸÑ Ÿàÿ∞ŸÑŸÉ ŸÑŸÜ Ÿäÿ™ŸÖ ÿßŸÑÿ• ÿ®ŸÖÿπÿ±ŸÅÿ© ŸÖÿß Ÿäÿ¨ÿ∞ÿ®ŸÉ ŸàŸäÿπÿ®ÿØŸÉ ÿπŸÜ ÿßŸÑŸÖÿ≥ÿßÿ± Ÿàÿ™ÿ¨ÿØŸäÿØ ÿßŸÑŸÜŸäÿ© ÿßŸÑÿØÿßÿ¶ŸÖ ŸàÿßŸÑÿ™Ÿàÿ¨Ÿáÿ© ÿßŸÑŸä ÿ±ÿ®ŸÉ. ÿ£ÿ≠ÿ® ÿßŸÜ ÿßÿ≥ŸÖŸäŸá ÿ•ÿ≥ÿ™ÿπÿßÿØÿ© ÿßŸÑŸÖÿ±ŸÉÿ≤ Ÿàÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ®ŸàÿµŸÑÿ© Ÿà ÿ£ŸÉÿ´ÿ± ŸÖŸÉÿßŸÜ ÿ£ÿ¨ÿØ ŸÜŸÅÿ≥Ÿá ŸÅŸäŸá ŸáŸà ÿ•ŸÖÿß ŸÅŸä ÿµŸÑÿßÿ© ÿµÿßÿØŸÇÿ© ŸÅŸä ÿ¨ŸàŸÅ ÿßŸÑŸÑŸäŸÑ ŸÖÿπ ÿØÿπÿßÿ° ŸÖÿ®ÿ™ŸáŸÑ ÿ£Ÿà ŸÅŸä ÿµŸÑÿßÿ© ÿ¨ŸÖÿßÿπÿ© ŸÖÿ®ŸÉÿ±ÿ© ŸáÿßÿØÿ¶ÿ©. ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿ≠ÿ∏ÿ© ÿ™ÿ¨ÿØ ÿßŸÑÿ≥ŸÉŸäŸÜÿ© ŸÅŸä ŸÇŸÑÿ®ŸÉ Ÿàÿ™ŸáÿØÿ¶ ŸÉŸÑ ÿßŸÑÿπŸàÿßÿµŸÅ. ÿßŸÑŸÑŸáŸÖ ÿ£ÿπŸÜÿß ÿπŸÑŸä ÿ∞ŸÉÿ±ŸÉ Ÿàÿ¥ŸÉÿ±ŸÉ Ÿàÿ∑ÿßÿπÿ™ŸÉ Ÿàÿ≠ÿ≥ŸÜ ÿπÿ®ÿßÿØÿ™ŸÉ.</p>
</section>
<section id="ŸÖÿ∫ÿØÿßÿ±ÿ©-ÿßŸÑŸÖÿØÿßÿ±" class="level2">
<h2 class="anchored" data-anchor-id="ŸÖÿ∫ÿØÿßÿ±ÿ©-ÿßŸÑŸÖÿØÿßÿ±">ŸÖÿ∫ÿØÿßÿ±ÿ© ÿßŸÑŸÖÿØÿßÿ±</h2>
<p>ÿ®ÿπÿ∂ ÿßŸÑÿ≠ŸÑŸàŸÑ ÿßŸÑÿ™Ÿä ŸÖÿßÿ≤ÿßŸÑÿ™ ŸÖÿ≠ŸÑ ÿßŸÑÿ®ÿ≠ÿ´ ŸàÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ©.</p>
<ol type="1">
<li>ÿ≥ŸÑ ŸÜŸÅÿ≥ŸÉ ŸÖÿßŸáŸà ÿßŸÑŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸÑŸáÿ∞ÿß ÿßŸÑŸÅÿπŸÑ ÿßŸà ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ© Ÿàÿ®ÿ£Ÿä ŸÜŸäÿ© ÿ£ŸÅÿπŸÑŸáÿß</li>
<li>ŸÖÿßŸáŸä ÿßŸÑŸÖÿ¥ÿßÿπÿ± ÿßŸÑŸÖÿ≠ÿ±ŸÉÿ© ŸÑŸáÿ∞ÿß ÿßŸÑÿπŸÖŸÑ ŸàŸÖŸÜ ŸáŸà ŸÖÿµÿØÿ±Ÿáÿß ŸáŸÑ ŸáŸÖ ÿßŸÑÿ£ŸáŸÑ ÿ£ŸÖ ŸÅÿ™ÿßÿ© ÿ£ŸÖ ŸÉŸÑŸÖÿ© ŸÇÿßŸÑŸáÿß ÿßÿ≠ÿØ ŸÖÿß ŸàŸÜÿ≥Ÿä ŸÖÿß ŸÇÿßŸÑ!</li>
<li>ŸáŸÑ ÿ™ÿ≥ÿ™ÿ≠ŸÇ ŸÉŸÑ Ÿáÿ∞ÿß ÿßŸÑŸàŸÇÿ™ ŸàÿßŸÑŸÖÿ¨ŸáŸàÿØ ŸÅŸáÿ∞ÿß ÿßŸÑÿ±ÿµŸäÿØ ŸÖŸÜ ÿπŸÖÿ±Ÿä ÿßŸÑÿ∞Ÿä ŸÑÿß ŸäÿπŸàÿ∂!</li>
<li>ŸáŸÑ ŸáŸä ÿ≠ŸÇÿß ÿ™ŸÇÿπ ŸÅŸä ÿ®ÿßÿ® ÿ£ŸáŸÖ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ™Ÿä Ÿäÿ¨ÿ® ÿßŸÜ ÿßŸÅÿπŸÑŸáÿß ÿßŸÖ ŸáŸä ÿ¥Ÿàÿßÿ∫ŸÑ ÿ™ÿπÿ™ÿ±ÿ∂ ÿßŸÑÿ∑ÿ±ŸäŸÇ</li>
<li>ŸÖÿ™ÿßÿ®ÿπÿ© ÿßŸÑŸàŸÇÿ™ ÿ®ŸÅÿπÿßŸÑŸäÿ© ŸÖŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖŸÇÿ™ÿ±ÿ≠ÿ© ŸÑŸáÿ∞ÿß :
<ol type="1">
<li>ActionDash</li>
<li>ActivityWatch</li>
<li>Focus Todo</li>
</ol></li>
</ol>
<p>ŸÖŸÇŸàŸÑÿ© ŸÖŸÖŸäÿ≤ÿ© ŸÖŸÜ ‚ÄúÿØ/ÿπÿ®ÿØ ÿßŸÑÿ±ÿ≠ŸÖŸÜ ÿßŸÑŸÖÿ≥Ÿäÿ±Ÿä‚Äù</p>
<blockquote class="blockquote">
<p>ŸàŸÅŸä ÿßŸÑÿ±Ÿäÿßÿ∂ ÿ™ŸÅÿ±ÿ∫ÿ™ ÿ™ŸÖÿßŸÖÿß ŸÑŸÑŸÖŸàÿ≥Ÿàÿπÿ© ..ÿå ŸàŸÉŸÜÿ™ ÿ£ÿ≠ÿ±ÿ± ÿ®ÿßÿ®ÿß ÿ£ÿ≥ÿ®ŸàÿπŸäÿß ÿ®ÿπŸÜŸàÿßŸÜ ‚Äúÿ•ÿ≥ÿ±ÿßÿ¶ŸäŸÑŸäÿßÿ™ ŸÖÿπÿßÿµÿ±ÿ©‚Äù ŸÅŸä ÿ¨ÿ±ŸäÿØÿ© ÿßŸÑÿ±Ÿäÿßÿ∂ÿå ŸàŸÑŸÉŸÜŸä ŸÑÿßÿ≠ÿ∏ÿ™ ÿ£ŸÜ ÿßŸÜÿ¥ÿ∫ÿßŸÑŸä ÿ®ÿßŸÑÿ≠ÿØÿ´ ÿßŸÑŸäŸàŸÖŸä ÿ®ÿØÿ£ ŸäŸÇŸàÿ∂ ŸÖŸÜ ÿ±ÿ§Ÿäÿ™Ÿä ÿßŸÑÿ®ÿßŸÜŸàÿ±ÿßŸÖŸäÿ© ÿßŸÑŸÖŸàÿ≥ŸàÿπŸäÿ©ÿå ÿßŸÑÿ™Ÿä ÿ™ÿ±ŸÉÿ≤ ÿπŸÑŸä ÿßŸÑÿ´Ÿàÿßÿ®ÿ™ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ™ÿ∑ŸÑÿ® ÿ•ŸäŸÇÿßÿπÿß ÿ®ÿ∑ÿ¶ŸäŸãÿßÿå ŸàÿßŸáÿ™ŸÖÿßŸÖŸãÿß ÿ®ŸÖŸàÿ∂Ÿàÿπÿßÿ™ ÿ™ÿßÿ±ŸäÿÆŸäÿ© ŸàŸÅŸÑÿ≥ŸÅŸäÿ© Ÿàÿ¨ŸàÿßŸÜÿ® ÿßÿ≥ÿ™ÿ±ÿßÿ™ÿ¨Ÿäÿ© ÿ±ÿ®ŸÖÿß ŸÑÿß ÿ™ŸÉŸàŸÜ ŸÑŸáÿß ÿπŸÑÿßŸÇÿ© ÿ®ŸÖÿ¥ÿßÿ±ÿ© ÿ®ÿßŸÑÿ≠ÿØÿ´ ÿßŸÑŸäŸàŸÖŸäÿå ŸàŸÑÿ∞ÿß ÿ™ŸàŸÇŸÅÿ™ ÿπŸÜ ÿ™ÿ≠ÿ±Ÿäÿ± Ÿáÿ∞ÿß ÿßŸÑÿ®ÿßÿ®) ÿßŸÑŸÖÿ≥Ÿäÿ±Ÿä ÿ±ÿ≠ŸÑÿ™Ÿä ÿßŸÑŸÅŸÉÿ±Ÿäÿ© ÿµŸÅÿ≠ÿ© 539</p>
</blockquote>
<p>I am thinking, then i am not here!</p>
</section>
<section id="ÿßŸÑŸÜŸáÿßŸäÿ©" class="level2">
<h2 class="anchored" data-anchor-id="ÿßŸÑŸÜŸáÿßŸäÿ©">ÿßŸÑŸÜŸáÿßŸäÿ©</h2>
<p>Ÿáÿ∞Ÿá ŸáŸä ŸÖÿ¨ÿ±ÿØ ÿÆŸàÿßÿ∑ÿ± ÿ≥ÿ±Ÿäÿπÿ© ÿ∫Ÿäÿ± ŸÖŸÜÿ≥ŸÇÿ© ŸàŸÇÿØ ÿ™ÿ®ÿØŸà ŸÖÿ™ŸÅÿ±ŸÇŸá ŸÑŸÅÿ™Ÿä ÿ™ÿπÿµŸÅ ÿ®Ÿá ÿßŸÑÿ£ŸÅŸÉÿßÿ± ŸàÿßŸÑŸÖÿ¥ÿßÿπÿ± ŸÅŸä ŸÅÿ™ÿ±ÿ© ÿ¥ÿØŸäÿØÿ© ÿßŸÑÿ™ŸÇŸÑÿ® ŸÅŸÑÿ™ÿØÿπŸàÿß ŸÑŸá ŸàŸÑŸàÿßŸÑÿØŸäŸá Ÿàÿ¨ÿ≤ÿßŸÉ ÿßŸÑŸÑŸá ŸÉŸÑ ÿßŸÑÿÆŸäÿ± ÿ•ŸÜ ÿ£ŸÉŸÖŸÑÿ™ ÿßŸÑŸÇÿ±ÿßÿ°ÿ© üòöüòö</p>


</section>

 ]]></description>
  <category>blogging</category>
  <category>idea_Forge</category>
  <category>publish</category>
  <category>rough_thoughts</category>
  <category>life_style</category>
  <guid>https://kareemai.com/blog/posts/life_style/fake_graviety.html</guid>
  <pubDate>Tue, 09 Jul 2024 21:00:00 GMT</pubDate>
  <media:content url="https://kareemai.com/blog/posts/life_style/images/burn_out.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>My little Dragon ‚Äúkobo‚Äù</title>
  <link>https://kareemai.com/blog/posts/mteb_encoding/my_little_dargon.html</link>
  <description><![CDATA[ 





<section id="table-of-contents" class="level2">
<h2 class="anchored" data-anchor-id="table-of-contents">Table of contents</h2>
</section>
<section id="the-time-i-spend-with-kobo" class="level2">
<h2 class="anchored" data-anchor-id="the-time-i-spend-with-kobo">The time I spend with kobo</h2>
<p>I spend on average 8 hours on my laptop ‚Äúkobo‚Äù doing a lot of programming, machine learning experiments and browsing many taps.</p>
<p>I don‚Äôt use my phone a lot on average 1 or 2 hours, so i wake up and go to see my little friend and start journaling, wirte my ideas, perparing my todo list.</p>
<p>I have been using it for 4 years now, and it was a nice period i love that it hasn‚Äôt broken till now, everything is working good even the battery can stand for the 2.5 hours in the battery life with a lot of memory and cpu usage</p>
<p>You can easily say that my laptop is now a part of me i can‚Äôt live without it any more my dairy, movies, work and college is depending on it</p>
</section>
<section id="who-is-kobo" class="level2">
<h2 class="anchored" data-anchor-id="who-is-kobo">Who is ‚ÄúKobo‚Äù!</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://kareemai.com/blog/posts/mteb_encoding/dragon_2.png" class="img-fluid figure-img"></p>
<figcaption>Kobo</figcaption>
</figure>
</div>
<section id="system-specifications" class="level3">
<h3 class="anchored" data-anchor-id="system-specifications">System Specifications</h3>
<p>My laptop is a Gfthin 95 core i7 9th gen, 16 GB RAM, 512GB SSD and GTX 1660 Ti, 120Hz screen</p>
<hr>
</section>
</section>
<section id="msi-vs-lenovo" class="level2">
<h2 class="anchored" data-anchor-id="msi-vs-lenovo">MSI vs Lenovo</h2>
<section id="msi-with-linux" class="level3">
<h3 class="anchored" data-anchor-id="msi-with-linux">MSI with Linux</h3>
<p>After buying it, it wasn‚Äôt configured with Windows, but was another DOS version so I had to install a Windows version on it. After 1 week I get a lot of errors on it with the external monitor and the WiFi stops working or is not configured. I tried every Hindi video about this problem and gave it to specialists to try it, but in vain, the problem happened again and again.</p>
<p><strong>The solution:</strong> It was my first year at a computer science college, so the geeky thing was to use Linux. After some search, I installed Ubuntu and then tried a lot of distros like Void Linux, but the one that I picked and still use is the amazing PopOS! which is based on Ubuntu but better than it!<br>
The WiFi problem doesn‚Äôt appear again! And for Nvidia graphics, it‚Äôs solved in PopOS! which has a command to install some drivers. And everything works smoothly</p>
</section>
<section id="the-cost-of-it" class="level3">
<h3 class="anchored" data-anchor-id="the-cost-of-it">The Cost of It!</h3>
<p>I bought it for the cost of 20,000 EGP, which at the time I bought it was $X, but now 20,000 EGP is worth $XX due to problems in my country.</p>
<p>Its cost at that time is really high for my budget and family, but I insisted on buying it because I knew it would stay with me for years, so I wanted a good one.</p>
</section>
<section id="how-i-decided-to-buy-it" class="level3">
<h3 class="anchored" data-anchor-id="how-i-decided-to-buy-it">How I Decided to Buy It!</h3>
<p>The phrase ‚ÄúMachine learning needs an Nvidia GPU‚Äù was dancing in my mind, so my main focus was on a nice GPU card in a laptop with a low budget. After some search, I found that the best choices are MSI or Lenovo, but the Lenovo version cost about 4000 EGP more than the MSI.</p>
<blockquote class="blockquote">
<p>I tested the keyboard of the Lenovo, and every time I felt like I wanted to cut my fingers off</p>
</blockquote>
<p>It wasn‚Äôt available online, so I had to travel 3 hours to the store that sells it. It was a nice experience to buy something I wanted instead of a random gift from my father.</p>
<hr>
</section>
</section>
<section id="i-am-not-a-gamer" class="level2">
<h2 class="anchored" data-anchor-id="i-am-not-a-gamer">I Am Not a Gamer!</h2>
<p>I didn‚Äôt use it for gaming because I am not a gamer, but I used it heavily in programming and some machine learning and basic computer vision models, and it works so nicely!</p>
</section>
<section id="kobo-for-ml" class="level2">
<h2 class="anchored" data-anchor-id="kobo-for-ml">Kobo for ML</h2>
<p><img src="https://kareemai.com/blog/posts/mteb_encoding/dragon_3.png" class="img-fluid" alt="Kobo"> Machine learning is a wide area, and you can use the GPU for 3 things:</p>
<ol type="1">
<li>Train a model from scratch</li>
<li>Fine-tune a model</li>
<li>Evaluate a model (inference)</li>
</ol>
<ul>
<li><strong>Train</strong> a model from scratch was an ideal task for such a GPU, but I was doing it for multiple computer vision classification tasks, learning new architectures, trying to build‚Ä¶etc. For ML you don‚Äôt always need a GPU but for deep learning, which is a subset of ML that uses more connected layers (which means more computing power and memory needs), you do.</li>
<li><strong>Fine-tune</strong> a model is the case I used the most - I download a trained model and try to make it work better on my data. What you need here is enough GPU RAM - in my case it‚Äôs a 6GB card. This worked fine with computer vision algorithms and classic NLP models with less than 1 billion parameters. There‚Äôs no chance to try the LLAMAS models on such a card!</li>
<li><strong>Evaluate</strong> a model means to just load the model and not fine-tune it.</li>
</ul>
<p>I was fine with all the ML tasks I tried to do, unless I opened the door to large language models like the GPT family (ChatGPT for example). These models require a lot of memory and need a good graphics card like an RTX 30 or 40 series to test, and there‚Äôs no chance to train these models on any RTX card!</p>
<section id="why-not-just-use-the-cloud" class="level3">
<h3 class="anchored" data-anchor-id="why-not-just-use-the-cloud">Why Not Just Use the Cloud!</h3>
<p>There are two main solutions:</p>
<ol type="1">
<li>Kaggle
<ul>
<li>Kaggle has two GPU options, and I used it a lot, especially if the data was already hosted on Kaggle and was more than 10GB. Other than that, I downloaded a sample of the data and did my work on my own environment with CLI commands and VS Code configurations. This helped me a lot compared to just using the Kaggle editor, and it‚Äôs faster too! Sometimes the Kaggle kernel panics or just stops responding entirely!</li>
</ul></li>
<li>Colab
<ul>
<li>Colab restarts after 4 hours and your work can get lost, and lots of annoying things like that happen a lot.</li>
<li>You have to pay for the GPU version. You get a number of hours to try it out, and it‚Äôs faster than my GTX 1660 by a good margin.</li>
</ul></li>
</ol>
<p>But I didn‚Äôt love these cloud solutions, and I found having my own local setup to be faster and more comfortable.</p>
</section>
</section>
<section id="kobo-for-web-development" class="level2">
<h2 class="anchored" data-anchor-id="kobo-for-web-development">Kobo for Web Development</h2>
<p>I sometimes work on web projects (Django and JavaScript frameworks, especially AstroJS). I never had any issues building and testing web projects - everything worked nicely and efficiently.</p>
</section>
<section id="the-battery-life" class="level2">
<h2 class="anchored" data-anchor-id="the-battery-life">The Battery Life</h2>
<p>The battery life can keep it working for 2.5 hours when the power is out if you switch to battery saver mode. I don‚Äôt think it could last more than 1 hour in normal mode! This is the laptop‚Äôs biggest issue. Sometimes it powers off even when fully charged if you do a lot of computation without plugging it in.</p>
</section>
<section id="the-heat" class="level2">
<h2 class="anchored" data-anchor-id="the-heat">The Heat</h2>
<p><img src="https://kareemai.com/blog/posts/mteb_encoding/dragon_4.png" class="img-fluid" alt="target"> I didn‚Äôt find heat to be a problem or even the fan noise in most of my work. But sometimes when running a deep learning model, the fan noise is a bit loud and it does get really hot. For normal coding and browsing though, there are no issues and the cooling system is fast. Overall I didn‚Äôt find heat to be a major problem.</p>
</section>
<section id="the-keyboard" class="level2">
<h2 class="anchored" data-anchor-id="the-keyboard">The Keyboard</h2>
<p>The keyboard is very responsive and well configured with smooth clicks - no issues or sticky keys even though I have fat fingers!</p>
<p>I‚Äôve been using this machine for 4 years and I write a lot. No broken keys have happened despite my clumsy fingers. I have a mechanical keyboard that I sometimes use, but I always miss the feel of the built-in keyboard. The red backlight is decent.</p>
</section>
<section id="finally" class="level2">
<h2 class="anchored" data-anchor-id="finally">Finally!</h2>
<p><img src="https://kareemai.com/blog/posts/mteb_encoding/draong_1.png" class="img-fluid" alt="Kobo_finally"> I just wanted to say that I love ‚ÄúKobo‚Äù and I‚Äôve spent nice times with it - some really difficult and others really happy. It‚Äôs been a loyal friend and something to rely on.</p>


</section>

 ]]></description>
  <guid>https://kareemai.com/blog/posts/mteb_encoding/my_little_dargon.html</guid>
  <pubDate>Sun, 31 Dec 2023 22:00:00 GMT</pubDate>
</item>
<item>
  <title>After one year of using Huawei Mate 11 without google services</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/products_reviews/Huawei_mate_pad_11.html</link>
  <description><![CDATA[ 





<section id="table-of-contents" class="level2">
<h2 class="anchored" data-anchor-id="table-of-contents">Table of contents</h2>
<p>Here is an expanded version of your blog post with some additional details:</p>
</section>
<section id="why-i-bought-it" class="level2">
<h2 class="anchored" data-anchor-id="why-i-bought-it">Why I bought it</h2>
<p>I purchased the Huawei tablet because I enjoy creative activities like drawing, taking notes, and reading books. I wished to have an iPad or premium tablet with a good stylus to fully explore my creative potential. My brother found an excellent deal on this Huawei tablet for around 60% off retail price and gifted it to me. I‚Äôm very thankful to him! <img src="https://consumer.huawei.com/content/dam/huawei-cbg-site/common/mkt/pdp/tablets/matepad-11-2023-new/images/kv/Huawei-matepad-11-inch-2023-kv@2x.webp" class="img-fluid"></p>
</section>
<section id="pros" class="level2">
<h2 class="anchored" data-anchor-id="pros">Pros</h2>
<ol type="1">
<li>Excellent audio quality with quad speakers</li>
<li>Gorgeous 10.95-inch LCD display
<ul>
<li>2560x1600 resolution</li>
<li>120Hz refresh rate for smooth visuals</li>
</ul></li>
<li>Fast charging capabilities
<ul>
<li>Large 7250 mAh battery</li>
<li>Supports 22.5W fast wired charging</li>
</ul></li>
<li>Comfortable lightweight design, easy to use for long periods</li>
<li>Seamless integration with other Huawei devices like watches and earbuds</li>
<li>Responsive stylus with good palm rejection</li>
</ol>
</section>
<section id="cons" class="level2">
<h2 class="anchored" data-anchor-id="cons">Cons</h2>
<ol type="1">
<li>Tablet gets hot with prolonged intensive use like drawing or taking notes. Quite annoying.</li>
<li>Battery life is decent but not enough to last a full day with heavy usage</li>
<li>Frequent ads in App Gallery and default music app are frustrating
<ul>
<li>Should not see ads just trying to open App Gallery</li>
<li>Default music app tries to push online streaming service with more ads</li>
</ul></li>
<li>Many apps spam notifications asking to reopen them. Very irritating.</li>
</ol>
</section>
<section id="using-huawei-devices-with-linux" class="level2">
<h2 class="anchored" data-anchor-id="using-huawei-devices-with-linux">Using Huawei Devices with Linux</h2>
<ul>
<li>File transfers require a cable, no wireless sharing</li>
<li>Must use third party apps like KDE Connect for notifications</li>
<li>Can‚Äôt develop custom themes or scripts due to lack of developer tools</li>
<li>Syncing to Linux with Syncthing is slow and buggy</li>
<li>Overall poor integration with Linux compared to Android/Windows</li>
</ul>
</section>
<section id="issues-with-google-services-on-huawei" class="level2">
<h2 class="anchored" data-anchor-id="issues-with-google-services-on-huawei">Issues with Google Services on Huawei</h2>
<section id="stylus-apps" class="level3">
<h3 class="anchored" data-anchor-id="stylus-apps">Stylus Apps</h3>
<ul>
<li><strong>Infinite Painter</strong> drawing app has broken stylus support and no pressure sensitivity</li>
<li><strong>NoteShelf</strong> note taking app can‚Äôt sync properly with cloud drives</li>
<li><strong>Nebo</strong> note taking app has subpar palm rejection and no Arabic language support</li>
<li><strong>Flexcil</strong> best ebook reader/annotator but lacks Google Drive integration</li>
</ul>
</section>
<section id="gbox-solution" class="level3">
<h3 class="anchored" data-anchor-id="gbox-solution">Gbox Solution</h3>
<ul>
<li>Provides access to YouTube, Maps and other Google apps</li>
<li>Available on App Gallery with native integration</li>
<li>Minimal battery drain</li>
<li>But lacks support for many Google services like Podcasts</li>
<li>Buggy syncing with Google Keep</li>
<li>Can‚Äôt leverage Google Drive within other apps</li>
</ul>
</section>
<section id="apk-pure" class="level3">
<h3 class="anchored" data-anchor-id="apk-pure">APK Pure</h3>
<ul>
<li>Apps sometimes fail to open, just black screen</li>
<li>Too many ads</li>
<li>Lacks reliability compared to Play Store</li>
</ul>
<p>Overall, while the Huawei tablet offers excellent hardware, the software experience is hampered by lack of Google services. This leads to janky third party solutions and poor integration with Linux systems. I still enjoy using the tablet but hope someday Huawei can properly resolve these issues.</p>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">references</h2>
<ul>
<li>https://www.noteshelf.net/</li>
<li>https://www.gboxlab.com/</li>
<li>https://www.infinitestudio.art/painter.php</li>
</ul>


</section>

 ]]></description>
  <guid>https://kareemai.com/blog/posts/products_reviews/Huawei_mate_pad_11.html</guid>
  <pubDate>Wed, 06 Dec 2023 22:00:00 GMT</pubDate>
</item>
<item>
  <title>Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!</title>
  <dc:creator>kareem </dc:creator>
  <link>https://kareemai.com/blog/posts/products_reviews/Huawei freebuds 5i.html</link>
  <description><![CDATA[ 





<section id="table-of-contents" class="level2">
<h2 class="anchored" data-anchor-id="table-of-contents">Table of contents</h2>
</section>
<section id="intro" class="level2">
<h2 class="anchored" data-anchor-id="intro">Intro</h2>
<p>Hi, In this fast blog i will talk about my review with Huawei Freebuds 5i, which is the first noise-cancelling earbuds i have tried. This is not an ad or even affiliate product, it‚Äôs my own review for fun and just seeking of knowledge. <img src="https://consumer.huawei.com/content/dam/huawei-cbg-site/common/mkt/pdp/headphones/freebuds5i/imges/huawei-freebuds-5i-kv.jpg" class="img-fluid" alt="freebuds"></p>
</section>
<section id="who-am-i" class="level2">
<h2 class="anchored" data-anchor-id="who-am-i">Who am i !</h2>
<ul>
<li>I am Kareem, a college student interested in machine learning and web technology.</li>
<li>I enjoy working deeply and seeking out quiet places, but I live in an area with some noisy disturbances in the mornings - people walking down the street, kids playing around the house, street vendors - which often interrupt my focus and break my state of flow.</li>
<li>I wish there was a solution to block out all these sounds so I could live in an isolated place free of annoying noises! Using noise-cancelling headphones or heading into outer space would be ideal environments with no bothersome sounds around.</li>
</ul>
</section>
<section id="how-i-bought-it" class="level2">
<h2 class="anchored" data-anchor-id="how-i-bought-it">how i bought it</h2>
<ul>
<li>I bought it from amazon prime, and it cost me around 100$ or 3,200 pounds. It reached within two days.</li>
</ul>
</section>
<section id="first-impressions" class="level2">
<h2 class="anchored" data-anchor-id="first-impressions">First impressions</h2>
<ul>
<li>Upon unboxing and using it for the first time, I was genuinely pleased with the initial track I played.</li>
<li>The sound quality was noticeably superior compared to my phone or any other earbuds I‚Äôve previously used. I then tested the noise-cancelling feature and was amazed when I couldn‚Äôt hear my younger brother calling me.</li>
<li>The street noises were effectively blocked out, with only a faint hum reaching my ears, which was quite tolerable. Initially, the earbud tips were a bit uncomfortable, but after switching to a smaller size, the discomfort was resolved. Everything seemed perfect, except for a slight pressure in my ears when using the noise-cancelling feature, particularly noticeable the following morning. Despite this, my ears seem to crave the earbuds and my skin seems to miss them when they‚Äôre not in use. This can be a bit of a downside, but it‚Äôs not always the case.</li>
</ul>
</section>
<section id="is-noise-cancelling-actually-work" class="level2">
<h2 class="anchored" data-anchor-id="is-noise-cancelling-actually-work">Is noise cancelling actually work ?</h2>
<p>I‚Äôve used these earbuds in various settings:</p>
<ol type="1">
<li><p>Subway: The noise-cancelling feature combined with my music created an immersive experience, effectively blocking out any other sounds and allowing me to enjoy my tunes in peace.</p></li>
<li><p>College: Amidst the chatter and shouts of other students, I was able to retreat into my own world of sound.</p></li>
<li><p>Bus: The noise of the bus engine was successfully blocked out, but I could still hear the conversations of those sitting next to me. It wasn‚Äôt overly bothersome, but it didn‚Äôt provide complete isolation.</p></li>
</ol>
<p>In summary, the noise-cancelling feature works well, but it doesn‚Äôt provide absolute silence. I can still hear some ambient sounds. One noticeable issue is that when I make calls using the earbuds, I can hear the other person clearly, but they often complain about the clarity of my voice. They say it sounds distant and unclear, sometimes even asking to call back later. This issue is particularly prevalent when I‚Äôm on the bus.</p>
</section>
<section id="the-modes-of-the-freebuds-and" class="level2">
<h2 class="anchored" data-anchor-id="the-modes-of-the-freebuds-and">the modes of the Freebuds and</h2>
<p>Here is a rephrased version of the key points about the Huawei Freebuds 5i‚Äôs features:</p>
<p><strong>Noise Cancellation Modes:</strong></p>
<ol type="1">
<li><p><strong>Noise Cancelling Mode</strong>: Actively cancels out ambient noise. Uses more battery power.</p></li>
<li><p><strong>Off Mode</strong>: No active noise cancellation, but still provides some passive noise isolation. Less battery usage.</p></li>
<li><p><strong>Awareness Mode</strong>: Allows ambient sounds to be heard clearly. Useful for hearing announcements at the gym or people talking to you. However, my own voice sounds muted in this mode, so I have to remove the earbuds temporarily to hold conversations.</p></li>
</ol>
<p><strong>Sound Quality Presets:</strong></p>
<ol type="1">
<li><p><em>Default</em>: No sound enhancements applied.</p></li>
<li><p><em>Treble Boost</em>: Boosts treble frequencies. I haven‚Äôt used this.</p></li>
<li><p><em>Bass Boost</em>: Emphasizes bass when listening to music like hip-hop.</p></li>
<li><p><em>Voices</em>: Optimizes sound for speech clarity. I use this for podcasts.</p></li>
</ol>
<p><strong>Connection Priority Modes:</strong></p>
<ol type="1">
<li><p><strong>Balance Mode</strong>: Balances audio quality and connection stability.</p></li>
<li><p><strong>Sound Quality Priority</strong>: Prioritizes sound quality over connectivity. Uses more power which may cause occasional lag.</p></li>
</ol>
<p>I have not noticed any discernible difference between these two modes, so I just use the Balance mode.</p>
</section>
<section id="the-gestures" class="level2">
<h2 class="anchored" data-anchor-id="the-gestures">The Gestures</h2>
<p>The Huawei Freebuds 5i offer various gesture controls:</p>
<ul>
<li>Double-tap, Triple-tap, Press &amp; hold, Swipe</li>
</ul>
<p>I particularly enjoy the swipe gesture for volume control, as it works smoothly. The press and hold gesture is a bit slow, and the triple-tap gesture can be annoying since tapping your ear three times isn‚Äôt very comfortable.</p>
<p>Occasionally, the Freebuds don‚Äôt recognize when I‚Äôve inserted the left or right earbud, and I continue listening with just one earbud without realizing the other isn‚Äôt connected. This doesn‚Äôt happen often, though.</p>
</section>
<section id="the-compatibility-with-other-devices" class="level2">
<h2 class="anchored" data-anchor-id="the-compatibility-with-other-devices">The compatibility with other devices</h2>
<ul>
<li>I love how it connect with both the phone and tablet without any problems or conflict</li>
<li>I‚Äôve been using the Freebuds with my Realme phone, MSI Linux laptop, and Huawei Mate Pad 11.</li>
<li>The connection with the Realme phone is seamless, regardless of whether the AI Life application is used or not.</li>
<li>When it comes to the Huawei Mate Pad 11, there‚Äôs a feature that allows you to adjust settings directly from the Bluetooth menu. This is a functionality that isn‚Äôt available on standard Android devices without the AI Life app.</li>
</ul>
<section id="linux-connection" class="level3">
<h3 class="anchored" data-anchor-id="linux-connection">Linux connection</h3>
<p>I‚Äôve connected the Freebuds to my Linux laptop using the ‚Äò<a href="https://smarttech101.com/bluetoothctl-management-of-bluetooth-devices-in-linux/">bluetoothctl</a>‚Äô command. However, I‚Äôve encountered an issue where I need to restart Bluetooth each time I want to establish a connection for it to work properly</p>
</section>
</section>
<section id="the-case-and-overall-design" class="level2">
<h2 class="anchored" data-anchor-id="the-case-and-overall-design">The case and overall design</h2>
<ul>
<li>The design of the Freebuds is truly appealing. It has a unique aesthetic that sets it apart from other earbuds, giving it a premium feel.</li>
<li>In terms of design, the FreeBuds 5i bear a resemblance to the 4i model, but they are 11% lighter and have shorter stems. They come with an IP54 rating, making them dust-tight and splash-resistant. The color options include a new ‚ÄúIsle Blue‚Äù, along with ‚ÄúNebula Black‚Äù and ‚ÄúCeramic White‚Äù. The package includes small, medium, and large silicone eartips, as well as a short USB-C cable for charging the case.</li>
<li>I love the sound of closing it, it‚Äôs a loud sound but lovely :)</li>
</ul>
</section>
<section id="the-battery" class="level2">
<h2 class="anchored" data-anchor-id="the-battery">The battery</h2>
<ul>
<li>The battery is really nice; I haven‚Äôt felt that I am missing the need to recharge it or that it has gone off at any time.</li>
</ul>
<section id="battery-capacity" class="level3">
<h3 class="anchored" data-anchor-id="battery-capacity">Battery capacity</h3>
<ul>
<li>Per earbud: 55 mAh (min)*</li>
<li>Charging case: 410 mAh (min)*</li>
</ul>
</section>
<section id="playtime" class="level3">
<h3 class="anchored" data-anchor-id="playtime">Playtime</h3>
<ul>
<li>Music playback on 1 charge: 6.0 hours (with ANC enabled)**</li>
<li>Music playback on 1 charge: 7.5 hours (with ANC disabled)**</li>
<li>Music playback with charging case: 18.5 hours (with ANC enabled)**</li>
<li>Music playback with charging case: 28 hours (with ANC disabled)**</li>
</ul>
</section>
<section id="charging-time" class="level3">
<h3 class="anchored" data-anchor-id="charging-time">Charging Time</h3>
<ul>
<li>About 60 minutes for the earbuds (in the charging case)***</li>
<li>About 110 for charging case without earbuds (wired)***</li>
</ul>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li>https://smarttech101.com/bluetoothctl-management-of-bluetooth-devices-in-linux/</li>
<li>https://askubuntu.com/questions/1225896/huawei-freebuds-3-pairing-with-ubuntu-18-04</li>
<li><a href="https://kamcalorie.com">ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä</a></li>
</ul>


</section>

 ]]></description>
  <guid>https://kareemai.com/blog/posts/products_reviews/Huawei freebuds 5i.html</guid>
  <pubDate>Tue, 05 Dec 2023 22:00:00 GMT</pubDate>
</item>
</channel>
</rss>
