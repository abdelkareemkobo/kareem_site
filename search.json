[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nAbdelkareem Elkhateb\n",
    "section": "",
    "text": "I build Arabic AI that actually works.\n\n\n500M+ Arabic speakers deserve better than translated English models.\n\n\nI create efficient NLP systems that run anywhere ‚Äî from cloud servers to cheap phones.\n\n\n GitHub\n Research\n Hire Me\n\n\n\n\n\nÿßŸÑŸÑÿ∫ÿ© ŸÑŸäÿ≥ÿ™ ÿπŸêŸÑŸÖŸãÿß .. ÿ®ŸÑ ŸáŸä ÿ¥Ÿäÿ° ŸÅŸàŸÇ ÿßŸÑÿπŸÑŸÖ ŸÑÿ∫ÿ™ŸÜÿß ŸÅŸä ÿÆÿ∑ÿ± ÿØÿßŸáŸÖ .. ŸàŸÜÿ≠ŸÜ ÿ£Ÿäÿ∂Ÿãÿß\n\n\n‚ÄúLanguage is not a science ‚Äî it is something above science.Our language is in danger ‚Äî and so are we.‚Äù\n\n\n\n\n\nWhat I‚Äôve Built\n\n\n\n\nBertHash-Femto\n\n\nArabic embedding model that‚Äôs 113x smaller than AraBERTv2 (1.2M vs 135M parameters) while achieving 94% of its performance. Runs on edge devices.\n\n\nWhy it matters: Production-ready Arabic AI without expensive GPU infrastructure.\n\nGitHub ‚Üí\n\n\n\nZarra & Bojji\n\n\nArabic AI models that are 10x smaller than competitors but just as accurate. They run on phones, not just expensive servers.\n\nRead more ‚Üí\n\n\n\nŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä\n\n\nAsk ‚Äúhow many calories in koshari?‚Äù in Arabic and get real answers. Semantic search for nutrition.\n\nTry it ‚Üí\n\n\n\nGPUVec\n\n\nDeveloper toolkit for ML infrastructure decisions. Compare GPU pricing across 50+ cloud providers, benchmark LLMs and embedding models, and calculate Qdrant vector database specs.\n\nCheck it out ‚Üí\n\n\n\nArabic GLiNER\n\n\nExtract names, places, and organizations from Arabic text automatically.\n\nGitHub ‚Üí\n\n\n\n\n\n\nWhere I Work\n\n\n\n\nXbites 2025 - now\n\n\nBuilding the AI backend for Darin, a smart real estate platform. I designed semantic search (improved relevancy from 30% to 92%), built an AI agent factory that generates custom agents in under 2 minutes, and automated data pipelines across 150+ developers and 500 projects.\n\n\nResult: Reduced broker workflow time by 83%. Enabled deals with major real estate companies.\n\n\n\n\nHamza Salem Lab 2024 - now\n\n\nResearch group focused on advancing Arabic AI. I build embedding models and contribute to academic publications. Our mission is to make cutting-edge Arabic AI accessible beyond big tech.\n\n\nResult: Multiple papers published, 54 citations, models used internationally.\n\n\n\n\nNAMMA Nov 2024 - now\n\n\nPart-time NLP Engineer and open-source maintainer. Contributing to state-of-the-art Arabic LLMs, embeddings, OCR, and ASR systems.\n\n\nResult: Multiple SOTA Arabic models released openly, used by thousands of developers across the Arab world.\n\n\n\n\nFreelance 2021 - now\n\n\nSearch engines, APIs, ML pipelines, and web applications for clients worldwide. Top-rated freelancer on Upwork with 20+ completed projects.\n\n\nResult: Repeat clients from 5+ countries.\n\n\n\n\n\n\n\nWhat I‚Äôm Working On Now\n\n\n\n\nBetter Arabic embeddings ‚Äî Current models struggle with dialects. Fixing that.\n\n\nArabic OCR ‚Äî Reading old Arabic manuscripts and printed books automatically.\n\n\nMultimodal Arabic AI ‚Äî Models that understand both Arabic text and images together.\n\n\nCPU-efficient Transformers ‚Äî Master‚Äôs thesis research on making models faster without GPUs.\n\n\n\n\n7 Papers\n\n\n54 Citations\n\n\n962 Papers Read\n\n\n\n\n\n\n\nWork With Me\n\n\nNeed Arabic AI, production ML systems, or efficient model architectures?\n\n\n Email Me  Upwork\n\n\n\n\n\nUpdates\n\n\nGet notified when I publish new research or projects.\n\n\n\n\n\n\n RSS  GitHub  YouTube"
  },
  {
    "objectID": "til/tils/2025-10-21.html",
    "href": "til/tils/2025-10-21.html",
    "title": "Evaluating Arabic Tokenizers",
    "section": "",
    "text": "When working with Arabic language models, choosing the right tokenizer can significantly impact model performance and efficiency. In this post, I‚Äôll share my experience comparing two popular Arabic tokenizers: AraModernBert and AraBERT v2."
  },
  {
    "objectID": "til/tils/2025-10-21.html#introduction",
    "href": "til/tils/2025-10-21.html#introduction",
    "title": "Evaluating Arabic Tokenizers",
    "section": "",
    "text": "When working with Arabic language models, choosing the right tokenizer can significantly impact model performance and efficiency. In this post, I‚Äôll share my experience comparing two popular Arabic tokenizers: AraModernBert and AraBERT v2."
  },
  {
    "objectID": "til/tils/2025-10-21.html#why-tokenizer-evaluation-matters",
    "href": "til/tils/2025-10-21.html#why-tokenizer-evaluation-matters",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Why Tokenizer Evaluation Matters",
    "text": "Why Tokenizer Evaluation Matters\nAfter reading the comprehensive guide on GPT tokenizers, I realized that tokenization is often overlooked but critically important. Poor tokenization can lead to:\n\nInefficient use of limited context windows\nHigher computational costs (you pay per token!)\nWorse model performance, especially for non-English languages\n\nFor Arabic specifically, tokenization is challenging because:\n\nArabic has rich morphology with prefixes and suffixes\nDifferent dialects (Egyptian, Levantine, Gulf) have varying vocabulary\nDiacritical marks (tashkeel) add complexity\nTasks the needs Tashkeel like Speech synthesis Grammar checking (need tashkeel) like arabic poetry tasks ..etc"
  },
  {
    "objectID": "til/tils/2025-10-21.html#the-evaluation-framework",
    "href": "til/tils/2025-10-21.html#the-evaluation-framework",
    "title": "Evaluating Arabic Tokenizers",
    "section": "The Evaluation Framework",
    "text": "The Evaluation Framework\nI built a simple evaluation function to measure tokenizer quality:\ndef evaluate_tokenizer(text, tokenizer):\n    number_of_tokens = len(tokenizer.tokenize(text))\n    number_of_bytes = len(text.encode('utf-8'))\n    number_of_words = len(text.split(\" \"))\n    fertility = number_of_tokens / number_of_words \n    compression_ratio = number_of_bytes / number_of_tokens \n    return {\n        \"fertility\": fertility,\n        \"compression_ratio\": compression_ratio,\n        \"total_tokens\": number_of_tokens\n    }\n\nKey Metrics\n\nFertility Rate (tokens/word): Lower is better. Measures how many tokens are needed per word.\nCompression Ratio (bytes/token): Higher is better. Measures how efficiently the tokenizer compresses text.\nTotal Tokens: The raw count for the given text."
  },
  {
    "objectID": "til/tils/2025-10-21.html#the-contenders",
    "href": "til/tils/2025-10-21.html#the-contenders",
    "title": "Evaluating Arabic Tokenizers",
    "section": "The Contenders",
    "text": "The Contenders\n\nAraModernBert\n\nVocabulary: 50,280 tokens\nTraining Data: 100GB of Arabic text\nArchitecture: ModernBERT with transtokenization\nContext Window: 8,192 tokens\n\n\n\nAraBERT v2\n\nVocabulary: ~30,000 tokens\nTraining Data: 77GB of Arabic text\nArchitecture: BERT-base\nPre-segmentation: Uses Farasa segmenter"
  },
  {
    "objectID": "til/tils/2025-10-21.html#test-results",
    "href": "til/tils/2025-10-21.html#test-results",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Test Results",
    "text": "Test Results\nI tested both tokenizers on three different Arabic texts with Encoder only for now more to come later!:\n\nTest 1: Modern Standard Arabic\nText: ‚ÄúŸÖÿ±ÿ≠ÿ®ÿß ŸÉŸäŸÅ ÿ≠ÿßŸÑŸÉ ÿßŸÑŸäŸàŸÖ‚Äù\n\n\n\nTokenizer\nFertility\nCompression Ratio\nTotal Tokens\n\n\n\n\nAraModernBert\n1.25\n7.4\n5\n\n\nAraBERT v2\n1.5\n6.17\n6\n\n\n\n\n\nTest 2: Egyptian Dialect\nText: ‚Äúÿ•ÿ≤ŸäŸÉ Ÿäÿß ÿµÿßÿ≠ÿ®Ÿä ÿπÿßŸÖŸÑ ÿ•ŸäŸá‚Äù\n\n\n\nTokenizer\nFertility\nCompression Ratio\nTotal Tokens\n\n\n\n\nAraModernBert\n1.2\n6.67\n6\n\n\nAraBERT v2\n1.4\n5.71\n7\n\n\n\n\n\nTest 3: Technical/Formal Text\nText: ‚ÄúÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä Ÿäÿ∫Ÿäÿ± ÿßŸÑÿπÿßŸÑŸÖ ÿ®ÿ≥ÿ±ÿπÿ© ŸÉÿ®Ÿäÿ±ÿ©‚Äù\n\n\n\nTokenizer\nFertility\nCompression Ratio\nTotal Tokens\n\n\n\n\nAraModernBert\n1.17\n10.71\n7\n\n\nAraBERT v2\n2.0\n6.25\n12"
  },
  {
    "objectID": "til/tils/2025-10-21.html#key-findings",
    "href": "til/tils/2025-10-21.html#key-findings",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Key Findings",
    "text": "Key Findings\n\n1. AraModernBert is Consistently More Efficient\nAcross all three tests, AraModernBert showed:\n\nLower fertility (15-42% fewer tokens per word)\nHigher compression ratio (14-71% better compression)\nFewer total tokens needed for the same text\n\n\n\n2. The Gap Widens with Complex Text\nThe most dramatic difference appeared in Test 3 (technical text):\n\nAraModernBert: 7 tokens\nAraBERT v2: 12 tokens (71% more!)\n\nThis means for an 8K context window, AraModernBert can fit significantly more Arabic text.\n\n\n3. Both Handle Dialects Reasonably Well\nThe Egyptian dialect test (Test 2) showed both tokenizers maintained similar efficiency to MSA, though AraModernBert still outperformed."
  },
  {
    "objectID": "til/tils/2025-10-21.html#why-aramodernbert-performs-better",
    "href": "til/tils/2025-10-21.html#why-aramodernbert-performs-better",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Why AraModernBert Performs Better",
    "text": "Why AraModernBert Performs Better\n\nLarger Vocabulary (50K vs 30K tokens)\nMore tokens means the model can learn longer, more common Arabic word chunks as single tokens.\nThis is especially important for Arabic‚Äôs morphologically rich structure.\n\n\nMore Training Data (100GB vs 77GB)\nMore data leads to better byte-pair encoding merges that reflect actual Arabic usage patterns.\n\n\nModern Architecture\nAraModernBert uses transtokenization - a technique that optimally initializes embeddings when creating the tokenizer, leading to better learned representations.\n\n\nRecency Advantage\nTrained in 2024 vs 2020, AraModernBert benefits from more recent data and improved training techniques."
  },
  {
    "objectID": "til/tils/2025-10-21.html#practical-implications",
    "href": "til/tils/2025-10-21.html#practical-implications",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Practical Implications",
    "text": "Practical Implications\n\nFor Model Training\n\nContext efficiency: AraModernBert lets you fit ~40% more Arabic text in the same context window\nCost savings: Fewer tokens = lower training costs\nBetter performance: More efficient tokenization often correlates with better downstream task performance\n\n\n\nFor Production Systems\n\nAPI costs: Pay per token, so more efficient tokenization = lower costs\nLatency: Fewer tokens to process = faster inference\nMemory: Smaller token sequences = lower memory footprint"
  },
  {
    "objectID": "til/tils/2025-10-21.html#should-you-train-your-own-tokenizer",
    "href": "til/tils/2025-10-21.html#should-you-train-your-own-tokenizer",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Should You Train Your Own Tokenizer?",
    "text": "Should You Train Your Own Tokenizer?\nAfter this evaluation, here‚Äôs my thinking:\nUse AraModernBert if:\n\nYou‚Äôre working with Modern Standard Arabic or mixed dialects\nYou want state-of-the-art efficiency out of the box\nYou don‚Äôt have massive compute resources for training\n\nTrain your own if:\n\nYou have a very specific domain (medical, legal, etc.)\nYou‚Äôre working with a specific dialect extensively (pure Egyptian, Levantine, etc.)\nYou have unique requirements (handling tashkeel differently, etc.)\n\nFor my Egyptian Arabic use case, I‚Äôm leaning toward using AraModernBert‚Äôs tokenizer as-is, since:\n\nIt already handles Egyptian dialect reasonably well\nThe 50K vocabulary is large enough to be flexible\nTraining a custom tokenizer requires significant effort and data"
  },
  {
    "objectID": "til/tils/2025-10-21.html#next-steps",
    "href": "til/tils/2025-10-21.html#next-steps",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Next Steps",
    "text": "Next Steps\n\nTest on real data: Evaluate on actual Egyptian Arabic corpus (FineWeb Egyptian)\nCompare with SentencePiece: Test a SentencePiece tokenizer trained on Arabic\nMeasure downstream performance: Tokenizer efficiency doesn‚Äôt always equal better model performance\nInvestigate tashkeel handling: How do these tokenizers handle diacritical marks?"
  },
  {
    "objectID": "til/tils/2025-10-21.html#conclusion",
    "href": "til/tils/2025-10-21.html#conclusion",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Conclusion",
    "text": "Conclusion\nTokenizer evaluation revealed that AraModernBert significantly outperforms AraBERT v2 in efficiency metrics, with 15-71% fewer tokens needed for the same Arabic text.\nThis translates to real cost savings and performance improvements in production systems.\nThe key lesson: don‚Äôt assume all tokenizers are equal. A few hours of evaluation can save months of headaches and significant costs down the line."
  },
  {
    "objectID": "til/tils/2025-10-21.html#code-repository",
    "href": "til/tils/2025-10-21.html#code-repository",
    "title": "Evaluating Arabic Tokenizers",
    "section": "Code Repository",
    "text": "Code Repository\nThe complete evaluation code is available as a simple function:\ndef evaluate_tokenizer(text, tokenizer):\n    number_of_tokens = len(tokenizer.tokenize(text))\n    number_of_bytes = len(text.encode('utf-8'))\n    number_of_words = len(text.split(\" \"))\n    fertility = number_of_tokens / number_of_words \n    compression_ratio = number_of_bytes / number_of_tokens \n    return {\n        \"fertility\": fertility,\n        \"compression_ratio\": compression_ratio,\n        \"total_tokens\": number_of_tokens\n    }\nthis post was built with guide from Amazing Solveit"
  },
  {
    "objectID": "til/tils/2025-05-23-til.html",
    "href": "til/tils/2025-05-23-til.html",
    "title": "Brave Leo AI with Ollama, vllm, and any huggingface llm locally",
    "section": "",
    "text": "Brave Leo AI is a super handy, privacy-first AI assistant built right into the Brave browser.\nIt‚Äôs there to help you out with all sorts of tasks, and it works on your computer (macOS, Windows, Linux) or phone (Android and iOS).\nThe best part? You don‚Äôt need to sign up or log in to use it for free, and it‚Äôs designed to keep your data private.\n\n\n\nBrave Leo with Ollama or VLLM\n\n\n\n\nLeo‚Äôs got a lot of tricks up its sleeve: - Summarize Stuff Instantly: It can give you quick summaries of webpages, PDFs, Google Docs, Google Sheets, or even YouTube videos by reading their transcripts.\n\nAnswer Questions: Whether it‚Äôs about a webpage or just something you‚Äôre curious about, Leo can explain things clearly and even offer different perspectives.\nWrite and Create: Need an article, email, essay, or some code? Leo can whip it up for you.\nTranslate and Code: It can translate text into different languages or help with coding by suggesting or generating code snippets.\nCustom AI Models: With the ‚ÄúBring Your Own Model‚Äù feature, you can plug in your own local or remote AI models for a personalized experience.\n\n\n\n\nPrivacy is Leo‚Äôs middle name! Here‚Äôs why it‚Äôs safe:\n\nAnonymized Requests: Leo uses a reverse proxy, so Brave can‚Äôt tie your requests to your IP address.\nNo Chat Storage: Your conversations aren‚Äôt saved on Brave‚Äôs servers or used to train AI models.\nNo Sign-Up Needed: You can use it for free without an account. Even the premium version uses anonymous tokens to keep things private.\nLocal Storage: Your chat history stays on your device, and you can clear it anytime through the browser settings.\nHeads-Up on Third-Party Models: If you use external AI models (like Anthropic‚Äôs Claude), their data policies might differ (Claude keeps chats for 30 days, for\nexample). Always check the privacy terms if you go that route.\n\n\n\n\nIf you‚Äôre using Brave version 1.75 or higher on desktop or Android (not in Incognito or Tor mode), you can keep track of your chats with Leo.\nThey‚Äôre stored locally on your device, not on any server, so you‚Äôre in control. You can revisit, continue, or delete them from the Leo full-page view (brave://leo-ai) or the browser‚Äôs sidebar.\nJust note that clearing your browsing history will also wipe out any webpage-related content in your chats. Easy peasy!"
  },
  {
    "objectID": "til/tils/2025-05-23-til.html#whats-brave-leo-ai-all-about",
    "href": "til/tils/2025-05-23-til.html#whats-brave-leo-ai-all-about",
    "title": "Brave Leo AI with Ollama, vllm, and any huggingface llm locally",
    "section": "",
    "text": "Brave Leo AI is a super handy, privacy-first AI assistant built right into the Brave browser.\nIt‚Äôs there to help you out with all sorts of tasks, and it works on your computer (macOS, Windows, Linux) or phone (Android and iOS).\nThe best part? You don‚Äôt need to sign up or log in to use it for free, and it‚Äôs designed to keep your data private.\n\n\n\nBrave Leo with Ollama or VLLM\n\n\n\n\nLeo‚Äôs got a lot of tricks up its sleeve: - Summarize Stuff Instantly: It can give you quick summaries of webpages, PDFs, Google Docs, Google Sheets, or even YouTube videos by reading their transcripts.\n\nAnswer Questions: Whether it‚Äôs about a webpage or just something you‚Äôre curious about, Leo can explain things clearly and even offer different perspectives.\nWrite and Create: Need an article, email, essay, or some code? Leo can whip it up for you.\nTranslate and Code: It can translate text into different languages or help with coding by suggesting or generating code snippets.\nCustom AI Models: With the ‚ÄúBring Your Own Model‚Äù feature, you can plug in your own local or remote AI models for a personalized experience.\n\n\n\n\nPrivacy is Leo‚Äôs middle name! Here‚Äôs why it‚Äôs safe:\n\nAnonymized Requests: Leo uses a reverse proxy, so Brave can‚Äôt tie your requests to your IP address.\nNo Chat Storage: Your conversations aren‚Äôt saved on Brave‚Äôs servers or used to train AI models.\nNo Sign-Up Needed: You can use it for free without an account. Even the premium version uses anonymous tokens to keep things private.\nLocal Storage: Your chat history stays on your device, and you can clear it anytime through the browser settings.\nHeads-Up on Third-Party Models: If you use external AI models (like Anthropic‚Äôs Claude), their data policies might differ (Claude keeps chats for 30 days, for\nexample). Always check the privacy terms if you go that route.\n\n\n\n\nIf you‚Äôre using Brave version 1.75 or higher on desktop or Android (not in Incognito or Tor mode), you can keep track of your chats with Leo.\nThey‚Äôre stored locally on your device, not on any server, so you‚Äôre in control. You can revisit, continue, or delete them from the Leo full-page view (brave://leo-ai) or the browser‚Äôs sidebar.\nJust note that clearing your browsing history will also wipe out any webpage-related content in your chats. Easy peasy!"
  },
  {
    "objectID": "til/tils/2025-05-23-til.html#bring-your-own-model-byom-with-brave-leo",
    "href": "til/tils/2025-05-23-til.html#bring-your-own-model-byom-with-brave-leo",
    "title": "Brave Leo AI with Ollama, vllm, and any huggingface llm locally",
    "section": "Bring Your Own Model (BYOM) with Brave Leo",
    "text": "Bring Your Own Model (BYOM) with Brave Leo\nWith BYOM , you can connect your own AI models to Leo for a custom experience. You can use platforms like vLLM, SGLang, or any inefernce engines with any Hugging Face Transformers model, as long as it follows the OpenAI Chat Protocol.\nFor example, you can run a model like Qwen2.5-VL-3B-Instruct locally with this command:\n\npython -m sglang.launch_server --port 7501 --model-path Qwen/Qwen2.5-VL-3B-Instruct\nThis sets up a server for SGLang (or you can use vLLM with a similar command).\nThen, in Brave Leo‚Äôs BYOM settings, add your model with these details:\nLabel: Qwen2.5-VL-3B-Instruct\nModel Request Name: Qwen2.5\nServer Endpoint: http://127.0.0.1:7501/v1/chat/completions\nContext Size: 4000\nAPI Key: local\nSystem Prompt: A custom prompt like, ‚ÄúYou are Leo, a helpful AI assistant by Brave. Provide clear, concise, polite responses under 80 words. Use a neutral tone, clarify if needed, and ensure accuracy.‚Äù\nBrave doesn‚Äôt proxy these requests, so check the privacy terms of your chosen provider. Once set up, your model integrates with Leo, letting you use it directly in the browser for tailored, private AI chats. It‚Äôs like giving Leo your own custom brain!"
  },
  {
    "objectID": "til/tils/2025-06-06-til.html",
    "href": "til/tils/2025-06-06-til.html",
    "title": "Connecting with ideas in ML",
    "section": "",
    "text": "Here is the corrected version with grammar errors fixed and improved clarity, while preserving the original meaning and tone:\n\nGet paid for your knowledge!\nI‚Äôm not interested in all this talk about being replaced by AI. If AI can replace an engineer‚Äôs mind, it will replace everything in the world.\nWhen this happens, it won‚Äôt really matter!\nI got my first job one year after graduation with a good salary for my experience and the local currency.\nÿßŸÑÿ≠ŸÖÿØ ŸàÿßŸÑÿ¥ŸÉÿ± ŸàÿßŸÑŸÅÿ∂ŸÑ ŸÑŸÑŸá Ÿàÿ≠ÿØŸá.\nActually, I got two jobs, not one!\nI landed a full-time AI Engineer position at a startup that is already operational with its own customers, plus a part-time role with flexible meetings. I‚Äôm the wildcard‚Äîmaybe even the AI‚Äîin this startup, which is set to receive funding in the coming weeks.\nThis might give the impression that I‚Äôm a great engineer, but I‚Äôm not!\nI‚Äôm not good at programming; I‚Äôm below average and can barely do cool stuff on my own. I only know some solutions to try, and I‚Äôm familiar with multiple resources and places to get help. I love asking more experienced people for feedback.\nI can only say that I love this field a lot! It‚Äôs very interesting. With just a laptop and my mind, I can create things the world needs and will pay for!\nThis may sound silly, but it‚Äôs an amazing idea to think about, especially for someone like me who doesn‚Äôt enjoy the outside world or dealing with people in real life.\nWhat I like is that the world is connected, and you can gain recognition quickly if you‚Äôre doing real work and building connections with people in your field.\nI‚Äôm interested in Machine Learning and focus on niche areas where not many people are working. In my language, there‚Äôs little competition, which gives me a unique edge! But in reality, I‚Äôm below average; the basics I explore in these areas are enough for now.\nI don‚Äôt advise anyone to do this, but I want to say that when you try your best, reflect on your goals, start crafting your ideas, and engage with others‚Äô ideas, your influence and impact will grow significantly.\nI‚Äôve met many ordinary people who simply read documentation, ask questions about what they don‚Äôt know, and are beginners, yet others look at them and think, ‚ÄúWow, they must be geniuses!‚Äù\nBut they‚Äôre not! You may have more knowledge and experience than them, but business, your birthplace, and the college you graduated from are strong factors in determining your path.\nYou can reach great places without these, but they accelerate your progress!\nWe all know the story of the child who learned programming at 11 years old and now, at 25, codes as easily as walking.\nWhat I‚Äôve found is that you can still build great connections with someone who has 10 years more experience than you, and they might even say, ‚ÄúYou‚Äôre a smart person! I want you to work with me.‚Äù\nWe‚Äôre all limited, and there will always be gaps that require other minds to fill. The great thing is that we grow faster when we connect with such minds!\nI really admire the work from the AnswerDotAI team. I find that Jeremy Howard has a profound impact on how I think about AI and learning.\nThe courses I‚Äôve taken with him, the community, and the tools make me feel ahead of the curve and capable of creating things!\nWhen you start following people like Omar Khatab, Benjamin, Antoine, Tom Arson, and many others, and interact with their work, you begin to gain weight in these spaces. I‚Äôm not just talking about getting a job‚ÄîI‚Äôm talking about the level of ideas.\nThere are people watching, people building tools around concepts, and people creating new concepts!\nI wish I could reach the cutting edge of knowledge. This may not be precise, but I see it as a journey I want to pursue.\nThere‚Äôs more to say, but this world has immense potential for smart people‚Äînot in terms of marketing or being a shallow influencer.\nI want to say that I have many ideas I want to create and share with other minds. I believe I‚Äôll be able to make a positive impact in the areas I‚Äôm passionate about and improve Islamic tech and Arabic NLP."
  },
  {
    "objectID": "til/tils/2025-05-19-til.html",
    "href": "til/tils/2025-05-19-til.html",
    "title": "Starting Substack as a AI Researcher",
    "section": "",
    "text": "From their about page: ‚ÄúOn Substack, writers and creators can publish their work and make money from paid subscriptions while supporters can directly sustain the work they deeply value.‚Äù\nIt‚Äôs a platform where you can publish what you want in an organized way, with great analytics tools and a powerful recommendation and search system.\nI like to think of it as a nicer version of Medium, with more than just SEO dumped from Google.\nI really love the network from a design perspective. It‚Äôs an organized recommendation system based on multiple aspects."
  },
  {
    "objectID": "til/tils/2025-05-19-til.html#what-is-substack",
    "href": "til/tils/2025-05-19-til.html#what-is-substack",
    "title": "Starting Substack as a AI Researcher",
    "section": "",
    "text": "From their about page: ‚ÄúOn Substack, writers and creators can publish their work and make money from paid subscriptions while supporters can directly sustain the work they deeply value.‚Äù\nIt‚Äôs a platform where you can publish what you want in an organized way, with great analytics tools and a powerful recommendation and search system.\nI like to think of it as a nicer version of Medium, with more than just SEO dumped from Google.\nI really love the network from a design perspective. It‚Äôs an organized recommendation system based on multiple aspects."
  },
  {
    "objectID": "til/tils/2025-05-19-til.html#why-use-substack-as-an-ai-researcher",
    "href": "til/tils/2025-05-19-til.html#why-use-substack-as-an-ai-researcher",
    "title": "Starting Substack as a AI Researcher",
    "section": "Why use Substack as an AI Researcher?",
    "text": "Why use Substack as an AI Researcher?\nI used LinkedIn and Medium, and I don‚Äôt find them very useful for engagement or building a real network.\nMy gravity is very tiny in these networks and I can‚Äôt get bigger for multiple reasons I will discuss later.\nThe same is true for X, but it‚Äôs a very good place for the ML community.\nMy reasons:\n\nImprove my writing style. I am not good at writing or English, but I am trying to do my best. Communication is a very important skill for my work as a researcher.\nI build products I want people to learn more about‚Ä¶more later.\nI have services I want to market‚Ä¶more later.\n\nDid you forget something?\n^_^\nDie, empty, and publish your knowledge!\nActually, the main reason for me to write is that I feel lonely in my journey of learning about DL and software engineering.\nAnd I feel bored most of the time.\nI love the feeling that I am writing and archiving my life. This reminds me that I am doing hard work, learning new things, and my life will not end without doing great things from my point of view.\nRecapping what I learned when I write about it makes the concepts stick in your mind, and you get more insights from people‚Äôs comments. This is very helpful for me.\nFor readers, you can see what I do, and you may be interested in it, be inspired, and learn from my mistakes.\n\nFollowing the Giants?\nWhen I started learning about DL, I searched for a great book about DL and PyTorch that is well explained in both code and theory.\nI found his Substack where he publishes what he learns. At the same time, I found similar people like\n\nJay Alammar\nMaarten Grootendorst\nPaul Iusztin\n\nThese people I follow and appreciate what they provide!\nSo I started to ask, why do they use Substack?\nThe answer is very clear if you know them ^_^\n\n\nQuick analysis\nThe UI/UX, speed of the website, and animations are very cool.\nLet‚Äôs look at the level I want to reach :)\n\nAhead of AI\nOn 28/04/2023\nIt reached 15,028 free subscribers and only 69 paid ones!\nThis is very disappointing for me.\nYou don‚Äôt know if these are monthly or yearly paid and how much they give.\nOf course, I don‚Äôt know how much he earns or others. I want to motivate myself and not create high expectations. He is doing great stuff, really great. His content is in the top 5 for me for AI and real content.\nNo scams, no ‚Äúread this paper,‚Äù ‚Äúlook at this book,‚Äù ‚Äúhere are the top 1000 chatbots that are better than 10 who are better than GPT!!‚Äù\nOh my god, QwenClaudeMixtral just released a model that will convert space into water in the year 1021932103120931920.\nThis is very silly if you respect your readers‚Äô minds!\n\n\n\nAhead of AI subscribers in 2024\n\n\nWhat about now?\nHe has more than 105k+ and is #71 Rising in Technology. I don‚Äôt know why 71!! He must be top 5.\nJay Alammar =&gt; 23k+ subscribers\nMaarten Grootendorst =&gt; 20k+ subscribers\nPaul Iusztin =&gt; 25k+ subscribers\nMost likes per post are around 10 to 20 only!\nThe comments are around 0 to 5 :)\n\n\n\nMy Goal in the coming 6 months?\nI am doing multiple things at the current time.\nI am on 4 projects and doing my Master Thesis and a lot of projects and websites I am developing.\nI will not be able to provide much, but I will try my best.\nI don‚Äôt care about the number of subscribers, I care about real ones, who will comment and read the content. If I can get 30 people to read it, this is great. Really, if you imagine 30 people in your room watching what you did, it‚Äôs mind-blowing. Imagine 300 or 3,000‚Ä¶Wow.\nFor money, if I can get only $200 per month, this is very great as a start.\n\nDisease from other websites?\nI noticed the following issues on the first day:\n\nSh*** shorts and copyright issues: By copyright, I mean some people take others‚Äô content from outside Substack and post it as if it is their own and get followers for this! This is very bad. I don‚Äôt like strict copyright like ‚Äúyou copied this sentence‚Äù or ‚Äúused a logo,‚Äù but stealing the whole content!!!\nVery short articles compared to normal tweets! I found a lot of articles that appeared to me are like tweets‚Ä¶I thought I was in a place where people write in-depth content, not clickbait.\n\nI don‚Äôt talk about the post but the long-form ones.\n\nDrop your Substack fake numbers: A lot of people post ‚Äúdrop your Substack below and whatever it‚Äôs about I will exchange‚Äù and multiple similar things!! What is the\npurpose then‚Ä¶ you have 1 million subscribers, then what?\n\n\n\nThere is no official API for Substack\nThe most annoying thing in Substack is there is no current API to develop apps, create extensions, and automate a lot of things.\n\n\n\nWhat things can I write about?\nYou seem to love to talk a lot? What will you write then?\nIt‚Äôs very obvious‚Ä¶\nI want to talk about the following:\n\nCompute world with AI, fine-tuning/training, and cloud instances, etc.\nProducts I use and tried, not product reviews.\nBooks and papers I read and summarized.\nTILs, what I learned today!\nNovel writing about the AI world like vector databases, embedding, and searching, etc.\nApplications I build and services I provide.\nMy workflow and software i use.\nSubstack tips and analysis.\n\nyou can find links here for now: 1. Gpuvec publications\n\n\n\nKareem‚Äôs TILs"
  },
  {
    "objectID": "til/tils/2025-05-25-til.html",
    "href": "til/tils/2025-05-25-til.html",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "",
    "text": "Over the last 2 days, I‚Äôve been exploring some fascinating new open source tools from Meta and other organizations. These tools are revolutionizing how we approach RAG (Retrieval-Augmented Generation), model compression, and Python development. Let me break down what I‚Äôve learned:\n\nRAPTOR RAG - Meta‚Äôs tree-based retrieval technique\nDFloat11 - Lossless compression for LLMs\n\nPyrefly - Fast Python type checker in Rust\nFastEmbed - Efficient embedding generation"
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#rag-raptor-dfloat11-and-pyrefly-metas-latest-open-source-tools",
    "href": "til/tils/2025-05-25-til.html#rag-raptor-dfloat11-and-pyrefly-metas-latest-open-source-tools",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "",
    "text": "Over the last 2 days, I‚Äôve been exploring some fascinating new open source tools from Meta and other organizations. These tools are revolutionizing how we approach RAG (Retrieval-Augmented Generation), model compression, and Python development. Let me break down what I‚Äôve learned:\n\nRAPTOR RAG - Meta‚Äôs tree-based retrieval technique\nDFloat11 - Lossless compression for LLMs\n\nPyrefly - Fast Python type checker in Rust\nFastEmbed - Efficient embedding generation"
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#what-is-raptor-rag-complete-guide-to-metas-raptor-technique",
    "href": "til/tils/2025-05-25-til.html#what-is-raptor-rag-complete-guide-to-metas-raptor-technique",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "What is RAPTOR RAG? Complete Guide to Meta‚Äôs RAPTOR Technique",
    "text": "What is RAPTOR RAG? Complete Guide to Meta‚Äôs RAPTOR Technique\n\n\n\nraptor rag\n\n\nRAPTOR RAG is Meta‚Äôs innovative technique designed to improve document retrieval performance. While they claim a 20% improvement, my testing shows mixed results depending on the use case.\n\nUnderstanding RAPTOR RAG\nRAPTOR stands for ‚ÄúRecursive Abstractive Processing for Tree-Organized Retrieval.‚Äù It‚Äôs a tree-based approach that constructs hierarchical representations of your documents by recursively clustering text chunks based on their vector embeddings and generating summaries of those clusters.\nThe core innovation is building a tree structure from the bottom up, which helps solve the fundamental limitation of traditional RAG systems: retrieving only a few short, contiguous text chunks that limit their ability to represent large-scale discourse structure.\n\n\nThe Problem RAPTOR RAG Solves\nTraditional RAG systems struggle with thematic questions that require integrating knowledge from multiple parts of a document. This is particularly relevant for complex queries like understanding an entire book or analyzing long-form content.\nExample: Consider the fairy tale of Cinderella and the question ‚ÄúHow did Cinderella reach her happy ending?‚Äù Traditional RAG‚Äôs top-k retrieved short contiguous texts won‚Äôt contain enough context to answer this comprehensively.\n\n\nHow RAPTOR RAG Works\nRAPTOR solves this by using a tree structure to capture both high-level and low-level details about text. The process involves:\n\nClustering text chunks based on semantic similarity\nGenerating summaries for each cluster using language models\nRepeating the process recursively to build a hierarchical tree\nTree-based retrieval during query time\n\n\n\nModel-Based Summarization in RAPTOR\nAfter clustering nodes using Gaussian Mixture Models, each cluster is sent to a language model (typically GPT-3.5-turbo) for summarization. This step transforms large chunks of text into concise, coherent summaries, condensing potentially large volumes of retrieved information into manageable sizes.\n\n\nQuerying RAPTOR RAG\n\n\n\nquery RAPTOR rag\n\n\nRAPTOR supports two main querying approaches:\n\nTree Traversal - Navigate through the hierarchical structure\nCollapsed Tree Retrieval - Flatten the tree for faster retrieval\n\n\n\nRAPTOR RAG Performance Analysis\nWhile the 20% improvement claim is appealing, my testing reveals some limitations:\n\nAccuracy gains are marginal compared to SBERT-based solutions\nComputational overhead is significant for creation and retrieval\nBest use case is document summarization rather than question answering\nInformation flow can be repetitive in some scenarios\n\n\n\nRAPTOR RAG for Document Summarization\nThe most compelling use case for RAPTOR is document summarization. By having detailed, medium, and high-level information representations, you can create better summaries by:\n\nDividing the summarization task across multiple levels\nPre-computing summaries at different granularities\nReducing the burden on the final LLM for summary generation"
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#dfloat11-efficient-lossless-compression-for-llms",
    "href": "til/tils/2025-05-25-til.html#dfloat11-efficient-lossless-compression-for-llms",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "DFloat11: Efficient, Lossless Compression for LLMs",
    "text": "DFloat11: Efficient, Lossless Compression for LLMs\nDFloat11 (DF11) is a novel, mathematically lossless compression technique that reduces large language model memory usage by about 30% with zero accuracy loss. Unlike traditional quantization methods that can degrade model quality, DF11 uses Huffman coding to compress only the predictable exponent bits of model weights.\n\nHow DFloat11 Works\n\n\n\nDFloat11 encoding\n\n\nDFloat11‚Äôs compression strategy is elegant in its simplicity:\n\nSign and Fraction Bits: Kept unchanged as they contain high-entropy information\nExponent Bits: Compressed using a precomputed Huffman tree, replacing the fixed 8-bit exponent with variable-length codes\nAverage Savings: About 5 bits per weight on average\n\n\n\nDFloat11 Storage and Decoding\nStorage Architecture: - Sign/fraction and exponent bits stored separately - Small header containing the Huffman codebook - Efficient packing for minimal overhead\nRuntime Decoding: - Original weights quickly reconstructed by combining sign/fraction block with decoded exponent - Enables fast, parallel processing on GPUs - No performance penalty during inference\n\n\nDFloat11 Key Benefits\n\n30% reduction in model size compared to bf16\n100% identical accuracy to the original model\nUniversal applicability to any transformer-based LLM\nZero training required - works with existing models"
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#pyrefly-fast-python-type-checker-in-rust",
    "href": "til/tils/2025-05-25-til.html#pyrefly-fast-python-type-checker-in-rust",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "Pyrefly: Fast Python Type Checker in Rust",
    "text": "Pyrefly: Fast Python Type Checker in Rust\nPyrefly is a blazingly fast Python type checker written in Rust, designed to provide near-instantaneous type checking for large Python codebases.\n\nInstalling Pyrefly with VS Code\nI installed Pyrefly into VS Code and tested it with several projects including LlamaIndex and TypeCodebase. The experience was impressive:\n\nLightning-fast type checking compared to traditional tools\nSeamless VS Code integration with real-time feedback\nExcellent performance on large codebases\nRust-powered reliability with minimal memory usage\n\n\n\nPyrefly vs Traditional Type Checkers\nPyrefly‚Äôs Rust implementation provides significant advantages:\n\nSpeed improvements of 10-100x over Python-based type checkers\nLower memory footprint for large projects\nBetter error reporting with precise location information\nIncremental checking for faster subsequent runs"
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#llamaindex-raptor-integration",
    "href": "til/tils/2025-05-25-til.html#llamaindex-raptor-integration",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "LlamaIndex RAPTOR Integration",
    "text": "LlamaIndex RAPTOR Integration\nFor those using LlamaIndex, RAPTOR RAG can be integrated to improve document retrieval performance. The tree-based approach works particularly well with LlamaIndex‚Äôs document processing pipeline.\n\nImplementation Considerations\nWhen implementing RAPTOR with LlamaIndex:\n\nConsider the computational cost of building the tree structure\nEvaluate performance gains for your specific use case\nTest with your document types before full deployment\nMonitor memory usage during tree construction"
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#meta-pyrefly-and-open-source-ecosystem",
    "href": "til/tils/2025-05-25-til.html#meta-pyrefly-and-open-source-ecosystem",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "Meta Pyrefly and Open Source Ecosystem",
    "text": "Meta Pyrefly and Open Source Ecosystem\nMeta‚Äôs contribution to the Python development ecosystem through Pyrefly demonstrates their commitment to developer productivity. The combination of Rust‚Äôs performance with Python‚Äôs flexibility creates a powerful tool for modern development workflows."
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#conclusion",
    "href": "til/tils/2025-05-25-til.html#conclusion",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "Conclusion",
    "text": "Conclusion\nThese three tools represent significant advances in their respective domains:\n\nRAPTOR RAG offers a novel approach to document retrieval, though with mixed practical benefits\nDFloat11 provides genuine value for LLM deployment with lossless compression\nPyrefly delivers substantial performance improvements for Python type checking\n\nWhile RAPTOR RAG‚Äôs claims may be overstated, the underlying tree-based approach shows promise for specific use cases like document summarization. DFloat11 and Pyrefly, however, offer clear, measurable benefits that make them valuable additions to any ML or Python development toolkit."
  },
  {
    "objectID": "til/tils/2025-05-25-til.html#references",
    "href": "til/tils/2025-05-25-til.html#references",
    "title": "RAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker",
    "section": "References",
    "text": "References\n\nXMad Team Blog - Meta‚Äôs research team insights\nRAPTOR Paper - Original research paper\nPyrefly Official Site - Documentation and installation\nDFloat11 Research - Compression technique details\nLlamaIndex Documentation - RAG framework integration"
  },
  {
    "objectID": "til/index.html",
    "href": "til/index.html",
    "title": "üìö kareem‚Äôs TILs",
    "section": "",
    "text": "This the place where is share what i learn nearly everyday..for more crafted articles see the blogs\nYou can also get in touch with me here.\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nEvaluating Arabic Tokenizers\n\n\n\nblogging\n\ntil\n\nnlp\n\nai\n\n\n\nA practical comparison of AraModernBert and‚Ä¶\n\n\n\n\n\nOct 21, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting with ideas in ML\n\n\n\nblogging\n\ntil\n\n\n\nsome random thoughts about nonsense thoughts.\n\n\n\n\n\nJun 6, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nPylate Day 1\n\n\n\nblogging\n\ntil\n\n\n\nTrying to explore pylate and create my first‚Ä¶\n\n\n\n\n\nMay 28, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nRAG RAPTOR: Complete Guide to Meta‚Äôs RAPTOR RAG, DFloat11 Compression & Pyrefly Type Checker\n\n\n\nblogging\n\ntil\n\nmachine-learning\n\npython\n\nrag\n\n\n\nLearn about RAPTOR RAG technique for improved‚Ä¶\n\n\n\n\n\nMay 25, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nBrave Leo AI with Ollama, vllm, and any huggingface llm locally\n\n\n\nblogging\n\ntil\n\nweb\n\nai\n\nllm\n\nlocal_llm\n\nollama\n\n\n\nHow to configure Brave Leo to use your any LLM‚Ä¶\n\n\n\n\n\nMay 23, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©\n\n\n\nblogging\n\ntil\n\nÿ™ÿ≤ŸÉŸäŸá\n\n\n\nŸÖÿ≠ÿßŸàŸÑÿ© ŸÑÿ•ÿπÿßÿØÿ© ŸÑÿ™ÿ≤ŸÉŸäÿ© ÿßŸÑŸÜŸÅÿ≥ Ÿàÿ≠ÿ≥ŸÜ ÿßŸÑÿπŸÖŸÑ ŸàÿßŸÑÿ™Ÿàÿ¨Ÿá‚Ä¶\n\n\n\n\n\nMay 21, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nDomains Day: Connecting Railway with Vercel, Cloudflare, and Hostinger\n\n\n\nblogging\n\ntil\n\nseo\n\ndomains\n\nvercel\n\nporkbun\n\nweb\n\n\n\nMy experience moving my domain from Hostinger to‚Ä¶\n\n\n\n\n\nMay 20, 2025\n\n\nKareem\n\n\n\n\n\n\n\n\n\n\n\n\nStarting Substack as a AI Researcher\n\n\n\nblogging\n\ntil\n\nseo\n\nsubstack\n\n\n\nWhy i started writing on substack and why you‚Ä¶\n\n\n\n\n\nMay 19, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nExplore the Qdrant Blog core concepts | Part 1\n\n\n\nblogging\n\ntil\n\nqdrant\n\n\n\nThis a 2 hours daily exploring and summarizing‚Ä¶\n\n\n\n\n\nMay 18, 2025\n\n\nkareem\n\n\n\n\n\n\n\n\n\n\n\n\nTIL ? Tody I lernt to create TIL\n\n\n\nblogging\n\ntil\n\n\n\nStarting with TIL for creating posts on my blogg‚Ä¶\n\n\n\n\n\nMay 17, 2025\n\n\nkareem\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html",
    "href": "blog/posts/minishlab/ctranslate_maswray.html",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "",
    "text": "It‚Äôs Friday and I have some time to continue working on open source tasks. I had an idea that requires translating a dataset. It‚Äôs not large - 2GB - and consists of some paragraphs from English. The average number of words is around 400 tokens per row from the 8 million rows :)\nI looked into the OpenAI models to calculate how much this would cost me to translate all these with GPT-4.1 and GPT-4.1-mini, and the prices are the following: my total tokens =&gt; 8,000,000 rows * 400 tokens = 3,200,000,000. For the following calculations, I will assume input and output tokens are the same for ease of calculation. I will use the normal API, not the Batched API:\n\ntotal input tokens =&gt; 3,200,000,000\ntotal output tokens =&gt; 3,200,000,000\n\nThe calculation based on this date 2025-10-03\n\n\n\nCost\nGPT4.1\nGPT4.1-mini\nGPT3.5 Turbo\n\n\n\n\nInput tokens\n3,200 * 2\n3,200 * 0.40\n3,200 * 0.50\n\n\nOutput tokens\n3,200 * 8\n3,200 * 1.60\n3,200 * 1.50\n\n\n\n\n\n\n\n\n\n\n\n\nCost\nGPT4.1\nGPT4.1-mini\nGPT3.5 Turbo\n\n\n\n\nInput tokens\n6400\n1280\n1600\n\n\nOutput tokens\n25600\n5120\n4800\n\n\nTotal $ cost\n32000\n6400\n6400\n\n\nTotal EGP cost\n1,527,680\n305,536\n305,536\n\n\nit‚Äôs interesting that the cost of gpt4.1 mini is the same as gpt3.5 Turbo ^ ^\n\n\n\n\n\n\nAlso, this is insane - I can afford only 1000 EGP or $50 at max :)"
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#going-from-32000-to-0-cost-with-small-models",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#going-from-32000-to-0-cost-with-small-models",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "",
    "text": "It‚Äôs Friday and I have some time to continue working on open source tasks. I had an idea that requires translating a dataset. It‚Äôs not large - 2GB - and consists of some paragraphs from English. The average number of words is around 400 tokens per row from the 8 million rows :)\nI looked into the OpenAI models to calculate how much this would cost me to translate all these with GPT-4.1 and GPT-4.1-mini, and the prices are the following: my total tokens =&gt; 8,000,000 rows * 400 tokens = 3,200,000,000. For the following calculations, I will assume input and output tokens are the same for ease of calculation. I will use the normal API, not the Batched API:\n\ntotal input tokens =&gt; 3,200,000,000\ntotal output tokens =&gt; 3,200,000,000\n\nThe calculation based on this date 2025-10-03\n\n\n\nCost\nGPT4.1\nGPT4.1-mini\nGPT3.5 Turbo\n\n\n\n\nInput tokens\n3,200 * 2\n3,200 * 0.40\n3,200 * 0.50\n\n\nOutput tokens\n3,200 * 8\n3,200 * 1.60\n3,200 * 1.50\n\n\n\n\n\n\n\n\n\n\n\n\nCost\nGPT4.1\nGPT4.1-mini\nGPT3.5 Turbo\n\n\n\n\nInput tokens\n6400\n1280\n1600\n\n\nOutput tokens\n25600\n5120\n4800\n\n\nTotal $ cost\n32000\n6400\n6400\n\n\nTotal EGP cost\n1,527,680\n305,536\n305,536\n\n\nit‚Äôs interesting that the cost of gpt4.1 mini is the same as gpt3.5 Turbo ^ ^\n\n\n\n\n\n\nAlso, this is insane - I can afford only 1000 EGP or $50 at max :)"
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#how-poor-am-i-very-gpu-poor",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#how-poor-am-i-very-gpu-poor",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "How poor am I? Very GPU poor! üíª",
    "text": "How poor am I? Very GPU poor! üíª\nI wish I had a local GPU to be able to test open source LLMs like Cohere 70B and such strong models, and I would not care about time!\nI remember there is amazing work that is not even an LLM for translation, created by Ahmed Wasfy from NAMMA Community\nIt‚Äôs a 240M parameter small model trained to translate English into Egyptian. It was trained on more than 150,000 rows with more than 10 Million tokens for Arabic language. It competes with closed LLMs like GPT-4o and Claude-3.5-Sonnet\n\n\n\nmasrawy results\n\n\nI tested it with my local laptop GPU 1660Ti GTX mobile version with 6GB and CPU is Core i7 gen9 from Intel with 32GB DDR4. I tested the model and it worked with PyTorch very fast and very efficiently! The translations are very similar and this is enough for the task I want to build on this translated dataset! Let‚Äôs do the math for how much this will cost on my laptop :)\n\n\n\nfaster masrawy"
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#pytorch-pipeline-with-hf-inference-through-transformers",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#pytorch-pipeline-with-hf-inference-through-transformers",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "PyTorch Pipeline with HF Inference through Transformers",
    "text": "PyTorch Pipeline with HF Inference through Transformers\nI created the translation pipeline and tested it with these batch sizes with these settings: float16 and batch sizes = [2,4,6,8,16]. I found that even though I have enough memory to load more batches, the optimal batch size was 4 and this is because of the RAM and CPU power. I was able to process 100 examples with these results:\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\n\nNumber of Examples\nBatch Size\nGPU setup\nFull time\nDays need\n\n\n\n\nPytorch + float16\n\n100\n8\n1660TI laptop GPU\n60s\n55.56 Days\n\n\nPytorch + float16\n\n100\n4\n1660TI laptop GPU\n45s\n41.67 Days\n\n\nPytorch + float16 + optimized version\n\n100\n4\n1660TI laptop GPU\n35s\n32.41 Days\n\n\n\noptimized version here i mean\nmodel = torch.compile(model, mode=\"max-autotune\", fullgraph=True)\n\nmodel = model.eval()\nIt‚Äôs a new feature in PyTorch 2 to accelerate the model speeds. I tried multiple settings and also the different backends but there is no huge difference. Convert to ONNX? It‚Äôs a nightmare. I did it before and the results didn‚Äôt worth the headache! I may try it when I have time."
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#lets-do-quantization",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#lets-do-quantization",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "Let‚Äôs Do Quantization",
    "text": "Let‚Äôs Do Quantization\nI tried to use the torchao which enables performing quantization in more stable and easier ways. I tried it a lot with my GPU but due to CUDA version it always throws this error:\n1. AssertionError: Float8 dynamic activation quantization is only supported on CUDA&gt;=8.9 and MI300+\nThe library code is not straightforward and I don‚Äôt have time - I have just 2 days to finish this before I return to my main work.\nI also faced some errors because the model I am trying to use is an old and not optimized one for these methods. It‚Äôs based on the OPUS-MT-en-ar created with marianNMT which is an efficient NMT implementation written in pure C++. The models have been converted to PyTorch using the Transformers library by Hugging Face"
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#vllms-and-sglang-for-hf-translation-pipeline",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#vllms-and-sglang-for-hf-translation-pipeline",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "VLLMs and SGLang for HF translation pipeline",
    "text": "VLLMs and SGLang for HF translation pipeline\nI searched for SGLang solution with the model and I didn‚Äôt find any help. I tried the vLLM documentation also and found the following pages: bring_your_own_model and this. The model speed was worse than normal HF tensors - it was 5 seconds more. I think there is a better way to write the vLLM version better than mine."
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#more-search-and-ctranslate-magic",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#more-search-and-ctranslate-magic",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "More search and Ctranslate magic üé©",
    "text": "More search and Ctranslate magic üé©\nI wanted to give up, but let‚Äôs try a final search on how to serve Marian model. In an old forum answer I found what is called CTranslate2. They say it‚Äôs faster than HF Transformers for specific architectures by around 4-6x.\nDefinition: CTranslate2 is a C++ and Python library for efficient inference with Transformer models. The following model types are currently supported:\n\nEncoder-decoder models: Transformer base/big, M2M-100, NLLB, BART, mBART, Pegasus, T5, Whisper\nDecoder-only models: GPT-2, GPT-J, GPT-NeoX, OPT, BLOOM, MPT, Llama, Mistral, Gemma, CodeGen, GPTBigCode, Falcon, Qwen2\nEncoder-only models: BERT, DistilBERT, XLM-RoBERTa\n\nCompatible models should be first converted into an optimized model format. The library includes converters for multiple frameworks:\n\nOpenNMT-py\nOpenNMT-tf\nFairseq\nMarian\nOPUS-MT\nTransformers\n\n\nKey features of Ctranslate\nFast and efficient execution on CPU and GPU\nThe execution¬†is significantly faster and requires less resources¬†than general-purpose deep learning frameworks on supported models and tasks thanks to many advanced optimizations: layer fusion, padding removal, batch reordering, in-place operations, caching mechanism, etc.\n\nQuantization and reduced precision\nThe model serialization and computation support weights with¬†reduced precision: 16-bit floating points (FP16), 16-bit brain floating points (BF16), 16-bit integers (INT16), 8-bit integers (INT8) and AWQ quantization (INT4).\nMultiple CPU architectures support\nThe project supports x86-64 and AArch64/ARM64 processors and integrates multiple backends that are optimized for these platforms:¬†Intel MKL,¬†oneDNN,¬†OpenBLAS,¬†Ruy, and¬†Apple Accelerate.\nAutomatic CPU detection and code dispatch\nOne binary can include multiple backends (e.g.¬†Intel MKL and oneDNN) and instruction set architectures (e.g.¬†AVX, AVX2) that are automatically selected at runtime based on the CPU information.\nParallel and asynchronous execution\nMultiple batches can be processed in parallel and asynchronously using multiple GPUs or CPU cores.\nDynamic memory usage\nThe memory usage changes dynamically depending on the request size while still meeting performance requirements thanks to caching allocators on both CPU and GPU.\nLightweight on disk\nQuantization can make the models 4 times smaller on disk with minimal accuracy loss.\nSimple integration\nThe project has few dependencies and exposes simple APIs in¬†Python¬†and C++ to cover most integration needs.\nConfigurable and interactive decoding\nAdvanced decoding features¬†allow autocompleting a partial sequence and returning alternatives at a specific location in the sequence.\nSupport tensor parallelism for distributed inference\nVery large model can be split into multiple GPUs. Following this¬†documentation¬†to set up the required environment.\n\nSome of these features are difficult to achieve with standard deep learning frameworks and are the motivation for this project.\n\n\nLet‚Äôs try it!\nI used the following script to convert the HF version into CTranslate2 expected format:\nct2-transformers-converter --model NAMAA-Space/masrawy-english-to-egyptian-arabic-translator-v2.9 --output_dir ct2_model_masrawy\nthen i used the model with this version\ntranslator = ctranslate2.Translator(\n    \"ct2_model_masrawy\",\n    device=\"cuda\",\n    compute_type=\"float16\",\n)\nIt worked and was very fast - much, much faster!\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\n\nNumber of Examples\nBatch Size\nGPU setup\nFull time\nDays need\n\n\n\n\nCtranslate + float16\n\n100\n8\n1660TI laptop GPU\n11s\n10.19 days\n\n\nCtranslate + float16\n\n100\n4\n1660TI laptop GPU\n16s\n12.04 days\n\n\nCtranslate\n\n100\n6\n1660TI laptop GPU\n13s\n14.81 days\n\n\n\n\n\n\n\n\n\n\n\n\nWe moved from 32.4 days to 10 days!!!"
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#getting-help-from-the-titan-rtx-24gb",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#getting-help-from-the-titan-rtx-24gb",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "Getting help from the Titan RTX 24GB",
    "text": "Getting help from the Titan RTX 24GB\nOne of my friends offered me access to his workstation which has dual GPU Titan RTX. It‚Äôs an old GPU but it‚Äôs far better than my little kobo.\nI found that the optimal batch is 64 after some tries. Let‚Äôs use this and see the results. I will also increase the size from 100 samples to 1000.\n\n\n\n\n\n\n\n\n\n\n\n\nMethod\n\nNumber of Examples\nBatch Size\nGPU setup\nFull time\nDays need\n\n\n\n\nPytorch + float16 + optimized version\n\n1000\n64\nTitan RTX\n240s\n22.22 days\n\n\nCtranslate + int8 \n\n1000\n64\nTitan RTX\n7.89s\n0.73¬†days\n\n\nCtranslate + int8 + dual GPU\n\n1000\n64\nDual Titan RTX\n4.42s\n0.41 days\n\n\nCtranslate + float16\n\n1000\n64\nTitan RTX\n6.46s\n0.60 days\n\n\nCtranslate + float16 + dual GPU\n\n1000\n64\nDual Titan RTX\n3.72\n0.34 days\n\n\nCtranslate + int8_float16\n\n1000\n64\nTitan RTX\n6.81s\n0.63 days\n\n\nCtranslate + int8_float16 + dual GPU\n\n1000\n64\nDual Titan RTX\n3.85s\n0.36 days\n\n\n==We moved now from 22 days in single Titan RTX to 0.60 days!==\n\n\n\n\n\n\n\n\n\n\nWhy float16 is faster than int8\nFloat16 Version (faster!):\n\nDual GPU: 269.2 docs/sec\nSingle GPU: 154.7 docs/sec\nTime for 1000 docs: 3.72 seconds\n\nInt8 Version (slower):\n\nDual GPU: 225.8 docs/sec\nSingle GPU: 126.7 docs/sec\nTime for 1000 docs: 4.43 seconds\n\nResult: Float16 is ~19% faster! (269.2 vs 225.8 docs/sec) Lower precision ‚â† Always faster! I need to increase the batch size for int8 and see which batch size will be better!"
  },
  {
    "objectID": "blog/posts/minishlab/ctranslate_maswray.html#next-steps",
    "href": "blog/posts/minishlab/ctranslate_maswray.html#next-steps",
    "title": "From $32,000 to $0 with Small Models and CTranslate2",
    "section": "Next steps!",
    "text": "Next steps!\nThis is just the start. I will search more and investigate how to make this faster because the 8 million rows are only 2GB and the next task is to translate 500GB :) Every second will make a huge difference!\n\nUse larger batch size with int8\nUse different GPU with modern architecture and better CPU\nDeep dive into vLLM\nTry the ONNX version for GPU, not CPU\nTry again with torchao\n\nThanks for your time! Here is the converted version on Hugging Face: ctranslate_masrawy. Small models can save your life ^ ^"
  },
  {
    "objectID": "blog/posts/seo/the_curse_of_seo.html",
    "href": "blog/posts/seo/the_curse_of_seo.html",
    "title": "The curse of SEO",
    "section": "",
    "text": "Definition: SEO is optimizing your website pages to appear in the top results of search engines like Google and Bing.\n\nWhy is this important? It makes you visible to more people who are interested in what you provide‚Äîproducts, services, news, etc.\nEnough of the basics. I assume you already know what SEO is about. Now, let‚Äôs explore a darker side of being involved in SEO.\n\nHow to Track Your Changes\n\nSince SEO revolves around ranking, how do you track your position?\nThere are multiple tools I enjoy using, such as:\n\nI love to manually search keywords and track their ranks myself! :)\n\nI do this often when I need a break at the gym or during study breaks.\n\nSEMrush\n\nI use it to check domain authority, organic keywords, and traffic increase.\nSeeing green in increased Ref. Domains and Authority Score brings joy.\nI don‚Äôt use it for anything else! :)\n\nRanking Math\n\nSay hi to the overrated WordPress SEO plugin ‚ÄúRanking Math SEO‚Äù\nIt claims to simplify content optimization with built-in suggestions based on widely-accepted practices.\nI use Rankmath Pro on a website I manage, showing impressions, total keywords, average position, and clicks. GSC offers all this for free!\nThis post isn‚Äôt about Rankmath; that‚Äôs for another time. In short:\n\nAI tools\nAMP\nAnalysis from Google Analytics\nInstant indexing\nBacklinks count\nLocal SEO\nNews sitemap\nPodcasts\nSchema\nSEO analysis\nSitemap\nVideo Sitemap\nWooCommerce\nGoogle Web Stories\n\nNone of these significantly impact SEO and ranking; there are other effective methods.\nWhat matters most to me with Rankmath is:\n\nTop 5 performing posts\nOther keywords\n\nI mainly use Rankmath for its focus keyword section in each article.\n\nMangools\n\nMy preferred tool! Its UI/UX is excellent, and it‚Äôs fast and efficient unlike other tools.\nWith the free account, I get:\n\n5 keyword researches daily\n8 SERP checks\n1,000 backlink analyses\nDomain profile checks for 2 domains daily\n\nFor Arabic, its keyword ideas aren‚Äôt as good.\n\nGoogle Search Console\n\nA free tool by Google offering most SEO tools‚Äô functionalities for free and accurately.\nYou get:\n\nPerformance of your website for any keyword at any time in any region!\nPage indexing status\nBacklink analysis\nPage experience and more\n\nYou might notice a recurring theme:\n\nCharts\nChanging numbers everywhere, numbers galore!\n\n\nNeil Patel\n\nRank tracking\nSEO opportunities\nSite audit\nKeyword research\nTraffic estimation\nBacklinks\n\nKeyword Tool\n\nFor Arabic, it provides the most related suggested keywords, though many aren‚Äôt quite relevant.\n\nGuinRank\n\nNew and more tailored for Arabic, gaining power.\nI use its content and keyword tools for Arabic, providing helpful recommendations and statistics for choosing useful keywords.\n\nMoz\n\nThey even blocked my IP -__-\n\n\n\nStarting to Lose!\n\nWhat‚Äôs going wrong? I hate losing after investing time, money, and mental health into something. If you‚Äôre like me, SEO can be crushing.\n‚ÄúSEO is like gambling‚Äù ~ Kareem\n\n\n\n\n\nHow to recover form SEO addiction\n\n\n\nLosing Backlinks\n\nSpam backlinks (like Khamsat, Fiverr, and Upwork)‚Äîmost are harmful.\nPBN Network\n\nThis service claims safe PBNs for backlinks from Web 2.0 blogs, profiles, social bookmarking, social likes/shares, etc. I tried it, and none appeared in GSC after 3 months; worse, my site‚Äôs rank dropped.\n\nManually Added Backlinks\n\nThis package offers 70 PR10 backlinks from foreign websites, 60 Arabic guest posts, and 10 EDU backlinks, etc.\nIt worked to some extent, but the impact was minimal. Four backlinks from specific places helped more than these services.\n\nOther services are mostly spam backlinks; some guest posts might help, but aim for real backlinks spaced out from related sites.\n\nLosing Ranking\n\nThis month, a home services website I manage improved from 65th to 9th in rankings, then disappeared, and later ranked 40th, etc.\nThis cycle repeats‚Äîa page gains rank, then drops.\nIt‚Äôs stressful; don‚Äôt check daily. Weekly (or every 2-3 weeks) is less stressful and gives fairer results, focusing on what‚Äôs important.\n\nWhat‚Äôs Going Wrong?\n\nWatching page changes from these tools is like social media‚Äôs new ‚Äúlike‚Äù button!\nMy mind loves the green and red numbers.\nUltimately, most analyses aren‚Äôt critical. Whether 23rd or 80th, if not in the top 5, what‚Äôs the use? Daily checks yield nothing; reaching top 5 goes unnoticed until notifications and calls confirm it.\nIf SEO is your sole income source, it‚Äôs a tough job‚Äîeven though it can make you a millionaire sometimes.\n\nHow to Recover\n\nHere‚Äôs what helped me recover from this addiction:\nCreate barriers for easy access:\n\nSeparate Google accounts/tabs into another browser profile. Using Brave or Bing makes this easy.\nRemove bookmarked tabs for these tools and clear browsing history.\nUse extensions to block these sites; Chrome Store has many offering motivational quotes.\n\nDelete Chrome and YouTube from mobile using ADB.\nMove tool emails to spam except weekly updates from Mangools and GSC.\n\n\n\n\n\ndark side of seo\n\n\n\nFinal Thoughts!\n\nAs a programmer, I initially thought a fast website and quality content were key in SEO. I later learned that choosing keywords and acquiring backlinks are crucial.\nA nice Arabic book which will give you true information about SEO ÿØŸÑŸäŸÑŸÉ ÿ•ŸÑŸä ÿ™ÿ≠ÿ≥ŸäŸÜ ŸÖÿ≠ÿ±ŸÉÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´\nFeel free to DM on Linkedin\nUltimately, backlinks boil down to how many you buy and from whom.\nŸÖŸÜÿµÿ© ÿµŸÜÿßÿπÿ© ÿßŸÑŸÖÿ≠ÿ™ŸàŸä ÿßŸÑÿπÿ±ÿ®Ÿä\nŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑŸÖŸàÿ≤\nÿµŸäÿßŸÜÿ© ÿßŸÅÿ±ÿßŸÜ ÿ∫ÿßÿ≤ ÿ®ÿßŸÑÿ±Ÿäÿßÿ∂\nÿ¥ÿ±ŸÉÿ© ÿ™ŸÜÿ≥ŸäŸÇ ÿ≠ÿØÿßÿ¶ŸÇ ÿ®ÿßŸÑŸÖÿØŸäŸÜÿ© ÿßŸÑŸÖŸÜŸàÿ±ÿ©\nÿ¥ÿ±ŸÉÿ© ÿ™ŸÜÿ∏ŸäŸÅ ŸÖŸÜÿßÿ≤ŸÑ ŸÅŸä ÿßŸÑÿπŸäŸÜ"
  },
  {
    "objectID": "blog/posts/seo/google_ads_black_box.html",
    "href": "blog/posts/seo/google_ads_black_box.html",
    "title": "Google Ads Black Box",
    "section": "",
    "text": "My cousin told me that he can‚Äôt create an ad for his work and he had a verified business profile, so i told him give you the website and i can do it in just few minutes. I opened google ads and created an account followed the instructions and added my visa then after one day the ad started to work.\nThen i noticed that i want to change the ad to make it more advanced for mobile calls. I paused it and created a new one, then my account get suspended and the reason is because circumvengint systems policy! Okey, then what is the wrong? Submit an appeal and add the needed documents to get verfified and after 15 days there is no response and the account is still suspended, what about the money i give to the add and neither me or google is using it! It had fly with wind."
  },
  {
    "objectID": "blog/posts/seo/google_ads_black_box.html#can-a-web-developer-creat-a-google-ad",
    "href": "blog/posts/seo/google_ads_black_box.html#can-a-web-developer-creat-a-google-ad",
    "title": "Google Ads Black Box",
    "section": "",
    "text": "My cousin told me that he can‚Äôt create an ad for his work and he had a verified business profile, so i told him give you the website and i can do it in just few minutes. I opened google ads and created an account followed the instructions and added my visa then after one day the ad started to work.\nThen i noticed that i want to change the ad to make it more advanced for mobile calls. I paused it and created a new one, then my account get suspended and the reason is because circumvengint systems policy! Okey, then what is the wrong? Submit an appeal and add the needed documents to get verfified and after 15 days there is no response and the account is still suspended, what about the money i give to the add and neither me or google is using it! It had fly with wind."
  },
  {
    "objectID": "blog/posts/seo/google_ads_black_box.html#another-try",
    "href": "blog/posts/seo/google_ads_black_box.html#another-try",
    "title": "Google Ads Black Box",
    "section": "Another try",
    "text": "Another try\nI toke my friend account, which is used for around 5 years on google ads and has spent a lot of money i create the ad with a different domain for the website and didn‚Äôt add the business profile and my identifiy is verified‚Ä¶etc my account get suspened immeditialy ? WTF!"
  },
  {
    "objectID": "blog/posts/seo/google_ads_black_box.html#final-thoughts",
    "href": "blog/posts/seo/google_ads_black_box.html#final-thoughts",
    "title": "Google Ads Black Box",
    "section": "Final thoughts",
    "text": "Final thoughts\n\nDont‚Äô add huge amount of money, add only 5$ with 5$ until everything is okey you can increase it abit for example 50$ per day.\nGoogle Ads is a black box! What, why, when, how are irrelevant.: Go ahead and create a new account and do the advertiser verification before creating any campaign. You can try creating a new google ad account with same email ID first and same payment method. Google allows multiple ad accounts with single email. Yes I know they say that you cannot create new account but trust me they do not follow this. I have multiple stable accounts running under same email IDs which also have suspended accounts. Just get those ads live whatever it takesü•Ç reddit answer"
  },
  {
    "objectID": "blog/posts/seo/google_ads_black_box.html#references",
    "href": "blog/posts/seo/google_ads_black_box.html#references",
    "title": "Google Ads Black Box",
    "section": "References",
    "text": "References\n\nnlp for seo\nseo if overated\ngoogle help\nÿ≠ÿ¨ÿ≤ ŸÖŸàÿπÿØ ŸÅÿ≠ÿµ ÿßŸÑŸÖÿ±ŸÉÿ®ÿßÿ™ ÿ®ÿßŸÑÿØŸÖÿßŸÖ"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "",
    "text": "Hi, I‚Äôm Kareem, a college student working on machine learning and web technology projects. I previously reviewed the Huawei FreeBuds 5i after 2 months of daily use, and now I‚Äôve been testing the new FreeBuds 7i for 20 days. I don‚Äôt own a Huawei phone - I use a Realme Android device and MSI Linux laptop - so this is an honest review from someone using these earbuds outside the Huawei ecosystem. If you want to see more reviews about Huawei you can join the Channel"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-freebuds-7i-review-is-it-worth-upgrading-from-freebuds-5i-20-days-testing",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-freebuds-7i-review-is-it-worth-upgrading-from-freebuds-5i-20-days-testing",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "",
    "text": "Hi, I‚Äôm Kareem, a college student working on machine learning and web technology projects. I previously reviewed the Huawei FreeBuds 5i after 2 months of daily use, and now I‚Äôve been testing the new FreeBuds 7i for 20 days. I don‚Äôt own a Huawei phone - I use a Realme Android device and MSI Linux laptop - so this is an honest review from someone using these earbuds outside the Huawei ecosystem. If you want to see more reviews about Huawei you can join the Channel"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#unboxing-and-first-impressions",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#unboxing-and-first-impressions",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Unboxing and First Impressions",
    "text": "Unboxing and First Impressions\nThe FreeBuds 7i comes in a neat package with the earbuds, charging case, four sizes of silicone ear tips (XS, S, M, L - one more than the 5i), a USB-C charging cable, and the usual documentation. The case is bigger than the 5i (57.8 x 57.8 x 27.8mm vs 61.8 x 48.2 x 26.9mm) and slightly heavier at 36.5g compared to 33.9g, but there‚Äôs a good reason: the battery capacity jumped from 410mAh to 510mAh.\nAvailable in three Morandi colors - Pink, White, and Black - the design is understated and elegant, though I personally miss the Isle Blue option from the 5i.\n\n\n\nHuawei 7i Review"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-freebuds-7i-call-qauilty-and-microphone",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-freebuds-7i-call-qauilty-and-microphone",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Huawei Freebuds 7i call Qauilty and Microphone",
    "text": "Huawei Freebuds 7i call Qauilty and Microphone\nThis is where the FreeBuds 7i truly shines. I don‚Äôt use these for regular mobile calls yet, but I rely on them daily for video meetings with my project partners. On the very first day, my friends noticed the difference immediately!\nOne partner said: ‚ÄúYour voice is now more clear, did you change anything?‚Äù\nAnother friend asked: ‚ÄúDo you have a mechanical keyboard?‚Äù The funny thing is, I‚Äôve always had a mechanical keyboard, but with the 5i my voice wasn‚Äôt clear enough for them to hear the typing sounds in the background. With the 7i, my voice comes through crystal clear while they can now actually hear my keyboard clicks.\nThe secret? The FreeBuds 7i features a bone conduction microphone working alongside three traditional microphones, with AI call noise cancellation that can handle noisy environments up to 90 dB. This combination delivers significantly better voice clarity compared to the standard mics on the 5i.\nFor anyone who does frequent video calls, online meetings, or even streaming, this upgrade alone justifies the purchase.\n\n\n\nHuawei Freebuds 7i"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#sound-quality-and-audio-performance",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#sound-quality-and-audio-performance",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Sound Quality and Audio Performance",
    "text": "Sound Quality and Audio Performance\nThe FreeBuds 7i packs an 11mm quad-magnet dynamic driver (upgraded from the 5i‚Äôs 10mm dynamic driver) with a wide frequency response range of 20 Hz to 40 kHz.\nIn real-world listening, the sound quality is similar to the 5i - both deliver excellent audio for the price point.\nMusic sounds clear with good separation, bass is punchy without being overwhelming, and podcasts come through crisp and detailed. The 7i also features Dynamic EQ that adjusts based on what you‚Äôre listening to, plus you can customize sound with 10 EQ bands through the AI Life app.\nIf you‚Äôre upgrading purely for music audio quality, you won‚Äôt notice a dramatic difference. The real improvements are in other areas."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-7i-noise-cancellation-intelligent-dynamic-anc-4.0",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-7i-noise-cancellation-intelligent-dynamic-anc-4.0",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "huawei 7i Noise Cancellation: Intelligent Dynamic ANC 4.0",
    "text": "huawei 7i Noise Cancellation: Intelligent Dynamic ANC 4.0\nThe noise cancelling performance is better by a good margin. Huawei‚Äôs new Intelligent Dynamic ANC 4.0 delivers an average noise cancellation depth of 28 dB with less than 0.5 second latency. In practical terms, this means faster adaptation to changing noise environments.\nWhen I walk down the street at night, I don‚Äôt hear most of the ambient voices and traffic noise anymore. On the subway or bus, the engine noise is effectively blocked.\nIn caf√©s, the background chatter fades away, letting me focus on my work. Are you in complete silence? No - some sounds still get through, especially sudden loud noises. But the improvement over the 5i is noticeable and makes a real difference in noisy environments.\nwarning: after a month the noise left bud creates a very noise sound when it‚Äôs in ultra mode or dynamic with hight noise it‚Äôs very annoying and give me headache i udpated the earbuds to the latest version but it didn‚Äôt fixed\n\nMode Switching: A Small Change That Matters\nOne of my biggest frustrations with the 5i was the mode cycle order: Awareness ‚Üí Off ‚Üí Noise Cancelling. Since I primarily use ANC mode, I had to cycle through two modes every time I put them on.\nThe 7i finally fixes this! The new order is: Noise Cancelling ‚Üí Off ‚Üí Awareness. This might seem like a minor detail, but when you use these earbuds multiple times a day, it‚Äôs a quality-of-life improvement I genuinely appreciate.\n\n\nMulti-Device Connection and Bluetooth Performance\nThe FreeBuds 7i runs on Bluetooth 5.4 (upgraded from 5.2 on the 5i) and supports simultaneous dual-device connection. It‚Äôs noticeably smarter at switching between my Linux laptop and Realme Android phone compared to the 5i.\nThe connection is stable, transitions are smooth, and it works seamlessly whether I‚Äôm using the Huawei AI Life app or not. This is impressive considering I don‚Äôt even own a Huawei phone. The improved Bluetooth version also means better range and more stable connectivity.\nFor the Linux users out there: yes, it connects via bluetoothctl, though you might need to restart Bluetooth occasionally for a clean connection - same as with the 5i.\n\n\n\nHuawei Freebuds 7i unboxing"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#battery-life-longer-and-faster",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#battery-life-longer-and-faster",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Battery Life: Longer and Faster",
    "text": "Battery Life: Longer and Faster\nThis is where the larger case really pays off:\n\nFreeBuds 7i Battery Performance:\n\nSingle charge with ANC ON: 5 hours\nSingle charge with ANC OFF: 8 hours\n\nTotal with case (ANC ON): 20 hours\nTotal with case (ANC OFF): 35 hours\nEarbud charging time: 40 minutes\nCase charging time: 60 minutes (wired USB-C)\nFast charging: 10 minutes = 4 hours of playback\n\n\n\nFreeBuds 5i Battery Performance:\n\nSingle charge with ANC ON: 6 hours\nSingle charge with ANC OFF: 7.5 hours\nTotal with case (ANC ON): 18.5 hours\nTotal with case (ANC OFF): 28 hours\nEarbud charging time: 60 minutes\nCase charging time: 110 minutes (wired USB-C)\n\nWhile the 5i offers slightly longer listening time on a single charge with ANC enabled (6h vs 5h), the 7i wins in total battery capacity and especially charging speed. Going from 110 minutes to 60 minutes for a full case charge is almost half the time! The earbuds also charge faster - 40 minutes vs 60 minutes.\nThe fast charging feature is genuinely useful: a quick 10-minute charge gives you 4 hours of playback when you‚Äôre in a hurry."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#design-build-quality-and-comfort",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#design-build-quality-and-comfort",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Design, Build Quality, and Comfort",
    "text": "Design, Build Quality, and Comfort\nI‚Äôll be honest here: the FreeBuds 5i case was more elegant and modern looking with its wider, flatter profile. The 7i‚Äôs case is more square-shaped and less stylish. However, the earbuds themselves are well-designed.\nEach earbud weighs just 5.4g (vs 4.9g on the 5i), which is barely noticeable. The 7i includes four ear tip sizes (XS, S, M, L) compared to three on the 5i (S, M, L), giving you better options for a secure, comfortable fit. Both models have IP54 rating, meaning they‚Äôre dust-tight and splash-resistant - perfect for workouts or light rain.\nThe sound when closing the case is satisfying - a solid, premium click that I genuinely enjoy."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#gesture-controls-and-smart-features",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#gesture-controls-and-smart-features",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Gesture Controls and Smart Features",
    "text": "Gesture Controls and Smart Features\nThe touch controls are intuitive and responsive: - Double-tap: Play/pause music, answer/end calls - Triple-tap: Skip to next track (new feature vs 5i) - Swipe up/down: Volume control - Touch-and-hold: Switch between ANC modes or reject calls\nNew features on the 7i include: - Nod to pick up: Answer calls by nodding your head (needs to be enabled) - Unlimited Spatial Audio: 360¬∞ sound with head-tracking - Audio Sharing: Connect two pairs of FreeBuds to one device\nThe spatial audio feature works across different apps and devices, creating an immersive listening experience for movies and gaming.\n\n\n\nFreebuds 7i"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-freebuds-7i-specs",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#huawei-freebuds-7i-specs",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Huawei Freebuds 7i specs",
    "text": "Huawei Freebuds 7i specs\nThe FreeBuds 7i is packed with sensors: - Infrared sensor (for wear detection) - Hall sensor (for case open/close detection) - Touch sensor (for gesture controls) - Gyroscope (for head-tracking in spatial audio) - Accelerometer - Bone voice sensor (for call quality)\nThese work together to provide smart features like auto-pause when you remove an earbud, and the improved call quality I mentioned earlier.\n\nCompatibility: Works Beyond Huawei Ecosystem\nOne question I see often: ‚ÄúDo these work with non-Huawei phones?‚Äù Yes, absolutely! I‚Äôve been using them with: - Realme Android phone (works perfectly) - MSI Linux laptop (connects via bluetoothctl) - Huawei Mate Pad 11 tablet (seamless integration)\nThe AI Life app (available for both iOS and Android) unlocks additional features like EQ customization, firmware updates, and gesture configuration. But even without the app, the core functionality works great on any Bluetooth device."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#freebuds-7i-vs-freebuds-5i-complete-comparison",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#freebuds-7i-vs-freebuds-5i-complete-comparison",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "FreeBuds 7i vs FreeBuds 5i: Complete Comparison",
    "text": "FreeBuds 7i vs FreeBuds 5i: Complete Comparison\n\n\n\n\n\n\n\n\nFeature\nFreeBuds 7i\nFreeBuds 5i\n\n\n\n\nDriver Size\n11mm quad-magnet dynamic\n10mm dynamic\n\n\nFrequency Response\n20 Hz - 40 kHz\nStandard\n\n\nANC Technology\nIntelligent Dynamic ANC 4.0 (28dB)\nActive noise cancellation\n\n\nMicrophone\n3 mics + bone conduction\nStandard mics\n\n\nCall Quality\nSignificantly clearer\nDistant, unclear\n\n\nBluetooth\n5.4\n5.2\n\n\nBattery (ANC ON)\n5h + 20h total\n6h + 18.5h total\n\n\nBattery (ANC OFF)\n8h + 35h total\n7.5h + 28h total\n\n\nCase Battery\n510mAh\n410mAh\n\n\nEarbud Charging\n40 minutes\n60 minutes\n\n\nCase Charging\n60 minutes\n110 minutes\n\n\nFast Charging\n10min = 4h\nNot available\n\n\nWeight (earbud)\n5.4g\n4.9g\n\n\nWeight (case)\n36.5g\n33.9g\n\n\nEar Tip Sizes\n4 sizes (XS, S, M, L)\n3 sizes (S, M, L)\n\n\nMode Cycle Order\nNC ‚Üí Off ‚Üí Awareness\nAwareness ‚Üí Off ‚Üí NC\n\n\nSpatial Audio\nYes with head-tracking\nNo\n\n\nTriple-tap Gesture\nYes\nNo\n\n\nNod to Answer\nYes\nNo\n\n\nIP Rating\nIP54\nIP54\n\n\nColors\nPink, White, Black\nNebula Black, Isle Blue, Ceramic White\n\n\nPrice Range\n~$100\n~$100\n\n\n\nWho Should Buy the FreeBuds 7i?\nBuy the 7i if you:\n\nDo frequent video calls, online meetings, or streaming\nWant the best call quality in this price range\nNeed better active noise cancellation\nValue faster charging (60min vs 110min for case)\nSwitch between multiple devices regularly\nWant spatial audio with head-tracking\nAppreciate the extra ear tip size for better fit\n\nStick with the 5i if you:\n\nNeed maximum single-charge battery life (6h vs 5h with ANC)\nPrefer the more elegant case design and Isle Blue color\nRarely make calls or do video meetings\nAre satisfied with current ANC performance\nWant slightly lighter earbuds (4.9g vs 5.4g)\n\n\nCommon Questions About FreeBuds 7i\nQ: Do FreeBuds 7i work with iPhone? Yes, they work with any Bluetooth device including iPhones. Download the AI Life app for iOS to access advanced features.\nQ: How is the microphone quality for calls? Excellent. The bone conduction mic combined with AI noise cancellation delivers clear voice quality even in noisy environments up to 90 dB.\nQ: Can I use just one earbud? Yes, both earbuds work independently. You can use either the left or right earbud alone.\nQ: Are they good for working out? Yes, the IP54 rating makes them dust-tight and splash-resistant. Just wipe them dry after workouts.\nQ: How‚Äôs the latency for gaming? The Bluetooth 5.4 connection provides low latency suitable for casual mobile gaming, though dedicated gaming earbuds might perform better for competitive play."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#final-verdict-is-the-freebuds-7i-worth-it",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#final-verdict-is-the-freebuds-7i-worth-it",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Final Verdict: Is the FreeBuds 7i Worth It?",
    "text": "Final Verdict: Is the FreeBuds 7i Worth It?\nAfter 20 days of daily use, the Huawei FreeBuds 7i is a meaningful upgrade over the 5i. The microphone quality improvement is immediately noticeable - my colleagues commented on it the first day. The Intelligent Dynamic ANC 4.0 delivers genuinely better noise cancellation, and the faster charging is a game-changer (60 minutes vs 110 minutes for the case).\nYes, the case design is less elegant than the 5i, but the functional improvements more than compensate. For anyone who relies on earbuds for productivity - video calls, meetings, focused work in noisy environments - the FreeBuds 7i is the clear winner.\nThe sound quality remains excellent, the battery life is better overall, the device switching is smarter, and features like spatial audio and nod-to-answer add genuine value. At around $100, these are among the best budget noise-cancelling earbuds available, even for non-Huawei phone owners.\nRating: 4.5/5\nPros: - Excellent call quality with bone conduction mic - Better ANC performance (28dB depth) - Much faster charging (60min vs 110min for case) - Smarter multi-device switching - Spatial audio with head-tracking - 4 ear tip sizes for better fit - Works great outside Huawei ecosystem\nCons: - Case design less elegant than 5i - Slightly heavier earbuds (5.4g vs 4.9g) - Single-charge battery with ANC slightly shorter (5h vs 6h) - No Isle Blue color option\nIf you do video calls or need excellent ANC, the FreeBuds 7i is worth every penny. If you only listen to music casually, the 5i is still a great choice.\nIf you want to see more review you can join the Channel"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 7i.html#refernces",
    "href": "blog/posts/products_reviews/Huawei freebuds 7i.html#refernces",
    "title": "Huawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?",
    "section": "Refernces",
    "text": "Refernces\n\nHuawei Freebuds 5i Review\nHuawei Freebuds Official site"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "",
    "text": "Here is an expanded version of your blog post with some additional details:"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#table-of-contents",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#table-of-contents",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "",
    "text": "Here is an expanded version of your blog post with some additional details:"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#why-i-bought-it",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#why-i-bought-it",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Why I bought it",
    "text": "Why I bought it\nI purchased the Huawei tablet because I enjoy creative activities like drawing, taking notes, and reading books. I wished to have an iPad or premium tablet with a good stylus to fully explore my creative potential. My brother found an excellent deal on this Huawei tablet for around 60% off retail price and gifted it to me. I‚Äôm very thankful to him!"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#pros",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#pros",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Pros",
    "text": "Pros\n\nExcellent audio quality with quad speakers\nGorgeous 10.95-inch LCD display\n\n2560x1600 resolution\n120Hz refresh rate for smooth visuals\n\nFast charging capabilities\n\nLarge 7250 mAh battery\nSupports 22.5W fast wired charging\n\nComfortable lightweight design, easy to use for long periods\nSeamless integration with other Huawei devices like watches and earbuds\nResponsive stylus with good palm rejection"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#cons",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#cons",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Cons",
    "text": "Cons\n\nTablet gets hot with prolonged intensive use like drawing or taking notes. Quite annoying.\nBattery life is decent but not enough to last a full day with heavy usage\nFrequent ads in App Gallery and default music app are frustrating\n\nShould not see ads just trying to open App Gallery\nDefault music app tries to push online streaming service with more ads\n\nMany apps spam notifications asking to reopen them. Very irritating.\n\nIf you want to see more reviews about Huawei you can join the Channel"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#using-huawei-devices-with-linux",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#using-huawei-devices-with-linux",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Using Huawei Devices with Linux",
    "text": "Using Huawei Devices with Linux\n\nFile transfers require a cable, no wireless sharing\nMust use third party apps like KDE Connect for notifications\nCan‚Äôt develop custom themes or scripts due to lack of developer tools\nSyncing to Linux with Syncthing is slow and buggy\nOverall poor integration with Linux compared to Android/Windows"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#issues-with-google-services-on-huawei",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#issues-with-google-services-on-huawei",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "Issues with Google Services on Huawei",
    "text": "Issues with Google Services on Huawei\n\nStylus Apps\n\nInfinite Painter drawing app has broken stylus support and no pressure sensitivity\nNoteShelf note taking app can‚Äôt sync properly with cloud drives\nNebo note taking app has subpar palm rejection and no Arabic language support\nFlexcil best ebook reader/annotator but lacks Google Drive integration\n\n\n\nGbox Solution\n\nProvides access to YouTube, Maps and other Google apps\nAvailable on App Gallery with native integration\nMinimal battery drain\nBut lacks support for many Google services like Podcasts\nBuggy syncing with Google Keep\nCan‚Äôt leverage Google Drive within other apps\n\n\n\nAPK Pure\n\nApps sometimes fail to open, just black screen\nToo many ads\nLacks reliability compared to Play Store\n\nOverall, while the Huawei tablet offers excellent hardware, the software experience is hampered by lack of Google services. This leads to janky third party solutions and poor integration with Linux systems. I still enjoy using the tablet but hope someday Huawei can properly resolve these issues."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_mate_pad_11.html#references",
    "href": "blog/posts/products_reviews/Huawei_mate_pad_11.html#references",
    "title": "After one year of using Huawei Mate 11 without google services",
    "section": "references",
    "text": "references\n\nhttps://www.noteshelf.net/\nhttps://www.gboxlab.com/\nhttps://www.infinitestudio.art/painter.php"
  },
  {
    "objectID": "blog/posts/nlp/embedding_world/late_interaction.html",
    "href": "blog/posts/nlp/embedding_world/late_interaction.html",
    "title": "Late Interaction and ColPali",
    "section": "",
    "text": "what is early interaction\nwhat is late interaction\nReasoning BERT\nmvbert\nColPali\ncolbert\npylate\nPLAID"
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html",
    "title": "tiny-gte ‚ÄúTiny, yet powerful, it is small in size but packs a lot of power.‚Äù",
    "section": "",
    "text": "#definition : This is a¬†sentence-transformers¬†model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search. It is distilled from¬†thenlper/gte-small, with comparable (slightly worse) performance at around half the size."
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#table-of-contents",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#table-of-contents",
    "title": "tiny-gte ‚ÄúTiny, yet powerful, it is small in size but packs a lot of power.‚Äù",
    "section": "",
    "text": "#definition : This is a¬†sentence-transformers¬†model: It maps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search. It is distilled from¬†thenlper/gte-small, with comparable (slightly worse) performance at around half the size."
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#details",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#details",
    "title": "tiny-gte ‚ÄúTiny, yet powerful, it is small in size but packs a lot of power.‚Äù",
    "section": "Details",
    "text": "Details\n\nIt‚Äôs around ~45MB very small compared to other models like MiniLM-L6-V2 which is equal to ~80 MB\nEmbedding vector size 384d\nBERT based\nDistilied from thenlper/gte-small,"
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#notice-about-using-small-size",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#notice-about-using-small-size",
    "title": "tiny-gte ‚ÄúTiny, yet powerful, it is small in size but packs a lot of power.‚Äù",
    "section": "Notice about using small size",
    "text": "Notice about using small size"
  },
  {
    "objectID": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#use-cases",
    "href": "blog/posts/mteb_encoding/tiny-gte_transformer_model.html#use-cases",
    "title": "tiny-gte ‚ÄúTiny, yet powerful, it is small in size but packs a lot of power.‚Äù",
    "section": "Use Cases",
    "text": "Use Cases"
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "",
    "text": "#defintion MTEB: MTEB spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on MTEB."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#introduction",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#introduction",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "",
    "text": "#defintion MTEB: MTEB spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on MTEB."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#embedding-models",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#embedding-models",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Embedding models",
    "text": "Embedding models\n\nText embedding models like GLove lack context awareness and ar=e thus commonly labeled as word embedding model. They consist of a layer mapping each input word to a vector often followed by an averaging layer to provide a final embedding invariant of input length.\nTransformers inject context awareness into language models via self-attention and form the foundation of most recent embedding models.\n\nBERT uses the transformer architecture and performs large-scale self-supervised pre-training. The resulting model can directly be used to produce text embeddings via an averaging operation alike Glove.\nSBERT be beneficial to perform additional fine-tuning of the transformer for competitive embedding performance.\nMost recent fine-tuned embedding models use a contrastive loss objective to perform supervised fine-tuned on positive and negative text pairs\n#critique Due to the large variety of available pretrained transformers,there is an at least equally large variety of potential text embedding models to be explored.This leads to confusion about which model provides practitioners with the best performance for their embedding use case."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-problem",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-problem",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "The problem",
    "text": "The problem\n\nThe problem with the current evaluation regime of current text embedding models rarely covers the breadth of their possible use cases.\n\n#example SimCSE or SBERT solely evaluate on STS and classification tasks,leaving open questions about the transfer ability of the embedding models to search or clustering tasks.\n\nevaluating embedding methods on many tasks requires implementing multiple evaluation pipelines.\nimplementation details like preprocessing or hyperparameters may influence the results making it unclear whether performance improvements simply come from a favorable evaluation pipeline. This leads to the ‚Äúblind‚Äù application of these models to new use cases in industry or requires incremental work to reevaluate them on different tasks."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-solution-with-this-benchmark",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-solution-with-this-benchmark",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "The solution with this benchmark",
    "text": "The solution with this benchmark\n\nMTEB consists of 58 datasets covering 112 languages from 8 embedding tasks:\n\n\nBitext mining\nclassification\nclustering\npair classification\nreranking, retrieval\nSTS\nsummarization.\n\n\nMTEB software is available open-source1 enabling evaluation of any embedding model by adding less than 10 lines of code.\nDatasets and the MTEB leaderboard are available on the Hugging Face Hub2 .\nWe evaluate over 30 models on MTEB with additional speed and memory benchmarking to provide a holistic view of the state of text embedding models. We cover both models available open-source as well as models accessible via APIs, such as the OpenAI Embeddings endpoint\nIt aims to sheds light on the weaknesses and strenghts of individual models,such as SimCSE‚Äôs(Gao et al., 2021b) low performance on clustering and retrieval despite its strong performance on STS."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-mteb-desiderata",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#the-mteb-desiderata",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "The MTEB Desiderata",
    "text": "The MTEB Desiderata\nMETB is build on a set of desiderat.\n\nDiversity:\n\nit consists of 58 total datasets, 10 are multilingual, covering 112 different langauges.\nSentence-level and paragraph level datasets are included to contrast performance on short and long texts.\n\nSimplicity\n\nIt provides a simple API for plugging in any model that given a list of text can produce a vector for each list of texts can produce a vector for each list item with a consistent shape.\n\nExtensibility\n\nyou can add new datasets for existing tasks via a single file that specifies the task and a Huggingface dataset name where the data has been uploaded.\nNew tasks require implementing a task interface for loading the data and an evaluator for benchmarking\n\nReproduciblity\n\nThrough versioning at a dataset and software level,they make it easy to reproduce results in METP.\nJSON files corresponding to all results available in this paper have been made available together with the MTEB benchmark"
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#tasks-and-evaluation",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#tasks-and-evaluation",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Tasks and Evaluation",
    "text": "Tasks and Evaluation\n#definition Bitext Mining\nInputs are two sets of sentences from two different languages. For each sentence in the first set, the best match in the second set needs to be found.\n\nThe matches are commonly translations.\nThe Provided model i used to embed each sentence and the closest pairs are found via cosine similarity\nF1 serves as the main metric for bitext mining.Accuracy, precision and recall are also computed. #definition Classification\nA train and test set are embedded with the provided model.\nThe train set embeddings are used to train a logistic regression classifier with 100 maximum iterations, which is scored on the test set.\nThe main metric is accuracy with average precision and f1 additionally provided. #definition Clustering Given a set of sentences or paragraphs, the goal is to group them into meaningful clusters.\nA mini-batch k-means model with batch size 32 and k equal to the number of different labels is trained on the embedded texts.\nThe model scored using V-measure - V-measure does not depend on the cluster label,thus the permutation of labels does not affect the score. #definition Classification A pair of text inputs is provided and a label needs to be assigned. Labels are typically binary variables denoting duplicate or paraphrase pairs.\nThe two texts are embedded and their distance is computed with various metrics (cosine similarity, dot product, euclidean distance, manhattan distance).\nUsing the best binary thresh- old accuracy, average precision, f1, precision and recall are computed.\nThe average precision score based on cosine similarity is the main metric. #definition Reranking : Inputs are a query and a list of relevant and irrelevant reference texts. The aim is to rank the results according to their relevance to the query.\nThe model is used to embed the references which are then compared to the query using cosine similarity.\nThe resulting ranking is scored for each query and averaged across all queries.\nMetrics are mean MRR@k and MAP with the latter being the main metric. #definition Retrieval Each dataset consists of a corpus, queries and a mapping for each query to relevant documents from the corpus.\nThe aim is to find these relevant documents.\nThe provided model is used to embed all queries and all corpus documents and similarity scores are computed using cosine similarity. After ranking the corpus documents for each query based on the scores, nDCG@k, MRR@k, MAP@k, precision@k and recall@k are computed for several values of k. nDCG@10 serves as the main metric.\nMTEB reuses datasets and evaluation from BEIR (Thakur et al., 2021). #definition Semantic Textual Similarity (STS) Given a sentence pair the aim is to determine their similarity. Labels are continuous scores with higher numbers indicating more similar sentences.\nThe provided model is used to embed the sentences and their similarity is computed using various distance metrics.\nDistances are benchmarked with ground truth similarities using Pearson and Spearman correlations.\nSpearman correlation based on cosine similarity serves as the main metric (Reimers et al.,2016). #definition Summarization A set of human-written and machine-generated summaries are provided. The aim is to score the machine summaries. The provided model is first used to embed all summaries. For each machine summary embedding, distances to all human summary embeddings are computed. The closest score (e.g.¬†highest cosine similarity) is kept and used as the model‚Äôs score of a single machine-generated summary. Pearson and Spearman correlations with ground truth human assessments of the machine-generated summaries are computed. Like for STS, Spearman correlation based on cosine similarity serves as the main metric\n\n\n#sidenote Non-Transformers : LASER (Heffernan et al.,2022) is the only context aware non-transformer model we benchmark, relying on an LSTM (Hochreiter and Schmidhuber, 1997) instead. Similar to LaBSE, the model trains on parallel data and focuses on bitext mining applications. ![[Pasted image 20231028124555.png]]"
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#analysis",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#analysis",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Analysis",
    "text": "Analysis\n\nwe observe that there is considerable variability between tasks. No model claims the state-of-the-art in all seven English tasks.\nThere is even more variability in the results per dataset present in the appendix.\nFurther, there remains a large gap between self-supervised and supervised methods.\nSelf-supervised large language models have been able to close this gap in many natural language generation tasks (Chowd- hery et al., 2022).\nHowever, they appear to still require supervised fine-tuning for competitive em- bedding performance.\nWe find that performance strongly coorelates with model size, A majority of MTEB tasks are domainted by multi-billion parameter models.However, these come at a significant cost\nFor classification\n\nST5 models dominate the classification task across most datasets\nST5-XXL has the highest average performance, 3% ahead of the best non-ST5 model, OpenAI Ada Similarity\n\nClustering\n\nDespite being almost 50x smaller, the MPNet embedding model is on par with the ST5- XXL state-of-the-art on Clustering. This may be due to the large variety of datasets MPNet (and MiniLM) has been fine-tuned on.\nClustering requires coherent distances between a large number of embeddings.\nModels like SimCSE-sup or SGPTnli, which are only fine-tuned on a single dataset,NLI, may produce incoherent embeddings when encountering topics unseen during fine-tuning.\nRelatedly, we find that the query embeddings of SGPT-msmarco and the Ada Search endpoint are competitive with SGPT-nli and the Ada Similarity endpoint,respectively.\nWe refer to the public leaderboard5 for Ada Search results. This could be due to the MSMARCO dataset being significantly larger than NLI.\nThus, while the OpenAI docs recommend using the similarity embeddings for clustering use cases6 , the retrieval query embeddings may be the better choice in some cases.\n\nPair Classification\n\nGTR-XL and GTR-XXL have the strongest performance. Pair classification is closest to STS in its framing, yet models rank significantly differently on the two tasks. This highlights the importance of benchmarking on a diverse set of tasks to avoid blindly reusing a model for a different task.\n\nReranking\n\nMPNet and MiniLM models perform strongly on reranking tasks.\nOn SciDocsRR (Co-han et al., 2020a) they perform far better than big- ger models, which is likely due to parts of SciDocsRR being included in their training data.\nOur scale of experiments and that of model pre-training make controlling for data contamination challenging.\nThus, we ignore overlap of MTEB datasets with model training datasets in MTEB scores.\nAs long as enough datasets are averaged, we believe these effects to be insignificant.\n\nRetrieval\n\nSGPT-5.8B-msmarco is the best em- bedding model on the BEIR subset in MTEB as well as on the full BEIR benchmark (Thakur et al., 2021; Muennighoff, 2022).\nThe even larger 7.1B SGPT model making use of BLOOM (Scao et al., 2022) performs significantly weaker, which is likely due to the multilinguality of BLOOM.\nModels geared towards STS (SimCSE, ST5, SGPT- nli) perform badly on retrieval tasks.\nRetrieval tasks are unique in that there are two distinct types of texts: Queries and documents (‚Äúasymmetric‚Äù), while other tasks only have a single type of text (‚Äúsymmetric‚Äù).\nOn the QuoraRetrieval dataset, which has been shown to be largely symmetric (Muennighoff, 2022), the playing field is more even with SGPT-5.8B-nli outperforming SGPT- 5.8B-msmarco,\n\nSTS & Summarization\n\nRetrieval models (GTR, SGPT-msmarco) perform badly on STS, while ST5-XXL has the highest performance.\nThis highlights the bifurcation of the field into separate embedding models for retrieval (asymmetric) and similarity (symmetric) use cases (Muennighoff, 2022)."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#efficiency",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#efficiency",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Efficiency",
    "text": "Efficiency\nMaximum speed -&gt; Word Embedding models offer maximum speed with Glove taking the lead on both performance and speed, thus making the choice simple in this case\nMaximum performance -&gt; If latency is less important than performance Depending on the task at hand, GTR-XXL, ST5-XXL or SGPT-5.8B may be the right choice,\nSpeed and Peformance -&gt; The fine-tuned MPNet and MiniLM models lead the middle cluster making the choice easy.\n\n#todo you can check the gte architecture here it‚Äôs highly related to the MTEP [[tiny-gte_transformer_model]]"
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#conclusion",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#conclusion",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "Conclusion",
    "text": "Conclusion\n\nWe found model performance on different tasks to vary strongly with no model claiming state-of-the-art on all tasks.\nOur studies on scaling behavior, model efficiency and multilinguality revealed various intricacies of models that should ease the decision-making process for future research or industry applications of text embeddings.\n\n\nThanks for reading. If you have any questions, feel free to comment down below or reach out to me on twitter @AbdelkareemElk1."
  },
  {
    "objectID": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#references",
    "href": "blog/posts/mteb_encoding/MTEB_massive_text_embedding_benchmark.html#references",
    "title": "MTEB Massive Text Embedding Benchmark",
    "section": "References",
    "text": "References\n\nhttps://huggingface.co/blog/mteb\nhttps://arxiv.org/abs/2210.07316"
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html",
    "href": "blog/posts/math/math_skills_for_AI.html",
    "title": "Math Skills For AI",
    "section": "",
    "text": "As a graduate with a Computer Science degree, my time has been primarily dedicated to three core areas:\n\nProgramming:¬†I‚Äôve worked extensively with Python, C++, JavaScript, and Rust.\nMathematics:¬†My studies have encompassed linear algebra, probability, calculus, and discrete mathematics.\nCore Computer Science:¬†I‚Äôve explored topics like databases, networking, and data structures & algorithms.\n\nDuring my final year, I realized there were significant gaps in my understanding, despite the courses and books I‚Äôd engaged with. I often wish I could start over, but real life doesn‚Äôt have a ‚Äúretry‚Äù button.\nCurrently, I‚Äôm involved in:\n\nAI Research:¬†My focus is on medical image preprocessing and natural language processing. I‚Äôm also keenly interested in areas like:\n\nFederated Learning\nAdversarial Neural Networks\nExplainable AI (XAI)\nGenerative Art (specifically Stable Diffusion models, Flux, and ControlNet)\n\nWeb Development:¬†I primarily use FastHTML and Astrojs for side projects. I enjoy building things and getting paid for them, as I don‚Äôt currently have a formal AI job."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#what-i-aim-to-achieve",
    "href": "blog/posts/math/math_skills_for_AI.html#what-i-aim-to-achieve",
    "title": "Math Skills For AI",
    "section": "",
    "text": "As a graduate with a Computer Science degree, my time has been primarily dedicated to three core areas:\n\nProgramming:¬†I‚Äôve worked extensively with Python, C++, JavaScript, and Rust.\nMathematics:¬†My studies have encompassed linear algebra, probability, calculus, and discrete mathematics.\nCore Computer Science:¬†I‚Äôve explored topics like databases, networking, and data structures & algorithms.\n\nDuring my final year, I realized there were significant gaps in my understanding, despite the courses and books I‚Äôd engaged with. I often wish I could start over, but real life doesn‚Äôt have a ‚Äúretry‚Äù button.\nCurrently, I‚Äôm involved in:\n\nAI Research:¬†My focus is on medical image preprocessing and natural language processing. I‚Äôm also keenly interested in areas like:\n\nFederated Learning\nAdversarial Neural Networks\nExplainable AI (XAI)\nGenerative Art (specifically Stable Diffusion models, Flux, and ControlNet)\n\nWeb Development:¬†I primarily use FastHTML and Astrojs for side projects. I enjoy building things and getting paid for them, as I don‚Äôt currently have a formal AI job."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#the-centrality-of-math-in-ai-research",
    "href": "blog/posts/math/math_skills_for_AI.html#the-centrality-of-math-in-ai-research",
    "title": "Math Skills For AI",
    "section": "The Centrality of Math in AI Research",
    "text": "The Centrality of Math in AI Research\nIt‚Äôs true that in both engineering and research, you can be an excellent software engineer and earn a substantial income without deep mathematical knowledge, possibly more than many mathematicians. However, to be a¬†good¬†researcher, a strong mathematical foundation is crucial. By that, I don‚Äôt just mean a superficial understanding of numerous topics. You need a solid grasp of linear algebra and probability, both theoretically and practically. And by ‚Äúpractical,‚Äù I mean the ability to translate mathematical concepts into code.\nOf course, other topics are relevant, depending on your specific field. For example:\n\nGenerative AI:¬†You‚Äôll often encounter differential equations and advanced probability and statistical models.\n\nAfter reading research papers, you begin to see recurring concepts like conditional probability, Bayes‚Äô theorem, and matrix factorization. But you‚Äôll also find complex, novel, or sometimes even older, techniques that are hard to grasp initially.\n\nIn my limited time exploring research, I‚Äôve observed that many papers lack significant contributions. Some seem to be primarily workarounds, comparisons of existing models, new data applied to established models, or minor observations. This isn‚Äôt inherently bad, but it‚Äôs not the kind of impact I‚Äôm aiming for. The researchers who are making substantial contributions are often very skilled in¬†both¬†math and coding. They create open-source projects, share their ideas, and actively contribute, like the authors of the Colbert papers in information retrieval. And these contributions are often enabled by math, such as PCA, LORA, and other optimization techniques.\nWhile a strong coding background can certainly be beneficial for optimization and research, I strive for a deeper understanding and to reach a higher level of impact. After all, we only have one life.\nI don‚Äôt consider myself a ‚Äúbookworm,‚Äù but I genuinely love reading and can become engrossed in books on diverse subjects and levels. I recall reading around four books on linear algebra, completing all the exercises, and summarizing the content. In deep learning, I‚Äôve tackled more than 30 books. For areas like networking, databases, and data structures, I‚Äôve read at least three books on each. When new topics like federated learning, XAI, and adversarial networks emerge, I always read at least one book on each.\nIf you were to examine my profile, CV, GitHub, or even this blog, you‚Äôd probably find that I‚Äôm below average for a recent graduate! What‚Äôs the problem?\nI believe the core issue is that while I‚Äôve read extensively and sometimes coded along with the material, I haven‚Äôt committed to projects that demand more time and mental effort. I haven‚Äôt really allowed the knowledge to ‚Äúgrow.‚Äù For instance, I learned linear algebra theory and did the pen-and-paper exercises, but I didn‚Äôt experiment with coding it. And, I didn‚Äôt apply the concepts I studied to the fields that truly interested me. There‚Äôs also a gap between the libraries we use in deep learning and the underlying skills ‚Äì they don‚Äôt always feel directly connected.\nIt‚Äôs unrealistic to understand every library at a micro-level. But it‚Äôs crucial to try and bridge the gap between your fundamental skills and the high-level APIs you use. For example, challenge yourself to implement PCA from scratch with NumPy on a Kaggle dataset. Try coding the matrix components of LORA with PyTorch. Take probability concepts and apply them to datasets you care about ‚Äì for me, that might be datasets related to fitness or Arabic language processing. Build projects you love using these new tools, and consciously choose what skills to prioritize. For example, I might be okay with letting go of some discrete math knowledge, but not linear algebra."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#the-days-of-problem-solving",
    "href": "blog/posts/math/math_skills_for_AI.html#the-days-of-problem-solving",
    "title": "Math Skills For AI",
    "section": "The Days of Problem Solving",
    "text": "The Days of Problem Solving\nDuring my second year, I began exploring problem-solving but initially struggled with platforms like Codeforces. However, after two months of encouragement from friends, I decided to give it another shot.\nI was using Edabit to practice Python problem-solving with easy problems and then moved to Codeforces without a solid grasp of C++. It took time and many hours struggling with error messages (I once learned a painful lesson that ‚Äú‚Äù and ‚Äô‚Äô are different in C++ unlike Python!).\nAfter about two months of this, my skills in both thinking and implementation improved dramatically. I recall one of my earliest achievements was writing a 300-line C++ solution without relying on Google, and of course, LLMs weren‚Äôt around at that time. This feeling of self-sufficiency was incredibly rewarding. After four months, my problem-solving skills had improved considerably, and I had reached the next level. However, I then decided to shift my focus to web development to improve my financial situation, and I never went back. I also remember failing a technical interview in my third year because I struggled to solve linked list problems in Python, despite being able to do so in C++. I felt lost throughout my college years\nBut that feeling of deep understanding, of being able to solve problems independently, is amazing and builds confidence. It‚Äôs a virtuous cycle."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#things-i-remember",
    "href": "blog/posts/math/math_skills_for_AI.html#things-i-remember",
    "title": "Math Skills For AI",
    "section": "Things I Remember",
    "text": "Things I Remember\nI‚Äôm revisiting linear algebra and realized I‚Äôd forgotten how to calculate eigenvalues, though I understand their role. However, I haven‚Äôt forgotten how to calculate the determinant of a 2x2 or 3x3 matrix. Why? Because I solved countless exercises with determinants, but with eigenvalues, I had primarily read the solutions or tried simple examples. When using PCA in code, it‚Äôs easy to rely on a library and not think about the underlying operations. While that‚Äôs okay to some degree, we should occasionally revisit how things work behind the scenes."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#the-mbzuai-exam-in-two-days",
    "href": "blog/posts/math/math_skills_for_AI.html#the-mbzuai-exam-in-two-days",
    "title": "Math Skills For AI",
    "section": "The MBZUAI Exam in Two Days",
    "text": "The MBZUAI Exam in Two Days\nA friend told me about a scholarship at MBZUAI with a deadline in three days. Although I didn‚Äôt have the necessary English test scores, I applied anyway. They‚Äôve scheduled an exam in 7 days from when I applied, and today was the first day I started preparing.\nI completed the linear algebra and probability specializations on Coursera taught by Luis G. Serrano. While it was a good refresher, I dislike relearning the same concepts every year! The exam will cover probability, linear algebra, calculus, algorithms, trigonometry, optimization, and some NLP questions.\nI honestly don‚Äôt remember much about trigonometry, and when I studied it before, it was in Arabic, not English, and the transition isn‚Äôt so simple. I also dislike cramming things for two days only to forget them immediately after ‚Äì that feels like a waste of time.\nDespite the odds, I‚Äôm determined to apply, even if the acceptance rate for the scholarship is only 5%. Working with the people at MBZUAI would be a great experience. If I‚Äôm not accepted, I‚Äôll continue to focus on mastering math and keep moving forward."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#maslakiat",
    "href": "blog/posts/math/math_skills_for_AI.html#maslakiat",
    "title": "Math Skills For AI",
    "section": "Maslakiat",
    "text": "Maslakiat\n\n\n\nŸÉÿ™ÿßÿ® ŸÖÿ≥ŸÑŸäŸÉÿßÿ™ ÿ•ÿ®ÿ±ÿßŸáŸäŸÖ ÿßŸÑÿ≥ŸÉÿ±ÿßŸÜ\n\n\nwhen i have a stress and a lof of taskes i go to reading books I have final exams in the comming days, MBZUAI exam, research paper review comments needed to be corrected, open source problem i must finish this week, some websites and a lot of things. I start reading the first the page and the author was talking to me and the words touch my soul deeply for example some qoutes from the book I will write them in arabic and you can translate them with GPT.\nTranslations of the Arabic Quotes (with slight interpretations for clarity):\n\n‚ÄúŸàŸÑŸÉŸÜ ÿ´ŸÖÿ© ÿπÿßŸÖŸÑ ŸÑŸá ŸÅŸä ŸÜŸÅÿ≥Ÿä ÿ≠ŸÅÿßŸàÿ© ÿÆÿßÿµÿ© ÿå ÿπÿßŸÖŸÑ ŸäŸÅÿ≥ÿ± ŸÉÿ´Ÿäÿ±ÿß ŸÖŸÜ ŸÅÿ¥ŸÑ ÿßŸÑÿ∑ŸÖŸàÿ≠ÿßÿ™ Ÿà ÿßŸÑÿ£ÿ≠ŸÑÿßŸÖ ‚Ä¶ Ÿáÿ∞ÿß ÿßŸÑÿπÿßŸÖŸÑ ÿ®ŸÉŸÑ ÿßÿÆÿ™ÿµÿßÿ±: ŸáŸà ÿ£ŸÜ ÿßŸÑÿÆÿ∑ÿ∑ ŸÅŸàŸÇ ÿßŸÑÿµÿÆŸàÿ± Ÿà ÿßŸÑÿßÿ±ÿ¨ŸÑ ŸÖÿßÿ≤ÿßŸÑÿ™ ŸÜÿßÿπŸÖÿ© ŸÖÿß ÿ≠ŸÅŸäÿ™ ÿ®ÿπÿØ‚Ä¶‚Äù\n\nTranslation:¬†‚ÄúBut there is a factor that resonates deeply within me, a factor that explains much of the failure of ambitions and dreams‚Ä¶ This factor, in short, is that the plans are laid on rocks, but our feet are still tender, not yet calloused.‚Äù\nInterpretation:¬†This emphasizes the gap between grand plans and the lack of practical experience or the ‚Äúhard knocks‚Äù that build resilience and skill.\n\n‚Äúÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÖÿ±ÿ° ŸäŸÜÿßŸÖ ÿ≠ÿ™Ÿä ÿ™ÿ¨Ÿáÿ±ŸÉ ÿ£ÿ¥ÿπÿ© ÿßŸÑÿ≠ŸÖÿ±ÿ© ŸÅŸä ÿπŸäŸÜŸäÿ© Ÿà Ÿäÿ®ÿ≥ÿ∑ ÿÆŸàÿßŸÜ ÿßŸÑÿ∑ÿπÿßŸÖ ŸÉŸÑŸÖÿß ÿßÿ¥ÿ™ŸáŸä ÿå ŸàŸäÿÆÿµÿµ ÿßŸÑÿ£ŸàŸÇÿßÿ™ ÿßŸÑÿ∑ŸàŸäŸÑÿ© ŸÑŸÑŸÇŸáŸàÿ© Ÿà ÿßŸÑÿ¥ÿßŸä Ÿà ÿßŸÑÿπÿµÿßÿ¶ÿ± Ÿà ÿßŸÑŸÅÿ∑ÿßÿ¶ÿ± ÿå ŸàŸÑÿß Ÿäÿ≥ŸÖÿ≠ ŸÑŸÜŸÅÿ≥Ÿá ÿ®ÿ£ŸÜ ÿ™ÿ™ŸÜÿßÿ≤ŸÑ ÿπŸÜ ÿ£Ÿä ŸÅÿ±ÿµÿ© ŸÅÿ≥ÿ≠ÿ© ÿ£Ÿà ŸÖÿ≥ÿßŸÖÿ±ÿßÿ™ ŸÖÿπ ÿ£ÿµÿ≠ÿßÿ®ÿ© ÿå Ÿà ŸÑÿß Ÿäÿ≥ÿ™ÿ∑Ÿäÿπ ŸÉÿ®ÿ≠ ÿ¨ŸÖÿßÿ≠ ÿ™ÿµŸÅÿ≠ ÿßŸÑÿ•ŸÜÿ™ÿ±ŸÜÿ™ ÿ£ŸÜ Ÿäÿ≥ÿ±ŸÇ ÿ≥ÿßÿπÿßÿ™Ÿá ÿå ÿßÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑŸÖÿ±ÿ° ŸÉÿ∞ŸÑŸÉ .. ŸàŸÖÿß ÿ≤ÿßŸÑ Ÿäÿ±ÿ¨Ÿà ÿßŸÜ ÿ™ÿ™ÿ≠ŸÇŸÇ ŸäŸàŸÖÿß ŸÖÿß ÿÆÿ∑ÿ∑Ÿá ÿßŸÑÿπŸÑŸÖŸäÿ© Ÿà ÿßŸÑÿØÿπŸàŸäÿ© Ÿà ÿßŸÑÿ•ÿµŸÑÿßÿ≠Ÿäÿ© ÿå ŸÅŸÖÿ´ŸÑ Ÿáÿ∞ÿß ÿßŸÑÿ¥ÿÆÿµ ŸÇÿØ ÿßÿ≥ÿ™ÿ£ÿµŸÑ ÿπŸÇŸÑŸá ÿå Ÿà ÿ≤ÿ±ÿπ ÿ®ÿØŸÑÿß ŸÖŸÜŸá ŸÖÿµÿ®ÿßÿ≠ ÿπŸÑÿßÿ° ÿßŸÑÿØŸäŸÜ‚Äù\n\nTranslation:¬†‚ÄúIf a person sleeps until the red rays of the sun glare in their eyes, lays out a feast whenever they desire, dedicates long periods to coffee, tea, juices, and pastries, never allows themselves to miss an opportunity for leisure or socializing with friends, and cannot restrain themselves from internet browsing stealing their hours‚Äîif a person is like this and still hopes that their scientific, religious, or reformist plans will one day be realized, then such a person has removed their mind and planted Aladdin‚Äôs lamp in its place.‚Äù\nInterpretation:¬†This strongly condemns a life of indulgence and procrastination, suggesting that those who wish to achieve great things must sacrifice leisure and work diligently. They cannot expect to magically fulfill ambitions like Aladdin with his lamp.\n\n‚ÄúŸÑÿß Ÿäÿ≥ÿ™ÿ∑ÿßÿπ ÿßŸÑÿπŸÑŸÖ ÿ®ÿ±ÿßÿ≠ÿ© ÿßŸÑÿ¨ÿ≥ŸÖ‚Äù\n\nTranslation:¬†‚ÄúKnowledge cannot be attained with bodily comfort.‚Äù\nInterpretation:¬†This is a concise statement emphasizing the necessity of effort and sacrifice in the pursuit of learning.\n\n‚ÄúÿßŸÑŸÉŸÖÿßŸÑÿßÿ™ ŸÉŸÑŸáÿß ŸÑÿß ÿ™ŸÜÿßŸÑ ÿ•ŸÑÿß ÿ®ÿ≠ÿ∏ ŸÖŸÜ ÿßŸÑŸÖÿ¥ŸÇÿ© Ÿà ŸÑÿß Ÿäÿπÿ®ÿ± ÿ•ŸÑŸäŸáÿß ÿ•ŸÑÿß ÿπŸÑŸä ÿ¨ÿ≥ÿ± ŸÖŸÜ ÿßŸÑÿ™ÿπÿ®‚Äù\n\nTranslation:¬†‚ÄúAll perfections are not achieved except through a portion of hardship, and they cannot be crossed except on a bridge of fatigue.‚Äù\nInterpretation:¬†This highlights that excellence and mastery require sustained effort, difficulty, and resilience.\n\n‚Äúÿ™ŸÑŸÖÿ≠ ŸÅÿ¨ÿ± ÿßŸÑÿ£ÿ¨ÿ± ŸäŸáŸÜ ÿ∏ŸÑÿßŸÖ ÿßŸÑÿ™ŸÉŸÑŸäŸÅ‚Äù\n\nTranslation:¬†‚ÄúYou perceive the dawn of reward makes the darkness of duty pale.‚Äù\nInterpretation:¬†This suggests that the hope of reward and the meaningful impact of your work make the hard work and sacrifice worthwhile.\n\n‚Äúÿ®ŸÇÿØÿ± ŸÖÿß ÿ™ÿ™ÿπŸÜŸä ÿ™ŸÜÿßŸÑ ŸÖÿß ÿ™ÿ™ŸÖŸÜŸä‚Äù\n\nTranslation:¬†‚ÄúTo the extent that you exert yourself, to that extent you will achieve what you desire.‚Äù\nInterpretation:¬†This is a direct statement of the relationship between effort and achievement.\n\n‚ÄúŸàŸÑŸÖ ÿ™ÿπÿ∑ŸÜŸä ÿßŸÑÿ£ŸäÿßŸÖ ŸÜŸàŸÖÿß ŸÖÿ≥ŸÉŸÜÿß ÿ£ŸÑÿ∞ ÿ®Ÿá ÿå ÿ•ŸÑÿß ÿ®ŸÜŸàŸÖ ŸÖÿ¥ÿ±ÿØ‚Äù\n\nTranslation:¬†‚ÄúThe days have not given me a comforting sleep more delicious than a scattered one.‚Äù\nInterpretation:¬†This beautifully evokes the idea that true rest is often earned by hard work and might not always be the most comfortable.\n\n‚ÄúŸà ÿßÿ∞ÿß ŸÉÿßŸÜÿ™ ÿßŸÑŸÜŸÅŸàÿ≥ ŸÉÿ®ÿßÿ±ÿß ÿ™ÿπÿ®ÿ™ ŸÅŸä ŸÖÿ±ÿßÿØŸáÿß ÿßŸÑÿ£ÿ¨ÿ≥ÿßŸÖ‚Äù\n\nTranslation:¬†‚ÄúIf the souls are great, the bodies will toil in pursuit of their desires.‚Äù\nInterpretation:¬†This highlights that ambitious goals require a commitment to hard work that will test the physical body.\n\n‚ÄúŸàŸÉÿ∞ŸÑŸÉ Ÿäÿ≠ÿ∞ÿ± ŸÖŸÜ ÿßŸÑÿ™ŸÜŸÇŸÑ ŸÖŸÜ ŸÉÿ™ÿßÿ® ÿßŸÑŸä ŸÉÿ™ÿßÿ® ŸÖŸÜ ÿ∫Ÿäÿ± ŸÖŸàÿ¨ÿ® ŸÅÿ•ŸÜŸá ÿπŸÑÿßŸÖÿ© ÿßŸÑÿ∂ÿ¨ÿ± ŸàÿπÿØŸÖ ÿßŸÑŸÅŸÑÿßÿ≠‚Äù\n\nTranslation:¬†‚ÄúLikewise, he warns against moving from book to book without a valid reason, for it is a sign of boredom and lack of success.‚Äù\nInterpretation:¬†This advises against haphazardly abandoning study materials, highlighting that deep learning comes from thorough exploration.\n\n‚ÄúŸàÿ•ŸÜ ŸÖŸÜ ÿßŸÑÿ≠ŸÉŸÖÿ© ÿ£ŸÜ ŸÖŸÜ ÿßÿ®ÿ™ÿØÿ£ ÿ®ÿπŸÖŸÑ Ÿàÿßÿ±ÿ™ÿßÿ≠ ŸÑŸá ŸÅŸÑŸäÿ≥ÿ™ŸÖÿ± ÿπŸÑŸäŸá ÿå ŸÅŸÖŸÜ ÿ®Ÿàÿ±ŸÉ ŸÑŸá ŸÅŸä ÿ¥ÿ¶ ŸÅŸÑŸäŸÑÿ≤ŸÖŸá ÿå Ÿàÿ®ÿπÿ∂ ÿßŸÑŸÜÿßÿ≥ Ÿäÿ®ÿØÿ£ ÿßŸÑÿ£ÿπŸÖÿßŸÑ Ÿà ŸÑÿß Ÿäÿ™ŸÖŸÖŸáÿß ÿå ŸÅŸäŸÖÿ∂Ÿä ÿπŸÑŸäŸá ÿßŸÑŸàŸÇÿ™ ÿ≥ÿ®ŸáŸÑŸÑÿß ŸÖŸÜ ÿ∫Ÿäÿ± ŸÅÿßÿ¶ÿØÿ© ŸÅŸÖÿ´ŸÑÿß ŸäŸÇÿ±ÿßÿ° ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑŸÉÿ™ÿßÿ® ÿßŸà Ÿáÿ∞ÿß ÿßŸÑŸÅŸÜ ÿå ÿ´ŸÖ ŸäÿØÿπŸá ŸÖŸÜ ÿ∫Ÿäÿ± ÿßŸÜ ŸäŸÉŸÖŸÑŸá ŸàŸäŸÜÿ™ŸÇŸÑ ÿßŸÑŸä ÿ∫Ÿäÿ±Ÿá ÿå ÿ´ŸÖ ÿßŸÑŸä ÿßÿÆÿ± ÿå ŸÖŸÜ ÿ∫Ÿäÿ± ÿ™ŸÉŸÖŸäŸÑ ÿßŸÑÿ£ŸàŸÑ ŸÅŸäÿ∂Ÿäÿπ ÿπŸÖŸÑŸá ŸàŸäŸÜŸÇÿ∂Ÿä ÿπŸÖÿ±Ÿá ÿ®ŸÑÿß ŸÅÿßÿ¶ÿØÿ© ÿå ŸàŸÉÿ∞ŸÑŸÉ ŸÅŸä ÿßŸÑÿ£ÿπŸÖÿßŸÑ ÿßŸÑÿßÿÆÿ±Ÿä ŸÉŸÑ ŸäŸàŸÖ ŸÑŸá ÿπŸÖŸÑ ŸàŸÉŸÑ ÿπŸÖŸÑ ŸÑŸá ÿ±ÿßŸä ŸÅŸäÿ∂Ÿäÿπ ÿßŸÑŸàŸÇÿ™ ÿπŸÑŸäŸá ŸÖŸÜ ÿ∫Ÿäÿ± ŸÅÿßÿ¶ÿØÿ©‚Äù - Translation:¬†‚ÄúAnd it is wisdom that whoever begins a work and finds comfort in it should continue with it. For whoever is blessed in something should stick to it. And some people begin tasks and do not complete them, so their time passes in vain without benefit. For example, they read in this book or this discipline and then leave it without completing it and move on to another and then another without completing the first, so they waste their work and their lives pass without benefit. And likewise in other works, each day has a work and each work has its own approach, so they waste time on that without benefit.‚Äù\n\nFor opensource project i have a lot of coold projects that i strated and will start soon but didn‚Äôt complete any one yet and i know when i finish one i will get a job easly but this is what happend."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#imam-al-nawawi",
    "href": "blog/posts/math/math_skills_for_AI.html#imam-al-nawawi",
    "title": "Math Skills For AI",
    "section": "Imam Al-Nawawi",
    "text": "Imam Al-Nawawi\nAl-Nawawi began his pursuit of knowledge relatively late, in the year 649 AH. He was, as he himself stated, 19 years old at that time. This was considered a late start compared to the custom of their time, where people would begin seeking knowledge before reaching puberty. As Al-Nawawi himself said, ‚ÄúWhen I was nineteen years old, my father brought me to Damascus in the year forty-nine, and I resided in the Rawahiyya School.‚Äù\nAl-Nawawi, may God have mercy on him, passed away in the year 676 AH, at the age of 45. Scholars in their forties typically begin to produce their most refined and meticulously researched scholarly work. Thus, the Sheikh, may God have mercy on him, did not live long.\nWell then‚Ä¶ when did the Sheikh begin writing and authoring? The Sheikh himself stated that he spent six years in the pursuit of knowledge, and then began authoring, i.e., he began authoring at the age of 25.\nAl-Nawawi also informed his student, Ibn al-Attar:\n‚ÄúHe mentioned to me, may God have mercy on him, that he did not waste any time, night or day, except in a task of engaging with knowledge. Even while walking on the streets, he would engage in reviewing what he had memorized or studying. He remained engaged in acquiring knowledge in this manner for about six years, and then he began writing.‚Äù\nThis means that most of Al-Nawawi‚Äôs works that we circulate today were authored during his twenties and thirties!\nAl-Isnawi explains: ‚ÄúThis phenomenon with Sheikh Muhi al-Din al-Nawawi was quite common. It is that, when he became qualified to study and acquire knowledge, he saw that it was part of his striving towards good deeds to make what he acquired and understood into an authorship, from which the reader could benefit. Thus, he made his authoring a means of acquiring knowledge, and his acquiring knowledge a means of authoring. Without this, he would not have been able to produce the amount of authorship he did. He entered Damascus to study when he was eighteen years old, and died before he reached forty-six.‚Äù\nAl-Isnawi‚Äôs point is that Al-Nawawi made his authoring a way to acquire and seek knowledge. He immediately put his seeking and acquiring of knowledge into the form of authorship, i.e., his notes during his pursuit of knowledge, he would convert them into a form of authorship, rather than allowing the notes of his youth to be wasted.\nWas this a coincidence for Al-Nawawi, or was it a conscious behavior? Meaning, did Al-Nawawi keep in mind the benefit of authorship in educating the author himself? In fact, there is a statement of Al-Nawawi in his other book,¬†Sharh al-Muhadhab, which reveals that his early attention to authorship was for the purposes of self-learning. In his introduction, where he explained the etiquette of a seeker of knowledge, Al-Nawawi stated:\n‚ÄúOne should pay attention to ‚Äòauthoring‚Äô when one is qualified for it, for through it one discovers the realities and subtleties of knowledge, and it becomes established in one‚Äôs mind. It forces one to engage in extensive searching, studying, investigating, and reviewing, and to become acquainted with the different opinions of the Imams, their agreements, what is clear, what is ambiguous, what is authentic, what is weak, what is eloquent, what is feeble, what is not subject to objection, and what is. Through this, a researcher takes on the qualities of a¬†mujtahid¬†(one who can exercise independent legal reasoning).‚Äù\nHere, Al-Nawawi is not just encouraging authoring, but he is revealing the motivations that drive authoring and expands on the effect it has on the advancement of the student‚Äôs understanding by obliging them to delve deeply.\nAlso, Al-Khatib Al-Baghdadi said: ‚ÄúWhoever wants to benefit, let them break the pen of copying and take up the pen of research.‚Äù\n\nAnd I‚Äôve noticed that a lot of prominent figures in Deep Learning (DL) are doing this. For example:\n\nMichael Lanham¬†(https://www.amazon.com/stores/author/B07BPS6WQL): The author of:\n\nEvolutionary Deep Learning\nPractical AI on the Google Platform\nLearn Python Game Development with ChatGPT\nand many other books.\n\nChristoph Molnar¬†(https://christophm.github.io/interpretable-ml-book/): The author of¬†Interpretable Machine Learning.\nChristopher M. Bishop¬†(https://www.amazon.com/stores/Christopher-M.-Bishop/author/B001IGLMNY?ref=ap_rdr&isDramIntegrated=true&shoppingPortalEnabled=true#): The author of the famous book,¬†Pattern Recognition and Machine Learning. He once mentioned that he wrote this book to ensure his own understanding of these concepts.\n\n‚Ä¶ and the list goes on.\nMy Approach: Building, Not Just Reading\nI don‚Äôt necessarily aspire to write a book, but rather to¬†recreate¬†knowledge from the sources I‚Äôve studied (books, courses, and papers). I don‚Äôt advocate for simply ‚Äúwriting a book‚Äù as a goal. Instead, I aim to create accessible pieces of knowledge that I can iterate on and use to help others understand these concepts.\nThis is my intended approach, and I will start with:\n\n‚ÄúBuilding DL from Scratch‚Äù Series:¬†Based on the fastai course and the¬†Deep Learning from Scratch¬†book.\n‚ÄúMath Level Up for DL‚Äù:¬†Based on multiple books, courses, and some experiments I want to conduct.\n\nThen, I will expand on these approaches in blog posts and other materials on topics like federated learning and other areas I‚Äôm interested in. I‚Äôll try my best to do all of this effectively."
  },
  {
    "objectID": "blog/posts/math/math_skills_for_AI.html#not-just-the-math",
    "href": "blog/posts/math/math_skills_for_AI.html#not-just-the-math",
    "title": "Math Skills For AI",
    "section": "NOT Just the Math",
    "text": "NOT Just the Math\nThis approach isn‚Äôt limited to math. It extends to every skill, including CSS, Deep Learning implementation with pure PyTorch code, and so on.\n‚Ä¶to be continued.\nyou can read:\n\nWhat is federated learning\nkam calorie"
  },
  {
    "objectID": "blog/posts/life_style/digital_minimalisim_arabic.html",
    "href": "blog/posts/life_style/digital_minimalisim_arabic.html",
    "title": "ŸÅŸÜ ÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ© ÿßŸÑÿ±ŸÇŸÖŸäÿ©",
    "section": "",
    "text": "ŸÑŸÖÿßÿ∞ÿß ŸÜŸÖÿØ ÿ£ŸäÿØŸäŸÜÿß ÿ®ÿ¥ŸÉŸÑ ÿ∫ÿ±Ÿäÿ≤Ÿä ÿ•ŸÑŸâ ŸáŸàÿßÿ™ŸÅŸÜÿß ÿÆŸÑÿßŸÑ ŸÑÿ≠ÿ∏ÿßÿ™ ÿßŸÑŸÖŸÑŸÑ ÿ£Ÿà ÿßŸÑŸÅÿ±ÿßÿ∫ÿü\nŸÑŸäÿ≥ ŸÖŸÜ ŸÇÿ®ŸäŸÑ ÿßŸÑÿµÿØŸÅÿ©. ÿ™ŸÖ ÿ™ÿµŸÖŸäŸÖ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÑÿ¨ÿ∞ÿ®ŸÜÿß ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâÿå ŸàÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿßŸÜÿ™ÿ®ÿßŸáŸÜÿß Ÿàÿ™ŸÇÿØŸäŸÖ ÿØŸÅÿπÿßÿ™ ŸÖŸÜ ÿßŸÑÿØŸàÿ®ÿßŸÖŸäŸÜ ÿ£ÿ´ŸÜÿßÿ° ÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸáÿß.\nŸàŸÖÿπ ÿ∞ŸÑŸÉÿå ŸÅÿ•ŸÜ ŸÖÿ¨ÿ±ÿØ ŸÖÿπÿ±ŸÅÿ© ÿ∞ŸÑŸÉ ŸÑÿß ŸäŸÖŸÜÿπŸÜÿß ŸÖŸÜ ÿ™ÿ¥ÿ™Ÿäÿ™ ÿßŸÜÿ™ÿ®ÿßŸáŸÜÿß.\nŸÅŸä Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÇÿßŸÑÿ©ÿå ÿ≥ÿ£ÿ¥ÿßÿ±ŸÉ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖŸÅŸäÿØÿ© ŸàÿßŸÑŸÜÿµÿßÿ¶ÿ≠ ÿßŸÑÿπŸÖŸÑŸäÿ© ŸÑŸÑÿ™ÿÆŸÑÿµ ŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿ£Ÿà ÿ™ŸÇŸÑŸäŸÑ ÿÆÿ∑ÿ±Ÿáÿß ÿ®ŸÇÿØÿ± ÿßŸÑÿ•ŸÖŸÉÿßŸÜ:\n1. ÿ£ŸàŸÇŸÅ ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™\n\nÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸáŸä ÿ®Ÿàÿßÿ®ÿ© ÿßŸÑŸÖÿ¥ÿ™ÿ™ÿßÿ™.\nŸÖÿπÿ∏ŸÖ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ÿ∫Ÿäÿ± ŸÖŸáŸÖÿ© ŸàŸÑŸÉŸÜŸáÿß ÿ™ÿÆŸÑŸÇ ÿ¥ÿπŸàÿ±Ÿãÿß ÿ≤ÿßÿ¶ŸÅŸãÿß ÿ®ÿßŸÑÿ•ŸÑÿ≠ÿßÿ≠.\nÿ®ÿØŸÑÿßŸã ŸÖŸÜ ŸÖÿ±ÿßÿ¨ÿπÿ© ÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸÉŸÑ ÿ™ÿ∑ÿ®ŸäŸÇ ÿπŸÑŸâ ÿ≠ÿØÿ©ÿå ŸÖŸÜ ÿßŸÑÿ£ÿ≥ŸáŸÑ ÿ™ÿ®ŸÜŸä ÿπŸÇŸÑŸäÿ© ÿ£ŸÜ ÿ¨ŸÖŸäÿπ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ŸÉŸàŸÜ ŸÖÿ™ŸàŸÇŸÅÿ© ÿ®ÿ¥ŸÉŸÑ ÿßŸÅÿ™ÿ±ÿßÿ∂Ÿä.\nÿ£ŸàŸÇŸÅ ÿ™ÿ¥ÿ∫ŸäŸÑ ŸÉŸÑ ÿ¥Ÿäÿ° ÿ£ŸàŸÑÿßŸãÿå ÿ´ŸÖ ŸÇŸÖ ÿ®ÿ™ŸÖŸÉŸäŸÜ ÿßŸÑÿ•ÿ¥ÿπÿßÿ±ÿßÿ™ ŸÅŸÇÿ∑ ŸÑŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÖÿ´ŸÑ ÿßŸÑŸÖÿ±ÿßÿ≥ŸÑÿ© ŸàÿßŸÑÿ™ŸÇŸàŸäŸÖ.\n\n2. ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿ£ŸäŸÇŸàŸÜÿßÿ™ ÿ≥ŸàÿØÿßÿ° ŸàŸÖÿµÿ∫ÿ±ÿ©\n\nÿ™ÿ£ÿ™Ÿä ŸÉÿßŸÅÿ© ÿßŸÑŸàÿßÿ¨Ÿáÿßÿ™ ÿ®ÿ£ŸäŸÇŸàŸÜÿßÿ™ ŸÉÿ®Ÿäÿ±ÿ© ŸàŸÖŸÑŸàŸÜÿ©ÿå ŸäŸÖŸÉŸÜŸÉ ŸÖÿπÿ±ŸÅÿ© ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿ®ŸÖÿ¨ÿ±ÿØ ÿßŸÑŸÑŸàŸÜ ŸÅŸÇÿ∑ÿå ŸÅÿßŸÑŸÑŸàŸÜ ÿßŸÑÿ£ÿµŸÅÿ± ŸáŸà ÿ™ÿ∑ÿ®ŸäŸÇ ÿ≥ŸÜÿßÿ® ÿ¥ÿßÿ™ ŸàÿßŸÑŸÑŸàŸÜ ÿßŸÑÿ®ŸÜŸÅÿ≥ÿ¨Ÿä ŸáŸà ÿßŸÑÿ•ŸÜÿ≥ÿ™ÿ¨ÿ±ÿßŸÖ.\nŸäŸÖŸÉŸÜŸÉ ŸÅÿ™ÿ≠ ŸÖÿ™ÿ¨ÿ± ÿßŸÑÿ´ŸäŸÖÿßÿ™ ÿßŸÑÿÆÿßÿµ ÿ®ÿ¨Ÿáÿßÿ≤ŸÉ ÿßŸÑÿ¥ÿÆÿµŸä Ÿàÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿ£ŸäŸÇŸàŸÜÿßÿ™ ŸÑŸÑŸàŸÜ ÿ´ÿßÿ®ÿ™ ŸàŸÖŸàÿ≠ÿØÿå ŸäŸÅÿ∂ŸÑ ÿ£ÿ≥ŸàÿØ ÿ£Ÿà ÿ±ŸÖÿßÿØŸä.\n\n3. ÿ£ÿ≤ŸÑ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÖŸÜ ÿßŸÑÿ¥ÿßÿ¥ÿ© ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©\n\nÿπŸÑŸâ ÿ∫ÿ±ÿßÿ± ÿ®Ÿäÿ¶ÿ™ŸÜÿß ÿßŸÑŸÖÿßÿØŸäÿ©ÿå ŸÅÿ•ŸÜ ŸÖÿß ŸáŸà ŸÖŸàÿ¨ŸàÿØ ÿπŸÑŸâ ÿ¥ÿßÿ¥ÿ™ŸÜÿß ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ© Ÿäÿµÿ®ÿ≠ ÿ•ÿ¥ÿßÿ±ÿßÿ™ ÿ™ÿ≠ŸÅÿ≤ ÿπÿßÿØÿßÿ™ŸÜÿß.\nÿπŸÜÿØŸÖÿß ÿ™ŸÉŸàŸÜ ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸàÿ≥ÿßÿ¶ÿ∑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿ© ŸÖÿ±ÿ¶Ÿäÿ© ÿ®ÿ¥ŸÉŸÑ ŸÉÿ®Ÿäÿ± ÿπŸÑŸâ ÿ¥ÿßÿ¥ÿ™ŸÉ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ©ÿå ŸÅŸÖŸÜ ÿßŸÑŸÖÿ±ÿ¨ÿ≠ ÿ£ŸÜ ÿ™ŸÅÿ™ÿ≠Ÿáÿß.\nŸÜŸàÿµŸä ÿ®ŸÜŸÇŸÑ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖÿ¥ÿ™ÿ™ÿ© ŸÑŸÑÿßŸÜÿ™ÿ®ÿßŸá ÿ•ŸÑŸâ ‚ÄúÿßŸÑÿÆŸÑŸÅ‚Äù.\nŸäŸÖŸÉŸÜ ŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ£ŸäŸÅŸàŸÜ ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÖŸÜ ÿßŸÑÿ¥ÿßÿ¥ÿ© ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ© Ÿàÿ™ÿÆÿ≤ŸäŸÜŸáÿß ŸÅŸä ŸÖŸÉÿ™ÿ®ÿ© ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ÿå ÿ®ŸäŸÜŸÖÿß ŸäŸÖŸÉŸÜ ŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖŸä ÿ£ŸÜÿØÿ±ŸàŸäÿØ ÿßŸÑÿßÿ≠ÿ™ŸÅÿßÿ∏ ÿ®ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ®ÿßŸÑŸÖÿ´ŸÑ ŸÅŸä ÿØÿ±ÿ¨ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™.\n\n4. ÿ¥ÿ∫ŸëŸÑ ŸÅŸÑÿ™ÿ± ÿßŸÑÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸä\n\nŸäŸÖŸÉŸÜ ÿ£ŸÜ Ÿäÿ§ÿØŸä ÿ™ÿ≠ŸàŸäŸÑ Ÿáÿßÿ™ŸÅŸÉ ÿ•ŸÑŸâ ÿßŸÑÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸä ÿ•ŸÑŸâ ÿ¨ÿπŸÑ ÿßŸÑÿ™ŸÖÿ±Ÿäÿ± ÿπÿ®ÿ± ÿßŸÑŸàÿ≥ÿßÿ¶ÿ∑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿ© ÿ£ŸÇŸÑ ÿ™ÿ¥ÿ™Ÿäÿ™Ÿãÿß ÿπŸÑŸâ ÿßŸÑŸÅŸàÿ±.\nŸÑŸÉŸÜŸÉ ŸÑÿ≥ÿ™ ŸÖÿ∂ÿ∑ÿ±Ÿãÿß ŸÑÿ•ÿ®ŸÇÿßÿ¶Ÿá ŸÇŸäÿØ ÿßŸÑÿ™ÿ¥ÿ∫ŸäŸÑ ÿ∑ŸàÿßŸÑ ÿßŸÑŸàŸÇÿ™.\nŸÜÿ≠ŸÜ ŸÜÿπŸÑŸÖ ŸÖÿØŸâ ŸÇŸàÿ© Ÿáÿ∞Ÿá ÿßŸÑÿ£ÿ¨Ÿáÿ≤ÿ© ÿßŸÑÿµÿ∫Ÿäÿ±ÿ© ŸÑŸÑÿπŸÖŸÑ ÿßŸÑÿ•ÿ®ÿØÿßÿπŸä ŸàÿßŸÑÿ™ÿ±ŸÅŸäŸá.\nŸÖÿß ŸÜŸàÿµŸä ÿ®Ÿá ŸáŸà Ÿàÿ¨ŸàÿØ ÿ∑ÿ±ŸäŸÇÿ© ÿ®ÿ≥Ÿäÿ∑ÿ© ŸÑÿ™ÿ¥ÿ∫ŸäŸÑ Ÿàÿ•ŸäŸÇÿßŸÅ ŸÅŸÑÿ™ÿ± ÿßŸÑÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸäÿå ŸÖÿ´ŸÑ ÿ•ÿ∂ÿßŸÅÿ™Ÿá ÿ•ŸÑŸâ ŸÖÿ±ŸÉÿ≤ ÿßŸÑÿ™ÿ≠ŸÉŸÖ ÿπŸÑŸâ ÿ£ÿ¨Ÿáÿ≤ÿ© iPhone.\n\n5. ÿÆÿØ ŸÜŸÅÿ≥ŸÉ - ÿ£ÿÆŸëÿ± ŸÅÿ™ÿ≠ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™\n\nŸÑÿ•ÿ∂ÿßŸÅÿ© ÿ™ÿ£ÿÆŸäÿ± ÿπŸÜÿØ ŸÅÿ™ÿ≠ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ÿå ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ™ÿ∑ÿ®ŸäŸÇ ŸÖÿ´ŸÑ: One Sec\nŸäŸÇÿØŸÖ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ŸàŸÇŸÅÿ© ŸÇÿµŸäÿ±ÿ© ŸÅŸä ŸÉŸÑ ŸÖÿ±ÿ© ÿ™ÿ≠ÿßŸàŸÑ ŸÅŸäŸáÿß ŸÅÿ™ÿ≠ ÿßŸÑŸàÿ≥ÿßÿ¶ÿ∑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿ© ÿ£Ÿà ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ£ÿÆÿ±Ÿâ ÿßŸÑŸÖÿ≠ÿØÿØÿ©.\nŸäÿπŸÖŸÑ ŸÉÿ≠ÿßÿ¨ÿ≤ ÿ¥ÿßÿ¥ÿ© ŸÖÿ§ŸÇÿ™ ÿ®ŸäŸÜŸÉ Ÿàÿ®ŸäŸÜ ÿßŸÑŸÖÿ¥ÿ™ÿ™ÿßÿ™ÿå ŸÖŸÖÿß Ÿäÿ≥ÿßÿπÿØŸÉ ÿπŸÑŸâ ÿ•ŸÖÿ≥ÿßŸÉ ŸÜŸÅÿ≥ŸÉ Ÿàÿ™ÿ≠ÿØŸäÿØ ŸÖÿß ÿ•ÿ∞ÿß ŸÉŸÜÿ™ ŸÖÿ¥ÿ™ÿ™Ÿãÿß ÿ£Ÿà ŸÖÿ™ÿπŸÖÿØŸãÿß.\nŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿπŸÑŸâ ÿßŸÑŸÖŸàÿ®ÿßŸäŸÑ ÿ£Ÿà ÿπŸÑŸâ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ®.\n\n\n\n\n\nOne Sec\n\n\n\n6. ÿßÿ≠ÿ∞ŸÅ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ∫Ÿäÿ± ÿßŸÑÿ∂ÿ±Ÿàÿ±Ÿäÿ©\n\nÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿ¥ÿ™ÿ™ ŸÑŸÑÿßŸÜÿ™ÿ®ÿßŸá ŸÑÿß Ÿäÿ∂ŸäŸÅ ÿ£Ÿä ŸÇŸäŸÖÿ© ÿ≠ŸÇŸäŸÇŸäÿ©ÿå ŸÅÿ•ŸÜ ÿßŸÑÿ≠ŸÑ ÿßŸÑÿ£ÿ®ÿ≥ÿ∑ ÿ∫ÿßŸÑÿ®Ÿãÿß ŸÖÿß ŸäŸÉŸàŸÜ ÿßŸÑÿ£ŸÅÿ∂ŸÑ.\nÿßÿ≠ÿ∞ŸÅŸá ŸÖŸÜ ÿ¨Ÿáÿßÿ≤ŸÉ ÿ™ŸÖÿßŸÖŸãÿß.\nÿ´ŸÖÿå ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸàŸÇÿ™ŸÉ ÿßŸÑÿ∞Ÿä ÿ™ŸÖ ÿ™ÿ≠ÿ±Ÿäÿ±Ÿá ÿ≠ÿØŸäÿ´Ÿãÿß ŸÅŸä ÿ£ŸÜÿ¥ÿ∑ÿ© ŸÖŸÅŸäÿØÿ©.\nŸÖŸÜ ÿßŸÑÿ™ÿ¨ÿßÿ±ÿ® ÿßŸÑŸÖÿ´Ÿäÿ±ÿ© ŸáŸä ÿ≠ÿ∞ŸÅ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸäŸàÿ™ŸäŸàÿ® ŸÖŸÜ ÿßŸÑŸÖŸàÿ®ÿßŸäŸÑ Ÿàÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸá ŸÖŸÜ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ÿå ÿ≥ŸäŸÇŸÑŸÑ Ÿáÿ∞ÿß ŸÖŸÜ ÿßŸÑÿßŸÜÿ∫ŸÖÿßÿ≥ ŸàŸäŸÅÿ∂ŸÑ ÿ≠ÿ∞ŸÅ ŸÉŸÑÿß ŸÖŸÜ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ ŸàÿßŸÑŸäŸàÿ™ŸäŸàÿ®!!\nŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ™ÿÆŸÑÿµ ŸÖŸÜ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸäŸàÿ™ŸäŸàÿ® ÿ®ÿßŸÑŸÉÿßŸÖŸÑ ÿπŸÑŸâ ŸÜÿ∏ÿßŸÖ ÿ£ŸÜÿØÿ±ŸàŸäÿØ ÿ®ÿØŸàŸÜ ÿπŸÖŸÑ ÿ±Ÿàÿ™ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Adb manager.\nŸàÿπŸÜÿØŸÖÿß ÿ™ÿ±ŸäÿØ ŸÖÿ¥ÿßŸáÿØÿ© ÿßŸÑŸäŸàÿ™ŸäŸàÿ® ÿ£Ÿà ÿ®ÿßŸÇŸä Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿå ŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ® ŸÅŸáŸà ÿ£ŸÇŸÑ ÿπÿ±ÿ∂ÿ© ŸÑŸÑÿ™ÿ¥ÿ™ÿ™ ŸàÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÅŸä ÿ£ŸàŸÇÿßÿ™ ŸÖÿ´ŸÑ ŸÇÿ®ŸÑ ÿßŸÑŸÜŸàŸÖ ÿ£Ÿà ŸÅŸä ÿ£ÿ´ŸÜÿßÿ° ÿßŸÑŸÖÿ±ÿ≠ÿßÿ∂ ÿ£Ÿà ÿ™ŸÜÿßŸàŸÑ ÿßŸÑÿ∑ÿπÿßŸÖ ŸÅŸä ÿßŸÑŸÖÿ∑ÿ®ÿÆ ŸÖÿ´ŸÑÿßŸã!\n\n7. ÿ£ÿπÿØ ÿ™ÿ¥ŸÉŸäŸÑ ÿπÿßŸÑŸÖŸÉ ŸÉŸÖÿß ÿ™ÿ±ŸäÿØ\n\nÿ•ÿ∞ÿß ŸÖÿß ÿ≤ŸÑÿ™ ÿ™ÿ±ŸäÿØ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ®ÿπÿ∂ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ÿå ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ™ÿ≠ŸÉŸÖ ŸÅŸä ŸÉŸäŸÅŸäÿ© ÿßŸÑÿπÿ±ÿ∂ ŸàŸÖÿßÿ∞ÿß ÿ™ÿ±ŸäÿØ ÿ£ŸÜ ÿ™ÿ±Ÿâ ŸàŸÖÿß ŸÑÿß ÿ™ÿ±ŸäÿØÿå ŸàÿßŸÑÿ™ŸàŸÇŸÅ ÿπŸÜ ÿßŸÑÿ™ÿ¥ÿ™ÿ™ ŸÖÿ´ŸÑÿßŸã.\nÿ®ÿπÿ∂ ÿ•ÿ∂ÿßŸÅÿßÿ™ ÿßŸÑŸÖÿ™ÿµŸÅÿ≠ ÿßŸÑÿ™Ÿä ÿ™ÿ≥ŸÖÿ≠ ŸÑŸÉ ÿ®ÿ™ÿπÿØŸäŸÑ ÿßŸÑŸÖŸàŸÇÿπ:\n\nMinimal theme for twitter: ÿ™ÿ≥ŸÖÿ≠ ŸÑŸÉ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿ•ÿπÿØÿßÿØ ÿπÿ±ÿ∂ ÿ™ŸàŸäÿ™ÿ± ÿßŸÑÿÆÿßÿµ ÿ®ŸÉ.\n\n\n\n\n\n\nMinimal Theme for Twitter\n\n\n\nUnhook\n\n\n\n\nEnhancer for Youtube - 1\n\n\n\nEnhancer for youtube\n\n\n\n\nEnhancer for Youtube - 2\n\n\n\n8. ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸàŸÇÿ™\n\nŸÖŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖŸÅŸäÿØÿ© ŸÑŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸàŸÇÿ™ ÿπŸÑŸâ ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ® ŸàÿßŸÑŸÖŸÅÿ™Ÿàÿ≠ÿ© ÿßŸÑŸÖÿµÿØÿ± ÿ£Ÿäÿ∂Ÿãÿß ŸáŸä: ActivitWatch\n\n\n\n\n\nActivity Watch Example\n\n\n\nŸáÿßÿ™ŸÅ ÿ∫ÿ®Ÿä\n\nŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ™ÿ∑ÿ®ŸäŸÇ\n\ndumb phone\n\nŸäÿ≥ÿßÿπÿØŸÉ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿπŸÑŸä ÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ±ŸäÿØ ŸÅÿ™ÿ≠Ÿáÿß ŸÅŸÇÿ∑ ŸàŸäŸÇŸàŸÖ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿßŸÑÿßŸäŸÇŸàŸÜÿ© ŸÑÿ™ÿµÿ®ÿ≠ ÿßÿ≥ŸÖ ŸÖÿ¨ÿ±ÿØ ŸÖŸÖÿß Ÿäÿ¨ÿπŸÑŸÉ ÿßŸÉÿ´ÿ± ŸàÿπŸäÿß ÿπŸÜÿØ ŸÖÿ≠ÿßŸàŸÑÿ™ŸÉ ŸÅÿ™ÿ≠ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ\nŸäŸÖŸÉŸÜŸÉ ÿ™ÿ¨ÿ±ÿ®ÿ©¬†ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸáÿßÿ™ŸÅ ÿßŸÑÿ∫ÿ®Ÿä¬†ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ™ŸÜÿ≤ŸäŸÑ ÿ£ÿØŸÜÿßŸá.\n\n\n\ndumb phone\n\n\n\n\n\ndumb phone example\n\n\n\n\n\nreview of dumb phone\n\n\n\n\nŸÖÿ±ÿßÿ¨ÿπ\n\nŸÖÿ≥ŸÑŸÉŸäÿßÿ™\nÿπŸÖŸÑ ÿπŸÖŸäŸÇ\nÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ© ÿßŸÑÿ±ŸÇŸÖŸäÿ©\nŸÅŸÜ ÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ©"
  },
  {
    "objectID": "blog/posts/life_style/protienai.html",
    "href": "blog/posts/life_style/protienai.html",
    "title": "ÿßŸÅÿ∂ŸÑ ÿßŸÜŸàÿßÿπ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™",
    "section": "",
    "text": "ÿ£ŸÅÿ∂ŸÑ ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸàÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑŸÑÿ™ÿ∂ÿÆŸäŸÖ ŸÖŸÜ ŸÖŸàŸÇÿπ Proteinai\nŸáŸÑ ÿ™ÿ®ÿ≠ÿ´ ÿπŸÜ ÿ£ŸÅÿ∂ŸÑ ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸàÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ Ÿàÿ™ÿ≠ŸÇŸäŸÇ ŸÜÿ™ÿßÿ¶ÿ¨ ŸÖÿ∞ŸáŸÑÿ© ŸÅŸä ÿßŸÑÿ™ÿ∂ÿÆŸäŸÖÿü ŸÖŸàŸÇÿπ ŸÖÿ≥ÿßÿ≠ŸäŸÇ ŸÉÿ±Ÿäÿßÿ™ŸäŸÜ Ÿà ÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ ŸáŸà ÿßŸÑŸàÿ¨Ÿáÿ© ÿßŸÑŸÖÿ´ÿßŸÑŸäÿ© ÿßŸÑÿ™Ÿä ÿ™ŸàŸÅÿ± ŸÑŸÉ ÿ¨ŸÖŸäÿπ ÿßŸÑŸÖŸàÿßÿ±ÿØ ŸàÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÑÿßÿ≤ŸÖÿ© ŸÑÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑŸÖŸÉŸÖŸÑÿßÿ™ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ© ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ© ŸÑÿ™ÿ≠ŸÇŸäŸÇ ÿ£ŸáÿØÿßŸÅŸÉ."
  },
  {
    "objectID": "blog/posts/life_style/protienai.html#ŸÖÿß-ÿßŸÑÿ∞Ÿä-Ÿäÿ¨ÿπŸÑ-ŸÖŸàŸÇÿπ-proteinai-ŸÖŸÖŸäÿ≤ÿß",
    "href": "blog/posts/life_style/protienai.html#ŸÖÿß-ÿßŸÑÿ∞Ÿä-Ÿäÿ¨ÿπŸÑ-ŸÖŸàŸÇÿπ-proteinai-ŸÖŸÖŸäÿ≤ÿß",
    "title": "ÿßŸÅÿ∂ŸÑ ÿßŸÜŸàÿßÿπ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™",
    "section": "ŸÖÿß ÿßŸÑÿ∞Ÿä Ÿäÿ¨ÿπŸÑ ŸÖŸàŸÇÿπ Proteinai ŸÖŸÖŸäÿ≤Ÿãÿßÿü",
    "text": "ŸÖÿß ÿßŸÑÿ∞Ÿä Ÿäÿ¨ÿπŸÑ ŸÖŸàŸÇÿπ Proteinai ŸÖŸÖŸäÿ≤Ÿãÿßÿü\n\n1. ŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ŸÖÿ™ÿÆÿµÿµÿ© ŸàŸÖŸÇÿßÿ±ŸÜÿßÿ™ ÿ¥ÿßŸÖŸÑÿ©\nŸäŸÇÿØŸÖ ŸÖŸàŸÇÿπ ŸÖÿ≥ÿßÿ≠ŸäŸÇ ŸÉÿ±Ÿäÿßÿ™ŸäŸÜ Ÿà ÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ ŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ÿØŸÇŸäŸÇÿ© ŸàŸÖÿ≥ÿ™ŸÇŸÑÿ© ŸÑÿ£ÿ¥Ÿáÿ± ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸàÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÅŸä ÿßŸÑÿ≥ŸàŸÇ. ŸÖŸÜ ÿ®ŸäŸÜ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿßŸÑÿ™Ÿä Ÿäÿ∫ÿ∑ŸäŸáÿß ÿßŸÑŸÖŸàŸÇÿπ:\n\nÿ±ŸäÿØÿ±ŸäŸÉÿ≥ ÿ®Ÿäÿ¨ ÿ±ÿßŸÖŸä ŸÑÿßÿ®ÿ≥\nRival Nutrition - Rival Whey\nMuscleTech - Nitro Tech Ripped\nDymatize - ISO100\n\nÿ™ÿ≥ÿßÿπÿØŸÉ ÿßŸÑŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ÿπŸÑŸâ ŸÅŸáŸÖ ÿßŸÑŸÖÿ≤ÿßŸäÿß ŸàÿßŸÑÿπŸäŸàÿ® ŸÑŸÉŸÑ ŸÖŸÜÿ™ÿ¨ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸâ ÿßŸÑÿ≥ÿπÿ±ÿå ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿå ÿßŸÑŸÖŸÉŸàŸÜÿßÿ™ÿå ŸàÿßŸÑŸÅÿπÿßŸÑŸäÿ©. ÿ®ÿßŸÑÿ•ÿ∂ÿßŸÅÿ© ÿ•ŸÑŸâ ÿ∞ŸÑŸÉÿå ŸäŸàŸÅÿ± ÿßŸÑŸÖŸàŸÇÿπ ÿÆÿßÿµŸäÿ© ÿßŸÑŸÖŸÇÿßÿ±ŸÜÿßÿ™ ÿ¨ŸÜÿ®Ÿãÿß ÿ•ŸÑŸâ ÿ¨ŸÜÿ® ŸÑÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿ£ŸÜÿ≥ÿ®.\n\n\n2. ÿ™ÿµŸÜŸäŸÅÿßÿ™ ŸÖÿ®ÿ≥ÿ∑ÿ© ŸÑÿ≥ŸáŸàŸÑÿ© ÿßŸÑÿßÿÆÿ™Ÿäÿßÿ±\nŸäÿ≥ŸáŸëŸÑ ÿßŸÑŸÖŸàŸÇÿπ ÿπŸÖŸÑŸäÿ© ÿßŸÑÿ®ÿ≠ÿ´ ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ™ŸÜÿ∏ŸäŸÖ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿ∂ŸÖŸÜ ŸÅÿ¶ÿßÿ™ ŸÖÿ≠ÿØÿØÿ© ÿ™ŸÜÿßÿ≥ÿ® ÿßÿ≠ÿ™Ÿäÿßÿ¨ÿßÿ™ŸÉÿå ŸÖÿ´ŸÑ:\n\nÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ (ÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ)\nÿ•ŸÜŸÇÿßÿµ ÿßŸÑŸàÿ≤ŸÜ (ÿßŸÑÿ™ŸÜÿ¥ŸäŸÅ)\nÿßŸÑÿ™ÿπÿßŸÅŸä ÿßŸÑÿπÿ∂ŸÑŸä\nÿßÿ≥ÿ™ÿ®ÿØÿßŸÑ ÿßŸÑŸàÿ¨ÿ®ÿßÿ™\nÿÆÿßŸÑŸä ŸÖŸÜ ÿßŸÑÿ∫ŸÑŸàÿ™ŸäŸÜ\nŸÜÿ®ÿßÿ™Ÿä\nÿπÿ∂ŸàŸä\n\n\n\n3. ÿ£ÿØŸàÿßÿ™ ŸàŸÖŸàÿßÿ±ÿØ ÿ™ÿπŸÑŸäŸÖŸäÿ©\nÿ•ŸÑŸâ ÿ¨ÿßŸÜÿ® ÿßŸÑŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ŸàÿßŸÑŸÖŸÇÿßÿ±ŸÜÿßÿ™ÿå ŸäŸÇÿØŸÖ ÿßŸÑŸÖŸàŸÇÿπ ŸÖÿ¨ŸÖŸàÿπÿ© ŸÖŸÜ ÿßŸÑÿ£ÿØŸàÿßÿ™ ŸàÿßŸÑŸÖŸàÿßÿ±ÿØ ŸÑŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ÿπŸÑŸâ ÿßÿ™ÿÆÿßÿ∞ ŸÇÿ±ÿßÿ±ÿßÿ™ ŸÖÿØÿ±Ÿàÿ≥ÿ©:\n\nÿØŸÑŸäŸÑ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ: ŸäŸàŸÅÿ± ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ¥ÿßŸÖŸÑÿ© ÿ≠ŸàŸÑ ÿ£ŸÜŸàÿßÿπ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ©ÿå ŸÅŸàÿßÿ¶ÿØŸáÿßÿå ŸàŸÖÿ™Ÿâ Ÿäÿ¨ÿ® ÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸáÿß.\nŸÇÿßÿπÿØÿ© ÿßŸÑŸÖÿπÿ±ŸÅÿ©: ÿ™ÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿ¥ÿ±ÿ≠ ŸàÿßŸÅŸç ŸÑŸÑŸÖŸÉŸàŸÜÿßÿ™ ÿßŸÑÿ¥ÿßÿ¶ÿπÿ© ŸÅŸä ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸàÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ.\nÿ£ÿ≠ÿØÿ´ ÿßŸÑÿ£ÿÆÿ®ÿßÿ± ŸàÿßŸÑŸÖŸÇÿßŸÑÿßÿ™: ÿ™ÿ®ŸÇŸäŸÉ ÿπŸÑŸâ ÿßÿ∑ŸÑÿßÿπ ÿØÿßÿ¶ŸÖ ÿ®ÿ£ÿ≠ÿØÿ´ ÿßŸÑÿ™ÿ∑Ÿàÿ±ÿßÿ™ ŸÅŸä ŸÖÿ¨ÿßŸÑ ÿßŸÑŸÖŸÉŸÖŸÑÿßÿ™ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ©."
  },
  {
    "objectID": "blog/posts/life_style/protienai.html#ŸÑŸÖÿßÿ∞ÿß-ÿ™ÿÆÿ™ÿßÿ±-proteinai",
    "href": "blog/posts/life_style/protienai.html#ŸÑŸÖÿßÿ∞ÿß-ÿ™ÿÆÿ™ÿßÿ±-proteinai",
    "title": "ÿßŸÅÿ∂ŸÑ ÿßŸÜŸàÿßÿπ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™",
    "section": "ŸÑŸÖÿßÿ∞ÿß ÿ™ÿÆÿ™ÿßÿ± Proteinaiÿü",
    "text": "ŸÑŸÖÿßÿ∞ÿß ÿ™ÿÆÿ™ÿßÿ± Proteinaiÿü\n\nÿ¥ŸÅÿßŸÅŸäÿ© ŸÉÿßŸÖŸÑÿ©: ŸäŸÇÿØŸÖ ÿßŸÑŸÖŸàŸÇÿπ ŸÖÿ±ÿßÿ¨ÿπÿßÿ™ ÿØŸÇŸäŸÇÿ© ÿ∫Ÿäÿ± ŸÖÿ™ÿ≠Ÿäÿ≤ÿ©.\nÿ≥ŸáŸàŸÑÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ: ÿ™ÿµŸÖŸäŸÖ ÿ®ÿ≥Ÿäÿ∑ ŸàŸàÿßÿ¨Ÿáÿ© ŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÖÿ±Ÿäÿ≠ÿ©.\nÿ™ŸÜŸàÿπ ÿßŸÑÿÆŸäÿßÿ±ÿßÿ™: ÿ™ÿ∫ÿ∑Ÿäÿ© ÿ¥ÿßŸÖŸÑÿ© ŸÑÿ£ŸÅÿ∂ŸÑ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ŸÅŸä ÿßŸÑÿ≥ŸàŸÇ.\n\nÿßÿ≥ÿ™ŸÅÿØ ÿßŸÑÿ¢ŸÜ ŸÖŸÜ ŸÖŸàŸÇÿπ ŸÖÿ≥ÿßÿ≠ŸäŸÇ ŸÉÿ±Ÿäÿßÿ™ŸäŸÜ Ÿà ÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™ ŸàÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ ŸÑÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑŸÖŸÉŸÖŸÑ ÿßŸÑŸÖÿ´ÿßŸÑŸä ŸÑÿ™ÿ≠ŸÇŸäŸÇ ÿ£ŸáÿØÿßŸÅŸÉ ÿßŸÑÿ±Ÿäÿßÿ∂Ÿäÿ© ŸàÿßŸÑÿµÿ≠Ÿäÿ©.\nŸäŸÖŸÉŸÜŸÉ ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÖŸàŸÇÿπ ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÑŸÖÿπÿ±ŸÅÿ© ŸÉÿßŸÅÿ© ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© ÿßŸäÿ∂ÿß: 1. ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ÿ®ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä"
  },
  {
    "objectID": "blog/posts/life_style/kamcalorie.html",
    "href": "blog/posts/life_style/kamcalorie.html",
    "title": "ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑÿ∑ÿπÿßŸÖ ÿü",
    "section": "",
    "text": "ŸÖŸàŸÇÿπ ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸáŸà ÿØŸÑŸäŸÑ ÿßŸÑŸÇÿßÿ±ÿ¶ ÿßŸÑÿπÿ±ÿ®Ÿä ÿßŸÑŸä ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© ŸÅŸä ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿ∑ÿπŸÖÿ© ÿ®ŸÖÿÆÿ™ŸÑŸÅ ÿßŸÑÿ®ŸÑÿØÿßŸÜ ŸàÿßŸÑŸÑŸáÿ¨ÿßÿ™ ÿå ÿØŸÑŸäŸÑŸÉ ŸÑŸÖÿπÿ±ŸÅÿ© ÿßŸÑŸÇŸäŸÖÿ© ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ© ŸÑŸáÿß ŸÖÿ´ŸÑ ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© Ÿà ÿßŸÑŸÖÿπÿßÿØŸÜ ŸàŸÜÿ≥ÿ® ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ Ÿà ÿßŸÑÿ≥ŸÉÿ±Ÿäÿßÿ™ ŸÑÿ≠ŸÖŸäÿ© ÿµÿ≠Ÿäÿ© Ÿà ŸÜÿ∏ÿßŸÖ ÿ∫ÿ∞ÿßÿ¶Ÿä ÿ£ŸÅÿ∂ŸÑ ÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ° ŸÖŸÜÿµÿ© ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ÿ®ŸáÿØŸÅ ÿ™ŸàŸÅŸäÿ±ŸÖÿµÿØÿ± ŸÖŸàÿ´ŸàŸÇ Ÿà ÿØŸÇŸäŸÇ ŸÑŸÑŸÇÿßÿ±ÿ¶ ÿßŸÑÿπÿ±ÿ®Ÿä ÿ®ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä"
  },
  {
    "objectID": "blog/posts/life_style/kamcalorie.html#ŸÉŸÖ-ŸÉÿßŸÑŸàÿ±Ÿä",
    "href": "blog/posts/life_style/kamcalorie.html#ŸÉŸÖ-ŸÉÿßŸÑŸàÿ±Ÿä",
    "title": "ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑÿ∑ÿπÿßŸÖ ÿü",
    "section": "",
    "text": "ŸÖŸàŸÇÿπ ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸáŸà ÿØŸÑŸäŸÑ ÿßŸÑŸÇÿßÿ±ÿ¶ ÿßŸÑÿπÿ±ÿ®Ÿä ÿßŸÑŸä ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© ŸÅŸä ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿ∑ÿπŸÖÿ© ÿ®ŸÖÿÆÿ™ŸÑŸÅ ÿßŸÑÿ®ŸÑÿØÿßŸÜ ŸàÿßŸÑŸÑŸáÿ¨ÿßÿ™ ÿå ÿØŸÑŸäŸÑŸÉ ŸÑŸÖÿπÿ±ŸÅÿ© ÿßŸÑŸÇŸäŸÖÿ© ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ© ŸÑŸáÿß ŸÖÿ´ŸÑ ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© Ÿà ÿßŸÑŸÖÿπÿßÿØŸÜ ŸàŸÜÿ≥ÿ® ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ Ÿà ÿßŸÑÿ≥ŸÉÿ±Ÿäÿßÿ™ ŸÑÿ≠ŸÖŸäÿ© ÿµÿ≠Ÿäÿ© Ÿà ŸÜÿ∏ÿßŸÖ ÿ∫ÿ∞ÿßÿ¶Ÿä ÿ£ŸÅÿ∂ŸÑ ÿ™ŸÖ ÿ•ŸÜÿ¥ÿßÿ° ŸÖŸÜÿµÿ© ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ÿ®ŸáÿØŸÅ ÿ™ŸàŸÅŸäÿ±ŸÖÿµÿØÿ± ŸÖŸàÿ´ŸàŸÇ Ÿà ÿØŸÇŸäŸÇ ŸÑŸÑŸÇÿßÿ±ÿ¶ ÿßŸÑÿπÿ±ÿ®Ÿä ÿ®ÿ™ŸÇŸÜŸäÿßÿ™ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä"
  },
  {
    "objectID": "blog/posts/life_style/kamcalorie.html#ŸÖŸÖŸäÿ≤ÿßÿ™-ÿßŸÑŸÖŸàŸÇÿπ",
    "href": "blog/posts/life_style/kamcalorie.html#ŸÖŸÖŸäÿ≤ÿßÿ™-ÿßŸÑŸÖŸàŸÇÿπ",
    "title": "ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑÿ∑ÿπÿßŸÖ ÿü",
    "section": "ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑŸÖŸàŸÇÿπ",
    "text": "ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑŸÖŸàŸÇÿπ\nÿßŸÑŸÖŸàŸÇÿπ ŸÖÿ®ŸÜŸä ÿ®ŸáÿØŸÅ ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ™ŸÇŸÜŸäÿßÿ™ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÑÿ∫ÿßÿ™ ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ŸàÿßŸÑŸÜŸÖÿßÿ∞ÿ¨ ÿßŸÑŸÑÿ∫ŸàŸäÿ© ŸÑÿ™ŸàŸÅŸäÿ± ŸÉÿßŸÅÿ© ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™Ÿä ŸÇÿØ Ÿäÿ≠ÿ™ÿßÿ¨Ÿáÿß ÿßŸÑŸÅÿ±ÿØ ŸÖÿ´ŸÑ: 1. ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿ∞ŸÉŸä : ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑŸÖÿπŸÜŸä ÿ≥Ÿàÿßÿ° ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ£Ÿà ÿßŸÑÿ•ŸÜÿ¨ŸäŸÑŸäÿ≤Ÿäÿ© Ÿàÿ≠ÿ™Ÿä ŸÉÿßŸÅÿ© ÿßŸÑŸÑÿ∫ÿßÿ™ Ÿà ŸäŸÖŸÉŸÜŸÉ ÿßŸÑÿ®ÿ≠ÿ´ ÿ®ÿßŸä ÿ∑ÿ±ŸäŸÇÿ© ÿ≥Ÿàÿßÿ° ŸÑÿ∫ÿ© ÿπÿ±ÿ®Ÿäÿ© ŸÅÿµÿ≠Ÿäÿ© ÿßŸà ÿßŸÑÿπÿßŸÖŸäÿ© ÿßŸà ÿ≠ÿ™Ÿä ÿ£ÿÆÿ∑ÿßÿ° ÿ•ŸÖŸÑÿßÿ¶Ÿäÿ© 2. ÿ≥ÿ±ÿπÿ© ŸÅŸä ÿ•ÿ≥ÿ™ÿ±ÿßÿ¨ÿßÿπ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ Ÿàÿπÿ±ÿ∂Ÿáÿß ŸÅŸä ÿ¥ŸÉŸÑ ÿ®ŸäÿßŸÜŸä ŸÖŸÖŸäÿ≤ Ÿäÿ≥ŸÖÿ≠ ŸÑŸÉ ÿ®ŸÖÿπÿ±ŸÅÿ© ÿßŸÑŸÖŸáŸÖ ŸÅŸä ŸàŸÇÿ™ ŸÅŸàÿ±Ÿä 3. ŸäŸÖŸÉŸÜŸÉ ÿ•ÿØÿÆÿßŸÑ ŸÖÿß ÿ£ŸÉŸÑ ÿ®ÿ¥ŸÉŸÑ ŸÉÿßŸÖŸÑ Ÿà ÿßŸÑŸÖŸàŸÇÿπ ŸäŸÇŸàŸÖ ÿ®ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿ™ŸÇÿØŸäÿ±ÿßÿ™ ÿßŸÑŸÑÿßÿ≤ŸÖÿ© ŸÑŸÉ\n\n\n\nŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä"
  },
  {
    "objectID": "blog/posts/life_style/kamcalorie.html#ÿÆÿßÿ™ŸÖÿ©",
    "href": "blog/posts/life_style/kamcalorie.html#ÿÆÿßÿ™ŸÖÿ©",
    "title": "ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑÿ∑ÿπÿßŸÖ ÿü",
    "section": "ÿÆÿßÿ™ŸÖÿ©",
    "text": "ÿÆÿßÿ™ŸÖÿ©\nŸäÿπÿ™ÿ®ÿ± ŸÖŸàŸÇÿπ ŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ÿ®ÿØÿßŸäÿ© ÿßŸÑŸä ÿ≥ŸÑÿ≥ŸÑÿ© ŸÖŸÖŸÜ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ≥ŸáŸÑ ÿπŸÑŸä ÿßŸÑŸÜÿßÿ∑ŸÇŸäŸÜ ÿ®ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÖŸÖÿßÿ±ÿ≥ÿ© ÿßŸÑÿ±Ÿäÿßÿ∂ÿ© Ÿà ŸÑÿπŸäÿ¥ ÿ≠Ÿäÿßÿ© ÿ£ŸÅÿ∂ŸÑ Ÿà ŸáŸÜÿßŸÉ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÇÿßÿØŸÖ ŸÖÿ´ŸÑ : 1. ŸÉŸàÿ® ÿ®ÿ±Ÿàÿ™ŸäŸÜ 2. ÿπÿ∂ŸÑÿßÿ™Ÿä\nŸÇÿßŸÖ ÿ®ÿ™ÿ∑ŸàŸäÿ± Ÿà ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑŸÖŸàŸÇÿπ ÿπÿ®ÿØ ÿßŸÑŸÉÿ±ŸäŸÖ ÿßŸÑÿÆÿ∑Ÿäÿ® ÿ®ÿßÿ≠ÿ´ ŸÅŸä ÿπŸÑŸàŸÖ ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä Ÿà ŸÖŸáÿ™ŸÖ ÿ®ÿßÿ´ÿ±ÿßÿ° ÿßŸÑŸÖÿ≠ÿ™ŸàŸä ÿßŸÑÿπÿ±ÿ®Ÿä"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html",
    "href": "blog/posts/life_style/fake_graviety.html",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "",
    "text": "target\n\n\nÿ£ÿ≠ÿØ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ£ŸÇŸàŸÖ ÿ®Ÿáÿß ŸÅŸä ÿ®ÿπÿ∂ ÿßŸÑÿ£ÿ≠ŸäÿßŸÜ ŸáŸä ŸÖÿ±ÿßŸÇÿ®ÿ© ŸÖÿµÿßÿØÿ± ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿßŸÑÿ™Ÿä ÿ™ÿ£ÿ™ŸäŸÜŸä ŸàÿßŸÑŸÖÿ≠ŸÅÿ≤ÿßÿ™ ŸÑŸáÿß Ÿàÿ™ÿ™ÿ®ÿπ ÿ£ÿ´ÿ± ÿ™ŸÑŸÉ ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿπŸÑŸä ÿ£ŸÅÿπÿßŸÑŸä ŸàŸÖÿ¥ÿßÿπÿ±Ÿä ÿå Ÿäÿπÿ™ÿ®ÿ±Ÿáÿß ÿßŸÑÿ®ÿπÿ∂ ÿ™ŸÅŸÉŸäÿ± ÿ≤ÿßÿ¶ÿØ Ÿàÿ£ÿπÿ™ÿ®ÿ±Ÿáÿß ÿ£ŸÜÿß ŸÜÿπŸÖÿ© ÿ™ŸÜŸÇÿ∞ŸÜŸä ÿ£ÿ≠ŸäÿßŸÜÿß ŸÖŸÜ ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÅ ŸÅŸä ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖŸáÿßŸÖ ŸàÿßŸÑÿ•ÿ≥ÿ™ŸäŸÇÿßÿ∏ ŸÖÿ™ÿßÿÆÿ±ÿß ŸÜÿ≥ÿ®Ÿäÿß.\nÿ®ÿØÿ£ÿ™ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÅŸä ÿßŸÑÿ∏ŸáŸàÿ± ŸÅŸä ÿßŸÑÿ≥ŸÜÿ© ÿßŸÑÿ£ŸàŸÑŸä ÿßŸÑÿ¨ÿßŸÖÿπŸäÿ© ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿ®ÿØÿßŸäÿ© ÿßŸÑÿ™Ÿä Ÿäÿ≠ÿßŸàŸÑ ŸÉŸÑ ÿ¥ÿÆÿµ ÿ£ŸÜ Ÿäÿ∏Ÿáÿ± ŸÖŸáÿßÿ±ÿßÿ™Ÿá ŸàŸÇÿØÿ±ÿßÿ™Ÿá ŸàŸäÿ´ÿ®ÿ™ ŸÜŸÅÿ≥Ÿá ŸàŸäÿ≠ÿßŸàŸÑ ÿ•ÿ´ÿßÿ±ÿ© ÿ•ÿπÿ¨ÿßÿ® ÿßŸÑÿ£ÿÆÿ±ŸäŸÜ Ÿàÿ™ŸÜÿ¥ÿßÿ°ÿ© ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ŸÖÿπ ÿ£ŸÜÿßÿ≥ ŸÖŸÜ ŸÉÿßŸÅÿ© ÿßŸÑŸÖÿ≠ÿßŸÅÿ∏ÿßÿ™ ÿ∞ŸÑŸÉ ÿßŸÑÿØÿÆŸàŸÑ ÿßŸÑŸÖŸÅÿßÿ¨ÿ¶ ŸàÿßŸÑŸÉÿ´ŸäŸÅ ŸÉÿßŸÜ ŸÑŸá ÿ£ÿ´ÿ± ŸÜŸÅÿ≥Ÿä ÿ≥ÿ¶.\nŸÖÿ´ŸÑ ÿ™ÿ∫Ÿäÿ± ÿßŸÑÿßŸáÿ™ŸÖÿßŸÖÿßÿ™ ÿπŸÑŸä ÿßŸÑŸÖÿ≥ÿ™ŸàŸä ÿßŸÑÿ¥ÿÆÿµ ŸàÿßŸÑŸÖÿπÿ±ŸÅŸä Ÿà ÿßŸÑÿØÿÆŸàŸÑ ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ÿßŸÑŸÉÿ´Ÿäÿ±Ÿá ÿ®ÿØÿ£ÿ™ ÿßŸÑÿ£ŸáÿØÿßŸÅ ÿßŸÑŸÖÿ±ŸÉÿ≤Ÿäÿ© ÿßŸÑÿ™Ÿä ŸÉŸÜÿ™ ÿ£ÿ≠ŸÑŸÖ ÿ®Ÿáÿß Ÿà ÿ£ŸÅŸÉÿßÿ±Ÿä ŸàŸÖÿ®ÿßÿØÿ¶ ÿ®ÿßŸÑÿ™ÿ¥ÿ™ÿ™ ŸàÿßŸÑÿ™ÿ£ÿ´ÿ± ÿ®ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÉŸÑ ÿ¥ÿÆÿµ ÿ™ÿπÿ±ŸÅÿ™ ÿπŸÑŸäŸá Ÿàÿµÿßÿ± ÿ®ŸäŸÜŸä Ÿàÿ®ŸäŸÜŸá ÿπŸÑÿßŸÇÿ© ÿ≤ŸÖÿßŸÑÿ© ÿ®ŸÑ Ÿàÿ≠ÿ™Ÿä ŸÖÿ¨ÿ±ÿØ ÿ±ÿ§Ÿäÿ© ÿµŸÅÿ≠ÿ™Ÿá ÿπŸÑŸä Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ŸÉŸÑ Ÿáÿ∞ÿß ÿ∑ÿ®ŸäÿπŸä Ÿà ŸÖŸÅŸáŸàŸÖ.\nÿ®ÿπÿØ ŸÖÿ≠ÿßŸàŸÑ ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸäŸàŸÖŸä ŸàÿßŸäŸÜ Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ŸÜÿßŸÅÿ≤Ÿá Ÿàÿ£ŸäŸÜ ÿ™ÿ≥ŸÜÿ≤ŸÅ ÿ£ŸÅŸÉÿßÿ±Ÿä Ÿà ŸÖÿÆÿ≤ŸàŸÜ ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ŸÑÿØŸä Ÿàÿ¨ÿØÿ™ ÿ£ŸÜŸä ÿ£ÿ∞Ÿáÿ® ŸÑŸÜÿ¥ÿ± ÿ®Ÿäÿ™ ÿßŸÑÿ¥ÿπÿ± Ÿáÿ∞ÿß Ÿàÿ™ŸÑŸäÿÆÿµ ÿßŸÑŸÉÿ™ÿßÿ® ÿ∞ÿßŸÉ ŸÑÿ£ŸÜÿ™ÿ∏ÿ± ÿ±ÿØ ŸÅÿπŸÑ ŸÅŸÑÿßŸÜ ŸàÿπŸÑÿßŸÜ Ÿà ÿßŸÜÿ∫ŸÖÿßÿ≥Ÿä ŸÅŸä ÿßŸÑÿ±ÿØŸàÿØ ÿπŸÑŸä ŸÖŸÜÿ¥Ÿàÿ±ÿßÿ™ŸáŸÖ Ÿàÿ™ÿ™ÿ®ÿπ ÿ£ÿÆÿ®ÿßÿ±ŸáŸÖ Ÿà ÿ™ÿ∂ÿÆŸÖ ÿ∑ŸÅŸäŸÑŸäŸä ÿßŸÑŸÅÿ∂ŸàŸÑ ÿπŸÜÿØŸä ÿ®ÿ¥ŸÉŸÑ ŸÖÿ®ÿßŸÑÿ∫ ŸÅŸäŸá ŸÖŸÖÿß ÿ£ÿµÿ®ÿ≠ Ÿäÿ≥ÿ®ÿ® ŸÇŸÑŸÇ Ÿàÿ≠Ÿäÿ±ÿ© Ÿàÿ™ÿ¥ÿ™ÿ™ ŸàŸÖŸÇÿßÿ±ÿßŸÜÿßÿ™ Ÿà Ÿàÿ∂Ÿäÿßÿπ ÿ£ÿπŸÖÿßÿ±."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ®ÿØÿßŸäÿ©",
    "href": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ®ÿØÿßŸäÿ©",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "",
    "text": "target\n\n\nÿ£ÿ≠ÿØ ÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ£ŸÇŸàŸÖ ÿ®Ÿáÿß ŸÅŸä ÿ®ÿπÿ∂ ÿßŸÑÿ£ÿ≠ŸäÿßŸÜ ŸáŸä ŸÖÿ±ÿßŸÇÿ®ÿ© ŸÖÿµÿßÿØÿ± ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿßŸÑÿ™Ÿä ÿ™ÿ£ÿ™ŸäŸÜŸä ŸàÿßŸÑŸÖÿ≠ŸÅÿ≤ÿßÿ™ ŸÑŸáÿß Ÿàÿ™ÿ™ÿ®ÿπ ÿ£ÿ´ÿ± ÿ™ŸÑŸÉ ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿπŸÑŸä ÿ£ŸÅÿπÿßŸÑŸä ŸàŸÖÿ¥ÿßÿπÿ±Ÿä ÿå Ÿäÿπÿ™ÿ®ÿ±Ÿáÿß ÿßŸÑÿ®ÿπÿ∂ ÿ™ŸÅŸÉŸäÿ± ÿ≤ÿßÿ¶ÿØ Ÿàÿ£ÿπÿ™ÿ®ÿ±Ÿáÿß ÿ£ŸÜÿß ŸÜÿπŸÖÿ© ÿ™ŸÜŸÇÿ∞ŸÜŸä ÿ£ÿ≠ŸäÿßŸÜÿß ŸÖŸÜ ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÅ ŸÅŸä ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖŸáÿßŸÖ ŸàÿßŸÑÿ•ÿ≥ÿ™ŸäŸÇÿßÿ∏ ŸÖÿ™ÿßÿÆÿ±ÿß ŸÜÿ≥ÿ®Ÿäÿß.\nÿ®ÿØÿ£ÿ™ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÅŸä ÿßŸÑÿ∏ŸáŸàÿ± ŸÅŸä ÿßŸÑÿ≥ŸÜÿ© ÿßŸÑÿ£ŸàŸÑŸä ÿßŸÑÿ¨ÿßŸÖÿπŸäÿ© ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿ®ÿØÿßŸäÿ© ÿßŸÑÿ™Ÿä Ÿäÿ≠ÿßŸàŸÑ ŸÉŸÑ ÿ¥ÿÆÿµ ÿ£ŸÜ Ÿäÿ∏Ÿáÿ± ŸÖŸáÿßÿ±ÿßÿ™Ÿá ŸàŸÇÿØÿ±ÿßÿ™Ÿá ŸàŸäÿ´ÿ®ÿ™ ŸÜŸÅÿ≥Ÿá ŸàŸäÿ≠ÿßŸàŸÑ ÿ•ÿ´ÿßÿ±ÿ© ÿ•ÿπÿ¨ÿßÿ® ÿßŸÑÿ£ÿÆÿ±ŸäŸÜ Ÿàÿ™ŸÜÿ¥ÿßÿ°ÿ© ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ŸÖÿπ ÿ£ŸÜÿßÿ≥ ŸÖŸÜ ŸÉÿßŸÅÿ© ÿßŸÑŸÖÿ≠ÿßŸÅÿ∏ÿßÿ™ ÿ∞ŸÑŸÉ ÿßŸÑÿØÿÆŸàŸÑ ÿßŸÑŸÖŸÅÿßÿ¨ÿ¶ ŸàÿßŸÑŸÉÿ´ŸäŸÅ ŸÉÿßŸÜ ŸÑŸá ÿ£ÿ´ÿ± ŸÜŸÅÿ≥Ÿä ÿ≥ÿ¶.\nŸÖÿ´ŸÑ ÿ™ÿ∫Ÿäÿ± ÿßŸÑÿßŸáÿ™ŸÖÿßŸÖÿßÿ™ ÿπŸÑŸä ÿßŸÑŸÖÿ≥ÿ™ŸàŸä ÿßŸÑÿ¥ÿÆÿµ ŸàÿßŸÑŸÖÿπÿ±ŸÅŸä Ÿà ÿßŸÑÿØÿÆŸàŸÑ ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿπŸÑÿßŸÇÿßÿ™ ÿßŸÑŸÉÿ´Ÿäÿ±Ÿá ÿ®ÿØÿ£ÿ™ ÿßŸÑÿ£ŸáÿØÿßŸÅ ÿßŸÑŸÖÿ±ŸÉÿ≤Ÿäÿ© ÿßŸÑÿ™Ÿä ŸÉŸÜÿ™ ÿ£ÿ≠ŸÑŸÖ ÿ®Ÿáÿß Ÿà ÿ£ŸÅŸÉÿßÿ±Ÿä ŸàŸÖÿ®ÿßÿØÿ¶ ÿ®ÿßŸÑÿ™ÿ¥ÿ™ÿ™ ŸàÿßŸÑÿ™ÿ£ÿ´ÿ± ÿ®ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÉŸÑ ÿ¥ÿÆÿµ ÿ™ÿπÿ±ŸÅÿ™ ÿπŸÑŸäŸá Ÿàÿµÿßÿ± ÿ®ŸäŸÜŸä Ÿàÿ®ŸäŸÜŸá ÿπŸÑÿßŸÇÿ© ÿ≤ŸÖÿßŸÑÿ© ÿ®ŸÑ Ÿàÿ≠ÿ™Ÿä ŸÖÿ¨ÿ±ÿØ ÿ±ÿ§Ÿäÿ© ÿµŸÅÿ≠ÿ™Ÿá ÿπŸÑŸä Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ŸÉŸÑ Ÿáÿ∞ÿß ÿ∑ÿ®ŸäÿπŸä Ÿà ŸÖŸÅŸáŸàŸÖ.\nÿ®ÿπÿØ ŸÖÿ≠ÿßŸàŸÑ ŸÖÿ±ÿßŸÇÿ®ÿ© ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸäŸàŸÖŸä ŸàÿßŸäŸÜ Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ŸÜÿßŸÅÿ≤Ÿá Ÿàÿ£ŸäŸÜ ÿ™ÿ≥ŸÜÿ≤ŸÅ ÿ£ŸÅŸÉÿßÿ±Ÿä Ÿà ŸÖÿÆÿ≤ŸàŸÜ ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ŸÑÿØŸä Ÿàÿ¨ÿØÿ™ ÿ£ŸÜŸä ÿ£ÿ∞Ÿáÿ® ŸÑŸÜÿ¥ÿ± ÿ®Ÿäÿ™ ÿßŸÑÿ¥ÿπÿ± Ÿáÿ∞ÿß Ÿàÿ™ŸÑŸäÿÆÿµ ÿßŸÑŸÉÿ™ÿßÿ® ÿ∞ÿßŸÉ ŸÑÿ£ŸÜÿ™ÿ∏ÿ± ÿ±ÿØ ŸÅÿπŸÑ ŸÅŸÑÿßŸÜ ŸàÿπŸÑÿßŸÜ Ÿà ÿßŸÜÿ∫ŸÖÿßÿ≥Ÿä ŸÅŸä ÿßŸÑÿ±ÿØŸàÿØ ÿπŸÑŸä ŸÖŸÜÿ¥Ÿàÿ±ÿßÿ™ŸáŸÖ Ÿàÿ™ÿ™ÿ®ÿπ ÿ£ÿÆÿ®ÿßÿ±ŸáŸÖ Ÿà ÿ™ÿ∂ÿÆŸÖ ÿ∑ŸÅŸäŸÑŸäŸä ÿßŸÑŸÅÿ∂ŸàŸÑ ÿπŸÜÿØŸä ÿ®ÿ¥ŸÉŸÑ ŸÖÿ®ÿßŸÑÿ∫ ŸÅŸäŸá ŸÖŸÖÿß ÿ£ÿµÿ®ÿ≠ Ÿäÿ≥ÿ®ÿ® ŸÇŸÑŸÇ Ÿàÿ≠Ÿäÿ±ÿ© Ÿàÿ™ÿ¥ÿ™ÿ™ ŸàŸÖŸÇÿßÿ±ÿßŸÜÿßÿ™ Ÿà Ÿàÿ∂Ÿäÿßÿπ ÿ£ÿπŸÖÿßÿ±."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ±",
    "href": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ±",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ±",
    "text": "ÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ±\n\n\n\ntarget\n\n\nÿßŸÑÿ•ŸÜÿ®Ÿáÿßÿ± ÿßŸÑÿ≥ÿ±Ÿäÿπ ÿ®ÿßŸä ÿ¥ÿÆÿµ Ÿäÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿ¥ÿ¶ ŸÑÿß ÿ£ÿπÿ±ŸÅŸá ŸÖÿ±ÿ™ 6 ÿ¥ŸáŸàÿ± ÿ™ŸÇÿ±Ÿäÿ®ÿß Ÿàÿ£ŸÜÿß ŸÖÿ™ÿßÿ´ÿ± ÿ®ÿ®ÿπÿ∂ ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ÿßŸÑÿ∞ŸäŸÜ ŸÉŸÜÿ™ ÿ£ÿπÿ™ŸÇÿØ ÿßŸÜ ŸÑÿØŸäŸáŸÖ ŸÇÿØÿ± ŸÖŸÜ ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑÿµÿØŸÇ ŸàÿßŸÑÿßÿ¥ÿ™ÿ±ÿßŸÉ ŸÅŸä ŸÉŸàÿ±ÿ≥ÿßÿ™ŸáŸÖ ÿßŸÑÿ™Ÿä ÿ≥ÿ™ÿ¨ÿπŸÑŸÜŸä ŸÖÿ®ÿ±ŸÖÿ¨ ŸÑÿ£ÿ≠ÿµŸÑ ÿπŸÑŸä ÿØÿÆŸÑ ÿ®ÿßŸÑÿØŸàŸÑÿßÿ± ŸÅŸä ŸÜŸáÿßŸäÿ© ÿßŸÑÿ¥Ÿáÿ± ÿßŸÑŸÇÿßÿØŸÖ ÿ∞ŸÑŸÉ ÿßŸÑÿ¥Ÿáÿ± ÿßŸÑÿ∞Ÿä ÿ£ŸÖÿ™ÿØ 4 ÿ≥ŸÜŸàÿßÿ™ ÿØÿ±ÿßÿ≥Ÿäÿ© !!! ÿ¥Ÿáÿ± ÿ£ÿ≥ÿ®ŸàÿπŸá ÿ®ŸÖŸÇÿØÿßÿ± ÿπÿßŸÖ!\nŸÑŸÜÿ±ŸÖÿ≤ ŸÑÿ™ŸÑŸÉ ÿßŸÑŸÅÿ¶ÿ© ŸÖŸÜ ÿßŸÑŸÖÿ§ÿ´ÿ±ŸäŸÜ ÿ®ÿßŸÑÿ±ŸÖÿ≤ ÿ≥ ŸàŸáŸà ÿ•ÿÆÿ™ÿµÿßÿ± ŸÑŸÉŸÑŸÖÿ© ÿ≥ÿ®Ÿàÿ®ÿ© ŸäŸÜÿ™ÿ¥ÿ± ŸáŸàŸÑÿßÿ° ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ŸÅŸä ÿ£ŸÖÿßŸÉŸÜ ÿµŸäÿØ ÿßŸÑŸÖÿ®ÿ™ÿØÿßÿ¶ŸäŸÜ Ÿäÿ®Ÿäÿπ ŸÑŸÉ ŸáŸàŸÑÿßÿ° ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ÿßŸÑŸàÿπŸàÿØ ÿßŸÑÿ®ÿ±ÿßŸÇÿ© ŸÉŸàÿ±ÿ≥ ŸÑÿ™ÿπŸÑŸÖ ÿßŸÑÿ≥ÿßŸäÿ®ÿ± ÿ≥ŸäŸÉŸàÿ±ÿ™Ÿä ŸÅŸä ÿÆŸÑÿßŸÑ 3 ÿ¥ŸáŸàÿ± ÿ£Ÿà ÿ™ÿπŸÑŸÖ ÿØÿ®ŸÑŸàŸÖÿ© ÿπŸÑŸÖ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ŸàÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿ¥Ÿáÿ±ŸäŸÜ ÿ™ŸÜÿ®Ÿáÿ± ŸÉÿ´Ÿäÿ±ÿß ÿ®ÿßŸÑŸÉÿßÿ±ÿ≤ŸäŸÖÿß Ÿàÿ∑ÿ±ŸäŸÇÿ© ÿßŸÑÿßŸÑŸÇÿßÿ° ŸàŸÜÿ∏ÿßŸÅÿ© ÿßŸÑŸÖŸÉÿßŸÜ ŸàÿßŸÑŸÖÿ≠ÿ™ŸàŸä ÿßŸÑÿ∞Ÿä ŸäÿπÿØ ŸÖÿ®Ÿáÿ± ÿ®ÿßŸÑŸÜÿ≥ÿ®ÿ© ŸÑŸÉ ŸÅŸÑÿ®ÿ≥ ŸÑÿØŸäŸÉ ÿ£Ÿä ÿ¢ŸÑŸäÿßÿ™ ŸÑŸÑÿ≠ŸÉŸÖ ÿπŸÑŸä ÿßŸÑÿ¥ÿÆÿµ ÿ£Ÿà ÿßŸÑŸÖÿ≠ÿ™ŸàŸä ŸÅŸÉŸÑ ŸÖÿπÿ±ŸÅÿ™ŸÉ ŸÅŸä ÿßŸÑÿπŸÑŸÖ ŸáŸä ÿ™ÿπÿßŸÑ ŸÜÿ¨ÿ±ÿ® ÿ≠ÿµÿ© ÿπŸÜÿØ ÿ£ÿ≥ÿ™ÿßÿ∞ ÿ¥ŸÉÿ±Ÿä\nÿ∑ÿßŸÑÿ® ŸÑÿß ÿ≠ŸàŸÑ ŸÑŸá ŸàŸÑÿß ŸÇŸàÿ© ŸÑÿß Ÿäÿπÿ±ŸÅ ÿ£Ÿä ÿ¥ÿ¶ ŸÅŸä ÿπŸÇŸÑÿ© ÿ∫Ÿäÿ± ŸÖŸÑÿÆÿµ ÿßŸÑÿØÿ±ÿ≥ ÿßŸÑÿ∞Ÿä Ÿäÿ≠ŸÅÿ∏ÿ© ÿπŸÜ ÿ∏Ÿáÿ± ŸÇŸÑÿ® ŸàŸäÿ∞Ÿáÿ® ŸÑŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ ŸÑŸäÿ≥ŸÉÿ® ÿ™ŸÑŸÉ ÿßŸÑÿßÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ¨ÿßŸáÿ≤Ÿá ŸÅŸä Ÿàÿ±ŸÇÿ© ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜ ÿßŸÑÿßÿ®ŸÑŸá ŸÑŸäÿ™ŸÅÿßÿ¨ÿ¶ ÿ∞ŸÑŸÉ ÿßŸÑŸÖÿ≥ŸÉŸäŸÜ ÿ£ŸÜ ŸÑÿß ŸäŸàÿ¨ÿØ ÿ™ÿπŸÑŸäŸÖ ÿ¨ÿßŸÖÿπŸä ÿ≠ŸÇŸäŸÇŸä ŸàÿßŸÜŸáÿß ŸÉÿßŸÜÿ™ ŸÉÿ∞ÿ®ÿ© ÿßŸÑÿπŸÖÿ± ÿßŸÑÿ∂ÿßÿ¶ÿπ ŸÅŸä ŸÉŸÑ ÿ™ŸÑŸÉ ÿßŸÑÿ≥ŸÜŸàÿßÿ™ ŸÖŸÜ ÿßŸÑÿßÿ®ÿ™ÿØÿßÿ¶Ÿäÿ© ŸàŸáŸà Ÿäÿ≥ÿ£ŸÑ ŸÖÿ™Ÿä ÿßŸÑÿ±ÿßÿ≠ÿ© ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑÿ™ŸÑŸÇŸäŸÜ ÿßŸÑŸÅÿßÿ¥ŸÑ Ÿàÿ™ŸÉŸàŸÜ ÿßŸÑÿßÿ¨ÿßÿ®ÿ© ÿßŸÑŸÉŸÑÿßÿ¥ŸÉŸäÿ© ŸáŸä ÿ£ÿ™ÿπÿ® ÿßŸÑŸàŸÇÿ™Ÿä ÿπŸÑÿ¥ÿßŸÜ ÿ™ÿ≥ÿ™ÿ±Ÿäÿ≠ ÿ®ÿπÿØŸäŸÜ ÿ®ÿπÿØŸäŸÜ ÿßŸÖÿ™Ÿá!\nŸÅŸä ÿßŸÑÿ¨ÿßŸÖÿπÿ© ÿπŸÜÿØŸÖÿß ÿ™ŸÜÿ™ŸáŸä ŸÖŸÜ ÿßŸÑ3 ÿßŸÑÿ´ÿßŸÜŸàŸä ŸÑÿ™ÿµŸäÿ± ÿØŸÉÿ™Ÿàÿ± ŸÖÿÆ Ÿàÿ£ÿπÿµÿßÿ® ÿ£Ÿà ŸÖŸáŸÜÿØÿ≥ ÿ®ÿ™ÿ±ŸàŸÑ"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿßŸÑŸÉŸáŸÜÿ©-Ÿà-ÿßŸÑŸÖÿπÿ®ÿØ",
    "href": "blog/posts/life_style/fake_graviety.html#ÿßŸÑŸÉŸáŸÜÿ©-Ÿà-ÿßŸÑŸÖÿπÿ®ÿØ",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿßŸÑŸÉŸáŸÜÿ© Ÿà ÿßŸÑŸÖÿπÿ®ÿØ",
    "text": "ÿßŸÑŸÉŸáŸÜÿ© Ÿà ÿßŸÑŸÖÿπÿ®ÿØ\nÿ≥Ÿàÿßÿ° ŸÉÿßŸÜÿ™ ŸÜÿ™Ÿäÿ¨ÿ© ÿßŸÑÿ´ÿßŸÜŸàŸäÿ© ŸÖÿ±ÿ∂Ÿäÿ© Ÿà ÿ£ÿ±ÿ∂Ÿäÿ™ ŸàÿßŸÑÿØŸäŸÉ ÿ£ŸÖ ŸÖÿ≠ÿ≤ŸÜÿ© Ÿàÿ£ÿµÿßÿ®ŸÉ ÿßŸÉÿ™ÿßÿ¶ÿ® ŸàÿßŸÖÿ™ŸÑÿ¶ÿ™ ÿ®ÿßŸÑÿ≠ÿ≤ŸÜ ŸÅŸÑÿß ÿ™ÿ®ÿ™ÿ£ÿ≥ ŸÅÿßŸÑŸÇÿßÿØŸÖ ÿ£ÿ≥Ÿàÿ° ÿπŸÑŸäŸÉŸÖÿß ŸàŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉ ŸÅŸä ÿπÿµÿ± ÿßŸÑŸÉŸáŸÜÿ© ÿßŸÑÿ¨ÿßŸÖÿπŸäÿ© ÿ®ÿπÿØ ŸÖÿ±ÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´ ÿßŸÑÿπÿØŸäÿØÿ© Ÿàÿ≥ŸÖÿßÿπ ÿßŸÑÿ£ÿ±ÿßÿ° ŸáŸÜÿß ŸàŸáŸÜÿßŸÉ ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÅŸäÿØŸàŸáÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ∞ŸÉÿ± ŸÑŸÉ ŸÖŸÖŸäÿ≤ÿßÿ™ ÿßŸÑÿ¨ÿßŸÖÿπÿ© ÿßŸÑŸÅŸÑÿßŸÜŸäÿ© Ÿàÿ£ŸÇÿ≥ÿßŸÖŸáÿß ŸàŸÜÿπŸäŸÖŸáÿß Ÿàÿ™ÿ∞ŸÉÿ±ŸÉ ÿ®ÿßŸÑÿßÿ®ÿ™ÿπÿßÿØ ÿπŸÜ ÿßŸÑŸáŸÜÿØÿ≥ÿ© ŸàÿßŸÑÿ¨ÿßŸÖÿπÿßÿ™ ÿßŸÑÿ™ŸÇŸÑŸäÿØŸäÿ© ŸàÿßŸÑÿ∞Ÿáÿßÿ® ÿßŸÑŸä ŸÉŸÑŸäÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ© ŸÖÿ´ŸÑ:\n\nŸÉŸÑŸäÿ© ÿßŸÑŸÖŸÑÿßÿ≠ÿ© ŸàÿßŸÑŸÅÿ∂ÿßÿ°\nŸÉŸÑŸäÿ© ÿßŸÑÿ´ÿ±Ÿàÿ© ÿßŸÑÿ≥ŸÖŸÉŸäÿ©\nŸàÿßŸÑÿ≠ÿ®Ÿäÿ®ÿ© ÿßŸÑÿÆÿ®Ÿäÿ´ÿ© ŸÉŸÑŸäÿ© ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä ŸÉŸÑŸäÿ© ÿßŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ŸàÿµŸÜÿßÿπÿ© ÿßŸÑÿ±ŸäŸÖŸàÿ™ÿßÿ™ ŸàŸÖŸÉŸÜ ÿßŸÑÿÆŸäÿßÿ∑ÿ©\nŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÉŸÑŸäÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ© ÿ£Ÿà ÿßŸÑŸÇÿ≥ÿßŸÖ ÿ∞ÿßÿ™ ÿßŸÑÿ£ÿ≥ŸÖÿßÿ° ÿßŸÑÿ®ÿ±ÿßŸÇÿ© ‚ÄúŸÑŸäÿ≥ ÿπŸÜÿØŸä ÿ£Ÿä ÿ•ÿπÿ™ÿ±ÿßÿ∂ ÿπŸÜ ÿ£Ÿä ŸÉŸÑŸäÿ© ÿ£Ÿà ÿ™ÿÆÿµÿµ ÿ®ŸÑ ÿ£ÿ™ŸÖŸÜŸä ÿ£ŸÜ ŸäŸÉŸàŸÜ ÿπŸÜÿØŸä ÿπŸÖÿ± ŸÑŸÉŸÑ ÿ™ÿÆÿµÿµ ŸÅÿ¥ÿ±ŸÅ ÿßŸÑÿπŸÑŸÖ ŸÉÿßŸÅŸä‚Äù\n\nŸÑŸÉŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÅŸä ÿ£ŸÜŸáÿß ŸÖÿ≥ÿ±ÿ≠Ÿäÿ© Ÿàÿ≥ÿ®Ÿàÿ®ÿ© ÿπÿßŸÖÿ© ŸàŸÉŸÑ ŸÅÿ±ÿØ ŸÖÿ¥ÿßÿ±ŸÉ ŸÅŸäŸáÿß ÿ®ÿØÿßŸäÿ© ŸÖŸÜ ÿßŸÑŸÖÿØÿ±ÿ≥ŸäŸÜ ŸàÿßŸÑÿ£ŸáŸÑ Ÿà ÿßŸÑŸÖŸáÿßÿ∑ŸäŸÑ ÿßŸÑÿ¨ÿßŸÖÿπŸäŸäŸÜ\nÿ∞ŸÑŸÉ ÿßŸÑŸÖÿπÿ®ÿØ ÿßŸÑŸÖŸÑÿ¶ ÿ®ÿßŸÑÿßŸÑŸáÿ© ŸàÿßŸÑŸÉŸáŸÜÿ© ŸàÿßŸÑŸÖÿ≠ÿ±ŸÖÿßÿ™ ŸàÿßŸÑÿ∞Ÿä ÿ®ŸÖÿ¨ÿ±ÿØ ÿØÿÆŸàŸÑŸÉ ŸÑÿ®Ÿàÿßÿ®ÿ© ÿ∞ŸÑŸÉ ÿßŸÑŸÖÿπÿ®ÿØ Ÿàÿ™ŸÇÿØŸäŸÖŸÉ ŸÑÿ£Ÿàÿ±ÿßŸÇ ÿßŸÑÿßŸÑÿ™ÿ≠ÿßŸÇ ŸÅŸÇÿØ ÿ™ŸÖÿ™ ÿπŸÑŸäŸÉ ÿßŸÑŸÑÿπŸÜÿ© ÿßŸÑÿ£ÿ®ÿØŸäÿ© ŸàŸÉŸÖÿß ÿØÿÆŸÑÿ™ ÿ¨ÿ≥ÿØ ŸÖŸÖÿ™ŸÑÿ¶ ÿ®ÿßŸÑÿ£ŸÖŸÑ ÿ£Ÿà ÿ≠ÿ™Ÿä ÿ¨ÿ≥ÿØ ŸÖŸÖÿ™ŸÑÿ¶ ÿ®ÿßŸÑÿ≠ÿ≤ŸÜ ŸàÿßŸÑŸÜÿØŸÖ ŸÅÿ≥ÿ±ÿπÿß ŸÖÿß ÿ≥ÿ™ÿÆÿ±ÿ¨ ÿ¨ÿ´ÿ© ŸáÿßŸÖÿØÿ© ŸÅÿßŸÇÿØÿ© ÿßŸÑÿ±ÿ∫ÿ®ÿ© ÿπŸÑŸä ÿßŸÑÿπŸäÿ¥ ÿ®ŸÑ ÿ™ŸÅŸÇÿØ ŸÅŸä ŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖÿ±ÿßÿ™ ÿ•ŸÜÿ≥ÿßŸÜÿ™ŸäŸÉ"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ŸáŸäŸÉŸÑŸäÿ©-ÿßŸÑŸÖÿπÿ®ÿØ",
    "href": "blog/posts/life_style/fake_graviety.html#ŸáŸäŸÉŸÑŸäÿ©-ÿßŸÑŸÖÿπÿ®ÿØ",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ŸáŸäŸÉŸÑŸäÿ© ÿßŸÑŸÖÿπÿ®ÿØ",
    "text": "ŸáŸäŸÉŸÑŸäÿ© ÿßŸÑŸÖÿπÿ®ÿØ\nÿ®ÿπÿØŸÖÿß ŸÇÿØÿ±ÿ™ ÿπŸÑŸä ÿßŸÑŸÜÿ¨ÿßÿ© ŸàŸÑÿ≠ÿßŸÇ ÿ£Ÿä Ÿàÿ≥ŸäŸÑÿ© ŸÖŸàÿßÿµŸÑÿßÿ™ ÿ≥Ÿàÿßÿ° ŸÖŸÜ ÿ®Ÿäÿ™ŸÉ ŸÑŸÑÿ¨ÿßŸÖÿπÿ© ÿ£Ÿà ŸÑŸÑŸÖŸàŸÇŸÅ ÿßŸÑÿπÿßŸÖ ÿßŸà ŸÖŸÜ ŸÖŸàŸÇŸÅ ÿßŸÑÿπÿßŸÖ ŸÑŸÑÿ¨ÿßŸÖÿπÿ© ŸáŸÜŸäÿßÿ¶ÿß ŸÑŸÉ ŸÅŸÇÿØ ÿßÿ≥ÿ™ŸÜŸÅÿ≤ÿ™ 20% ŸÖŸÜ ŸÇÿØÿ±ÿ™ŸÉ ÿπŸÑŸä ÿßŸÑÿµŸÖŸàÿØ\nÿ≥ÿ™ÿØÿÆŸÑ Ÿáÿ∞ÿß ÿßŸÑÿµÿ±ÿ≠ ÿßŸÑŸáÿßÿ¶ŸÑ ÿßŸÑŸÖÿ®Ÿáÿ± ŸÅŸä ÿ®ÿØÿßŸäÿ™Ÿá Ÿàÿ™ÿ™Ÿàÿ¨Ÿá ÿßŸÑŸä ÿßŸÑŸÖÿπÿ®ÿØ ÿßŸÑÿ∞Ÿä ŸÑÿπŸÜÿ™ ÿ®Ÿá ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿÆÿØŸÖ ÿßŸÑÿ£ŸÉÿ®ÿ± ŸÖŸÜŸÉ Ÿäÿ™ŸÜÿµŸÑŸàŸÜ ŸÑŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ÿßŸÑŸÅÿ™Ÿäÿßÿ™ ÿßŸÑÿ≥ÿßÿ∞ÿ¨ÿßÿ™ ŸÑÿ•ÿ¥ÿ®ÿßÿπ ÿ¥ŸáŸàÿßÿ™ŸáŸÖ."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ∑ÿßŸÇÿ©-ÿßŸÑÿ≥ŸàÿØÿßÿ°",
    "href": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ∑ÿßŸÇÿ©-ÿßŸÑÿ≥ŸàÿØÿßÿ°",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑÿ≥ŸàÿØÿßÿ°",
    "text": "ÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑÿ≥ŸàÿØÿßÿ°\nŸÉÿßŸÜ ÿßŸÑÿ™ŸÅÿ≥Ÿäÿ± ÿßŸÑŸàÿ≠ŸäÿØ ŸÑŸÉŸÑ Ÿáÿ∞ÿß ÿßŸÑÿπÿ®ÿ´ ŸáŸà Ÿàÿ¨ŸàÿØ ÿÆÿ∑ÿ© ÿ¥ÿ± ŸÉÿ®ÿ±Ÿä ŸÖŸÜ ÿßŸÑŸÅÿ±ÿßÿπŸÜÿ© ÿßŸÑŸÇÿØŸÖÿßÿ° ŸÑÿ™ŸàŸÑŸäÿØ ÿ£ŸÉÿ®ÿ± ŸÇÿØÿ± ŸÖŸÜ ÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑÿ≥ŸÑÿ®Ÿäÿ© ŸàÿßŸÑÿ•ÿ≠ÿ®ÿßÿ∑ ŸÅŸä ŸÉŸÑ ŸÖŸÉÿßŸÜ Ÿäÿ¨ÿ™ŸÖÿπ ŸÅŸäŸá ÿßŸÑÿ®ÿ¥ÿ± ÿßŸà ŸÉÿßŸÜ ŸäŸÅÿ™ÿ±ÿ∂ ÿßŸÜ ŸäŸÉŸàŸÜ ŸàŸÑÿßÿØÿ© ÿ¨ÿØŸäÿØÿ© ŸÑÿ£ÿ±Ÿàÿßÿ≠ ŸÖÿ™ÿπÿ®ÿ©.\nŸäÿ™ŸÖ ÿ•ÿ≥ÿ™ÿÆÿØÿßŸÖ ÿ™ŸÑŸÉ ÿßŸÑÿ∑ÿßŸÇÿ© Ÿàÿ•ŸÖÿ™ÿµÿßÿµŸáÿß ŸÅŸáŸä ÿ™ÿπŸÜŸä ŸÑŸáŸÖ ÿßŸÑÿÆŸÑŸàÿØ ŸÅÿ™ŸÑŸÉ ÿßŸÑŸÖŸÜÿ∑ŸÇÿ© ÿ≠ŸÑÿ™ ÿπŸÑŸäŸáÿß ŸÑÿπŸÜÿ© ŸÑÿß ŸäŸÖŸÉŸÜ ÿ≠ŸÑŸáÿß ÿ•ŸÑÿß ÿ®ÿßŸÑŸÇÿ∂ÿßÿ° ÿπŸÑŸä ÿßŸÑŸÅÿ±ÿßÿπŸÜÿ© Ÿà ÿ•ÿπÿßÿØÿ© ÿßŸÑÿßÿ±Ÿàÿßÿ≠ ÿßŸÑÿ™Ÿä ÿ£ÿ∫ÿ™ÿµÿ®ÿ™ ŸàÿßŸÑÿ£ÿ≠ŸÑÿßŸÖ ÿßŸÑŸÖŸÅŸÇŸàÿØÿ© ÿ£ÿ≠ŸÑÿßŸÖ ÿßŸÑÿ®ÿ≥ÿ∑ÿßÿ° ŸàŸÑŸÑÿ≠ÿØŸäÿ´ ŸáŸÜÿß ÿ®ŸÇŸäÿ© ŸÅŸä ŸÖŸÉÿßŸÜ Ÿàÿ≤ŸÖÿßŸÜ ÿ£ÿÆÿ±Ÿä."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©",
    "href": "blog/posts/life_style/fake_graviety.html#ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©",
    "text": "ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ©\n\n\n\ntarget\n\n\nÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© (ŸÖŸÜ ŸÅÿπŸÑ ÿ¨Ÿéÿ∞Ÿéÿ®Ÿé) Ÿàÿ™ÿπÿ±ŸÅ ÿ£Ÿäÿ∂ÿßŸã ÿ®ÿßÿ≥ŸÖ ÿßŸÑÿ´ŸéŸÇÿßŸÑÿ© (ŸÖŸÜ ŸÅÿπŸÑ ÿ´ŸéŸÇŸèŸÑŸé) ŸáŸä ÿ∏ÿßŸáÿ±ÿ© ÿ∑ÿ®ŸäÿπŸäÿ© Ÿäÿ™ŸÖ ÿ®Ÿàÿßÿ≥ÿ∑ÿ™Ÿáÿß ÿ™ÿ≠ÿ±ŸäŸÉ ŸàÿßŸÜÿ¨ÿ∞ÿßÿ® ŸÉŸÑ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ŸÖŸÜ ÿßŸÑŸÉÿ™ŸÑÿ© ÿ£Ÿà ÿßŸÑÿ∑ÿßŸÇÿ© -ÿ®ŸÖÿß ŸÅŸä ÿ∞ŸÑŸÉ ÿßŸÑŸÉŸàÿßŸÉÿ® ŸàÿßŸÑŸÜÿ¨ŸàŸÖ ŸàÿßŸÑŸÖÿ¨ÿ±ÿßÿ™ Ÿàÿ≠ÿ™Ÿâ ÿßŸÑÿ∂Ÿàÿ°- ŸÜÿ≠Ÿà ÿ®ÿπÿ∂Ÿáÿß ÿßŸÑÿ®ÿπÿ∂.\nÿπŸÑŸâ ÿßŸÑÿ£ÿ±ÿ∂ÿå ÿ™ÿπÿ∑Ÿä ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿ´ŸÇŸÑÿßŸã ŸÑŸÑÿ£ÿ¨ÿ≥ÿßŸÖ ÿßŸÑŸÖÿßÿØŸäÿ© (ÿßŸÑŸàÿ≤ŸÜ)ÿå Ÿàÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑŸÇŸÖÿ± ÿ™ÿ≥ÿ®ÿ® ÿßŸÑŸÖÿØ ŸàÿßŸÑÿ¨ÿ≤ÿ± ŸÅŸä ÿßŸÑŸÖÿ≠Ÿäÿ∑. ÿ™ÿ≥ÿ®ÿ® ÿßŸÑÿßŸÜÿ¨ÿ∞ÿßÿ® ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿä ŸÑŸÑŸÖÿßÿØÿ© ÿßŸÑÿ∫ÿßÿ≤Ÿäÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ© ÿßŸÑŸÖŸàÿ¨ŸàÿØÿ© ŸÅŸä ÿßŸÑŸÉŸàŸÜ ŸÅŸä ÿßŸÑÿ®ÿØÿ° ŸÅŸä ÿßŸÑÿßŸÜÿØŸÖÿßÿ¨ ÿßŸÑŸÜŸàŸàŸäÿå Ÿàÿ™ŸÉŸàŸäŸÜ ÿßŸÑŸÜÿ¨ŸàŸÖ -Ÿàÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑŸÜÿ¨ŸàŸÖ ŸÖÿπŸãÿß ŸÅŸä ŸÖÿ¨ÿ±ÿßÿ™- ŸÑÿ∞ÿß ŸÅÿ•ŸÜ ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≥ÿ§ŸàŸÑÿ© ÿπŸÜ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ÿßŸÑŸáŸäÿßŸÉŸÑ ÿßŸÑŸàÿßÿ≥ÿπÿ© ÿßŸÑŸÜÿ∑ÿßŸÇ ŸÅŸä ÿßŸÑŸÉŸàŸÜ.\nÿπŸÑŸâ ÿßŸÑÿ±ÿ∫ŸÖ ŸÖŸÜ ÿ∞ŸÑŸÉ ŸÅÿ•ŸÜ ÿ¢ÿ´ÿßÿ± ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿ™ÿµÿ®ÿ≠ ÿ£ÿ∂ÿπŸÅ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ™ÿ≤ÿßŸäÿØ ÿπŸÑŸâ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ®ÿπŸäÿØÿ©."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°",
    "href": "blog/posts/life_style/fake_graviety.html#ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°",
    "text": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°\nŸáŸÑ ŸäŸÖŸÉŸÜŸÉ ÿ£ŸÜ ÿ™ŸÅŸÉÿ± ŸÉÿ´Ÿäÿ±ÿß ŸÅŸä ŸÉÿßŸÅÿ© ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ™Ÿä ÿ™ÿ¨ÿ∞ÿ®ŸÉ ŸÑŸáÿß ŸÖŸÜ ÿ≠ŸàŸÑŸÉ ÿπŸÑŸä ŸÖÿ≥ÿ™ŸàŸä ÿßŸÑŸàŸÇÿ™ Ÿà ÿßŸÑÿ£ŸÅŸÉÿßÿ± ŸàÿßŸÑŸÖÿ¥ÿßÿπÿ± ŸàŸÇŸàÿ© ÿßŸÑÿ•ÿ±ÿßÿØÿ©!\n\nÿ™ÿßÿ´Ÿäÿ± ÿ£ÿµÿØŸÇÿßÿ¶ŸÉ ÿπŸÑŸäŸÉ\nŸÖŸÉÿßŸÜ ÿ≥ŸÉŸÜŸÉ\nÿ£ÿ≥ÿ±ÿ™ŸÉ\nŸàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ\n\nÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ŸÑŸäÿ≥ ŸáŸà ŸÇÿ∂ÿßÿ° ÿ£ŸÉÿ´ÿ± ŸàŸÇÿ™ ŸÅŸä ÿ£ŸÖÿ± ŸÖÿß ŸÑŸÉŸÜŸá ŸÇÿØÿ±ÿ™ŸÉ ÿπŸÑŸä ÿ•ÿ®ÿπÿßÿØ ÿßŸÑŸÖÿ¥ÿ™ÿßÿ™ ÿπŸÜ ÿ™ŸÑŸÉ ÿßŸÑŸÖŸáŸÖÿ© ŸàÿßŸÑŸÇÿØÿ±ÿ© ÿπŸÑŸä ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ÿßŸÑŸÉÿßŸÖŸÑ ŸÅŸäŸáÿß. ŸÅŸÖÿ´ŸÑÿß: ŸÅŸÖÿ´ŸÑÿß ÿßŸÑÿ™ÿ±ŸÉŸäÿ≤ ŸáŸà ÿßŸÜ ÿ™ÿ∞ÿßŸÉÿ± 4 ÿ≥ÿßÿπÿßÿ™ ÿ®ÿ±ŸÖÿ¨ÿ© ŸÅŸÇÿ∑ ŸàŸÑŸäÿ≥ ÿßŸÜ ÿ™ÿ±ŸÉÿ≤ ÿπŸÑŸä ÿ≥ÿßÿπÿ™ŸäŸÜ ÿ®ÿ±ŸÖÿ¨ÿ© ŸàŸäÿ® Ÿàÿ≥ÿßÿπÿ© ŸÖÿßÿ±ŸÉÿ™ŸÜŸäÿ¨ Ÿàÿ≥ÿßÿπÿ© ŸÖÿ∞ÿßŸÉÿ±ÿ© ŸÑŸÑÿ¨ÿßŸÖÿπÿ© ŸàŸÖÿ≠ÿßŸàŸÑ ÿßŸÑÿ™ŸÜŸÇŸÑ ÿ®ŸäŸÜŸáŸÖ ÿπŸÑŸä= ŸÖÿØÿßÿ± ÿßŸÑŸäŸàŸÖ ÿßŸà ŸÉŸÖÿß ÿßÿ≠ÿ® ÿßŸÜ ÿßŸÇŸàŸÑ ÿπŸÑŸä ŸÖÿØÿßÿ± ŸÜŸàŸÖ!\n\nŸÑŸäÿ≥ÿ™ ÿßŸÑŸÇÿ∂Ÿäÿ© ŸÉŸÖ ŸÑÿØŸä ŸÖŸÜ ÿßŸÑŸàŸÇÿ™ ŸÑÿ£ÿπŸÖŸÑ ŸÉÿ∞ÿß ÿ®ŸÑ ŸÉŸÖ ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑŸàŸÇÿ™ ŸÑÿØŸä ÿßŸÑŸÇÿØÿ±ÿ© ÿπŸÑŸä ÿπŸÖŸÑ Ÿáÿ∞ÿß ŸÅŸàÿ¨ŸàÿØ 10 ÿ≥ÿßÿπÿßÿ™ ŸÅÿ±ÿßÿ∫ ŸÑŸäÿ≥ ŸÖÿπŸÜÿßŸá ÿßŸÜŸÉ ÿ™ÿ≥ÿ™ÿ∑Ÿäÿπ ÿ•ÿ≥ÿ™ÿÆÿØÿßŸÖŸáŸÖ ÿ¨ŸÖŸäÿπÿß ÿ®ŸÑ ŸäŸàÿ¨ÿØ ŸÖŸÜŸáŸÖ ŸÖÿ´ŸÑÿß 4 ÿ≥ÿßÿπÿßÿ™ ŸÅŸÇÿ∑ ŸàŸáÿ∞Ÿá ÿ±ÿ≠ŸÑÿ© ÿ∑ŸàŸäŸÑÿ© Ÿàÿ™ÿ≠ÿ™ÿßÿ¨ ŸÑÿ™ŸÜÿ∏ŸäŸÖ ÿπÿßŸÑŸä ŸàŸÖÿ≠ÿßŸàŸÑ ŸàÿÆÿ∑ÿßÿ° ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÜÿµÿßÿ¶ÿ≠ ŸÑŸäÿ≥ Ÿáÿ∞ÿß ŸàŸÇÿ™ ÿ∞ŸÉÿ±Ÿáÿß.\nŸÅŸÑŸáÿ∞ÿß ŸäŸÜÿµÿ≠ ÿ®ÿßŸÑÿßÿ®ÿ™ÿπÿßÿØ ÿπŸÜ Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ Ÿà ÿ™ÿØŸÅŸÇ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ¥ÿ∫ŸÑ ÿπŸÇŸÑŸÉ ŸàŸÇŸÑÿ®ŸÉ ŸÅŸä ÿ®ÿØÿßŸäÿ© ÿßŸÑŸäŸàŸÖ ŸÅÿ®ÿπÿØ ÿ≥ÿßÿπÿ™ŸäŸÜ ÿ™ÿ¥ÿπÿ± ÿ®ÿßŸÑÿµÿØÿßÿπ ŸàÿßŸÑÿ±ÿ∫ÿ®ÿ© ÿπŸÑŸä ÿßŸÑŸÜŸàŸÖ ŸàŸÉÿ£ŸÜ ÿπŸÇŸÑŸÉ ÿ™ŸàŸÇŸÅ ÿπŸÜ ÿßŸÑÿπŸÖŸÑ."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿ≠ÿØŸäÿ´-ÿ™ÿÆÿ±ÿ¨",
    "href": "blog/posts/life_style/fake_graviety.html#ÿ≠ÿØŸäÿ´-ÿ™ÿÆÿ±ÿ¨",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿ≠ÿØŸäÿ´ ÿ™ÿÆÿ±ÿ¨",
    "text": "ÿ≠ÿØŸäÿ´ ÿ™ÿÆÿ±ÿ¨\n ŸÖÿØŸä ÿπŸÑŸä ÿ™ÿÆÿ±ÿ¨Ÿä ŸÖŸÜ ÿßŸÑÿ¨ÿßŸÖÿπÿ© ÿ®ÿ™ŸÇÿØŸäÿ± ÿ¨ŸäÿØ ÿ¨ÿØÿß +B ŸÖÿ™ÿ±ŸÅÿπ ÿ®ÿ∂ÿπÿ© ÿ£ŸäÿßŸÖ ÿ™ÿ™ŸÖŸÑŸÉŸÜŸä ŸÅÿ±ÿ≠ÿ© ÿπÿßÿ±ŸÖÿ© ÿ£ŸÜŸÜŸä ŸÇÿØÿ™ Ÿáÿ±ÿ®ÿ™ ŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑÿ≥ÿ¨ŸàŸÜ ÿßŸÑÿ™Ÿä Ÿàÿ∂ÿπÿ™ ÿπŸÑŸäÿß ÿ∑ŸàÿßŸÑÿ© Ÿáÿ∞Ÿá ÿßŸÑÿ£ÿπŸàÿßŸÖ ÿ¥ÿπŸàÿ± ŸÖÿ±Ÿäÿ≠ ÿ¨ÿØÿß ÿ™ÿ®ŸÇŸä ÿ≥ÿ¨ŸÜ ÿßŸÑÿÆÿØŸÖÿ© ÿßŸÑÿπÿ≥ŸÉÿ±Ÿäÿ© ÿßŸÑŸÑŸáŸÖ ÿ•ŸÜŸä ÿ£ÿ≥ÿßŸÑŸÉ ÿßŸÑÿ•ÿπŸÅÿßÿ° ŸÖŸÜ Ÿáÿ∞Ÿá ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ŸàŸÖŸÜ ÿ¥ÿ±Ÿáÿß Ÿàÿ¥ÿ± ŸÖŸÜ ŸÅŸäŸáÿß.\nÿ≠ÿØŸäÿ´ ÿ™ÿÆÿ±ÿ¨ ŸÅŸä ŸÖÿØÿßÿ± ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ∞Ÿä ŸÑŸÖ Ÿäÿ™ŸÖ ÿ™ÿ≠ÿØŸäÿØŸá ÿ®ÿßŸÑŸÉÿßŸÖŸÑ ŸáŸà ŸÅŸäŸÖÿß ÿ≥ŸàŸÅ ÿ£ÿ™ÿÆÿµÿµ ÿßŸÑÿ¢ŸÜ ÿ£ŸÅŸÉÿ± ŸÅŸä ÿ•ÿ¨ÿßÿ®ÿ© ŸÖŸÜÿ∞ 3 ÿ≥ŸÜŸàÿßÿ™ ŸàŸÉŸÑ ÿ¥Ÿáÿ±ŸäŸÜ ÿ™ÿ≤ÿØÿßÿØ ŸÖÿπÿ±ŸÅÿ™Ÿä ŸàÿÆÿ®ÿ±ÿ™Ÿä Ÿàÿ£ÿ¨ÿØ ÿ£ŸÜŸÜŸä ŸÑŸäÿ≥ ŸÑÿØŸä ÿ•ÿ¨ÿßÿ®ÿ© ÿ≠ŸÇŸäŸÇÿ© ÿ≠ÿ™Ÿä ÿßŸÑÿ¢ŸÜ. ŸáŸÜÿßŸÉ 3 ÿ™ÿÆÿµÿµÿßÿ™ ÿ£ÿ≥ÿ™ÿ∑Ÿäÿπ ÿßŸÜ ÿ£ÿ®ÿØÿß ÿ®Ÿáÿß:\n\nŸÖŸáŸÜÿØÿ≥ ÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ (ŸàŸÖŸÜ ÿÆŸÑÿßŸÑŸá ÿ£ÿÆÿ™ÿßÿ± ŸÅÿ±ÿπ ŸÖÿ´ŸÑ ÿ®ÿ±ŸÖÿ¨ÿ© ÿßŸÑŸàÿßÿ¨Ÿáÿßÿ™ ÿßŸà ÿßŸÑÿ®ÿßŸÉ ÿ•ŸÜÿØ)\nŸÖÿ™ÿÆÿµÿµ ŸÅŸä ÿπŸÑŸàŸÖ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ( ŸÖŸÜ ÿÆŸÑÿßŸÑŸá ÿ£ÿÆÿ™ÿßÿ± ŸÅÿ±ÿπ ŸÖÿ´ŸÑ ÿ™ÿπŸÑŸÖ ÿßŸÑÿπŸÖŸäŸÇ ŸàÿßŸÑŸÖÿ¨ÿßŸÑÿßÿ™ ÿßŸÑÿ®ÿ≠ÿ´Ÿäÿ© ÿßŸÑÿ¥ŸäŸÇÿ© ÿßŸÑÿ£ÿÆÿ±Ÿä)\nÿßŸÑŸÖÿßÿ±ŸÉÿ™ŸäŸÜÿ¨ + ÿßŸÑÿ≥ŸäŸà + ŸÉÿ™ÿßÿ®ÿ© ÿßŸÑŸÖÿ≠ÿ™ŸàŸä (ŸÖŸÜ ÿÆŸÑÿßŸÑ ŸáŸà ÿ£ŸÇÿ±ÿ® ŸÅÿ±ÿµÿ© ŸÑŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸä ÿßŸÑŸÖÿßŸÑ ŸÑÿ≥ÿ®ÿ® ÿ∫Ÿäÿ± ŸÖÿπŸÑŸàŸÖ ŸÑŸÜ ÿ£ÿµÿ±ÿ≠ ÿπŸÜŸá) ÿ£ŸäŸÜ ŸáŸä ÿßŸÑÿµÿπŸàÿ®ÿ©! ÿßŸÑÿµÿπŸàÿ®ÿ© ÿ™ŸÉŸÖŸÜ ŸÅŸä ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÉŸÑ ŸÅÿ±ÿπ ŸÖŸÜ ÿ™ŸÑŸÉ ÿßŸÑŸÅÿ±Ÿàÿπ Ÿà ÿ£ÿ´ÿ± ÿ£ÿÆÿ™Ÿäÿßÿ± ÿ£ÿ≠ÿØŸáŸÖ ÿπŸÜ ÿßŸÑÿ£ÿÆÿ± ŸÖŸÜ ŸÜÿßÿ≠Ÿäÿ© ÿßŸÑÿ£Ÿäÿ¨ÿßÿ®Ÿäÿßÿ™ ŸàÿßŸÑÿ≥ŸÑÿ®Ÿäÿßÿ™ ŸÑŸÉŸÑÿß ŸÖŸÜŸáŸÖÿß ŸàŸÑŸäÿ≥ Ÿáÿ∞ÿß ŸÖŸÉÿßŸÜ ÿßŸÑŸÜŸÇÿßÿ¥ ŸàŸÑŸÉŸÜ ŸÖÿß ÿ£ÿ±ŸäÿØ ÿ£ŸÜ ÿ£ÿ¥Ÿäÿ± ŸÑŸá ŸáŸà ÿ™ÿ£ÿ´Ÿäÿ± ÿßŸÑÿ•ÿÆÿ™Ÿäÿßÿ±ÿßÿ™ ÿπŸÑŸäŸÉ Ÿà ÿ£ÿ´ÿ±Ÿáÿß ÿπŸÑŸä ÿ≠Ÿäÿßÿ™ŸÉ Ÿà ŸàŸÖÿßŸáŸä ÿ£ÿ≥ÿ®ÿßÿ® ŸÖŸäŸàŸÑŸÉ ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÑÿ•ÿÆÿ™Ÿäÿßÿ± ŸÖÿ≠ÿØÿØ.\n\nŸÉŸäŸÅ ÿ≥ÿ£ÿÆÿ™ÿßÿ± ÿßŸÑÿ¢ŸÜ ŸÅŸä ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÇÿØ ÿ£ÿÆÿ±ÿ™ ÿßŸÜ ÿ£ÿ≠ÿ¨ŸÖ ÿ¨ÿ∞ÿ® ŸÉŸÑ ÿ™ÿÆÿµÿµ ŸÖŸÜŸáŸÖ ŸÑŸä ŸÅŸä ÿßŸÑŸÅÿ™ÿ±ÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ© ÿ®ÿßŸÑŸÇÿØÿ± ÿßŸÑÿ∞Ÿä ÿ£ÿ±ÿ≥ŸÖŸá ŸÑŸÜŸÅÿ≥Ÿä ŸàŸÖÿ≠ÿßŸàŸÑ ÿßŸÑÿ•ŸÑÿ™ÿ≤ÿßŸÖ ÿ®ÿ∞ŸÑŸÉ ŸàÿßŸÑÿ¨ŸÖÿπ ÿ®ŸäŸÜŸáŸÖ ŸÑŸÑÿÆÿ±Ÿàÿ¨ ÿ®ÿ£ŸÅÿ∂ŸÑ ÿ•ÿ≥ÿ™ŸÅÿßÿØÿ© ŸÖŸÖŸÉŸÜÿ©."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑŸÖÿ¥ÿßÿπÿ±-ÿßŸÑÿ∞ÿßÿ™Ÿäÿ©",
    "href": "blog/posts/life_style/fake_graviety.html#ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑŸÖÿ¥ÿßÿπÿ±-ÿßŸÑÿ∞ÿßÿ™Ÿäÿ©",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑŸÖÿ¥ÿßÿπÿ± ÿßŸÑÿ∞ÿßÿ™Ÿäÿ©",
    "text": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑŸÖÿ¥ÿßÿπÿ± ÿßŸÑÿ∞ÿßÿ™Ÿäÿ©\n\n\n\ntarget\n\n\nÿ®ÿπÿ∂ ÿßŸÑÿ£ŸÖÿ´ŸÑÿ© ÿßŸÑÿ™Ÿä ÿ£ÿ™ÿ∞ŸÉÿ±Ÿáÿß Ÿà ÿ£ÿ¨ÿØ ŸÅŸäŸáÿß ÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÇ ÿ£ÿµÿ≠ÿßÿ®Ÿáÿß ŸÅŸä ŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿ£ŸàŸÇÿßÿ™ ÿ®ÿ∫Ÿäÿ± ŸÇÿµÿØ ŸàŸÜŸÉÿ±ÿßŸÜ ÿ¥ÿØŸäÿØ ŸÑŸÖÿß ŸäŸÅÿπŸÑŸàŸÜ ŸàŸáÿ∞ÿß ŸÖÿß ÿ£ÿÆÿßŸÅ Ÿà ÿ£ÿ≠ÿßÿ∞ÿ± ŸÖŸÜŸá.\n\nÿßŸÑÿ¨ŸäŸÖ\nŸÅŸä ÿµÿ®ÿßÿ≠ ÿßŸÑŸäŸàŸÖ ÿØÿÆŸÑ ÿ¥ÿÆÿµ ÿ£ŸàŸÑ ŸÖÿ±Ÿá ÿ£ÿ±ÿßŸá ŸÅŸä ÿßŸÑÿ¨ŸäŸÖ Ÿäÿ®ÿØŸà ŸÖÿ™ŸÖÿ±ÿ≥ ŸÅŸä ŸÉŸÖÿßŸÑ ÿßŸÑÿ£ÿ¨ÿ≥ÿßŸÖ ŸÑŸá ŸÜŸÅÿ≥Ÿä ÿπŸÖÿ±Ÿä ÿ™ŸÇÿ±Ÿäÿ®ÿß ŸäŸÖÿ¥Ÿä ŸÖÿ´ŸÑ ÿßŸÑÿ≠ÿµÿßŸÜ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ±Ÿäÿ® ÿ™ÿ¥ÿπÿ± ŸÉÿ£ŸÜ Ÿäÿ±ŸäÿØ ÿ£ŸÜ ŸäÿÆÿ®ÿ∑ ŸÅŸä ÿ£Ÿä ÿ¥ÿ¶ ÿ£ŸÖÿßŸÖŸá ŸàŸÑÿØŸäŸá ÿ•ÿ®ÿ™ÿ≥ÿßŸÖÿ© ÿπÿ±Ÿäÿ∂Ÿá ÿ∑ŸàÿßŸÑ ÿßŸÑŸàŸÇÿ™ ŸàÿπŸäŸÜŸäŸá ÿ™ŸÜÿ∏ÿ± ŸÑŸÉŸÑ ŸÖŸÜ ÿ≠ŸàŸÑŸá ÿ®ÿ¥ŸÉŸÑ ŸÖÿ±Ÿäÿ® ŸàŸÉÿ£ŸÜŸá ÿ™ŸÇŸàŸÑ ŸáŸÑ ÿ™ÿ±ÿßŸÜŸä! ÿ£Ÿà ŸáŸà ŸÉÿ∞ÿß ŸÇÿ±ÿßÿ¶Ÿáÿß ÿπŸÇŸÑŸä ÿ∑ŸàÿßŸÑ ÿßŸÑÿ≥ÿßÿπÿ™ŸäŸÜ ÿßŸÑÿ™Ÿä ŸÇÿ∂ÿßŸáŸÖ ÿ®ÿ¨ÿßŸÜÿ®Ÿä Ÿäÿµÿ±ÿÆ ÿ®ÿµŸàÿ™ ÿπÿßŸÑŸä ÿ£ÿπŸÑŸä ŸÖŸÜ ÿ±ŸàŸÜŸä ŸÉŸàŸÑŸÖÿßŸÜ ÿ®ÿ¥ŸÉŸÑ ŸÖÿ±Ÿäÿ® ÿ®ÿ±ÿ∫ŸÖ ÿ£ŸÜ ÿßŸÑÿßÿ´ŸÇÿßŸÑ ÿßŸÑÿ™Ÿä Ÿäÿ™ŸÖÿ±ŸÜ ÿ®Ÿáÿß ŸÇÿ±Ÿäÿ®ÿ© ÿ¨ÿØÿß Ÿàÿ£ÿ≠ŸäÿßŸÜÿß ÿ£ŸÇŸÑ ŸÖŸÜ ÿßŸÑÿ™Ÿä ÿ£ÿ™ŸÖÿ±ŸÜ ÿ®Ÿáÿß Ÿà ÿ™ÿπÿßŸÖŸÑŸá ŸÖÿπ ÿßŸÑÿ£Ÿàÿ≤ÿßŸÜ ÿ∫ÿ±Ÿäÿ® ÿ®ÿ≠ŸÇ Ÿäÿ±ŸÅÿπ ÿßŸÑÿ®ÿßÿ± ÿßŸÑÿ≠ÿØŸäÿØŸä ŸÑÿ£ÿπŸÑŸä ŸàŸäÿ≥ŸÇÿ∑Ÿá ÿπŸÑŸä ÿßŸÑÿ£ÿ±ÿ∂ ÿ®ŸÇŸàŸá ŸàŸÑÿØŸäŸá ŸáŸàÿ≥ ÿ®ÿßŸÑÿµÿ±ÿßÿÆ ŸàÿßŸÑÿ™ŸÉÿ≥Ÿäÿ± ÿ≠ÿ™Ÿä ÿ£ŸÜ ŸÖŸÜ Ÿäÿ®ÿπÿØŸá ÿØŸàÿ±ŸäŸÜ Ÿäÿ≥ÿ™Ÿäÿ∑ÿπ ÿ≥ŸÖÿßÿπÿ© ŸàŸÖŸÜ Ÿäÿ≥ŸÉŸÜ ŸÅŸä ÿßŸÑÿØŸàÿ± ÿßŸà ŸäŸÖÿ¥Ÿä ŸÅŸä ÿßŸÑÿ¥ÿßÿ±ÿπ ŸàŸÜÿ≠ŸÜ ŸÅŸä ÿßŸÑÿØŸàÿ± ÿßŸÑ3 Ÿäÿ≥ÿ™ÿ∑Ÿäÿπ ÿ≥ŸÖÿßÿπÿ© ÿ®ÿµŸàÿ™ Ÿàÿßÿ∂ÿ≠ ŸÅŸäÿßÿ™ÿ±Ÿä ŸÖÿßŸáŸà ŸÖÿµÿØÿ± ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸàÿßŸÑŸÖÿ≠ÿ±ŸÉ ŸÑŸáÿ∞Ÿá ÿßŸÑÿ£ŸÅÿπÿßŸÑ ÿßŸÑÿ™Ÿä ŸÑŸÖ ÿ™ÿ≥ÿ™ÿ∑Ÿäÿπ ŸÉŸÑŸÖÿßÿ™Ÿä ŸàÿµŸÅ ÿßŸÑŸáŸÖÿ¨Ÿäÿ© Ÿà ÿßŸÑÿ•ÿ≤ÿπÿßÿ¨ ÿßŸÑŸÖÿ®ÿ™ÿ∞ŸÑ ÿßŸÑŸäŸàŸÖ\n\n\nÿßŸÑÿ¨ÿßŸÖÿπÿ©\nŸäÿ≠ÿ∂ÿ±ŸÜŸä ÿ∞ŸÉÿ± ŸÖÿ´ÿßŸÑŸäŸÜ ŸÖŸÜÿ™ÿ¥ÿ±ŸäŸÜ ÿ∑ÿßŸÑÿ® ÿßŸÑÿ•ÿ™ÿ≠ÿßÿØ ÿßŸà ÿßŸÑÿ£ŸÜÿ¥ÿ∑ÿ© ÿßŸÑÿ∑ÿßŸÑÿ®Ÿäÿ© ÿßŸÑŸÉÿ´Ÿäÿ±Ÿá\n\nÿ•ÿ™ÿ≠ÿßÿØ ÿßŸÑÿ∑ŸÑÿ®ÿ© ŸàÿßŸÑÿ£ŸÜÿ¥ÿ∑ÿ© ÿßŸÑÿ∑ŸÑÿßÿ®Ÿäÿ©\nÿ∞ŸÑŸÉ ÿßŸÑÿ∑ŸÑÿßÿ® ÿµÿßÿ≠ÿ® ÿßŸÑÿ®ÿØŸÑÿ© ÿßŸÑÿ£ŸÜŸäŸÇÿ© ŸàÿßŸÑÿ•ÿ®ÿ™ÿ≥ÿßŸÖÿ© ÿßŸÑÿπÿ±Ÿäÿ∂ÿ© ÿßŸÑÿ∞Ÿä Ÿäÿ¥ÿ∫ŸÑ ŸÜŸÅÿ≥Ÿá ŸÅŸä ÿßŸÑÿ•ÿ≠ÿ™ŸÅÿßŸÑÿßÿ™ ŸàÿßŸÑÿ™ŸÜÿ∏ŸäŸÖÿßÿ™ ŸàÿßŸÑŸÖŸÖÿßÿ±ÿ≥ÿßÿ™ ÿßŸÑÿ•ÿ¨ÿ™ŸÖÿßÿπŸäÿ© ÿßŸÑŸÉÿ´Ÿäÿ± Ÿàÿ™ŸÜÿ∏ŸäŸÖ ÿßŸÑŸÜÿØŸàÿßÿ™ ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑŸÜŸÅÿßŸÇ (ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿßŸÑŸàÿßŸÇÿπ ÿßŸÑÿ¨ÿßŸÖÿπŸä ŸÑÿπÿßŸÖ 2024) ÿßŸÑÿ£ŸÖÿ± Ÿäÿ¥ÿ®Ÿá ŸÖÿ≥ÿ±ÿ≠Ÿäÿ© ÿ≥ÿÆŸäŸÅÿ© Ÿäÿµÿ®ÿ≠ ŸÅŸäŸáÿß Ÿáÿ∞ÿß ÿßŸÑÿ∑ÿßŸÑÿ® ÿßŸÑÿ®ÿßÿ¶ÿ≥ Ÿäÿ±ŸÇÿµ ÿπŸÑŸä Ÿáÿ∞ÿß ÿßŸÑŸÖÿ≥ÿ±ÿ≠ ÿßŸÑŸÖÿ≤ŸäŸÅ ŸàŸäÿ∏ŸÜ ÿ£ŸÜŸá ÿ®ÿ∑ŸÑ ÿßŸÑŸÅŸäŸÑŸÖ Ÿàÿ≥ŸàŸÅ ŸäŸÜÿ™ÿµÿ± ŸÅŸä ÿßŸÑŸÜŸáÿßŸäÿ© ŸàŸÑŸÉŸÜ ŸÉŸÑ ÿßŸÑŸÖÿπÿ™ÿ∑Ÿäÿßÿ™ ÿ™ÿµÿ±ÿ≠ ÿ®ÿ£ŸÜŸá ŸÖŸáÿ±ÿ¨ ÿ®ÿ•ŸÖÿ™Ÿäÿßÿ≤ ŸàŸäÿÆÿßÿØÿπ ŸÜŸÅÿ≥Ÿá.\n\n\nÿ£ÿ∞ŸÉŸä ÿ¥ÿÆÿµ ŸÅŸä ÿπÿßŸÑŸÖŸá\n\n\n\ntarget\n\n\nÿ∞ŸÑŸÉ ÿßŸÑÿ≤ŸÖŸäŸÑ ÿßŸÑÿ∞Ÿä ÿ™ÿ¨ÿØÿ© Ÿäÿ≠ÿßŸàŸÑ ÿ®ÿ•ÿ≥ÿ™ŸÖÿ±ÿßÿ± ÿ£ŸÜ Ÿäÿ´ÿ®ÿ™ ŸÑŸÉ ÿ£ŸÜŸá ÿ£ÿ∞ŸÉŸä ŸÖŸÜŸÉ Ÿàÿ£ÿ∞ŸÉŸä ŸÖŸÜ ÿ£Ÿä ÿ£ÿ≠ÿØ ŸÅŸä ÿßŸÑÿ∫ÿ±ŸÅÿ© ŸàÿπŸÑŸä ÿ®ÿπÿØ 100 ŸÉŸäŸÑŸà ŸÖÿ™ÿ± ŸÖŸÜ ŸÖÿ±ŸÉÿ≤ ŸàŸÇŸàŸÅŸá.\nÿ∞ŸÑŸÉ ÿßŸÑÿ≤ŸÖŸäŸÑ ŸäŸÜÿπŸÖÿ≥ ŸÅŸä ÿµŸàÿ™ ÿßŸÑÿ£Ÿäÿ¨Ÿà ÿßŸÑÿ∞Ÿä ÿ®ÿØÿßÿÆŸÑŸá ŸÅÿ™ÿ¨ÿØŸá ŸäŸÜÿπÿ±ŸÅ ÿπŸÜ ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿµÿ≠Ÿäÿ≠Ÿá ŸÑÿ™ÿ≠ÿµŸäŸÑ ÿßŸÑÿπŸÑŸÖ ÿ®ÿ¥ŸÉŸÑ ÿ±ÿ£ÿ≥Ÿä Ÿàÿ£ŸÅŸÇŸä ÿ®ÿ™Ÿàÿßÿ≤ŸÜ ÿ≠ŸÇŸäŸÇŸä ŸÑŸäÿµŸÑ ÿßŸÑŸä ŸÖÿ±ÿ≠ŸÑÿ© ŸÖŸÜ ÿ•ÿ™ŸÇÿßŸÜ ÿßŸÑÿπŸÑŸÖ Ÿà ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸä Ÿàÿ∏ŸäŸÅÿ© ŸÖÿ±Ÿäÿ≠ÿ© ŸÉŸÖ ÿ£ÿ¥ÿπÿ± ÿ®ÿßŸÑÿ≠ÿ≤ŸÜ ÿπŸÑŸäŸá ŸÅŸÑÿØŸäŸá ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿ∑ÿßŸÇÿ© ŸàŸÑŸÉŸÜŸá Ÿäÿ≥ÿ™ÿ∫ŸÑŸáÿß ÿ®ÿ¥ŸÉŸÑ ÿ±ÿ®ŸÖÿß ŸäŸÉŸàŸÜ ÿÆÿßÿ∑ÿ¶ Ÿà ŸÖÿ§ŸÉÿØ ÿ£ŸÜŸá ŸÖÿ≤ÿπÿ¨ ÿ£Ÿäÿ∂ÿß!\nÿßŸÑŸÖÿ§ÿ≥ŸÅ ÿßŸÜŸá ÿ®ÿπÿØ ŸÖÿ±Ÿàÿ± ÿ®ÿπÿØ ÿßŸÑŸàŸÇÿ™ Ÿäÿ®ÿØÿß ŸÉŸÑ ÿ¥ÿÆÿµ ŸÖŸÜÿß ŸÅŸä ÿ¨ŸÖÿπ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÅŸä ÿßŸÑÿ™ÿÆÿµÿµ ÿßŸÑÿ∞Ÿä Ÿäÿπÿ¨ÿ®Ÿá ŸàÿßŸÑÿ•ŸÑÿ™ÿ≠ÿßŸÇ ÿ®Ÿàÿ∏ÿßÿ¶ŸÅ ŸàÿµÿØŸäŸÇŸÜÿß ŸÑÿß Ÿäÿ≤ÿßŸÑ ŸÅŸä ÿ≥ÿ±ÿßÿ® ÿ£ÿ∞ŸÉŸä ÿ¥ÿÆÿµ ŸÅŸä ÿßŸÑÿπÿßŸÑŸÖ ŸàŸÖÿ≠ÿßŸàŸÑÿßÿ™Ÿá ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ±Ÿá ÿ®ÿØŸàŸÜ ŸÇÿµÿØ ŸÑÿ™ÿ®ŸäÿßŸÜ ÿ∞ŸÑŸÉ ÿ£ÿµÿ®ÿ≠ÿ™ ŸÖÿ≤ÿπÿ¨ÿ© Ÿàÿ£ÿµÿ®ÿ≠ÿ™ ŸÖÿπÿ±ŸÅÿ™Ÿá ÿßŸÑÿ™Ÿä ÿ£ŸÉÿ´ÿ±Ÿáÿß ÿ£ŸÅŸÇŸäÿ© ŸÖÿµÿØÿ± ÿ•ÿ≤ÿπÿßÿ¨ ŸàŸÜŸàÿπ ŸÖŸÜ ÿ£ŸÜŸàÿßÿπ ÿßŸÑÿ™ÿ®ÿßŸáŸä ÿßŸÑŸÖÿ´Ÿäÿ± ŸÑŸÑÿ¥ŸÅŸÇÿ© ŸàÿßŸÑÿ∫ÿ∂ÿ® ÿ£ÿ≠ŸäÿßŸÜÿß! ŸäŸÖŸÉŸÜ ÿßŸÑÿ™ŸÅŸÉŸäÿ± ŸÅŸä ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ•Ÿäÿ¨Ÿà ÿπŸÑŸäŸÉ ŸàÿÆÿØÿßÿπŸÉ ŸÑŸÜŸÅÿ≥ŸÉ ŸÅŸä ÿßŸÑÿ≠ÿßŸÑŸäÿ™ŸÜ ŸàÿßŸÑÿ™ŸÅÿµŸäŸÑ ŸÉÿ´Ÿäÿ± ŸàŸÑŸäÿ≥ ÿßŸÑÿ∫ÿ±ÿ∂ ÿßŸÑÿ™ÿπŸÖŸäŸÖ.\nŸÖŸÇÿ™ÿ±ÿ≠ÿßÿ™ ŸÑŸÑÿÆÿ±Ÿàÿ¨ ŸÖŸÜ Ÿáÿ∞ÿß ÿßŸÑŸÅÿÆ\n\nÿ±ÿßŸÇÿ® ŸàŸÇÿ™ŸÉ ÿπŸÑŸä Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ ÿßŸÑÿ£ÿ¨ÿ™ŸÖÿßÿπŸä ŸàŸÑŸäÿ≥ ÿßŸÑŸÖŸÇÿµÿØ ŸÉŸÖ ÿ™ÿ¨ŸÑÿ≥ ÿπŸÑŸä Ÿáÿ∞Ÿá ÿßŸÑŸÖŸÜÿµÿßÿ™ ŸàŸÑŸÉŸÜ ÿ£ŸÜÿ∏ÿ± ÿßŸÑŸä ÿ™ÿπŸÑŸÇŸäÿßÿ™ŸÉ Ÿà ŸÖŸÜÿ¥Ÿàÿ±ÿßÿ™ŸÉ ÿ≥ÿ™ÿ¨ÿØ ÿ£ŸÜ ÿ£ŸÉÿ´ÿ± ÿ¥ÿÆÿµ ÿ™ÿ™ÿ≠ÿØÿ´ ÿπŸÜŸá ÿ®ÿ¥ŸÉŸÑ ÿµÿ±Ÿäÿ≠ ÿ£Ÿà ÿÆŸÅŸä ŸáŸà ŸÉŸÖ ÿ£ŸÜÿ™ ÿπÿ®ŸÇÿ±Ÿä Ÿàÿ™ŸÅŸáŸÖ ŸÖÿß ŸÑÿßŸäŸÅŸáŸÖŸá ÿßŸÑÿ£ÿÆÿ±ŸäŸÜ! ŸÉŸÖ ÿ£ŸÜÿ™ ÿ∞ŸÉŸä! ÿ≥ÿ™ÿ¨ÿØŸÉ ŸÖÿ™ŸÇŸàŸÇÿπ ÿπŸÑŸä ÿ∞ÿßÿ™ŸÉ!\nÿßŸÑÿ•ŸÜÿ≥ÿ≠ÿßÿ® ŸÖŸÜ ŸÖÿ±ÿßŸÇÿ®ÿ© Ÿà ÿ£ÿπŸäŸÜ ÿßŸÑŸÜÿßÿ≥ Ÿà ŸÖÿ≠ÿßÿ≥ÿ®ÿ© ÿßŸÑŸÜŸÅÿ≥ ÿ®ÿ¥ŸÉŸÑ ÿ£ŸÉÿ´ÿ± ÿ≠ÿ≤ŸÖ Ÿà ÿßŸÑÿ£ŸÜÿ≥ÿ≠ÿßÿ® ŸáŸÜÿß ŸÖŸÇÿµŸàÿØ ÿ®Ÿá Ÿàÿ≥ÿßÿ¶ŸÑ ÿßŸÑÿ™ŸàÿßÿµŸÑ Ÿà ÿßŸÑÿ™ÿ¨ŸÖÿπÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ÿ∏Ÿáÿ± ŸÅŸäŸá ÿ™ŸÑŸÉ ÿßŸÑÿ£ŸÅÿπÿßŸÑ ŸÖÿ´ŸÑ ŸÖÿ∞ÿßŸÉÿ±ÿ™ŸÉ ŸÅŸä ŸÜŸÅÿ≥ ÿ∫ÿ±ŸÅÿ© ÿßŸÑÿ≥ŸÉŸÜ ÿßŸÑÿ¨ÿßŸÖÿπŸä ÿ£ŸÖÿßŸÖ ÿ£ÿµÿØŸÇÿßÿ¶ŸÉ Ÿà ÿ≥ÿ§ÿßŸÑŸÉ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ± ŸÑŸÑÿ£ÿÆÿ±ŸäŸÜ ŸáŸÑ ÿ™ÿπÿ±ŸÅ ŸÖÿßŸáŸä ŸÜÿ∏ÿ±Ÿäÿ© ÿßŸÑŸáÿ™ŸàÿßŸÜÿß ŸÖÿ∑ÿßÿ∑ÿß ! Ÿà ÿØÿπŸÜŸä ÿ£ÿ¥ÿ±ÿ≠ ŸÑŸÉ ŸÉŸÖ ÿµÿπŸàÿ®ÿ© Ÿáÿ∞Ÿá ÿßŸÑŸÜÿ∏ÿ±Ÿäÿ© Ÿàÿπÿ®ŸÇÿ±Ÿäÿ™Ÿáÿß ..ÿßŸÑÿÆ\nŸÑÿß ÿ™ÿ™ÿ±ŸÉ ÿ•ÿ¥ÿßÿ±ÿßÿ™ ŸÑŸÑÿßÿÆÿ±ŸäŸÜ ŸÖÿ´ŸÑ ÿßŸÑÿßŸáÿ™ŸÖÿßŸÖ ÿßŸÑÿ≤ÿßÿ¶ÿØ ÿ®ÿ≠ÿßŸÑÿßÿ™ ÿßŸÑŸàÿßÿ™ÿ≥ ŸàÿßŸÑÿ™ŸäŸÑŸäÿ¨ÿ±ÿßŸÖ Ÿàÿ•ÿ∏Ÿáÿßÿ± ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ± ŸÑŸÖÿßÿ∞ÿß ÿ™ŸÅÿπŸÑ ŸÖÿ´ŸÑ ÿØŸäÿ≥ŸÉŸàÿ±ÿØ ŸàÿßŸÑÿ£ÿ∫ÿßŸÜŸä ÿßŸÑÿ™Ÿä ÿ™ÿ≥ÿ™ŸÖÿπ ŸÑŸáÿß\n\n\n\n\nŸáŸàÿ≥ ÿßŸÑÿ¨ŸÖÿßŸÑ\nŸáŸàÿ≥ ÿßŸÑÿ¨ŸÖÿßŸÑ ÿ™ŸÑŸÉ ÿßŸÑŸÅÿ™ÿßÿ© ÿßŸÑÿ™Ÿä ŸÉŸÑ ÿ•Ÿáÿ™ŸÖÿßŸÖŸáÿß ŸáŸà ÿ¨ŸÖÿßŸÑŸáÿß ŸàÿßŸÑÿ¨ŸÖÿßŸÑ ŸàÿßŸÑÿ´ÿ±Ÿàÿ© ŸàÿßŸÑŸÖÿßŸÑ ÿ™ÿ¨ÿØ ÿ£ŸÜŸá ŸÖŸáŸàÿ≥ÿ© ÿ®ÿßŸÑÿ¨ÿßŸÜÿ® ÿßŸÑÿ®ÿµÿ±Ÿä ÿπŸÜÿØŸáÿß ÿ®ÿ¥ŸÉŸÑ Ÿäÿ¨ÿπŸÑŸÉ ÿ™ÿ∏ŸÜŸáÿß ŸÖÿßŸÉŸäÿ™ ŸÖÿÆŸäŸÅ ŸÖŸÜ ÿßŸÑÿ•ŸÜÿ¨ÿ∞ÿßÿ® ŸÑŸÑŸÖÿßÿØŸäÿßÿ™ ÿ®ÿ¥ŸÉŸÑ Ÿäÿ∑ÿ∫Ÿä ÿπŸÑŸä ÿ¨ŸÖÿßŸÑŸáÿß ŸÉÿ£ŸÜÿ´Ÿä ŸäÿµŸÑ ÿßŸÑÿ£ŸÖÿ± ÿßŸÑŸä ÿ•ŸÑÿ∫ÿßÿ° ÿßŸÑŸáÿßŸÑÿ© ÿßŸÑŸÖÿ≠Ÿäÿ∑ÿ© ÿ®Ÿáÿß ŸÉÿ£ŸÖ ÿ£Ÿà ÿ≤Ÿàÿ¨ÿ© ÿ£Ÿà ŸÅÿ™ÿßÿ© ÿπŸÖŸàŸÖÿß ÿ™ÿ¥ÿπÿ±.\nŸÖÿ¥ÿßŸáÿØÿ© ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÖ ŸàÿßŸÑÿ™ŸäŸÉ ÿ™ŸàŸÉ ÿ®ÿ¥ŸÉŸÑ ŸÖŸÉÿ´ŸÅ ŸàŸÖÿ≠ÿßŸàŸÑÿ© ÿ™ŸÇŸÑŸäÿØ ÿßŸÑÿ™ÿ±ŸÜÿØÿßÿ™ ŸàÿßŸÑŸÖÿ¥ÿßŸáŸäÿ± ŸàÿßŸÑÿ•ŸÜÿ∫ŸÖÿßÿ≥ ŸÅŸä ÿ£ÿÆÿ®ÿßÿ±ŸáŸÖ‚Ä¶ ÿ®ÿπÿØ ŸÖÿ±Ÿàÿ± ÿ®ÿπÿ∂ ÿßŸÑŸàŸÇÿ™ ÿ™ÿ¨ÿØ ÿ£ŸÜŸÉ ÿßŸÖÿßŸÖ ŸÅÿ™ÿßÿ© ŸÑÿß ÿ™ÿØÿ±Ÿä ÿ£Ÿä ÿ¥ÿ¶ ÿπŸÜ ŸÉŸàŸÜŸáÿß ŸÅÿ™ÿßÿ© ÿ∫Ÿäÿ± ÿ¨ÿ≥ÿØŸáÿß Ÿàÿ¨ŸÖÿßŸÑŸáÿß ÿ≠ÿ™Ÿä Ÿáÿ∞ÿß ŸäÿµŸÑ ÿ®ÿ¥ŸÉŸÑ ÿÆÿßÿ∑ÿ¶Ÿä.\n\n\nÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÇ ÿßŸÑÿ≥Ÿäÿßÿ≥Ÿä ŸàÿßŸÑŸÖÿ¨ÿßÿ±Ÿäÿßÿ™\nŸäŸÉÿ´ÿ± ŸÅÿÆ ÿßŸÑÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸáŸÜÿß ŸÅŸä ÿßŸÑÿ•ÿ≥ÿ™ÿ∫ÿ±ÿßŸÅ ÿßŸÑÿ≥Ÿäÿßÿ≥Ÿä ŸÑŸÉ ŸÉÿ£ÿ® Ÿàÿ™ŸÇÿµŸäÿ±ŸÉ ŸÅŸä ÿ™ÿ±ÿ®Ÿäÿ© ÿ£ŸàŸÑÿßÿØŸÉ ÿßŸà ÿ≤ŸäÿßÿØÿ© ÿØÿÆŸÑŸÉ Ÿà ÿ≥ÿØ ÿ±ŸÖŸÇ ÿ®Ÿäÿ™ŸÉ!"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿ£ŸäŸÜ-ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©",
    "href": "blog/posts/life_style/fake_graviety.html#ÿ£ŸäŸÜ-ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿ£ŸäŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©ÿü",
    "text": "ÿ£ŸäŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©ÿü\nÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸÑŸäÿ≥ÿ™ ŸÅŸä ÿßŸÑÿ£ŸÜÿ¨ÿ∞ÿßÿ® ŸÑÿ¥ÿ¶ ŸÅŸáÿ∞ÿß ŸÖÿ≥ÿ™ÿ≠ŸäŸÑ ÿ≠ÿØŸàÿ´Ÿá ŸÑŸÉŸÜ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ŸáŸÑ ÿ£ŸÜÿß ŸÅÿπŸÑÿß ÿ£ÿ≥Ÿäÿ± ŸÅŸä ÿßŸÑŸÖÿØÿßÿ± ÿßŸÑÿµÿ≠Ÿäÿ≠ ÿßŸÑÿ∞Ÿä Ÿäÿ™ŸÅŸÇ ŸÖÿπ ÿßŸÑÿ∫ÿßŸäÿ© ÿßŸÑŸÉÿ®ÿ±Ÿä ÿ®ÿ£ŸÅÿ∂ŸÑ ÿ¥ŸÉŸÑ ŸÖŸÖŸÉŸÜ ŸàŸáŸÑ ÿ™Ÿàÿ¨ÿØ ŸÖÿ≠ÿßŸàŸÑÿ© ÿßŸÑÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ± ÿ£ŸÖ ÿ£ŸÜŸÉ ÿ™ÿ™ÿ±ŸÉŸáÿß ŸÑŸÑÿ∏ÿ±ŸàŸÅ Ÿàÿ™ŸÑÿπÿ® ÿØŸàÿ± ÿßŸÑŸÖŸÅÿπŸàŸÑ ÿ®Ÿá! ŸáŸÑ ŸÅÿπŸÑÿß ÿ®ÿπÿØ ÿ∞Ÿáÿßÿ® ÿßŸÑÿπŸÖÿ± ŸáŸÑ Ÿáÿ∞ÿß ŸáŸà ŸÖÿß ŸÉŸÜÿ™ ÿ™ŸàÿØ ÿ£ŸÜŸÉ ÿ£ŸÖÿ∂Ÿäÿ™ ŸÅŸäŸá ÿπŸÖÿ±ŸÉ! ÿßŸÑÿÆÿ∑ÿ± ŸäŸÉŸÖŸÜ ÿ£ŸÜ Ÿáÿ∞ÿß ŸÉŸÑŸá Ÿäÿ≠ÿØÿ´ ŸÖŸÜ ÿ¥ÿØ Ÿàÿ¨ÿ∞ÿ® ÿ®ÿØŸàŸÜ ÿ£ŸÜ ÿ™ÿ™ÿØÿ±ŸÉ ŸÅŸä ÿ£Ÿä ŸÅÿ∂ÿßÿ° ÿµÿßÿ± ŸÇŸÖÿ±ŸÉ."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ≠Ÿäÿßÿ©-ÿπŸÑŸä-ÿßŸÑÿ£ÿ±ÿ∂",
    "href": "blog/posts/life_style/fake_graviety.html#ÿ¨ÿßÿ∞ÿ®Ÿäÿ©-ÿßŸÑÿ≠Ÿäÿßÿ©-ÿπŸÑŸä-ÿßŸÑÿ£ÿ±ÿ∂",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ≠Ÿäÿßÿ© ÿπŸÑŸä ÿßŸÑÿ£ÿ±ÿ∂",
    "text": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ≠Ÿäÿßÿ© ÿπŸÑŸä ÿßŸÑÿ£ÿ±ÿ∂\nÿ∑ÿπÿßŸÖ ÿßŸÑÿ±Ÿàÿ≠ : ŸÉŸÖÿß ÿ£ŸÜ ÿßŸÑÿ¨ÿ≥ÿØ ŸÑŸá ÿ∫ÿ∞ÿßÿ°ÿ© ŸÅÿßŸÑÿ¨ÿ≥ÿØ ÿÆŸÑŸÇ ŸÖŸÜ ÿ∑ŸäŸÜ ÿ™ÿ¨ÿØ ÿ£ŸÜ ÿ±Ÿàÿ≠ŸÉ ÿ™ÿ´ŸÇŸÑ Ÿàÿ™ÿ≤ÿØÿßÿØ ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿØŸÜŸäÿß Ÿàÿ¥ŸáŸàÿßÿ™Ÿáÿß ŸÑŸÉ Ÿà ŸÉÿ∞ŸÑŸÉ ŸÅÿ±Ÿàÿ≠ŸÉ ŸÑŸáÿß ÿ∫ÿ∞ÿßÿ° ŸàŸáŸà ÿßŸÑÿ∞ŸÉÿ± ŸÅÿßŸÑÿ∞ŸÉÿ± ÿ∫ÿ∞ÿßÿ° ÿ±Ÿàÿ≠ŸÉ ŸÉŸÑŸÖÿß ÿ£ŸÉÿ´ÿ±ÿ™ ŸÖŸÜŸá ÿßÿ±ÿ™ŸÅÿπÿ™ ÿ±Ÿàÿ≠ŸÉ ÿßŸÑŸä ÿßŸÑÿ£ÿπŸÑŸä ŸàÿÆŸÅÿ© ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿ±ÿ∂ ŸÑŸÉ.\nÿßŸÑŸáÿØŸÅ ÿßŸÑÿ≠ŸÇŸäŸÇŸä: ÿßŸÑŸáÿØŸÅ ÿ£ŸÜ ÿ™ÿØŸàÿ± ŸÅŸä ÿßŸÑŸÖÿØÿßÿ± ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸàÿßŸÑÿ£ŸÖŸÜ ŸàŸÑÿß ÿ™ÿ∫ÿ±ŸäŸÉ ÿßŸÑŸÖŸÖÿ±ÿßÿ™ ÿßŸÑŸÇÿµŸäÿ±ÿ© ÿßŸÑÿ≥ÿ±Ÿäÿπÿ© ÿßŸÑÿ™Ÿä ÿ™ŸÜÿ≠ÿ±ŸÅ ÿ®ŸÉ ŸäŸäŸÖŸäŸÜ ŸàŸäŸäÿ≥ÿßÿ± ÿßŸÑŸáÿØŸÅ ÿ£ŸÜ ŸäŸÉŸàŸÜ ÿ≥Ÿäÿ±ŸÉ ÿßŸÑŸä ÿßŸÑŸÖŸàŸÑŸä ÿπÿ≤Ÿàÿ¨ŸÑ Ÿàÿ∞ŸÑŸÉ ŸÑŸÜ Ÿäÿ™ŸÖ ÿßŸÑÿ• ÿ®ŸÖÿπÿ±ŸÅÿ© ŸÖÿß Ÿäÿ¨ÿ∞ÿ®ŸÉ ŸàŸäÿπÿ®ÿØŸÉ ÿπŸÜ ÿßŸÑŸÖÿ≥ÿßÿ± Ÿàÿ™ÿ¨ÿØŸäÿØ ÿßŸÑŸÜŸäÿ© ÿßŸÑÿØÿßÿ¶ŸÖ ŸàÿßŸÑÿ™Ÿàÿ¨Ÿáÿ© ÿßŸÑŸä ÿ±ÿ®ŸÉ. ÿ£ÿ≠ÿ® ÿßŸÜ ÿßÿ≥ŸÖŸäŸá ÿ•ÿ≥ÿ™ÿπÿßÿØÿ© ÿßŸÑŸÖÿ±ŸÉÿ≤ Ÿàÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ®ŸàÿµŸÑÿ© Ÿà ÿ£ŸÉÿ´ÿ± ŸÖŸÉÿßŸÜ ÿ£ÿ¨ÿØ ŸÜŸÅÿ≥Ÿá ŸÅŸäŸá ŸáŸà ÿ•ŸÖÿß ŸÅŸä ÿµŸÑÿßÿ© ÿµÿßÿØŸÇÿ© ŸÅŸä ÿ¨ŸàŸÅ ÿßŸÑŸÑŸäŸÑ ŸÖÿπ ÿØÿπÿßÿ° ŸÖÿ®ÿ™ŸáŸÑ ÿ£Ÿà ŸÅŸä ÿµŸÑÿßÿ© ÿ¨ŸÖÿßÿπÿ© ŸÖÿ®ŸÉÿ±ÿ© ŸáÿßÿØÿ¶ÿ©. ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑÿ≠ÿ∏ÿ© ÿ™ÿ¨ÿØ ÿßŸÑÿ≥ŸÉŸäŸÜÿ© ŸÅŸä ŸÇŸÑÿ®ŸÉ Ÿàÿ™ŸáÿØÿ¶ ŸÉŸÑ ÿßŸÑÿπŸàÿßÿµŸÅ. ÿßŸÑŸÑŸáŸÖ ÿ£ÿπŸÜÿß ÿπŸÑŸä ÿ∞ŸÉÿ±ŸÉ Ÿàÿ¥ŸÉÿ±ŸÉ Ÿàÿ∑ÿßÿπÿ™ŸÉ Ÿàÿ≠ÿ≥ŸÜ ÿπÿ®ÿßÿØÿ™ŸÉ."
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ŸÖÿ∫ÿØÿßÿ±ÿ©-ÿßŸÑŸÖÿØÿßÿ±",
    "href": "blog/posts/life_style/fake_graviety.html#ŸÖÿ∫ÿØÿßÿ±ÿ©-ÿßŸÑŸÖÿØÿßÿ±",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ŸÖÿ∫ÿØÿßÿ±ÿ© ÿßŸÑŸÖÿØÿßÿ±",
    "text": "ŸÖÿ∫ÿØÿßÿ±ÿ© ÿßŸÑŸÖÿØÿßÿ±\nÿ®ÿπÿ∂ ÿßŸÑÿ≠ŸÑŸàŸÑ ÿßŸÑÿ™Ÿä ŸÖÿßÿ≤ÿßŸÑÿ™ ŸÖÿ≠ŸÑ ÿßŸÑÿ®ÿ≠ÿ´ ŸàÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ©.\n\nÿ≥ŸÑ ŸÜŸÅÿ≥ŸÉ ŸÖÿßŸáŸà ÿßŸÑŸÖÿ≠ÿ±ŸÉ ÿßŸÑÿ≠ŸÇŸäŸÇŸä ŸÑŸáÿ∞ÿß ÿßŸÑŸÅÿπŸÑ ÿßŸà ÿßŸÑŸÖŸáŸÖÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ© Ÿàÿ®ÿ£Ÿä ŸÜŸäÿ© ÿ£ŸÅÿπŸÑŸáÿß\nŸÖÿßŸáŸä ÿßŸÑŸÖÿ¥ÿßÿπÿ± ÿßŸÑŸÖÿ≠ÿ±ŸÉÿ© ŸÑŸáÿ∞ÿß ÿßŸÑÿπŸÖŸÑ ŸàŸÖŸÜ ŸáŸà ŸÖÿµÿØÿ±Ÿáÿß ŸáŸÑ ŸáŸÖ ÿßŸÑÿ£ŸáŸÑ ÿ£ŸÖ ŸÅÿ™ÿßÿ© ÿ£ŸÖ ŸÉŸÑŸÖÿ© ŸÇÿßŸÑŸáÿß ÿßÿ≠ÿØ ŸÖÿß ŸàŸÜÿ≥Ÿä ŸÖÿß ŸÇÿßŸÑ!\nŸáŸÑ ÿ™ÿ≥ÿ™ÿ≠ŸÇ ŸÉŸÑ Ÿáÿ∞ÿß ÿßŸÑŸàŸÇÿ™ ŸàÿßŸÑŸÖÿ¨ŸáŸàÿØ ŸÅŸáÿ∞ÿß ÿßŸÑÿ±ÿµŸäÿØ ŸÖŸÜ ÿπŸÖÿ±Ÿä ÿßŸÑÿ∞Ÿä ŸÑÿß ŸäÿπŸàÿ∂!\nŸáŸÑ ŸáŸä ÿ≠ŸÇÿß ÿ™ŸÇÿπ ŸÅŸä ÿ®ÿßÿ® ÿ£ŸáŸÖ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ÿßŸÑÿ™Ÿä Ÿäÿ¨ÿ® ÿßŸÜ ÿßŸÅÿπŸÑŸáÿß ÿßŸÖ ŸáŸä ÿ¥Ÿàÿßÿ∫ŸÑ ÿ™ÿπÿ™ÿ±ÿ∂ ÿßŸÑÿ∑ÿ±ŸäŸÇ\nŸÖÿ™ÿßÿ®ÿπÿ© ÿßŸÑŸàŸÇÿ™ ÿ®ŸÅÿπÿßŸÑŸäÿ© ŸÖŸÜ ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑŸÖŸÇÿ™ÿ±ÿ≠ÿ© ŸÑŸáÿ∞ÿß :\n\nActionDash\nActivityWatch\nFocus Todo\n\n\nŸÖŸÇŸàŸÑÿ© ŸÖŸÖŸäÿ≤ÿ© ŸÖŸÜ ‚ÄúÿØ/ÿπÿ®ÿØ ÿßŸÑÿ±ÿ≠ŸÖŸÜ ÿßŸÑŸÖÿ≥Ÿäÿ±Ÿä‚Äù\n\nŸàŸÅŸä ÿßŸÑÿ±Ÿäÿßÿ∂ ÿ™ŸÅÿ±ÿ∫ÿ™ ÿ™ŸÖÿßŸÖÿß ŸÑŸÑŸÖŸàÿ≥Ÿàÿπÿ© ..ÿå ŸàŸÉŸÜÿ™ ÿ£ÿ≠ÿ±ÿ± ÿ®ÿßÿ®ÿß ÿ£ÿ≥ÿ®ŸàÿπŸäÿß ÿ®ÿπŸÜŸàÿßŸÜ ‚Äúÿ•ÿ≥ÿ±ÿßÿ¶ŸäŸÑŸäÿßÿ™ ŸÖÿπÿßÿµÿ±ÿ©‚Äù ŸÅŸä ÿ¨ÿ±ŸäÿØÿ© ÿßŸÑÿ±Ÿäÿßÿ∂ÿå ŸàŸÑŸÉŸÜŸä ŸÑÿßÿ≠ÿ∏ÿ™ ÿ£ŸÜ ÿßŸÜÿ¥ÿ∫ÿßŸÑŸä ÿ®ÿßŸÑÿ≠ÿØÿ´ ÿßŸÑŸäŸàŸÖŸä ÿ®ÿØÿ£ ŸäŸÇŸàÿ∂ ŸÖŸÜ ÿ±ÿ§Ÿäÿ™Ÿä ÿßŸÑÿ®ÿßŸÜŸàÿ±ÿßŸÖŸäÿ© ÿßŸÑŸÖŸàÿ≥ŸàÿπŸäÿ©ÿå ÿßŸÑÿ™Ÿä ÿ™ÿ±ŸÉÿ≤ ÿπŸÑŸä ÿßŸÑÿ´Ÿàÿßÿ®ÿ™ÿå ŸàÿßŸÑÿ™Ÿä ÿ™ÿ™ÿ∑ŸÑÿ® ÿ•ŸäŸÇÿßÿπÿß ÿ®ÿ∑ÿ¶ŸäŸãÿßÿå ŸàÿßŸáÿ™ŸÖÿßŸÖŸãÿß ÿ®ŸÖŸàÿ∂Ÿàÿπÿßÿ™ ÿ™ÿßÿ±ŸäÿÆŸäÿ© ŸàŸÅŸÑÿ≥ŸÅŸäÿ© Ÿàÿ¨ŸàÿßŸÜÿ® ÿßÿ≥ÿ™ÿ±ÿßÿ™ÿ¨Ÿäÿ© ÿ±ÿ®ŸÖÿß ŸÑÿß ÿ™ŸÉŸàŸÜ ŸÑŸáÿß ÿπŸÑÿßŸÇÿ© ÿ®ŸÖÿ¥ÿßÿ±ÿ© ÿ®ÿßŸÑÿ≠ÿØÿ´ ÿßŸÑŸäŸàŸÖŸäÿå ŸàŸÑÿ∞ÿß ÿ™ŸàŸÇŸÅÿ™ ÿπŸÜ ÿ™ÿ≠ÿ±Ÿäÿ± Ÿáÿ∞ÿß ÿßŸÑÿ®ÿßÿ®) ÿßŸÑŸÖÿ≥Ÿäÿ±Ÿä ÿ±ÿ≠ŸÑÿ™Ÿä ÿßŸÑŸÅŸÉÿ±Ÿäÿ© ÿµŸÅÿ≠ÿ© 539\n\nI am thinking, then i am not here!"
  },
  {
    "objectID": "blog/posts/life_style/fake_graviety.html#ÿßŸÑŸÜŸáÿßŸäÿ©",
    "href": "blog/posts/life_style/fake_graviety.html#ÿßŸÑŸÜŸáÿßŸäÿ©",
    "title": "ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ",
    "section": "ÿßŸÑŸÜŸáÿßŸäÿ©",
    "text": "ÿßŸÑŸÜŸáÿßŸäÿ©\nŸáÿ∞Ÿá ŸáŸä ŸÖÿ¨ÿ±ÿØ ÿÆŸàÿßÿ∑ÿ± ÿ≥ÿ±Ÿäÿπÿ© ÿ∫Ÿäÿ± ŸÖŸÜÿ≥ŸÇÿ© ŸàŸÇÿØ ÿ™ÿ®ÿØŸà ŸÖÿ™ŸÅÿ±ŸÇŸá ŸÑŸÅÿ™Ÿä ÿ™ÿπÿµŸÅ ÿ®Ÿá ÿßŸÑÿ£ŸÅŸÉÿßÿ± ŸàÿßŸÑŸÖÿ¥ÿßÿπÿ± ŸÅŸä ŸÅÿ™ÿ±ÿ© ÿ¥ÿØŸäÿØÿ© ÿßŸÑÿ™ŸÇŸÑÿ® ŸÅŸÑÿ™ÿØÿπŸàÿß ŸÑŸá ŸàŸÑŸàÿßŸÑÿØŸäŸá Ÿàÿ¨ÿ≤ÿßŸÉ ÿßŸÑŸÑŸá ŸÉŸÑ ÿßŸÑÿÆŸäÿ± ÿ•ŸÜ ÿ£ŸÉŸÖŸÑÿ™ ÿßŸÑŸÇÿ±ÿßÿ°ÿ© üòöüòö"
  },
  {
    "objectID": "blog/posts/life_style/back_to_rss.html",
    "href": "blog/posts/life_style/back_to_rss.html",
    "title": "Getting Back to RSS",
    "section": "",
    "text": "Hi!\nThese are my thoughts on digital minimalism and staying ahead in AI without burning out."
  },
  {
    "objectID": "blog/posts/life_style/back_to_rss.html#the-flood-of-information",
    "href": "blog/posts/life_style/back_to_rss.html#the-flood-of-information",
    "title": "Getting Back to RSS",
    "section": "The Flood of Information",
    "text": "The Flood of Information\nI use Fluent Reader to keep track of the feeds I love, covering topics like machine learning (ML), life, and more.\n\nYesterday, I read an article from Answerdotai about Vision Language Models (VLMs).\nI spent about 15 minutes diving into the ideas and reflecting on how they relate to my recent projects using Colpali and DSE.\nToday, I opened X.com and saw a thread by Benjamin about the same article.\nI skimmed it but couldn‚Äôt recall anything meaningful! There was no real engagement‚Äîjust a fleeting sense of encountering new VLM updates.\nI bookmarked the post, thinking I‚Äôd revisit it for my next project or research idea that could ‚Äúchange my life.‚Äù Spoiler: I probably won‚Äôt."
  },
  {
    "objectID": "blog/posts/life_style/back_to_rss.html#is-twitter-the-best-for-ml-maybe",
    "href": "blog/posts/life_style/back_to_rss.html#is-twitter-the-best-for-ml-maybe",
    "title": "Getting Back to RSS",
    "section": "Is Twitter the Best for ML? Maybe!",
    "text": "Is Twitter the Best for ML? Maybe!\nMy Twitter feed is highly customized, and I use an extension to block distractions.\nYet, every time I open it, I‚Äôm flooded with ideas and AI updates that feel overwhelming.\nIt‚Äôs one reason I struggle to finish projects. While X is great for staying updated and connecting with top minds in the field, it‚Äôs not the only way.\nYou can mention people like Jeremy Howard, Tom Arson, or the Hugging Face team and often get a response within an hour‚Äîpretty cool!\nI deleted my Twitter account last year but created a new one, hoping to earn from the ad system and share my projects.\nHowever, I haven‚Äôt completed a single project I‚Äôm proud to share. Everything‚Äôs still in the early stages.\nI don‚Äôt need X! These feel like flimsy reasons to stay active there. There‚Äôs a way to get the benefits without harming my focus, health, or life."
  },
  {
    "objectID": "blog/posts/life_style/back_to_rss.html#personal-branding-and-linkedin",
    "href": "blog/posts/life_style/back_to_rss.html#personal-branding-and-linkedin",
    "title": "Getting Back to RSS",
    "section": "Personal Branding and LinkedIn",
    "text": "Personal Branding and LinkedIn\nWhat is LinkedIn? It‚Äôs supposed to be your portfolio for job opportunities and personal branding. I‚Äôve tried perfecting my profile, applying for jobs, and sharing work, but I‚Äôve had no offers through LinkedIn. This week, I landed two jobs‚Äîone through a friend‚Äôs referral and another via open-source connections‚Äîwithout LinkedIn‚Äôs help.\nTo me, LinkedIn feels fake. The algorithms are broken, and it‚Äôs become a waste of time. If you want to learn about me, check my CV and website at kareemai.com.\nBy focusing on deep, unique work, I believe I can create my own gravity to attract better opportunities aligned with my interests. Will this work for everyone? Probably not. These are just my thoughts and experiences.\nBy the way, a Hugging Face profile might be better for landing AI jobs if you‚Äôre creating real, impactful work."
  },
  {
    "objectID": "blog/posts/life_style/back_to_rss.html#make-it-hard-for-people-to-reach-you",
    "href": "blog/posts/life_style/back_to_rss.html#make-it-hard-for-people-to-reach-you",
    "title": "Getting Back to RSS",
    "section": "Make It Hard for People to Reach You",
    "text": "Make It Hard for People to Reach You\nAm I going to live in a cave? No! In a recent meeting, a friend jokingly called me ‚Äúour search engine.‚Äù\nI want to stay connected to what matters and gain maximum benefits without fracturing my attention with short posts or inauthentic interactions.\nThere‚Äôs freedom in posting something without expecting comments or reactions. If you like it, great! If not, that‚Äôs fine too. Why didn‚Äôt you like it? Maybe it‚Äôs beginner-level or poorly written. I‚Äôll do better next time.\nI‚Äôve set boundaries to manage interactions:\nDon‚Äôt send me voice notes‚Äîwrite instead. It‚Äôs quicker, and I don‚Äôt have to pause everything to listen.\nDon‚Äôt call me‚Äîsend a message first.\nDon‚Äôt leave comments‚Äîemail me instead.\nTough? Sure. Some people might not like it, but it filters out noise and preserves what‚Äôs important. People may get annoyed initially, but they adapt quickly."
  },
  {
    "objectID": "blog/posts/life_style/back_to_rss.html#back-to-rss-discord",
    "href": "blog/posts/life_style/back_to_rss.html#back-to-rss-discord",
    "title": "Getting Back to RSS",
    "section": "Back to RSS + Discord",
    "text": "Back to RSS + Discord\nAfter five years, I‚Äôve identified the sources I value and noticed a pattern. Why not collect them in one managed place, free from algorithms and ads? That‚Äôs where RSS comes in. I love it‚Äîit‚Äôs a superpower! When I first learned about RSS in college, I pictured an old Englishman in a garden reading about obscure topics. Now, I‚Äôve become that ‚Äúold man‚Äù who craves calm, minimal, and boring tools.\nYou can even follow YouTube channels via RSS without opening a browser! \nFor interacting with people, Discord channels are better. I can still reach folks like Jeremy and Tom there."
  },
  {
    "objectID": "blog/posts/life_style/back_to_rss.html#next-ideas",
    "href": "blog/posts/life_style/back_to_rss.html#next-ideas",
    "title": "Getting Back to RSS",
    "section": "Next Ideas",
    "text": "Next Ideas\nI have many changes I want to implement and thoughts to refine. I‚Äôm working on improving:\nActivity Watch\nTodo Manager\nThoughts Logging\nMedia Manager\nI‚Äôm also focusing on better habits like sleeping, eating, and walking.\nWant to find me? Visit my customized space at kareeai.com.\nAll my love,\nKareem"
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html",
    "href": "blog/posts/fl/what_is_federated_learning.html",
    "title": "What is Federated Learning",
    "section": "",
    "text": "You‚Äôre on a mission to create the purest, sweetest, and healthiest honey in the world. As a mad scientist, you want to improve your beehive‚Äôs efficiency and ensure no one can steal your secret recipe for magic honey.\nAfter researching how to set up your beehive system‚Äîhow the bees should communicate, and where to collect nectar in a protected way to guard against wasps that want to steal your honey and harm your beehive‚Äîyou discover that a Federated Beehive could meet all your needs. However, it adds complexity to your system and requires a new mindset."
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#traditional-ml-systems-centralized",
    "href": "blog/posts/fl/what_is_federated_learning.html#traditional-ml-systems-centralized",
    "title": "What is Federated Learning",
    "section": "Traditional ML Systems (Centralized)",
    "text": "Traditional ML Systems (Centralized)\nIn centralized systems, you collect flowers into your beehive and start processing them to create honey, which is not secure since people will know the type of flower on its way.\n\n\n\ncentralized Learning\n\n\nIn centralized systems, we aggregate data from multiple sources into a specific center where training occurs, consuming significant bandwidth and moving user data off their devices."
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#federated-learning-decentralized",
    "href": "blog/posts/fl/what_is_federated_learning.html#federated-learning-decentralized",
    "title": "What is Federated Learning",
    "section": "Federated Learning (Decentralized)",
    "text": "Federated Learning (Decentralized)\nIn FL, your bees visit different types of flowers to collect nectar and bring it back to your beehive in a fast and efficient way. The nectar is covered in a protective container to prevent the scent from attracting dark wasps and others in the world. While this approach is secure and efficient, it requires more overhead in managing bee communication globally, combining diverse nectar, and handling potential issues like poisoned nectar that could harm your entire honey supply.\n\n\n\nfederated learning"
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#introduction-to-federated-learning",
    "href": "blog/posts/fl/what_is_federated_learning.html#introduction-to-federated-learning",
    "title": "What is Federated Learning",
    "section": "Introduction to Federated Learning",
    "text": "Introduction to Federated Learning\nDefinition: Federated Learning (FL) enables machine learning models on distributed data by moving the training to the data, instead of transferring data to the training center.\nFL was first developed by Google in 2016 for their Gboard application, which uses a user‚Äôs typing history to suggest corrections and predict upcoming words while preserving user data privacy.\nThe idea is as follows: distribute our model across Android users‚Äô applications, train their data locally on their phones, and then aggregate the knowledge each user has learned using aggregation algorithms like FedAvg to combine the updates into a single global model.\nThis process must be repeated for multiple rounds to allow the model to learn from these small updates."
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#honey-with-multiple-flavors",
    "href": "blog/posts/fl/what_is_federated_learning.html#honey-with-multiple-flavors",
    "title": "What is Federated Learning",
    "section": "Honey with Multiple Flavors",
    "text": "Honey with Multiple Flavors\nWe decided to offer honey jars with multiple flavors based on the flower types from which nectar was collected. We‚Äôll create a base flavor that everyone recognizes, plus special flavors with unique ingredients‚Äîsome containing vitamin C, others a dose of caffeine.\n\n\n\nPersonalization in Federated Learning\n\n\nIn FL, this is called personalization. It can be seen as fine-tuning our global model (the base taste) with local data (special flowers) to meet specific needs.\nSince these unique flavors are likely to appeal only to certain local customers, they won‚Äôt be as popular with all customers compared to the base taste.\nOur personalized model will excel on local data but may underperform on general data due to increased bias from fine-tuning.\nAn FL system allows us to manage the trade-off between user-specific preferences and generalization."
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#horizontal-and-vertical-fl",
    "href": "blog/posts/fl/what_is_federated_learning.html#horizontal-and-vertical-fl",
    "title": "What is Federated Learning",
    "section": "Horizontal and Vertical FL",
    "text": "Horizontal and Vertical FL\nThere are two types of FL: Horizontal (homogeneous) FL and Vertical (heterogeneous) FL.\n\nHorizontal Federated Learning\nImagine our bees extracting nectar from the same type of flower in different places and in various quantities.\nAn example of horizontal FL is the Gboard application, where local training on phones uses identical data formats with unique content reflecting the user‚Äôs typing history.\n\n\n\nHorizontal Federated Learning\n\n\n\n\nVertical Federated Learning\nFor a new honey type, we instruct our bees to collect nectar from different plants with unique characteristics, creating a distinctive honey.\n\n\n\nVertical Federated Learning"
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#why-fl-instead-of-centralized-machine-learning",
    "href": "blog/posts/fl/what_is_federated_learning.html#why-fl-instead-of-centralized-machine-learning",
    "title": "What is Federated Learning",
    "section": "Why FL instead of Centralized Machine Learning?",
    "text": "Why FL instead of Centralized Machine Learning?\n\nCentralized Learning lacks security, making FL essential for industries like banking and healthcare.\nPrivate data availability surpasses public data, offering more insights and patterns to uncover new abilities.\nUser preference: Some users expect that no data will leave their device. For example, entering passwords or credit card information should not send those details to a keyboard app‚Äôs server. This use case led to FL‚Äôs development.\nRegulations: Various data privacy laws (GDPR, CCPA, etc.) protect sensitive data from being transferred. Regulations may even prohibit organizations from merging their users‚Äô data across different countries.\nReduced Compute Costs: Centralized ML with large datasets demands high computational resources, limited by individual machine performance.\nFaster Training: With FL, models can train immediately after receiving data, providing users with faster, more responsive solutions."
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#are-we-running-out-of-training-data-for-genai",
    "href": "blog/posts/fl/what_is_federated_learning.html#are-we-running-out-of-training-data-for-genai",
    "title": "What is Federated Learning",
    "section": "Are We Running Out of Training Data for GenAI?",
    "text": "Are We Running Out of Training Data for GenAI?\nMost LLMs are trained on publicly available web data, but there‚Äôs a need for diverse data across modalities (text, images, audio, video). LLM architectures are similar, but the data they are trained or fine-tuned on is crucial. FL can help by enabling training on:\n\nPrivate data\n\nPhones\nEmails\n\nRegulated data\n\nFinancial\nLegal\n\nSensitive data\n\nDoorbell camera images\nMedical\n\nIsolated data\n\nManufacturing\nAutomotive"
  },
  {
    "objectID": "blog/posts/fl/what_is_federated_learning.html#wasps-attacking-your-data",
    "href": "blog/posts/fl/what_is_federated_learning.html#wasps-attacking-your-data",
    "title": "What is Federated Learning",
    "section": "Wasps Attacking Your Data",
    "text": "Wasps Attacking Your Data\nFederated Learning minimizes data exposure, but gaps in federated systems still need secure solutions.\n\nPrivacy Attacks on Federated Systems\n\nMembership Inference Attack: Identifies whether specific data samples were used in training.\nAttribute Inference Attack: Infers unseen attributes of training data.\nReconstruction Attack: Reconstructs specific training data samples.\n\n\n\n\nPrivacy Attacks on Federated Learning\n\n\nWe‚Äôll explore different types of FL attacks and create defenses in a future blog post.\n\n\nReferences\nIn upcoming posts, I will explain the components of Federated Learning in greater detail, including math, code, and more beekeeping analogies.\n\nFlower Framework"
  },
  {
    "objectID": "publish.html",
    "href": "publish.html",
    "title": "üìö Books",
    "section": "",
    "text": "Still cooking ‚Ä¶"
  },
  {
    "objectID": "publish.html#still-under-review",
    "href": "publish.html#still-under-review",
    "title": "üìö Books",
    "section": "",
    "text": "Still cooking ‚Ä¶"
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "üìù Papers",
    "section": "",
    "text": "These are a list of papers I‚Äôve given:\n\nQARI-OCR: High-Fidelity Arabic Text Recognition through Multimodal Large Language Model Adaptation\nXAI for Alzheimer‚Äôs Dieases based on Particle Swarm Optimization: Explainable Artificial Intelligence of Multi-Level Stacking Ensemble for Detection of Alzheimer‚Äôs Disease Based on Particle Swarm Optimization and the Sub-Scores of Cognitive Biomarkers\nOptimiznig Medical Image Classification : Leveraging Advanced Segmentation Models for Enhanced Object Detection in Real-World Scenarios\nAI-Powered ICare ifnant cry Analysis and Speech Therapy"
  },
  {
    "objectID": "blog/feed.html",
    "href": "blog/feed.html",
    "title": "üìÆ Blog",
    "section": "",
    "text": "üìÆ Blog\nThoughts, experiments, and learnings on Arabic NLP, AI research, and building real-world systems.\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nDiversifying Search Results with Pyversity and Qdrant\n\n\n\nblogging\n\nminishlab\n\nembedding\n\nqdrant\n\ntil\n\n\n\nDiversifying search results with Qdrant and Pyversity for better RAG System with MMR, DDP and‚Ä¶\n\n\n\n\n\nDec 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nOnePlus Pad 3 Review (2025) - Researcher Review\n\n\nIn-depth OnePlus Pad 3 review with Snapdragon 8 Elite. Covering the 13.2-inch 3.4K display‚Ä¶\n\n\n\n\n\nDec 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHuawei FreeBuds 7i Review and specs: Is It Worth Upgrading from FreeBuds 5i?\n\n\nHonest review of the Huawei FreeBuds 7i after 20 days of daily use. Compare FreeBuds 7i vs 5i -‚Ä¶\n\n\n\n\n\nNov 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nFrom $32,000 to $0 with Small Models and CTranslate2\n\n\n\nmachine-learning\n\noptimization\n\ntranslation\n\nctranslate2\n\ncost-optimization\n\n\n\nHow I reduced translation costs from $32,000 to $0 using small models and CTranslate2‚Ä¶\n\n\n\n\n\nOct 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Back to RSS\n\n\n\nblogging\n\nidea_Forge\n\npublish\n\nrough_thoughts\n\nlife_style\n\n\n\nExploring digital minimalism and strategies to stay ahead in AI without burnout. This post‚Ä¶\n\n\n\n\n\nJun 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLate Interaction and ColPali\n\n\n\nblogging\n\nembedding\n\nminishlab\n\nmodel2vec\n\narabic\n\n\n\nWhat is Colapli, Late interaction and their impact\n\n\n\n\n\nMay 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBojji & Zarra Embedding models\n\n\n\nblogging\n\nembedding\n\nminishlab\n\nmodel2vec\n\narabic\n\n\n\nBojji and Zarra model2vec family model analysis and testing on Arabic Embeddings tasks.\n\n\n\n\n\nMay 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCloud GPU Pricing Comparsion in 2025\n\n\n\nblogging\n\nidea_Forge\n\npublish\n\nrough_thoughts\n\nlife_style\n\n\n\nExplore 2025 cloud GPU pricing with GPUvec. Compare top providers, GPU benchmarks, and tools like‚Ä¶\n\n\n\n\n\nApr 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nmy dream job at Tarteel\n\n\n\nblogging\n\ntarteel\n\nspeech_recognition\n\nmachine_learning\n\nquran\n\njob\n\n\n\nSharing my thoughts about my dream to work at Tarteel on Quran as Machine learning Engineer\n\n\n\n\n\nMar 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nŸÅŸÜ ÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ© ÿßŸÑÿ±ŸÇŸÖŸäÿ©\n\n\n\nblogging\n\nidea_Forge\n\npublish\n\nrough_thoughts\n\nlife_style\n\n\n\nŸÅŸÜ ÿ™ÿ®ÿ≥Ÿäÿ∑ ÿßŸÑÿ≠Ÿäÿßÿ© ÿßŸÑÿ±ŸÇŸÖŸäÿ© ŸÜÿµÿßÿ¶ÿ≠ Ÿàÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿ™ÿ≥ÿßÿπÿØŸÉ ÿπŸÑŸä ÿßŸÑÿ™ÿ≠ÿ±ÿ± ŸÖŸÜ ÿπŸÇŸÑŸäÿ© ÿßŸÑŸÇÿ±ÿØ Ÿà ŸÖÿ≠ÿßŸÅÿ∏ÿ© ÿπŸÑŸä ŸàŸÇÿ™ŸÉ Ÿà ÿ∑ÿßŸÇÿ©‚Ä¶\n\n\n\n\n\nFeb 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nMath Skills For AI\n\n\n\nblogging\n\nai\n\nmath\n\nlinear_algebra\n\ncalculus\n\nstatistics\n\nprobability\n\n\n\nImproving my math skills from pure math , concepts to applied AI and try to keep this skills share‚Ä¶\n\n\n\n\n\nJan 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑÿ∑ÿπÿßŸÖ ÿü\n\n\n\nblogging\n\nidea_Forge\n\npublish\n\nrough_thoughts\n\nlife_style\n\n\n\nÿ£ŸàŸÑ ŸÖŸàŸÇÿπ ÿ®ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä ŸÑÿ™ÿ≠ÿØŸäÿØ ÿßŸÑÿ≥ÿπÿ±ÿßÿ™ ÿßŸÑÿ≠ÿ±ÿßÿ±Ÿäÿ© ŸÅŸä ÿßŸÑÿ£ÿ∑ÿπŸÖÿ© ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ®ÿ¥ŸÉŸÑ ÿ™ŸÑŸÇÿßÿ¶Ÿä Ÿàÿ≥ŸáŸÑ Ÿà‚Ä¶\n\n\n\n\n\nJan 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nÿßŸÅÿ∂ŸÑ ÿßŸÜŸàÿßÿπ ÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÑÿ®ŸÜÿßÿ° ÿßŸÑÿπÿ∂ŸÑÿßÿ™\n\n\n\nblogging\n\nidea_Forge\n\npublish\n\nrough_thoughts\n\nlife_style\n\n\n\nÿ®ÿ±Ÿàÿ™ŸäŸÜ ÿßŸä ÿßŸÅÿ∂ŸÑ ŸÖŸàŸÇÿπ ŸÑŸÖŸÇÿßÿ±ŸÜÿ© ŸÖÿ≥ÿßÿ≠ŸäŸÇ ÿßŸÑÿ®ÿ±Ÿàÿ™ŸäŸÜ ŸàÿßŸÑŸÉÿ±Ÿäÿßÿ™ŸäŸÜ ŸÑŸÑÿ™ŸÜÿ¥ŸäŸÅ Ÿà ÿßŸÑÿ™ÿ∂ÿÆŸäŸÖ Ÿà ÿßÿÆÿ™Ÿäÿßÿ± ÿßŸÑÿßŸÅÿ∂ŸÑ Ÿà ŸÖÿßŸäŸÜÿßÿ≥ÿ®‚Ä¶\n\n\n\n\n\nJan 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Federated Learning\n\n\n\nblogging\n\npublish\n\nfl\n\n\n\nA quick introduction to Federated Learning Systems, comparing them with centralized machine‚Ä¶\n\n\n\n\n\nNov 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGoogle Ads Black Box\n\n\n\nblogging\n\npublish\n\ngoogle\n\nseo\n\nads\n\n\n\nSuspended Google Account without any explaination why and how to fix Circumventing Systems Poclicy\n\n\n\n\n\nOct 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLearning Data Structures and Algorithms as Machine Learning Engineer\n\n\nTrying to learning Data structure and algorithms after gradute from college to improve my problem‚Ä¶\n\n\n\n\n\nOct 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nReview of Huawei watch gt 4\n\n\n\nhuawei\n\nwatch\n\nexp\n\nblogging\n\npublish\n\n\n\nHuawei watch gt4 review after 1 year of use focus more on cons and leaving pros to the media\n\n\n\n\n\nOct 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nThe curse of SEO\n\n\n\nblogging\n\nseo\n\n\n\nDiscover the hidden challenges of SEO, effective tools, and strategies to track changes and‚Ä¶\n\n\n\n\n\nJul 31, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nÿ¨ÿßÿ∞ÿ®Ÿäÿ© ŸÖÿ≤ŸäŸÅÿ© Ÿà ÿπÿßŸÑŸÖ ŸÖÿÆÿßÿØÿπ\n\n\n\nblogging\n\nidea_Forge\n\npublish\n\nrough_thoughts\n\nlife_style\n\n\n\nŸÖÿÆÿßŸàŸÅ ÿπŸÜ ÿßŸÑŸàŸÇŸàÿπ ŸÅŸä ÿ¨ÿßÿ∞ÿ®Ÿäÿ© ÿßŸÑÿ£ÿÆÿ±ŸäŸÜ Ÿàÿ£ŸáŸàÿßÿ¶ŸáŸÖ ŸàÿßŸÑÿßÿ®ÿ™ÿπÿßÿØ ÿßŸÑÿ∫Ÿäÿ± ŸÖŸÇÿµŸàÿØ ÿπŸÜ ÿßŸÑŸáÿØŸÅ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä Ÿàÿ∂Ÿäÿßÿπ ÿßŸÑÿ®ŸàÿµŸÑÿ©‚Ä¶\n\n\n\n\n\nJul 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMy little Dragon ‚Äúkobo‚Äù\n\n\nA review about my MSI Gaming Laptop as a machine learning student and also a web developer! and‚Ä¶\n\n\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAfter one year of using Huawei Mate 11 without google services\n\n\nSharing my experience with using Huawei Mate product line for one year without huawei services, a‚Ä¶\n\n\n\n\n\nDec 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHuawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!\n\n\nReview of the Huawei Freebuds 5i after 2 months of use. Huawei Freebuds is latest pair of‚Ä¶\n\n\n\n\n\nDec 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMTEB Massive Text Embedding Benchmark\n\n\nMTEB Benchmark aims to provide clarity on how models perform on a variety of embedding tasks and‚Ä¶\n\n\n\n\n\nOct 28, 2023\n\n\n\n\n\n\n\n\n\n\n\n\ntiny-gte ‚ÄúTiny, yet powerful, it is small in size but packs a lot of power.‚Äù\n\n\nlet‚Äôs explore this applications with txtai and other workflow with some notes and future directions\n\n\n\n\n\nOct 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nhavrard CS197 AI research experiences\n\n\nEmbark on a transformative journey into the world of scientific research, particularly deep‚Ä¶\n\n\n\n\n\nJul 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nwhy i am blogging\n\n\n\nlife\n\nblogging\n\npublish\n\n\n\nwhy i am blogging and should you also blog? Why you (yes, you) should blog blogging with astro js‚Ä¶\n\n\n\n\n\nJul 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHow I am using NLP to improve my Websites SEO\n\n\n\nlife\n\nblogging\n\npublish\n\nseo\n\n\n\nHow i use python scripts and natural language processing to improve my landing page SEO\n\n\n\n\n\nJul 18, 2023\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/courses/havrard CS197 AI research experiences.html",
    "href": "blog/posts/courses/havrard CS197 AI research experiences.html",
    "title": "havrard CS197 AI research experiences",
    "section": "",
    "text": "This course consists of 21 quick lectures that include valuable experiences and important tips for anyone interested in the field of scientific research, especially deep learning. The course can be completed in approximately one or two days. The title is not very precise, and the content of the lectures ranges from about 8 to 26 pages each. Some topics may not be directly related to the specifics of scientific research, but they are generally very helpful lectures for beginners in the field."
  },
  {
    "objectID": "blog/posts/courses/havrard CS197 AI research experiences.html#table-of-contents",
    "href": "blog/posts/courses/havrard CS197 AI research experiences.html#table-of-contents",
    "title": "havrard CS197 AI research experiences",
    "section": "",
    "text": "This course consists of 21 quick lectures that include valuable experiences and important tips for anyone interested in the field of scientific research, especially deep learning. The course can be completed in approximately one or two days. The title is not very precise, and the content of the lectures ranges from about 8 to 26 pages each. Some topics may not be directly related to the specifics of scientific research, but they are generally very helpful lectures for beginners in the field."
  },
  {
    "objectID": "blog/posts/courses/havrard CS197 AI research experiences.html#reviews",
    "href": "blog/posts/courses/havrard CS197 AI research experiences.html#reviews",
    "title": "havrard CS197 AI research experiences",
    "section": "Reviews",
    "text": "Reviews\nLecture 1: Exciting Advances with AI Language Models Content : Interact with language models like GPT-3‚Äôs text completion and use Codex‚Äôs code generation abilities feedback : ‚≠ê (1/5)\n\nLecture 2: The Zen of python Content : vscode,git,conad,linting and Debugging. feedback: feedback : ‚≠ê (1/5)\n\nLecture 3: Reading AI Research papers Content :\n\nConduct a literature search to identify papers relevant to a topic of interest\nDifference between Reading Wide and Reading deep and how to balance between them\nHow to use Google Scholar and paper with code feedback : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)\n\n\nLecture 4: In-Tune with Jazz Hands Content:\n\nquick intro into huggingface\nTokenization\nCausal language modeling (CLM) feedback : ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)\n\n\nLecture 5: Lightning McTorch Content :\n\nFine-tuning A vision Transformer\nIntro to pytorch lightning (Lightning)\nData Loading\nHow to Build a Neural net Module with lightning and how lightning modules work feedback : ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)\n\n\nLecture 6 & 7: Moonwalking with Pytorch Content :\n\nPytorch Exercises\nTensors\nAutograd and neural networks feedback : ‚≠ê (1/5)\n\n\nLecture 8 & 9: Experiment Organization Spakrs Joy Content :\n\nWeight and Biases\nHyperparameter Search\nHydra feedback : ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)\n\n\nLecture 10 & 11 : I Dreamed a Dream Content\n\nIdentifying Gaps in A Research Paper\n\nCLIP and CheXzero\n\nGenerating Ideas for Building a Research Paper\nIterating on your research ideas feedback : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)\n\n\nLecture 12 & 13 : Today Was a Fairytale\n\nhow to deconstruct the elements of a research paper and their sequence\nResulting template that you can use as a general example feedback : ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)\n\n\nLecture 14 & 15: Deep Learning on Cloud Nine didn‚Äôt complete it üôÉüôÉüôÉ\n\nLecture 16 & 17:Make your dreams come tuned Content\n\nhigh level use of Stable Diffusion using a Dreambooth template\nUse AWS to accelerate the training of Stable Diffusion models with GPUs\nHF Accelerator feedback : ‚≠ê‚≠ê (2/5)\n\n\nLecture 18 : Research Productivity Power-Ups Content\n\nHow update meetings and working sessions\norganizing your efforts on a project\nwhat is technical dept and examples on it feedback : ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)\n\n\nLecture 19 :The AI Ninja Content\n\nHow to make Steady Progress\nSome Research Skills\nDiscussion Questions feedback : ‚≠ê‚≠ê (2/5) I found that Colah‚Äô blog content about research is better in the context and offers a great details\n\n\nLecture 20: Bejeweled ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê(5/5)\n\nhow to make a slides to improve your research talk\nAssertion Evidence Approach feedback : ‚≠ê‚≠ê (2/5) This is great related talk from MIT about this topic How to speak ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê(5/5)\n\n\nLecture 21 : Model Showdown Content\n\nStatistical Testing feedback : ‚≠ê‚≠ê ‚≠ê(3/5)"
  },
  {
    "objectID": "blog/posts/ds_and_algo/master_ds.html",
    "href": "blog/posts/ds_and_algo/master_ds.html",
    "title": "Learning Data Structures and Algorithms as Machine Learning Engineer",
    "section": "",
    "text": "I am a fresh graduate from AI college, i spent the last 4 years learning about both Computer science and AI.\nI was learning some math, machine learning , Deep learning and a lot of programming with python and C++, spent some a lot of time learning web also for freelance jobs.\na lot of time i had multiple interviews while i was a student in the summer and all the time the questions was about linkedlist, and some medium leetcode question and a few of them was about frameworks like pytorch or pandas.\nI faced a strange fact when i started to work on life projects or some advanced books‚Ä¶etc they require a strong problem solving skills that i don‚Äôt have!!\nI am revisiting these topics and will try to get out from the juypter notebook and kaggle world in software engineer with python and focus more on open source projects.\nI want to reazlie the time/memeory order of the data structures i am using in my projects\nI have read the algorithm book v3 and spent 6 months on codeforces with c++ i remember these days where i could spent around 10 hours per day solving problems with myself before the AI assistants like GPT..etc i am missing the good feeling after every problem i manage to solve and i was able to write around 90 lines of code without research or AI help..etc.\nI will start learning again about this topics and make them a daily habit to solve a problem per day: - [grokking_ds] - it‚Äôs a new book about data structure in python and explained with the grokking style\n[DS with python] - it‚Äôs a mostafa saad ibrhaim udemy course with python version with a lot of problems to solve\n[neetcode] - a roadmap to focus on some problems selected from neetcode\n[coding challenges] - A SE problems to help you focus more on how to build projects not just problem solving which will help me to start doing some open source\n\n\n\n- multiple time when i was trying to building some solutions related to NLP or graph neural network i know that this problem must solved with Linkedlist and this needs a type of tree then i struggle to continue....\n- Learning about some NLP Algorithms or the new searching and matching techniques most of the time they are math equations with some optimizations you can't fully understand unless your skills in problem solving\n- research in DL needs a huge skills in problem solving and how to understand the following architectures then update or utilize them to your needs more in this in the future but i think the better you are in SE the better you are in ML.\n\n\n\n\nArrays"
  },
  {
    "objectID": "blog/posts/ds_and_algo/master_ds.html#why-revisit-ds-and-algorithms",
    "href": "blog/posts/ds_and_algo/master_ds.html#why-revisit-ds-and-algorithms",
    "title": "Learning Data Structures and Algorithms as Machine Learning Engineer",
    "section": "",
    "text": "I am a fresh graduate from AI college, i spent the last 4 years learning about both Computer science and AI.\nI was learning some math, machine learning , Deep learning and a lot of programming with python and C++, spent some a lot of time learning web also for freelance jobs.\na lot of time i had multiple interviews while i was a student in the summer and all the time the questions was about linkedlist, and some medium leetcode question and a few of them was about frameworks like pytorch or pandas.\nI faced a strange fact when i started to work on life projects or some advanced books‚Ä¶etc they require a strong problem solving skills that i don‚Äôt have!!\nI am revisiting these topics and will try to get out from the juypter notebook and kaggle world in software engineer with python and focus more on open source projects.\nI want to reazlie the time/memeory order of the data structures i am using in my projects\nI have read the algorithm book v3 and spent 6 months on codeforces with c++ i remember these days where i could spent around 10 hours per day solving problems with myself before the AI assistants like GPT..etc i am missing the good feeling after every problem i manage to solve and i was able to write around 90 lines of code without research or AI help..etc.\nI will start learning again about this topics and make them a daily habit to solve a problem per day: - [grokking_ds] - it‚Äôs a new book about data structure in python and explained with the grokking style\n[DS with python] - it‚Äôs a mostafa saad ibrhaim udemy course with python version with a lot of problems to solve\n[neetcode] - a roadmap to focus on some problems selected from neetcode\n[coding challenges] - A SE problems to help you focus more on how to build projects not just problem solving which will help me to start doing some open source\n\n\n\n- multiple time when i was trying to building some solutions related to NLP or graph neural network i know that this problem must solved with Linkedlist and this needs a type of tree then i struggle to continue....\n- Learning about some NLP Algorithms or the new searching and matching techniques most of the time they are math equations with some optimizations you can't fully understand unless your skills in problem solving\n- research in DL needs a huge skills in problem solving and how to understand the following architectures then update or utilize them to your needs more in this in the future but i think the better you are in SE the better you are in ML.\n\n\n\n\nArrays"
  },
  {
    "objectID": "blog/posts/life_style/why_I_am_blogging.html#why-i-am-blogging",
    "href": "blog/posts/life_style/why_I_am_blogging.html#why-i-am-blogging",
    "title": "why i am blogging",
    "section": "Why I am blogging",
    "text": "Why I am blogging\n\nI am blogging to establish a presence on the internet and hope to collaborate with people who are interested in what I write or think about (reducing the search space by reversing the process).\nIt serves as a resume and blueprint for my existence in this world.\nMy goal is to help others by providing valuable content that makes their lives easier and better.\nOrganizing my knowledge and recapping topics I‚Äôve forgotten helps me experience ‚Äúaha‚Äù moments! üí°\n\nIt‚Äôs a test of whether I truly understand something or not.\n\nI don‚Äôt like social media posts, Facebook, Twitter, or LinkedIn articles. I believe these platforms are not the best places for technical blogs, and their disadvantages outweigh the advantages.\nI value the freedom of speech. Some topics or thoughts may be censored on social media, but I want to express my opinions without restrictions from others whose opinions I may not respect.\nI want to discuss topics while I‚Äôm learning them because they‚Äôre still fresh in my mind. This will help anyone in a similar position as me in the future.\nWhen studying a topic and knowing that I can write about it on my blog, I find my mind more focused on details that would fit well in the blog. This makes the learning process more enjoyable, focused, and valuable.\nI want my posts and knowledge to be more organized!\n\nWho will search for a post written six years ago on Facebook or see your first tweet?\nThis problem is related to the feed of these social platforms."
  },
  {
    "objectID": "blog/posts/life_style/why_I_am_blogging.html#references",
    "href": "blog/posts/life_style/why_I_am_blogging.html#references",
    "title": "why i am blogging",
    "section": "References",
    "text": "References\n\nhttps://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045"
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html",
    "href": "blog/posts/life_style/gpuvec.html",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "",
    "text": "In the fast-paced tech world of 2025, cloud GPUs drive AI breakthroughs, machine learning, and high-performance computing (HPC). Whether you‚Äôre training large language models (LLMs) or tackling vision tasks, finding the best cloud GPU providers at the right price is critical. With varied pricing from platforms like CoreWeave and Hyperstack, the landscape can feel overwhelming. That‚Äôs where GPUvec shines‚Äîyour go-to hub for cloud GPU pricing comparison, GPU benchmarks, and tools like our model size calculator.\n\n\nCloud GPU pricing can define your project‚Äôs success. From startups to enterprises, demand for scalable, cost-effective GPUs is surging. Providers like Hyperstack offer NVIDIA H100s at $1.90/hr, while others compete with flexible rates for AI workloads. But it‚Äôs more than hourly costs‚ÄîVRAM, CUDA cores, and hidden fees (storage, networking) shape true value. GPUvec cuts through the noise, spotlighting the cheapest cloud GPUs and high-performance options tailored to you.\n\n\n\nGPUvec Best Cloud GPU Providers"
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#cloud-gpu-pricing-in-2025",
    "href": "blog/posts/life_style/gpuvec.html#cloud-gpu-pricing-in-2025",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "",
    "text": "In the fast-paced tech world of 2025, cloud GPUs drive AI breakthroughs, machine learning, and high-performance computing (HPC). Whether you‚Äôre training large language models (LLMs) or tackling vision tasks, finding the best cloud GPU providers at the right price is critical. With varied pricing from platforms like CoreWeave and Hyperstack, the landscape can feel overwhelming. That‚Äôs where GPUvec shines‚Äîyour go-to hub for cloud GPU pricing comparison, GPU benchmarks, and tools like our model size calculator.\n\n\nCloud GPU pricing can define your project‚Äôs success. From startups to enterprises, demand for scalable, cost-effective GPUs is surging. Providers like Hyperstack offer NVIDIA H100s at $1.90/hr, while others compete with flexible rates for AI workloads. But it‚Äôs more than hourly costs‚ÄîVRAM, CUDA cores, and hidden fees (storage, networking) shape true value. GPUvec cuts through the noise, spotlighting the cheapest cloud GPUs and high-performance options tailored to you.\n\n\n\nGPUvec Best Cloud GPU Providers"
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#gpuvec-your-cloud-gpu-companion",
    "href": "blog/posts/life_style/gpuvec.html#gpuvec-your-cloud-gpu-companion",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "GPUvec: Your Cloud GPU Companion",
    "text": "GPUvec: Your Cloud GPU Companion\nGPUvec delivers real-time GPU pricing comparison from top GPU cloud providers. From the budget-friendly NVIDIA A4000 at $0.15/hr to the cutting-edge H200, we help you find the perfect fit. Explore these features:\n\nProviders\n\nVector Database\n\nComparison Tool\n\nModel Size Calculator\n\nCost Estimator\n\nGPUs for AI:\n\nNVIDIA H200\n\nNVIDIA A100\n\nNVIDIA A10\n\nNVIDIA H100\n\nNVIDIA A6000\n\nNVIDIA RTX 4090\n\nNVIDIA RTX 5090\n\nNVIDIA RTX 3090\n\n\nFilter by VRAM, CUDA cores, and more to optimize GPU costs effortlessly."
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#best-cloud-providers",
    "href": "blog/posts/life_style/gpuvec.html#best-cloud-providers",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "Best Cloud Providers",
    "text": "Best Cloud Providers\nDiscover top GPU cloud providers:\n\nCoreWeave: Cost-effective, AI-focused GPUs with unmatched scalability.\n\nHyperstack: NVIDIA GPUs like the A100 at $0.50/hr, eco-friendly and powerful.\n\nLambda Labs: Tailored for AI and deep learning with robust NVIDIA options.\n\nPaperspace: User-friendly cloud computing GPU solutions for all workloads.\n\nGoogle Cloud (GCP): Comprehensive GPU offerings for machine learning.\n\nAWS: Wide-ranging GPU instances for AI and HPC.\n\nAzure: Robust cloud platform with GPU capabilities.\n\nVast.ai: A marketplace for GPU rental pricing at competitive rates.\n\nRunPod: Affordable GPU instances for AI tasks.\n\nModal: Competitive pricing with a sleek interface for AI workloads.\n\nGPUvec ranks them by price, performance, and specs like vCPUs and storage."
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#weekly-update---gpuvec-newsletter",
    "href": "blog/posts/life_style/gpuvec.html#weekly-update---gpuvec-newsletter",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "Weekly Update - GPUvec Newsletter",
    "text": "Weekly Update - GPUvec Newsletter\nStay ahead with our weekly newsletter‚Äîupdates on NVIDIA GPU pricing, new providers, and exclusive deals. Get insights to make smarter choices for your projects.\nSubscribe Now"
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#gpu-benchmarks",
    "href": "blog/posts/life_style/gpuvec.html#gpu-benchmarks",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "GPU Benchmarks",
    "text": "GPU Benchmarks\nOur GPU benchmarks target AI tasks‚ÄîLLMs, vision models, and libraries like Flash-Attention. Compare NVIDIA, AMD, TPUs, and Huawei inference chips to find the best performer for your workload."
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#gpuvec-tools",
    "href": "blog/posts/life_style/gpuvec.html#gpuvec-tools",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "GPUvec Tools",
    "text": "GPUvec Tools\n\nModel Size Calculator: Input your model (e.g., 7B, 9B) for compute recommendations.\n\nCost Estimator: Forecast costs based on VRAM, runtime, and provider.\n\nQuantization: Optimize models for cost and performance.\n\nGPU Comparison: Analyze GPUs by VRAM, CUDA cores, and more.\n\nSpot Instance Finder: Snag the cheapest cloud GPUs with spot pricing."
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#cheapest-cloud-gpus",
    "href": "blog/posts/life_style/gpuvec.html#cheapest-cloud-gpus",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "Cheapest Cloud GPUs",
    "text": "Cheapest Cloud GPUs\nNeed affordability? GPUvec tracks budget options like the A4000 at $0.15/hr and spot instances across providers, blending price with performance for AI GPU costs."
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#compare-gpus-for-ai-tasks",
    "href": "blog/posts/life_style/gpuvec.html#compare-gpus-for-ai-tasks",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "Compare GPUs for AI Tasks",
    "text": "Compare GPUs for AI Tasks\nGPUvec excels at comparing GPUs for AI. Dive into:\n\nLLMs: Benchmarks for large language models.\n\nVision Models: Performance for image tasks.\n\nFlash-Attention: GPUs optimized for advanced techniques.\n\nHugging Face: Compatibility with popular libraries.\n\nVLLM: Tailored benchmarks for VLLM tasks.\n\nBookmark favorites for later analysis."
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#filter-based-on-vram-cuda-cores-and-more",
    "href": "blog/posts/life_style/gpuvec.html#filter-based-on-vram-cuda-cores-and-more",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "Filter Based on VRAM, CUDA Cores, and More",
    "text": "Filter Based on VRAM, CUDA Cores, and More\nRefine your search with filters:\n\nVRAM (e.g., 16GB, 80GB)\n\nCUDA cores\n\nSystem RAM\n\nLocal storage\n\nFind the ideal GPU fast."
  },
  {
    "objectID": "blog/posts/life_style/gpuvec.html#conclusion",
    "href": "blog/posts/life_style/gpuvec.html#conclusion",
    "title": "Cloud GPU Pricing Comparsion in 2025",
    "section": "Conclusion",
    "text": "Conclusion\nIn 2025, cloud GPUs fuel AI and high-performance computing pricing. GPUvec simplifies your journey with real-time cloud GPU comparison, GPU benchmarks, and tools to optimize GPU costs. Whether you‚Äôre hunting the cheapest cloud GPUs or scaling for enterprise AI, GPUvec empowers you to save time and money. Visit GPUvec today and master the cloud GPU landscape!\nread also:\n\nwhat is federated Learning\nŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-time-i-spend-with-kobo",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-time-i-spend-with-kobo",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "The time I spend with kobo",
    "text": "The time I spend with kobo\nI spend on average 8 hours on my laptop ‚Äúkobo‚Äù doing a lot of programming, machine learning experiments and browsing many taps.\nI don‚Äôt use my phone a lot on average 1 or 2 hours, so i wake up and go to see my little friend and start journaling, wirte my ideas, perparing my todo list.\nI have been using it for 4 years now, and it was a nice period i love that it hasn‚Äôt broken till now, everything is working good even the battery can stand for the 2.5 hours in the battery life with a lot of memory and cpu usage\nYou can easily say that my laptop is now a part of me i can‚Äôt live without it any more my dairy, movies, work and college is depending on it"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#who-is-kobo",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#who-is-kobo",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "Who is ‚ÄúKobo‚Äù!",
    "text": "Who is ‚ÄúKobo‚Äù!\n\n\n\nKobo\n\n\n\nSystem Specifications\nMy laptop is a Gfthin 95 core i7 9th gen, 16 GB RAM, 512GB SSD and GTX 1660 Ti, 120Hz screen"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#msi-vs-lenovo",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#msi-vs-lenovo",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "MSI vs Lenovo",
    "text": "MSI vs Lenovo\n\nMSI with Linux\nAfter buying it, it wasn‚Äôt configured with Windows, but was another DOS version so I had to install a Windows version on it. After 1 week I get a lot of errors on it with the external monitor and the WiFi stops working or is not configured. I tried every Hindi video about this problem and gave it to specialists to try it, but in vain, the problem happened again and again.\nThe solution: It was my first year at a computer science college, so the geeky thing was to use Linux. After some search, I installed Ubuntu and then tried a lot of distros like Void Linux, but the one that I picked and still use is the amazing PopOS! which is based on Ubuntu but better than it!\nThe WiFi problem doesn‚Äôt appear again! And for Nvidia graphics, it‚Äôs solved in PopOS! which has a command to install some drivers. And everything works smoothly\n\n\nThe Cost of It!\nI bought it for the cost of 20,000 EGP, which at the time I bought it was $X, but now 20,000 EGP is worth $XX due to problems in my country.\nIts cost at that time is really high for my budget and family, but I insisted on buying it because I knew it would stay with me for years, so I wanted a good one.\n\n\nHow I Decided to Buy It!\nThe phrase ‚ÄúMachine learning needs an Nvidia GPU‚Äù was dancing in my mind, so my main focus was on a nice GPU card in a laptop with a low budget. After some search, I found that the best choices are MSI or Lenovo, but the Lenovo version cost about 4000 EGP more than the MSI.\n\nI tested the keyboard of the Lenovo, and every time I felt like I wanted to cut my fingers off\n\nIt wasn‚Äôt available online, so I had to travel 3 hours to the store that sells it. It was a nice experience to buy something I wanted instead of a random gift from my father."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#i-am-not-a-gamer",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#i-am-not-a-gamer",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "I Am Not a Gamer!",
    "text": "I Am Not a Gamer!\nI didn‚Äôt use it for gaming because I am not a gamer, but I used it heavily in programming and some machine learning and basic computer vision models, and it works so nicely!"
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-ml",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-ml",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "Kobo for ML",
    "text": "Kobo for ML\n Machine learning is a wide area, and you can use the GPU for 3 things:\n\nTrain a model from scratch\nFine-tune a model\nEvaluate a model (inference)\n\n\nTrain a model from scratch was an ideal task for such a GPU, but I was doing it for multiple computer vision classification tasks, learning new architectures, trying to build‚Ä¶etc. For ML you don‚Äôt always need a GPU but for deep learning, which is a subset of ML that uses more connected layers (which means more computing power and memory needs), you do.\nFine-tune a model is the case I used the most - I download a trained model and try to make it work better on my data. What you need here is enough GPU RAM - in my case it‚Äôs a 6GB card. This worked fine with computer vision algorithms and classic NLP models with less than 1 billion parameters. There‚Äôs no chance to try the LLAMAS models on such a card!\nEvaluate a model means to just load the model and not fine-tune it.\n\nI was fine with all the ML tasks I tried to do, unless I opened the door to large language models like the GPT family (ChatGPT for example). These models require a lot of memory and need a good graphics card like an RTX 30 or 40 series to test, and there‚Äôs no chance to train these models on any RTX card!\n\nWhy Not Just Use the Cloud!\nThere are two main solutions:\n\nKaggle\n\nKaggle has two GPU options, and I used it a lot, especially if the data was already hosted on Kaggle and was more than 10GB. Other than that, I downloaded a sample of the data and did my work on my own environment with CLI commands and VS Code configurations. This helped me a lot compared to just using the Kaggle editor, and it‚Äôs faster too! Sometimes the Kaggle kernel panics or just stops responding entirely!\n\nColab\n\nColab restarts after 4 hours and your work can get lost, and lots of annoying things like that happen a lot.\nYou have to pay for the GPU version. You get a number of hours to try it out, and it‚Äôs faster than my GTX 1660 by a good margin.\n\n\nBut I didn‚Äôt love these cloud solutions, and I found having my own local setup to be faster and more comfortable."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-web-development",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#kobo-for-web-development",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "Kobo for Web Development",
    "text": "Kobo for Web Development\nI sometimes work on web projects (Django and JavaScript frameworks, especially AstroJS). I never had any issues building and testing web projects - everything worked nicely and efficiently."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-battery-life",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-battery-life",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "The Battery Life",
    "text": "The Battery Life\nThe battery life can keep it working for 2.5 hours when the power is out if you switch to battery saver mode. I don‚Äôt think it could last more than 1 hour in normal mode! This is the laptop‚Äôs biggest issue. Sometimes it powers off even when fully charged if you do a lot of computation without plugging it in."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-heat",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-heat",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "The Heat",
    "text": "The Heat\n I didn‚Äôt find heat to be a problem or even the fan noise in most of my work. But sometimes when running a deep learning model, the fan noise is a bit loud and it does get really hot. For normal coding and browsing though, there are no issues and the cooling system is fast. Overall I didn‚Äôt find heat to be a major problem."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#the-keyboard",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#the-keyboard",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "The Keyboard",
    "text": "The Keyboard\nThe keyboard is very responsive and well configured with smooth clicks - no issues or sticky keys even though I have fat fingers!\nI‚Äôve been using this machine for 4 years and I write a lot. No broken keys have happened despite my clumsy fingers. I have a mechanical keyboard that I sometimes use, but I always miss the feel of the built-in keyboard. The red backlight is decent."
  },
  {
    "objectID": "blog/posts/mteb_encoding/my_little_dargon.html#finally",
    "href": "blog/posts/mteb_encoding/my_little_dargon.html#finally",
    "title": "My little Dragon ‚Äúkobo‚Äù",
    "section": "Finally!",
    "text": "Finally!\n I just wanted to say that I love ‚ÄúKobo‚Äù and I‚Äôve spent nice times with it - some really difficult and others really happy. It‚Äôs been a loyal friend and something to rely on."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#intro",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#intro",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "Intro",
    "text": "Intro\nHi, In this fast blog i will talk about my review with Huawei Freebuds 5i, which is the first noise-cancelling earbuds i have tried. This is not an ad or even affiliate product, it‚Äôs my own review for fun and just seeking of knowledge."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#who-am-i",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#who-am-i",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "Who am i !",
    "text": "Who am i !\n\nI am Kareem, a college student interested in machine learning and web technology.\nI enjoy working deeply and seeking out quiet places, but I live in an area with some noisy disturbances in the mornings - people walking down the street, kids playing around the house, street vendors - which often interrupt my focus and break my state of flow.\nI wish there was a solution to block out all these sounds so I could live in an isolated place free of annoying noises! Using noise-cancelling headphones or heading into outer space would be ideal environments with no bothersome sounds around."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#how-i-bought-it",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#how-i-bought-it",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "how i bought it",
    "text": "how i bought it\n\nI bought it from amazon prime, and it cost me around 100$ or 3,200 pounds. It reached within two days."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#first-impressions",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#first-impressions",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "First impressions",
    "text": "First impressions\n\nUpon unboxing and using it for the first time, I was genuinely pleased with the initial track I played.\nThe sound quality was noticeably superior compared to my phone or any other earbuds I‚Äôve previously used. I then tested the noise-cancelling feature and was amazed when I couldn‚Äôt hear my younger brother calling me.\nThe street noises were effectively blocked out, with only a faint hum reaching my ears, which was quite tolerable. Initially, the earbud tips were a bit uncomfortable, but after switching to a smaller size, the discomfort was resolved. Everything seemed perfect, except for a slight pressure in my ears when using the noise-cancelling feature, particularly noticeable the following morning. Despite this, my ears seem to crave the earbuds and my skin seems to miss them when they‚Äôre not in use. This can be a bit of a downside, but it‚Äôs not always the case."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#is-noise-cancelling-actually-work",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#is-noise-cancelling-actually-work",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "Is noise cancelling actually work ?",
    "text": "Is noise cancelling actually work ?\nI‚Äôve used these earbuds in various settings:\n\nSubway: The noise-cancelling feature combined with my music created an immersive experience, effectively blocking out any other sounds and allowing me to enjoy my tunes in peace.\nCollege: Amidst the chatter and shouts of other students, I was able to retreat into my own world of sound.\nBus: The noise of the bus engine was successfully blocked out, but I could still hear the conversations of those sitting next to me. It wasn‚Äôt overly bothersome, but it didn‚Äôt provide complete isolation.\n\nIn summary, the noise-cancelling feature works well, but it doesn‚Äôt provide absolute silence. I can still hear some ambient sounds. One noticeable issue is that when I make calls using the earbuds, I can hear the other person clearly, but they often complain about the clarity of my voice. They say it sounds distant and unclear, sometimes even asking to call back later. This issue is particularly prevalent when I‚Äôm on the bus.\nIf you want to see more reviews about Huawei you can join the Channel"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-modes-of-the-freebuds-and",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-modes-of-the-freebuds-and",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "the modes of the Freebuds and",
    "text": "the modes of the Freebuds and\nHere is a rephrased version of the key points about the Huawei Freebuds 5i‚Äôs features:\nNoise Cancellation Modes:\n\nNoise Cancelling Mode: Actively cancels out ambient noise. Uses more battery power.\nOff Mode: No active noise cancellation, but still provides some passive noise isolation. Less battery usage.\nAwareness Mode: Allows ambient sounds to be heard clearly. Useful for hearing announcements at the gym or people talking to you. However, my own voice sounds muted in this mode, so I have to remove the earbuds temporarily to hold conversations.\n\nSound Quality Presets:\n\nDefault: No sound enhancements applied.\nTreble Boost: Boosts treble frequencies. I haven‚Äôt used this.\nBass Boost: Emphasizes bass when listening to music like hip-hop.\nVoices: Optimizes sound for speech clarity. I use this for podcasts.\n\nConnection Priority Modes:\n\nBalance Mode: Balances audio quality and connection stability.\nSound Quality Priority: Prioritizes sound quality over connectivity. Uses more power which may cause occasional lag.\n\nI have not noticed any discernible difference between these two modes, so I just use the Balance mode."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-gestures",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-gestures",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The Gestures",
    "text": "The Gestures\nThe Huawei Freebuds 5i offer various gesture controls:\n\nDouble-tap, Triple-tap, Press & hold, Swipe\n\nI particularly enjoy the swipe gesture for volume control, as it works smoothly. The press and hold gesture is a bit slow, and the triple-tap gesture can be annoying since tapping your ear three times isn‚Äôt very comfortable.\nOccasionally, the Freebuds don‚Äôt recognize when I‚Äôve inserted the left or right earbud, and I continue listening with just one earbud without realizing the other isn‚Äôt connected. This doesn‚Äôt happen often, though."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-compatibility-with-other-devices",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-compatibility-with-other-devices",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The compatibility with other devices",
    "text": "The compatibility with other devices\n\nI love how it connect with both the phone and tablet without any problems or conflict\nI‚Äôve been using the Freebuds with my Realme phone, MSI Linux laptop, and Huawei Mate Pad 11.\nThe connection with the Realme phone is seamless, regardless of whether the AI Life application is used or not.\nWhen it comes to the Huawei Mate Pad 11, there‚Äôs a feature that allows you to adjust settings directly from the Bluetooth menu. This is a functionality that isn‚Äôt available on standard Android devices without the AI Life app.\n\n\nLinux connection\nI‚Äôve connected the Freebuds to my Linux laptop using the ‚Äòbluetoothctl‚Äô command. However, I‚Äôve encountered an issue where I need to restart Bluetooth each time I want to establish a connection for it to work properly"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-case-and-overall-design",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-case-and-overall-design",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The case and overall design",
    "text": "The case and overall design\n\nThe design of the Freebuds is truly appealing. It has a unique aesthetic that sets it apart from other earbuds, giving it a premium feel.\nIn terms of design, the FreeBuds 5i bear a resemblance to the 4i model, but they are 11% lighter and have shorter stems. They come with an IP54 rating, making them dust-tight and splash-resistant. The color options include a new ‚ÄúIsle Blue‚Äù, along with ‚ÄúNebula Black‚Äù and ‚ÄúCeramic White‚Äù. The package includes small, medium, and large silicone eartips, as well as a short USB-C cable for charging the case.\nI love the sound of closing it, it‚Äôs a loud sound but lovely :)"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-battery",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#the-battery",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "The battery",
    "text": "The battery\n\nThe battery is really nice; I haven‚Äôt felt that I am missing the need to recharge it or that it has gone off at any time.\n\n\nBattery capacity\n\nPer earbud: 55 mAh (min)*\nCharging case: 410 mAh (min)*\n\n\n\nPlaytime\n\nMusic playback on 1 charge: 6.0 hours (with ANC enabled)**\nMusic playback on 1 charge: 7.5 hours (with ANC disabled)**\nMusic playback with charging case: 18.5 hours (with ANC enabled)**\nMusic playback with charging case: 28 hours (with ANC disabled)**\n\n\n\nCharging Time\n\nAbout 60 minutes for the earbuds (in the charging case)***\nAbout 110 for charging case without earbuds (wired)***"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei freebuds 5i.html#references",
    "href": "blog/posts/products_reviews/Huawei freebuds 5i.html#references",
    "title": "Huawei Freebuds 5i review: is it the best budget earbuds for Huawei phone owner!",
    "section": "References",
    "text": "References\n\nhttps://smarttech101.com/bluetoothctl-management-of-bluetooth-devices-in-linux/\nhttps://askubuntu.com/questions/1225896/huawei-freebuds-3-pairing-with-ubuntu-18-04\nŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html",
    "title": "Review of Huawei watch gt 4",
    "section": "",
    "text": "I bought it from Amazon for 13,000 EGP. I opened it immediately, and it looked so nice; I was very happy with its design and feel.\nI charged it with the wireless stand.\nI wore it after an hour and took some time to download the Huawei Health app on my Realme6 mobile."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#buying-the-huawei-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#buying-the-huawei-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "",
    "text": "I bought it from Amazon for 13,000 EGP. I opened it immediately, and it looked so nice; I was very happy with its design and feel.\nI charged it with the wireless stand.\nI wore it after an hour and took some time to download the Huawei Health app on my Realme6 mobile."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#feeling-pain",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#feeling-pain",
    "title": "Review of Huawei watch gt 4",
    "section": "Feeling pain",
    "text": "Feeling pain\n\nI wore it, and after three days, my hand started to hurt, causing some discomfort because I was sleeping with it on without removing it.\nI wore it on my right hand for four days, then switched it to my left hand, and my body felt more comfortable with it."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#the-design-of-the-huawei-watch-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#the-design-of-the-huawei-watch-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "The Design of the Huawei watch gt4",
    "text": "The Design of the Huawei watch gt4\n\nThe design is attractive, and many people who saw me wearing it didn‚Äôt notice that it was a smartwatch‚Äîthey thought it was a classic watch.\nOthers said that it looks better than the repetitive and dull design of the Apple Watch.\nIt looks very premium.\nThe brightness in sunlight is impressive."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#sleeping-with-huawei-watch-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#sleeping-with-huawei-watch-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "Sleeping with Huawei watch gt4",
    "text": "Sleeping with Huawei watch gt4\n\nThe accuracy of the sleep detector is almost perfect. Sometimes, when you leave the watch near you for 6 hours, it detects that you are sleeping, but this has only happened maybe three times this year.\nThe accuracy of detecting sleep cycles and the time for each is spot on, and the graph analysis and statistics on this watch are easy to understand, creative, and full of information.\nWhy can‚Äôt I set an alarm based on the sleep cycle, like in the Sleep Cycle app? This feature would be a game-changer!"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#calories-calculations-with-huawei-health",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#calories-calculations-with-huawei-health",
    "title": "Review of Huawei watch gt 4",
    "section": "Calories calculations with huawei health",
    "text": "Calories calculations with huawei health\n\nYou enter your information, like weight and height, and based on your vitals and activity, it detects the calories you burn every second. I like this estimation feature.\nYou can set a goal, for example, to go from 92 kg to 85 kg, but the problem is you need to calculate the calories and record it using the phone, not the watch. This is slow and inconvenient‚ÄîI don‚Äôt like having to open my phone often. Most of the time, my meals are repetitive, and recording them on the Huawei Health app is boring, so I usually just do a quick add.\nIn the future, I hope they let us add a list of meals to the app so we can select them directly from the watch."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#activities-with-huawei-watch-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#activities-with-huawei-watch-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "Activities with Huawei Watch gt4",
    "text": "Activities with Huawei Watch gt4\n\nHeart rate tracking is a little slow compared to real-time detection, and sometimes when you are running and want to check your speed and heart rate, it takes around 3 seconds‚Äîquite a long time if you‚Äôre in the middle of a run!\nThe auto-detection of activities may only start after 20 minutes of walking!\nSpO2‚Ä¶ and then what?\nThey claim there are more than 100 exercises to choose from, but do I really use all of these 100?\nLet‚Äôs look at the ones that are useful to me:\n\nOutdoor run\nElliptical\nJump rope: My favorite! It‚Äôs accurate and very helpful.\nIndoor run\nIndoor walk\n\nOnes I don‚Äôt use:\n\nOutdoor cycling\nIndoor cycling\nPool swimming\nOpen-water swimming\nMountain hiking\nHiking\nTrail running\nSkiing\nSnowboarding\nCross-country skiing\nTriathlon\nRowing\nTrack running\n\nAre these really 100 exercises?\nWhere are the gym exercises like pull-ups, push-ups, squats, bench presses, etc.?"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#syncing-with-huawei-health",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#syncing-with-huawei-health",
    "title": "Review of Huawei watch gt 4",
    "section": "Syncing with huawei health",
    "text": "Syncing with huawei health\n\nYou must use one main device. I have both a Huawei Health and a Huawei MatePad, but I have to log in on just one of them to sync the information. What if I want to use both? You can‚Äôt.\nSyncing with Linux or from the web? No, you can‚Äôt do that either.\nHowever, syncing is very fast.\n\nIf you want to see more reviews about Huawei you can join the Channel"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#messages-with-huawei-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#messages-with-huawei-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "Messages with huawei gt4",
    "text": "Messages with huawei gt4\n\nI love the messaging feature. You can read messages in multiple languages without any problem and respond using preconfigured answers, but you can‚Äôt type on the watch."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#music-with-huawei-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#music-with-huawei-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "Music with huawei gt4",
    "text": "Music with huawei gt4\n\nThe music quality and sound are great, especially if you want to listen to tracks before sleeping."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#calls-with-huawei-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#calls-with-huawei-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "Calls with huawei gt4",
    "text": "Calls with huawei gt4\n\nAnswering calls from the watch is really nice if you‚Äôre at home, but not so much if you‚Äôre outside on the street, for example."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#battery-with-huawei-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#battery-with-huawei-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "Battery with huawei gt4",
    "text": "Battery with huawei gt4\n\nThe best thing about the watch is the battery life. I don‚Äôt worry about it at all. I charge it for 30 minutes per week, and even when I use the always-on display, the battery doesn‚Äôt drain much."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#apps-with-huawei-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#apps-with-huawei-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "Apps with huawei gt4",
    "text": "Apps with huawei gt4\n\nCamera Opus\n\ndidn‚Äôt use it\n\nPhotex\n\ndidn‚Äôt use it\n\nNavigation - G maps\n\ndidn‚Äôt use it\n\nOneCalc\n\ndidn‚Äôt use it\n\nFor Spotify Controller\n\ndidn‚Äôt use it\n\nCalculator New\n\nused it multiple times\n\nEvents - G Calender\n\nI use it alot\n\nSurfing Joe\n\ndidn‚Äôt use it\n\nMobcards\n\ndidn‚Äôt use it\n\neSound music\n\ndidn‚Äôt use it\n\npetal maps\n\nuse it when walking and running\n\nnavigation watch\n\ndidn‚Äôt use it\n\neasyCalenderGT\n\ndidn‚Äôt use it\n\nmyTuner Radio\n\ndidn‚Äôt use it\n\nKeepStrong\n\nThe app has problem with login with google it‚Äôs focused more for Chinese people\n\nCompass navgation\n\ndidn‚Äôt use it\n\nTickTick\n\nvery useful can do/undo tasks from the watch but only tasks not the habbits\n\nRadarbot\n\ndidn‚Äôt use it\n\nFragola\n\ndidn‚Äôt use it\n\nSalaat first\n\nusing it on daily basis\n\nhome workout\n\nnot very useful\n\n2028 lite\n\ndidn‚Äôt use it\n\nwordpuz\n\ndidn‚Äôt use it\n\nlove test\n\ndidn‚Äôt use it\n\nfocus to-do\n\nit‚Äôs not synced with cloud or the mobile app\n\nDice\n\ndidn‚Äôt use it\n\nFitify workouts\n\ndidn‚Äôt use it\n\nRTL\n\ndidn‚Äôt use it\n\nhue essentials\n\ndidn‚Äôt use it\n\nFotMob\n\ndidn‚Äôt use it\n\nCalories Counter\n\ndidn‚Äôt use it\n\nFilGoal\n\ndidn‚Äôt use it\n\nS7 Airlines\n\ndidn‚Äôt use it\n\nŸáÿ≥ÿ®ÿ±Ÿäÿ≥\n\ndidn‚Äôt use it\n\nGold GPS Rangefinder\n\ndidn‚Äôt use it"
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#i-broked-the-glass-of-the-huawei-gt4",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#i-broked-the-glass-of-the-huawei-gt4",
    "title": "Review of Huawei watch gt 4",
    "section": "I broked the glass of the huawei gt4",
    "text": "I broked the glass of the huawei gt4\n\nThe watch broke on the first day of college, probably because I pressed my hand too hard on a marble surface or something similar at the university.\nI immediately contacted customer service, and a representative answered‚ÄîI can‚Äôt remember her name‚Äîbut she was incredibly polite, understanding, and helpful. I spoke to her again shortly after, and she asked me for specific information about the watch to check if it was under warranty or not. She followed up with me two days later, then again a day after that, and again two days later until I managed to get the invoice from Amazon. She tried to solve the issue by recommending an exchange and even told me which day to go when there would be discounts on the products.\nHonestly, it was the best customer service experience I‚Äôve ever had. She was able to go beyond being just a robot to become someone who understands, values, and helps‚Äîa human experience that brings joy.\nAt the very least, I had to document and acknowledge that she is someone exceptional. I requested to give her a rating, and I did. I‚Äôm really happy about that.\nBut I haven‚Äôt fixed the watch yet because there are no spare parts available in Egypt."
  },
  {
    "objectID": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#references",
    "href": "blog/posts/products_reviews/Huawei_watch_gt_4_experience.html#references",
    "title": "Review of Huawei watch gt 4",
    "section": "References",
    "text": "References\n\nHuawei freebuds 5i review\nHuawei watch gt4"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "",
    "text": "I bought the OnePlus Pad 3 (12GB RAM version) for 25,000 EGP (530$) because I needed a second device for work. Not a laptop replacement ‚Äî just something I could use for SSH connections, coding in VS Code, taking notes, and managing projects without constantly reaching for my main machine.\nI also wanted to separate my work life from everything else. A device I could leave on standby for days without worrying about battery. Something lightweight I could grab for reading or blogging after work hours. And honestly, I wasn‚Äôt about to sell my kidney for an iPad or spend Samsung flagship money.\nThe OnePlus Pad 3 packs the world‚Äôs fastest mobile CPU ‚Äî the Snapdragon 8 Elite, 12GB RAM, a massive 12,140mAh battery, and a stunning 13.2-inch 3.4K 144Hz display in a 5.97mm ultra-slim metal body. On paper, it‚Äôs competitive with much more expensive tablets. But does it actually work for real productivity? That‚Äôs what this review is about.\n\n\n\nOne plus pad 3 Review"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-pad-3-review-is-this-the-best-budget-productivity-tablet-in-2025",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-pad-3-review-is-this-the-best-budget-productivity-tablet-in-2025",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "",
    "text": "I bought the OnePlus Pad 3 (12GB RAM version) for 25,000 EGP (530$) because I needed a second device for work. Not a laptop replacement ‚Äî just something I could use for SSH connections, coding in VS Code, taking notes, and managing projects without constantly reaching for my main machine.\nI also wanted to separate my work life from everything else. A device I could leave on standby for days without worrying about battery. Something lightweight I could grab for reading or blogging after work hours. And honestly, I wasn‚Äôt about to sell my kidney for an iPad or spend Samsung flagship money.\nThe OnePlus Pad 3 packs the world‚Äôs fastest mobile CPU ‚Äî the Snapdragon 8 Elite, 12GB RAM, a massive 12,140mAh battery, and a stunning 13.2-inch 3.4K 144Hz display in a 5.97mm ultra-slim metal body. On paper, it‚Äôs competitive with much more expensive tablets. But does it actually work for real productivity? That‚Äôs what this review is about.\n\n\n\nOne plus pad 3 Review"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#whats-in-the-box-spoiler-not-much",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#whats-in-the-box-spoiler-not-much",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "What‚Äôs in the Box? (Spoiler: Not Much)",
    "text": "What‚Äôs in the Box? (Spoiler: Not Much)\nOpening the OnePlus Pad 3 box, you get the tablet and a USB cable. That‚Äôs it.\nNo charger. No stylus. No keyboard. Just the device and a cable.\nIf you want to actually charge it at the blazing 80W SUPERVOOC speeds this tablet supports, you‚Äôll need to buy OnePlus‚Äôs charger separately for around 1,500 EGP. The Stylo 2 stylus costs about 5,000 EGP, and the official Smart Keyboard runs between 6,000 to 10,000 EGP depending on where you buy it.\nSo while the tablet itself is 25,000 EGP (530$), the full setup can easily push you to 37,500-41,500 EGP.\nKeep that in mind when comparing prices to other tablets."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#build-quality-weight-thermal-performance",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#build-quality-weight-thermal-performance",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Build Quality, Weight & Thermal Performance",
    "text": "Build Quality, Weight & Thermal Performance\nThe OnePlus Pad 3 is impossibly thin at just 5.97mm. It‚Äôs an all-metal unibody design that feels premium and solid. You can hold it with one hand for a while without your arm getting tired. Despite the massive 13.2-inch screen, it doesn‚Äôt feel like you‚Äôre carrying around a brick.\nBuild quality is excellent. The Storm Blue color looks sophisticated, and the materials feel genuinely premium, not plasticky at all.\nOne thing that really surprised me: the temperature. This tablet doesn‚Äôt get hot. Even when I‚Äôm running multiple apps, doing SSH work, or watching videos for hours, it stays cool. OnePlus engineered a vapor chamber cooling system with 34,857mm¬≤ of heat dissipation area ‚Äî that‚Äôs 14% better than the OnePlus Pad 2. I‚Äôve used other devices that turn into hand warmers after 30 minutes. This one? No issues at all.\nBattery life is exceptional. With a 12,140mAh battery (the highest capacity in its class), I can leave it on standby for days and it barely drains. OnePlus claims up to 18 hours of video playback and up to 6 hours of AAA gaming. In real-world use for work ‚Äî coding, browsing, note-taking ‚Äî I‚Äôm easily getting through a full day. This is exactly what I wanted: a device I don‚Äôt have to babysit with a charger.\n\n\n\nOne plus Pad 3"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#display-13.2-inch-3.4k-144hz-for-coding-productivity",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#display-13.2-inch-3.4k-144hz-for-coding-productivity",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Display: 13.2-inch 3.4K 144Hz for Coding & Productivity",
    "text": "Display: 13.2-inch 3.4K 144Hz for Coding & Productivity\nThe 13.2-inch screen is phenomenal for productivity work. The 3.4K resolution (315 PPI) with 12-bit color depth delivers razor-sharp text and incredibly lifelike colors. The 144Hz refresh rate makes everything feel buttery smooth ‚Äî scrolling through code, switching between apps, or just browsing feels incredibly responsive.\nFor reading and coding, the text is crystal clear. I spend a lot of time in VS Code and Obsidian, and I haven‚Äôt had any eye strain issues. The screen size gives you enough room to actually work without feeling cramped. You can comfortably run multiple apps side by side.\nThe display supports Dolby Vision HDR and covers the DCI-P3 color gamut. Colors look natural and accurate. Not overly saturated or washed out. Videos and images look stunning.\nPeak brightness hits 900 nits, which means indoor visibility is excellent. The brightness gets high enough for well-lit rooms without any problems. I haven‚Äôt tested it extensively outdoors in direct sunlight, but it should handle most conditions."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#battery-life-18-hours-video-all-day-work",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#battery-life-18-hours-video-all-day-work",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Battery Life: 18 Hours Video, All-Day Work",
    "text": "Battery Life: 18 Hours Video, All-Day Work\nThe 12,140mAh battery on this tablet is outstanding. It‚Äôs one of the best things about it.\nI can leave it on standby for days without worrying. When I pick it up after not using it for a while, the battery is basically where I left it. This is perfect for my use case ‚Äî I wanted a device I could grab whenever I need it without constantly checking if it needs charging.\nFor active use, it easily lasts a full work day. SSH sessions, VS Code, browsing, note-taking, watching videos ‚Äî I‚Äôm getting through 8-10 hours of real work without needing to plug in. OnePlus claims up to 18 hours of video playback, and I believe it.\nCharging is fast with the 80W SUPERVOOC charger (sold separately, unfortunately). It charges quickly enough that you can top up during a break and be good for hours.\n\n\n\nOne plus pad 3 Battery"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#speakers-microphone-8-speaker-setup",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#speakers-microphone-8-speaker-setup",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Speakers & Microphone: 8-Speaker Setup",
    "text": "Speakers & Microphone: 8-Speaker Setup\nThe audio system on the OnePlus Pad 3 is seriously impressive. It has 8 speakers ‚Äî four bass units and four tweeters. The sound is clear, loud, and has actual depth. You get proper stereo separation and bass response that most tablets can‚Äôt match.\nWatching videos or listening to music is genuinely enjoyable without headphones. The speakers get loud enough to fill a room without distorting.\nThe microphone quality is solid too. I‚Äôve used it for calls and meetings, and people on the other end can hear me clearly. No complaints there.\nOne small thing I really appreciate: the alarm sound isn‚Äôt annoying. It actually wakes you up without making you want to throw the device across the room. Small detail, but it matters."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#camera-good-enough-for-video-calls",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#camera-good-enough-for-video-calls",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Camera: Good Enough for Video Calls",
    "text": "Camera: Good Enough for Video Calls\nThe camera is surprisingly nice. It‚Äôs sharp and takes clear photos. I wasn‚Äôt expecting much from a tablet camera, but this one actually delivers decent quality.\nRealistically though, how often do you use a tablet camera? For video calls and scanning documents, it works perfectly fine. For taking actual photos, you‚Äôre probably better off using your phone just because it‚Äôs more convenient to carry around.\nBut if you do need to take a photo with the tablet, you won‚Äôt be disappointed. The quality is there."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#performance-snapdragon-8-elite-dominates",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#performance-snapdragon-8-elite-dominates",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Performance: Snapdragon 8 Elite Dominates",
    "text": "Performance: Snapdragon 8 Elite Dominates\nThe OnePlus Pad 3 is ridiculously fast. The Snapdragon 8 Elite is the world‚Äôs fastest mobile CPU, and it shows. This chip delivers 45% faster CPU performance, 40% faster GPU performance, and 300% faster NPU performance compared to the Snapdragon 8 Gen 3. The AnTuTu benchmark score hits 2,947,633.\nOpening apps is instant. Switching between multiple apps is seamless. Running VS Code over SSH, having Obsidian open with large notes, browsing with multiple tabs, playing videos in the background ‚Äî it all just works without any lag whatsoever.\nThe response time is excellent. No stuttering, no waiting around for things to load. It feels snappy in a way that makes you forget you‚Äôre using a mid-range priced tablet.\nPerformance-wise, this thing competes with and often beats Apple‚Äôs M2 chip, getting close to M3 territory. And here‚Äôs the crazy part: it‚Äôs significantly cheaper than the Samsung Galaxy Tab S10 FE+, but outperforms it in nearly every aspect.\nFor gaming, the upgraded Adreno GPU with advanced cooling keeps frame rates high and consistent even during extended sessions. I don‚Äôt game much, but the performance headroom is there.\nFor the price, the performance you get is honestly insane."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-os-the-weakest-link",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-os-the-weakest-link",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "OnePlus OS: The Weakest Link",
    "text": "OnePlus OS: The Weakest Link\nThis is where things get rough. The software is the weakest part of this tablet by far.\nThe UI feels unpolished. It‚Äôs similar to Realme‚Äôs interface, and honestly, it‚Äôs not great. OnePlus clearly didn‚Äôt put much effort into the software side. The built-in Notes app, for example, looks like something someone threw together in ChatGPT in 10 minutes. It‚Äôs that basic.\nThe system update experience was absolutely terrible. It‚Äôs the worst update process I‚Äôve ever dealt with on a new device. Frustrating, slow, and poorly designed. This alone almost made me regret the purchase.\nOn the positive side: the Music app doesn‚Äôt have ads. That might sound like a low bar, but after dealing with Realme‚Äôs music app that forced you to watch ads just to play local music files, this is actually refreshing. The fan fact: it doesn‚Äôt has an Music app it uses YouTube music ^ ^\nThe software works, but it feels like OnePlus shipped this tablet with placeholder apps and never bothered to finish them. For a device with this kind of hardware, the software experience is disappointing.\n\nOxygen OS 16\nThe new version os 16 gets a lot of updates, the UI is more better, the animations and the apps gets a lot of updates, especially the notebook app it‚Äôs more better and works smoothly with the notebook they added a lot of updates like:\n\nEnhance writing with AI : Create high-quality notes with Polish, Format, and more tools.\n\nBlock-based editing\n\nSwipe right to adjust the format for a block of content.\nHold and drag to move text around.\n\n‚Äú/‚Äù for quick edits\nTap ‚Äú/‚Äù to change paragraph format, insert images or tables, and use other quick features.\nHighlight key information\nDouble-tap to select words and tap ‚ÄúHighlight‚Äù to add a highlight.\nShare link\nExport notes as PDF, TXT, or image files, or share them via link so anyone can read them, view embedded images, and listen to attached recordings on any device. **** Does they worked ? Yes, but the the share link and edit AI are not working due to errors in their servers for now, I also which the / quick edit can be smarter and has auto completions .\nIt will be more smart to has native support for MD writing and when I type ## it should make it heading by default but it doesnt. ## OnePlus AI Features: Actually Useful\nOnePlus has packed some genuinely useful AI features into this tablet, and they‚Äôre actually practical for daily work.\nAI Notes is probably the most useful one for me. One tap gives you instant summaries of long notes, or it can transcribe voice recordings without all the ‚Äúumms‚Äù and ‚Äúahhs.‚Äù You can also clean up text, format it, continue writing, or adjust the tone between formal and casual. This is helpful when I‚Äôm taking quick notes and need to turn them into something more polished.\nAI Voice Recorder works really well. It transcribes accurately and removes filler words automatically. Great for meetings or capturing ideas quickly.\nIt‚Äôs lags for the first words and when you speak fast it‚Äôs not there yet this is for Arabic\nAI Search (previously called Intelligent Search) is smart about finding things across your device. You can ask naturally like ‚ÄúHow much do I need to pay for video production?‚Äù and it searches through your files, notes, and settings. It understands context, which makes finding stuff much faster than traditional search.\nAI Translation is solid. It works on text, images, live conversations, and even screen content in real-time. If you deal with multiple languages or watch foreign content, this is genuinely useful.\nAI Summary gives you instant summaries of articles and websites with one tap. AI Writer helps polish your writing and change tone. AI Speak reads on-screen content aloud for multitasking.\nThe tablet also features Google Gemini built-in. You can access it via the dedicated AI button on the keyboard or by long-pressing the navigation bar. It‚Äôs helpful for brainstorming, writing, planning, and learning.\nThe AI photo features (Perfect Shot, Unblur, Reflection Eraser, AI Eraser) are nice to have but I don‚Äôt use them much since I‚Äôm not focused on photography.\nOverall, the AI features are actually practical tools, not just marketing gimmicks. The Notes and Voice Recorder AI especially help with my workflow. AI Transcriptions :it‚Äôs an automatic captions for vidoes in specific languages I use it for generate captions in English it‚Äôs very cool! The most loved one for me :)"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#keyboard-stylus-pro-grade-accessories",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#keyboard-stylus-pro-grade-accessories",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Keyboard & Stylus: Pro-Grade Accessories",
    "text": "Keyboard & Stylus: Pro-Grade Accessories\nI tested the tablet with a Redragon Bluetooth keyboard, and it works better than I expected. No noticeable latency at all. Typing feels responsive and smooth.\nThe problem is that using a separate Bluetooth keyboard without a proper setup gets annoying. You need to keep the tablet at the right distance, make sure it‚Äôs standing correctly, and you‚Äôre stuck without a mouse nearby. It works, but it‚Äôs not comfortable for long sessions.\nOnePlus Smart Keyboard (6,000-10,000 EGP) The official keyboard has a 6-row layout with a dedicated function row. It‚Äôs detachable with Bluetooth connectivity (works up to 10 meters wirelessly), and features NFC tap for One-touch Transmission to quickly share files. That‚Äôs expensive ‚Äî especially when you consider the tablet itself is 25,000 EGP.\nI bought it after one week of buying the tablet itself. The first impression that It‚Äôs name was one plus pad 2 pro in Chinese and after that I thought it‚Äôs was a mistake from the buyer..then I found it‚Äôs another name for the same OnePlus pad 3 . The most important it‚Äôs keys are better than normal laptop and it‚Äôs totally different from mechanical one and i found it better than the redregon it‚Äôs wide and very good. The smell of the leather cover is nice and feels premium!\nThe touchpad is normal not that good but it‚Äôs okay. The shortcuts are very nice also ‚Ä¶you will start that this more to be a productivity machine : don‚Äôt forget to mute all the notifications OnePlus Stylo 2 (5,000 EGP) The stylus offers 16,000 levels of pressure sensitivity, ultra-low latency, and haptic feedback. It also doubles as a laser pointer with page turn functions for presentations.\nI‚Äôm probably going to end up buying the official keyboard anyway. I‚Äôm curious about the layout and how the switches compare to the mechanical keyboards I‚Äôm used to. I don‚Äôt know if I‚Äôll love it, but I need something more integrated for serious work.\nThe typing experience matters when you‚Äôre coding or writing for hours, so having a proper keyboard setup is worth the investment.\n\n\n\noneplus pad 3 keyboard"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#my-workflow-how-i-use-it-as-a-programmer",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#my-workflow-how-i-use-it-as-a-programmer",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "My Workflow: How I Use It as a Programmer",
    "text": "My Workflow: How I Use It as a Programmer\nThis is why I bought the tablet in the first place ‚Äî to create a separate workspace that doesn‚Äôt mix with my personal life.\nI wanted a device I could pick up for specific work tasks without reaching for my main laptop every time. Something I could leave on standby for days and grab whenever I need it. The OnePlus Pad 3 does exactly that.\nHere‚Äôs how I use it:\nCoding & Development - VS Code for SSH connections to my servers and remote development - I can work on projects without being tied to my main machine - The large 13.2-inch screen lets me see more code at once\nNote-Taking & Knowledge Management - Obsidian for my personal knowledge base and daily notes - OneNote for quick captures and shared notes - The AI Notes feature helps clean up and format my thoughts quickly\nProductivity & Task Management - Super Productivity for tracking my daily tasks and time - Linear for project management - Ankicards for learning and spaced repetition - Zotero for research and reference management\nFile Sync & Transfer - Syncthing keeps my files synced across devices - LocalSend for quick file transfers between my laptop and tablet\nContent Creation - YouTube Studio and TikTok Studio for uploading shorts and managing content properly - Substack for writing and publishing - Infinite Painter for occasional creative work\nBrowsing - Brave as my main browser\nMedia Consumption - Reading articles and documentation offline - Watching videos ‚Äî the 3.4K screen and 8-speaker system make this incredible\nSeamless Connectivity The OnePlus Pad 3 connects seamlessly with my OnePlus phone. I can use my phone‚Äôs 5G without setting up a hotspot, sync notifications and clipboard, and use App Relay to continue tasks between devices. It also supports remote connection to Mac via the O+ Connect app for drag-and-drop file transfers and native Mac gestures.\nThe separation is the key benefit. I can work on an open project daily through these apps, then close the tablet and leave work behind. It‚Äôs a mental boundary that helps me stay focused during work hours and actually relax after."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#the-downsides-what-oneplus-got-wrong",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#the-downsides-what-oneplus-got-wrong",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "The Downsides: What OnePlus Got Wrong",
    "text": "The Downsides: What OnePlus Got Wrong\nNo device is perfect, and the OnePlus Pad 3 has some real frustrations.\nNo SIM Support This is probably my biggest disappointment. The tablet doesn‚Äôt support a SIM card at all. If you need cellular connectivity on the go, you‚Äôre out of luck. You‚Äôre stuck with WiFi only or tethering to your phone (though the OnePlus phone integration makes this easier).\nNo Charger in the Box You get a USB cable and that‚Äôs it. Want to actually charge the device at the advertised 80W SUPERVOOC speeds? Pay another 1,500 EGP for the official charger. It feels cheap to leave this out of a 25,000 EGP device.\nSoftware Needs Serious Polish The UI is rough. Built-in apps feel half-finished. The Notes app is embarrassingly basic. OnePlus clearly focused on hardware and ignored the software experience.\nSystem Updates Are Terrible This was the worst part of setting up the device. The update process is painfully slow, poorly designed, and frustrating. It‚Äôs the kind of experience that makes you question your purchase decision.\nExpensive Accessories The Stylo 2 costs 5,000 EGP. The Smart Keyboard is 6,000-10,000 EGP. The charger is 1,500 EGP. By the time you have a complete setup, you‚Äôre approaching iPad pricing territory ‚Äî but at least you‚Äôre getting better specs."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-pad-3-total-cost-breakdown-egp",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-pad-3-total-cost-breakdown-egp",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "OnePlus Pad 3 Total Cost Breakdown (EGP)",
    "text": "OnePlus Pad 3 Total Cost Breakdown (EGP)\nHere‚Äôs what you‚Äôre actually paying when you buy the OnePlus Pad 3 with all the accessories you‚Äôll realistically need:\n\n\n\nItem\nPrice (EGP)\n\n\n\n\nOnePlus Pad 3 (12GB RAM)\n25,000\n\n\nOnePlus Stylo 2\n5,000\n\n\nOnePlus Smart Keyboard\n6,000 - 10,000\n\n\n80W SUPERVOOC Charger\n1,500\n\n\nTotal\n37,500 - 41,500\n\n\n\nSo while the tablet itself looks affordable at 25,000 EGP, the full setup pushes you into the 37,500-41,500 EGP range.\nFor context: that‚Äôs approaching the total cost of a basic iPad setup. The difference? You‚Äôre getting significantly better specs with the OnePlus ‚Äî the world‚Äôs fastest mobile CPU, a larger and sharper 3.4K display, double the battery capacity, and 8 speakers.\nHere‚Äôs the really funny part: the iPad Magic Keyboard alone costs about the same as the entire OnePlus Pad 3 tablet. You‚Äôre paying iPad Magic Keyboard prices for a whole tablet that outperforms the iPad it would plug into. Let that sink in."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-pad-3-vs-ipad-vs-samsung-which-wins",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#oneplus-pad-3-vs-ipad-vs-samsung-which-wins",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "OnePlus Pad 3 vs iPad vs Samsung: Which Wins?",
    "text": "OnePlus Pad 3 vs iPad vs Samsung: Which Wins?\nLet‚Äôs talk about what you‚Äôre getting compared to the competition, because the numbers are honestly wild.\nvs iPad (Base Model) The base iPad with similar accessories ends up costing roughly the same as a fully kitted OnePlus Pad 3. But the OnePlus has objectively better specs: - Snapdragon 8 Elite beats Apple‚Äôs M2 chip in many benchmarks - 13.2-inch 3.4K display vs 10.9-inch 2360x1640 on iPad - 144Hz vs 60Hz refresh rate - 12,140mAh vs ~7,600mAh battery - 8 speakers vs 2 speakers - 80W charging vs 20W charging\nAnd here‚Äôs the absurdity: Apple‚Äôs Magic Keyboard costs around 25,000 EGP on its own. That‚Äôs the same price as the entire OnePlus Pad 3. You‚Äôre paying for a keyboard what OnePlus charges for a whole flagship tablet. The value proposition is insane.\nvs Samsung Galaxy Tab S10 FE+ The Samsung costs more than the OnePlus Pad 3, but the OnePlus beats it in nearly every aspect. Better processor (Snapdragon 8 Elite vs Exynos 1480), larger battery, faster charging, bigger display, and better value. The Samsung might have slightly more polished software, but you‚Äôre paying a premium for the brand name.\nThe Real Winner For 25,000 EGP, you‚Äôre getting performance that beats Apple‚Äôs M2 and approaches M3 territory. You‚Äôre getting flagship specs at mid-range pricing. The only real compromise is the software experience, which is rough but workable.\nIf you can live with OnePlus OS and don‚Äôt need cellular connectivity, this tablet offers unbeatable value in 2025."
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#who-should-buy-the-oneplus-pad-3",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#who-should-buy-the-oneplus-pad-3",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Who Should Buy the OnePlus Pad 3?",
    "text": "Who Should Buy the OnePlus Pad 3?\nYou should buy the OnePlus Pad 3 if:\n‚úÖ You‚Äôre a programmer or developer who needs a secondary device for SSH, coding, and productivity work\n‚úÖ You want to separate work from your main laptop without spending iPad money\n‚úÖ You‚Äôre a content creator on a budget who needs something for YouTube Studio, TikTok, or blogging\n‚úÖ You‚Äôre a student who needs a powerful tablet for note-taking, research, and media consumption\n‚úÖ You want flagship performance without paying flagship prices\n‚úÖ You primarily use WiFi and don‚Äôt need cellular connectivity (though OnePlus phone integration helps)\n‚úÖ You can tolerate rough software in exchange for excellent hardware\n‚úÖ You want the best display and audio experience on an Android tablet\nDon‚Äôt buy this if:\n‚ùå You need SIM/cellular support ‚Äî this tablet doesn‚Äôt have it\n‚ùå You‚Äôre deeply invested in the Apple ecosystem and need seamless integration\n‚ùå You expect premium accessories to be included ‚Äî they cost extra\n‚ùå You can‚Äôt deal with frustrating system updates\n‚ùå You need polished, refined software out of the box"
  },
  {
    "objectID": "blog/posts/products_reviews/one_plus_pad_3.html#final-verdict-910",
    "href": "blog/posts/products_reviews/one_plus_pad_3.html#final-verdict-910",
    "title": "OnePlus Pad 3 Review (2025) - Researcher Review",
    "section": "Final Verdict: 9/10",
    "text": "Final Verdict: 9/10\nThe OnePlus Pad 3 is a fantastic tablet trapped in mediocre software.\nThe hardware is exceptional. The Snapdragon 8 Elite performance is incredible. The 13.2-inch 3.4K 144Hz display is stunning. The 12,140mAh battery life is outstanding. The 8-speaker audio system is phenomenal. The 5.97mm ultra-slim metal design is gorgeous. For 25,000 EGP, you‚Äôre getting specs that compete with devices costing twice as much.\nBut the software experience is frustrating. The system updates are terrible. The built-in apps feel unfinished. OnePlus clearly put all their effort into hardware and phoned it in on software.\nHere‚Äôs the thing though: if you‚Äôre like me and you‚Äôre installing your own apps anyway ‚Äî VS Code, Obsidian, Super Productivity, Brave ‚Äî the stock software doesn‚Äôt matter as much. You‚Äôre building your own environment. The hardware gives you an exceptional foundation to work with.\nWould I buy it again? Yes. Despite the software frustrations and the lack of SIM support, this tablet does exactly what I needed: a fast, lightweight, long-lasting secondary device for work that didn‚Äôt cost iPad money. The Snapdragon 8 Elite performance, massive battery, and beautiful display make it worth every compromise.\nThe OnePlus Pad 3 isn‚Äôt perfect, but it‚Äôs the best value Android tablet for productivity work in 2025. Just budget for the accessories and prepare yourself for a rough software experience.\nRating: 9/10 ‚Äî Exceptional hardware held back by rough software, but still the best value in its class.\n\nReferences:\n\nAll One plus news and reviwes\nhuawei freebuds 7i Review"
  },
  {
    "objectID": "blog/posts/seo/how_i_use_nlp_for_seo.html",
    "href": "blog/posts/seo/how_i_use_nlp_for_seo.html",
    "title": "How I am using NLP to improve my Websites SEO",
    "section": "",
    "text": "Unlocking SEO Potential with NLP: A Journey of Website Optimization\nIn the vast digital landscape, the visibility of a website amidst the sea of search results can make or break its success. Search Engine Optimization (SEO) stands as the beacon guiding businesses towards the shores of higher visibility and traffic. As the digital realm evolves, so do the strategies employed to enhance SEO. One such frontier that holds immense promise is the integration of Natural Language Processing (NLP) into SEO practices.\n\nUnderstanding the Landscape\nSEO isn‚Äôt just about optimizing keywords anymore; it‚Äôs about understanding user intent, predicting trends, and delivering value-rich content. Harnessing the power of NLP, we embark on a journey to revolutionize SEO practices for our websites. Here‚Äôs how we‚Äôre leveraging NLP to bolster our SEO efforts:\n\n\n1. Daily Downloads and Keyword Integration\nWe kickstart our journey by integrating Google Search Console into our workflow. By fetching daily downloads of our top queries, we gain invaluable insights into user behavior and preferences. These queries are seamlessly integrated into a specific folder, forming the backbone of our content optimization strategy.\n\n\n2. Content Analysis and Optimization\nNLP comes into play as we meticulously analyze our content to ensure alignment with the top queries identified. By leveraging NLP techniques, we ascertain the presence of these keywords within our content, ensuring relevance and resonance with our audience‚Äôs search intent.\n\n\n3. Predictive Analytics and Trend Spotting\nPowered by NLP, we delve into the realm of predictive analytics to forecast future trends. By analyzing historical data and current patterns, we identify emerging trends and capitalize on them proactively. This enables us to stay ahead of the curve and position our content strategically to meet evolving user demands.\n\n\n4. Semantic and Exact Match Integration\nNLP empowers us to delve deeper into the semantics of language, enabling us to differentiate between exact matches and similar meanings. Through advanced NLP algorithms, we ensure that our content not only features exact keyword matches but also resonates with synonymous terms, enhancing its visibility across diverse search queries.\n\n\nLeveling Up the Game\nAs we progress on our journey of NLP-driven SEO optimization, we outline a roadmap for leveling up our capabilities:\n\nLevel 1:\n\nData Management: Implementing robust data storage solutions tailored to multiple websites.\nVisualization: Crafting compelling visualizations using tools like Bokeh and Plotly.\nMachine Learning Models: Developing forecasting models to predict future trends.\nSemantic Search: Leveraging vector databases for semantic and exact search capabilities.\n\n\n\nLevel 2:\n\nOptimization: Streamlining our codebase through asynchronous processing and caching mechanisms.\n\n\n\nLevel 3:\n\nProduct Development: Exploring avenues to transform our NLP-driven SEO framework into software products like WordPress plugins or desktop applications.\n\n\n\nLevel 4:\n\nInnovation: Drawing inspiration from industry leaders to create bespoke solutions, such as an Arabic version of our SEO platform akin to UberSuggest and Guni Rank.\n\n\n\n\nConclusion\nI mainly using NLP with python to improve my landing pages for home services like the following services: Here are the markdown links with target titles for the provided text:\n\nŸÖŸÜÿµÿ© ÿµŸÜÿßÿπÿ© ÿßŸÑŸÖÿ≠ÿ™ŸàŸä ÿßŸÑÿπÿ±ÿ®Ÿä\nŸÉŸÖ ŸÉÿßŸÑŸàÿ±Ÿä ŸÅŸä ÿßŸÑŸÖŸàÿ≤\nÿµŸäÿßŸÜÿ© ÿßŸÅÿ±ÿßŸÜ ÿ∫ÿßÿ≤ ÿ®ÿßŸÑÿ±Ÿäÿßÿ∂\nÿ¥ÿ±ŸÉÿ© ÿ™ŸÜÿ≥ŸäŸÇ ÿ≠ÿØÿßÿ¶ŸÇ ÿ®ÿßŸÑŸÖÿØŸäŸÜÿ© ÿßŸÑŸÖŸÜŸàÿ±ÿ©\nÿ¥ÿ±ŸÉÿ© ÿ™ŸÜÿ∏ŸäŸÅ ŸÖŸÜÿßÿ≤ŸÑ ŸÅŸä ÿßŸÑÿπŸäŸÜ\n\nIn the ever-evolving landscape of SEO, the integration of NLP marks a paradigm shift towards more sophisticated and nuanced optimization strategies. By harnessing the power of NLP, we not only decipher the language of search but also anticipate and cater to the evolving needs of our audience. As we continue to refine our approach and explore new frontiers, the synergy between NLP and SEO promises to redefine the digital landscape, empowering businesses to thrive in an era of unparalleled connectivity and discovery. you can read more articles here"
  },
  {
    "objectID": "blog/posts/minishlab/blog_zaraah.html",
    "href": "blog/posts/minishlab/blog_zaraah.html",
    "title": "Bojji & Zarra Embedding models",
    "section": "",
    "text": "This blog post introduces the Bojji and Zarra family of static embedding models, designed for Arabic language tasks and built using the model2vec distillation technique from MinishLab.\nThese models distill knowledge from larger transformer models, such as SBERT, into compact, efficient embeddings.\nThis approach balances performance with speed and resource efficiency.\nBelow, I explore the Bojji models and their relationship to Potion models, their strengths and limitations, and their applications in Arabic embedding tasks.\n\n\nPotion models combine innovative techniques to create high-performing, compact static embeddings.\nI liken them to Bojji from Ousama Ranking small in size but capable of competing with giants like Jina AI and BGE models.\n\n\n\nBojji Embedding\n\n\nKey features of Potion models include:\n\nSuperior Performance: They outperform traditional static embeddings like GloVe and FastText across various tasks, matching the performance of models like all-MiniLM-L6-v2 in English.\nCompact Size: With approximately 2‚Äì4 million parameters, they are ~55 times smaller than GloVe, with model sizes ranging from 8 MB to 30 MB.\nEfficiency: Designed for CPU execution and browser-based applications, they are ideal for edge devices and low-resource environments.\nMTEB Performance: They achieve an average MTEB score above 50%, making them highly competitive for their size.\n\n\n\n\nThe model2vec distillation method addresses the challenge of creating fast, compact sentence transformers.\nIt transforms large sentence transformer models into static embeddings that are up to 500x faster and 15x smaller, with only a minor performance trade-off.\nUnlike traditional methods like GloVe, model2vec captures knowledge from large sentence transformers, producing uncontextualized word vectors.\nWhile this sacrifices some contextual nuance, it offers significant advantages in:\n\nSpeed: Up to 500x faster inference.\nSize: Models reduced by up to 50x, ranging from 8 MB to 30 MB.\nVersatility: Sufficient word representations for most NLP applications.\n\nFor more details, refer to the MinishLab blog and GitHub repository."
  },
  {
    "objectID": "blog/posts/minishlab/blog_zaraah.html#arabic-embedding-models",
    "href": "blog/posts/minishlab/blog_zaraah.html#arabic-embedding-models",
    "title": "Bojji & Zarra Embedding models",
    "section": "",
    "text": "This blog post introduces the Bojji and Zarra family of static embedding models, designed for Arabic language tasks and built using the model2vec distillation technique from MinishLab.\nThese models distill knowledge from larger transformer models, such as SBERT, into compact, efficient embeddings.\nThis approach balances performance with speed and resource efficiency.\nBelow, I explore the Bojji models and their relationship to Potion models, their strengths and limitations, and their applications in Arabic embedding tasks.\n\n\nPotion models combine innovative techniques to create high-performing, compact static embeddings.\nI liken them to Bojji from Ousama Ranking small in size but capable of competing with giants like Jina AI and BGE models.\n\n\n\nBojji Embedding\n\n\nKey features of Potion models include:\n\nSuperior Performance: They outperform traditional static embeddings like GloVe and FastText across various tasks, matching the performance of models like all-MiniLM-L6-v2 in English.\nCompact Size: With approximately 2‚Äì4 million parameters, they are ~55 times smaller than GloVe, with model sizes ranging from 8 MB to 30 MB.\nEfficiency: Designed for CPU execution and browser-based applications, they are ideal for edge devices and low-resource environments.\nMTEB Performance: They achieve an average MTEB score above 50%, making them highly competitive for their size.\n\n\n\n\nThe model2vec distillation method addresses the challenge of creating fast, compact sentence transformers.\nIt transforms large sentence transformer models into static embeddings that are up to 500x faster and 15x smaller, with only a minor performance trade-off.\nUnlike traditional methods like GloVe, model2vec captures knowledge from large sentence transformers, producing uncontextualized word vectors.\nWhile this sacrifices some contextual nuance, it offers significant advantages in:\n\nSpeed: Up to 500x faster inference.\nSize: Models reduced by up to 50x, ranging from 8 MB to 30 MB.\nVersatility: Sufficient word representations for most NLP applications.\n\nFor more details, refer to the MinishLab blog and GitHub repository."
  },
  {
    "objectID": "blog/posts/minishlab/blog_zaraah.html#jina-embeddings-v3-for-arabic",
    "href": "blog/posts/minishlab/blog_zaraah.html#jina-embeddings-v3-for-arabic",
    "title": "Bojji & Zarra Embedding models",
    "section": "Jina Embeddings v3 for Arabic",
    "text": "Jina Embeddings v3 for Arabic\nThe jina-embeddings-v3 model is currently the top-performing open-source, zero-shot embedding model for Arabic on the MTEB leaderboard.\nIt excels across various tasks and has been validated in production for Arabic applications.\nHowever, its large size and high memory requirements make it computationally expensive and slow compared to other embedding models.\nTo address this, I used model2vec to create a compact Arabic version, the Zarra and bojji with with another base model and different method, which retains strong performance while being significantly smaller and faster."
  },
  {
    "objectID": "blog/posts/minishlab/blog_zaraah.html#bojji-and-zarra",
    "href": "blog/posts/minishlab/blog_zaraah.html#bojji-and-zarra",
    "title": "Bojji & Zarra Embedding models",
    "section": "Bojji and Zarra",
    "text": "Bojji and Zarra\n\nBojji HuggingFace\nZarra HuggingFace\n\nThe Zarra models are the first static embedding models for Arabic trained with tokenlearn on the Arabic subset of the C4 dataset.\nThey are optimized for Arabic-specific tasks and come in multiple sizes:\nAll variants support float32 and int8 quantization without performance loss, making them highly efficient for resource-constrained environments."
  },
  {
    "objectID": "blog/posts/minishlab/blog_zaraah.html#bojji-model-vs-competitors",
    "href": "blog/posts/minishlab/blog_zaraah.html#bojji-model-vs-competitors",
    "title": "Bojji & Zarra Embedding models",
    "section": "Bojji Model vs Competitors",
    "text": "Bojji Model vs Competitors\nTo evaluate Bojji‚Äôs performance, I compared it against several multilingual and Arabic-specific sentence transformer models using MTEB tasks tailored for Arabic.\n\n\n                                            Model Evaluation Summary                                             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model                                 ‚îÉ    Avg ‚îÉ  MIRAC ‚îÉ  MLQAR ‚îÉ  Massi ‚îÉ  Multi ‚îÉ  STS17 ‚îÉ  STS22 ‚îÉ  XNLI_ ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ 0.6610 ‚îÇ 0.6262 ‚îÇ 0.5093 ‚îÇ 0.5577 ‚îÇ 0.5868 ‚îÇ 0.8531 ‚îÇ 0.6396 ‚îÇ 0.8542 ‚îÇ\n‚îÇ muffakir_embedding                    ‚îÇ 0.6494 ‚îÇ 0.6424 ‚îÇ 0.5267 ‚îÇ 0.5462 ‚îÇ 0.5943 ‚îÇ 0.8485 ‚îÇ 0.6291 ‚îÇ 0.7583 ‚îÇ\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ 0.6473 ‚îÇ 0.6159 ‚îÇ 0.5674 ‚îÇ 0.5832 ‚îÇ 0.5993 ‚îÇ 0.8002 ‚îÇ 0.6254 ‚îÇ 0.7393 ‚îÇ\n‚îÇ gate_arabert-v1                       ‚îÇ 0.6444 ‚îÇ 0.5774 ‚îÇ 0.4808 ‚îÇ 0.5345 ‚îÇ 0.5847 ‚îÇ 0.8278 ‚îÇ 0.6310 ‚îÇ 0.8746 ‚îÇ\n‚îÇ get_multilingual_base                 ‚îÇ 0.6440 ‚îÇ 0.7177 ‚îÇ 0.5698 ‚îÇ 0.5071 ‚îÇ 0.5521 ‚îÇ 0.7881 ‚îÇ 0.6145 ‚îÇ 0.7584 ‚îÇ\n‚îÇ arabic_sts_matryoshka                 ‚îÇ 0.6413 ‚îÇ 0.5828 ‚îÇ 0.4840 ‚îÇ 0.5457 ‚îÇ 0.5494 ‚îÇ 0.8290 ‚îÇ 0.6242 ‚îÇ 0.8740 ‚îÇ\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ 0.6138 ‚îÇ 0.3799 ‚îÇ 0.5011 ‚îÇ 0.5600 ‚îÇ 0.5749 ‚îÇ 0.8559 ‚îÇ 0.6122 ‚îÇ 0.8125 ‚îÇ\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ 0.5431 ‚îÇ 0.2240 ‚îÇ 0.3612 ‚îÇ 0.4775 ‚îÇ 0.5698 ‚îÇ 0.8111 ‚îÇ 0.5540 ‚îÇ 0.8043 ‚îÇ\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ 0.5208 ‚îÇ 0.2191 ‚îÇ 0.3496 ‚îÇ 0.4515 ‚îÇ 0.5573 ‚îÇ 0.7916 ‚îÇ 0.4908 ‚îÇ 0.7859 ‚îÇ\n‚îÇ bojji                                 ‚îÇ 0.5177 ‚îÇ 0.2941 ‚îÇ 0.3989 ‚îÇ 0.4667 ‚îÇ 0.5433 ‚îÇ 0.7233 ‚îÇ 0.5880 ‚îÇ 0.6094 ‚îÇ\n‚îÇ zarra                                 ‚îÇ 0.4822 ‚îÇ 0.2295 ‚îÇ 0.3473 ‚îÇ 0.4119 ‚îÇ 0.5237 ‚îÇ 0.6469 ‚îÇ 0.6218 ‚îÇ 0.5942 ‚îÇ\n‚îÇ potion-multilingual-128M              ‚îÇ 0.4699 ‚îÇ 0.1658 ‚îÇ 0.3150 ‚îÇ 0.4285 ‚îÇ 0.5338 ‚îÇ 0.6511 ‚îÇ 0.5951 ‚îÇ 0.5999 ‚îÇ\n‚îÇ all_minilm_l6_v2                      ‚îÇ 0.2843 ‚îÇ 0.0005 ‚îÇ 0.0064 ‚îÇ 0.1905 ‚îÇ 0.4934 ‚îÇ 0.5089 ‚îÇ 0.2518 ‚îÇ 0.5384 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nI filtered the most related MTEB tasks that supports Arabic-script only the evalution script is in the references blow. We can say that the average score for the Zarra are very low compared to the other models, but didn‚Äôt let the Average score fool you! Average is affected with the outliers so, if one task is the low the final answer with be low also.\nBut from the first look, we can see the peformance is similar to the Arabic versions of MiniLM-L12 in Average and if you looked at the Sentence similarity for STS22 it‚Äôs score are very good compared to static-embedding model.\n\nUnderstanding MTEB Tasks for Arabic\nThe Massive Text Embedding Benchmark (MTEB) evaluates embedding models across various tasks. Here‚Äôs a breakdown of the tasks used :\n\nMIRACLRetrievalHardNegatives: Measures retrieval accuracy for hard negative examples, critical for search and question-answering systems. Zarra‚Äôs lower score here reflects its static embedding nature, which sacrifices some contextual nuance.\nMLQARetrieval: Tests retrieval performance on multilingual question-answering datasets, where Zarra performs comparably to MiniLM models.\nSTS17 & STS22: Evaluates semantic textual similarity, where Zarra excels, particularly in STS22, with scores rivaling larger models.\nXNLI: Assesses natural language inference, where Zarra‚Äôs performance is competitive despite its compact size.\n\nThese tasks highlight Zarra‚Äôs strengths in semantic similarity and efficiency, making it ideal for applications like chatbots and lightweight search systems\nYou can see the peformance for every task in MTEB here\n\n\n             Sorted by MIRACLRetrievalHardNegatives_main (Score)             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model Name                            ‚îÉ MIRACLRetrievalHardNegatives_main ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ get_multilingual_base                 ‚îÇ                             0.718 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ muffakir_embedding                    ‚îÇ                             0.642 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ                             0.626 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ                             0.616 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_sts_matryoshka                 ‚îÇ                             0.583 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ gate_arabert-v1                       ‚îÇ                             0.577 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ                             0.380 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bojji                                 ‚îÇ                             0.294 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ zarra                                 ‚îÇ                             0.230 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ                             0.224 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ                             0.219 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ potion-multilingual-128M              ‚îÇ                             0.166 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ all_minilm_l6_v2                      ‚îÇ                             0.001 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n             Sorted by MLQARetrieval_main (Score)             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model Name                            ‚îÉ MLQARetrieval_main ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ get_multilingual_base                 ‚îÇ              0.570 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ              0.567 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ muffakir_embedding                    ‚îÇ              0.527 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ              0.509 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ              0.501 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_sts_matryoshka                 ‚îÇ              0.484 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ gate_arabert-v1                       ‚îÇ              0.481 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bojji                                 ‚îÇ              0.399 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ              0.361 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ              0.350 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ zarra                                 ‚îÇ              0.347 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ potion-multilingual-128M              ‚îÇ              0.315 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ all_minilm_l6_v2                      ‚îÇ              0.006 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n             Sorted by MassiveIntentClassification_main (Score)             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model Name                            ‚îÉ MassiveIntentClassification_main ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ                            0.583 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ                            0.560 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ                            0.558 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ muffakir_embedding                    ‚îÇ                            0.546 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_sts_matryoshka                 ‚îÇ                            0.546 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ gate_arabert-v1                       ‚îÇ                            0.534 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ get_multilingual_base                 ‚îÇ                            0.507 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ                            0.478 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bojji                                 ‚îÇ                            0.467 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ÔøΩÔøΩ                            0.451 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ potion-multilingual-128M              ‚îÇ                            0.428 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ zarra                                 ‚îÇ                            0.412 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ all_minilm_l6_v2                      ‚îÇ                            0.190 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n             Sorted by MultiHateClassification_main (Score)             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model Name                            ‚îÉ MultiHateClassification_main ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ                        0.599 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ muffakir_embedding                    ‚îÇ                        0.594 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ                        0.587 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ gate_arabert-v1                       ‚îÇ                        0.585 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ                        0.575 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ                        0.570 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ                        0.557 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ get_multilingual_base                 ‚îÇ                        0.552 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_sts_matryoshka                 ‚îÇ                        0.549 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bojji                                 ‚îÇ                        0.543 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ potion-multilingual-128M              ‚îÇ                        0.534 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ zarra                                 ‚îÇ                        0.524 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ all_minilm_l6_v2                      ‚îÇ                        0.493 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n             Sorted by STS17_main (Score)             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model Name                            ‚îÉ STS17_main ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ      0.856 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ      0.853 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ muffakir_embedding                    ‚îÇ      0.849 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_sts_matryoshka                 ‚îÇ      0.829 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ gate_arabert-v1                       ‚îÇ      0.828 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ      0.811 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ      0.800 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ      0.792 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ get_multilingual_base                 ‚îÇ      0.788 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bojji                                 ‚îÇ      0.723 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ potion-multilingual-128M              ‚îÇ      0.651 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ zarra                                 ‚îÇ      0.647 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ all_minilm_l6_v2                      ‚îÇ      0.509 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n             Sorted by STS22.v2_main (Score)             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model Name                            ‚îÉ STS22.v2_main ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ         0.640 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ gate_arabert-v1                       ‚îÇ         0.631 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ muffakir_embedding                    ‚îÇ         0.629 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ         0.625 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_sts_matryoshka                 ‚îÇ         0.624 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ zarra                                 ‚îÇ         0.622 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ get_multilingual_base                 ‚îÇ         0.615 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ         0.612 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ potion-multilingual-128M              ‚îÇ         0.595 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bojji                                 ‚îÇ         0.588 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ         0.554 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ         0.491 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ all_minilm_l6_v2                      ‚îÇ         0.252 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n             Sorted by XNLI_main (Score)             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model Name                            ‚îÉ XNLI_main ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ gate_arabert-v1                       ‚îÇ     0.875 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_sts_matryoshka                 ‚îÇ     0.874 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ     0.854 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ     0.813 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ Arabic-MiniLM-L12-v2-all-nli-triplet  ‚îÇ     0.804 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ     0.786 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ get_multilingual_base                 ‚îÇ     0.758 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ muffakir_embedding                    ‚îÇ     0.758 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ     0.739 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bojji                                 ‚îÇ     0.609 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ potion-multilingual-128M              ‚îÇ     0.600 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ zarra                                 ‚îÇ     0.594 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ all_minilm_l6_v2                      ‚îÇ     0.538 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\n\n\n\nBojji vs.¬†all-MiniLM\nThe Bojji model outperform the all-MiniLM family from SBERT in Arabic tasks while being significantly faster and capable of running on CPU.\nThis makes Bojji an excellent lightweight alternative for applications requiring efficient Arabic embeddings.\nAlso the models performance is most of the time better than the potion-multilingual-128M which indicates that techniques are working with any language not just English.\n\n\nArabic RAG Leaderboard\nTo complement MTEB evaluations, I tested Zarra on the Arabic-RAG Leaderboard, which provides a robust benchmark for Arabic-specific tasks. Zarra ranks 37 out of 45 models with an average score of 36.84.\nThis is impressive, as Zarra is the smallest model in the leaderboard, highlighting its efficiency and competitive performance in resource-constrained settings.\n\nWhat about Bojji perfomrance in Arabic RAG Leaderboard?\nActually the first model with Zarra and not bojji is the second release of Zarra with different updates but..i know that if i didn‚Äôt write the blog as it as, i will not publish it again!\nBojji will be test on the Arabic Rag soon."
  },
  {
    "objectID": "blog/posts/minishlab/blog_zaraah.html#speed-comprsion",
    "href": "blog/posts/minishlab/blog_zaraah.html#speed-comprsion",
    "title": "Bojji & Zarra Embedding models",
    "section": "Speed comprsion",
    "text": "Speed comprsion\n\n\nSome weights of the model checkpoint at Alibaba-NLP/gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\nCompleted zarra on cpu: 26893.63 sentences/second\n\n\n\nCompleted bojji on cpu: 27478.15 sentences/second\n\n\n\nCompleted potion-multilingual-128M on cpu: 27145.31 sentences/second\n\n\n\nCompleted paraphrase-multilingual-MiniLM-L12-v2 on cuda: 2363.24 sentences/second\n\n\n\nCompleted silma_ai_embedding_sts_v0.1 on cuda: 627.13 sentences/second\n\n\n\nCompleted muffakir_embedding on cuda: 621.77 sentences/second\n\n\n\nCompleted get_multilingual_base on cuda: 895.41 sentences/second\n\n\n\nCompleted arabic_retrieval_v1.0 on cuda: 618.56 sentences/second\n\n\n\nCompleted arabic_triplet_matryoshka_v2 on cuda: 610.64 sentences/second\n\n\n\n                           Model Benchmark Results                           \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model                                 ‚îÉ Speed (sentences/second) ‚îÉ Device ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ zarra                                 ‚îÇ 26893.63                 ‚îÇ cpu    ‚îÇ\n‚îÇ bojji                                 ‚îÇ 27478.15                 ‚îÇ cpu    ‚îÇ\n‚îÇ potion-multilingual-128M              ‚îÇ 27145.31                 ‚îÇ cpu    ‚îÇ\n‚îÇ paraphrase-multilingual-MiniLM-L12-v2 ‚îÇ 2363.24                  ‚îÇ cuda   ‚îÇ\n‚îÇ silma_ai_embedding_sts_v0.1           ‚îÇ 627.13                   ‚îÇ cuda   ‚îÇ\n‚îÇ muffakir_embedding                    ‚îÇ 621.77                   ‚îÇ cuda   ‚îÇ\n‚îÇ get_multilingual_base                 ‚îÇ 895.41                   ‚îÇ cuda   ‚îÇ\n‚îÇ arabic_retrieval_v1.0                 ‚îÇ 618.56                   ‚îÇ cuda   ‚îÇ\n‚îÇ arabic_triplet_matryoshka_v2          ‚îÇ 610.64                   ‚îÇ cuda   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\n\n\nSafetensorsRepoMetadata(metadata=None, sharded=False, weight_map={'embeddings': 'model.safetensors'}, files_metadata={'model.safetensors': SafetensorsFileMetadata(metadata={}, tensors={'embeddings': TensorInfo(dtype='F32', shape=[249999, 256], data_offsets=(0, 255998976), parameter_count=63999744)}, parameter_count={'F32': 63999744})}, parameter_count={'F32': 63999744})\n\n\n\n\nResults saved to model_info_results.csv\n\n\n\n                                             Model Information Results                                             \n‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ Model                            ‚îÉ Parameters (M) ‚îÉ Size (MB) ‚îÉ Relative to Largest (%) ‚îÉ Less than Largest (x) ‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ zarra                            ‚îÇ          64.00 ‚îÇ    244.14 ‚îÇ                   41.92 ‚îÇ                  2.39 ‚îÇ\n‚îÇ bojji                            ‚îÇ         124.88 ‚îÇ    476.40 ‚îÇ                   81.79 ‚îÇ                  1.22 ‚îÇ\n‚îÇ potion-multilingual-128M         ‚îÇ         128.09 ‚îÇ    488.63 ‚îÇ                   83.89 ‚îÇ                  1.19 ‚îÇ\n‚îÇ paraphrase-multilingual-MiniLM-‚Ä¶ ‚îÇ         117.65 ‚îÇ    448.82 ‚îÇ                   77.06 ‚îÇ                  1.30 ‚îÇ\n‚îÇ silma_ai_embedding_sts_v0.1      ‚îÇ         135.19 ‚îÇ    515.72 ‚îÇ                   88.54 ‚îÇ                  1.13 ‚îÇ\n‚îÇ muffakir_embedding               ‚îÇ         135.19 ‚îÇ    515.72 ‚îÇ                   88.54 ‚îÇ                  1.13 ‚îÇ\n‚îÇ arabic_retrieval_v1.0            ‚îÇ         135.19 ‚îÇ    515.73 ‚îÇ                   88.54 ‚îÇ                  1.13 ‚îÇ\n‚îÇ arabic_triplet_matryoshka_v2     ‚îÇ         135.19 ‚îÇ    515.72 ‚îÇ                   88.54 ‚îÇ                  1.13 ‚îÇ\n‚îÇ get_multilingual_base            ‚îÇ         305.37 ‚îÇ    582.45 ‚îÇ                  100.00 ‚îÇ                  1.00 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\n\n\nIt‚Äôs very clear the main advantage of the static embedding models here:\nThey can process large number of samples on cpu which make them very useful for : 1. Clustring 2. Build classification pipelines on top of them 3. Use them in edge-devices 4. base models for chunking algorithms and dudplications..more to come soon ! ‚ù§Ô∏è\n\nWhat‚Äôs Next for Bojji?\nIt‚Äôs just the start with initial tests, there is more to explore from the base models, datasets and the new features from minishlab which will try to narrow the gab between model2vec and sentence-transformers.\n\n\n\nzarra and Bojji\n\n\nAlso thanks a lot for the minishlab team for their continous help to debug and update the models with me!\n\n\nBojji model references\n\nArabic Leaderboard\nMTEB\nMinishlab\nNAMAA-Space colleciton"
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html",
    "href": "blog/posts/minishlab/pyversity_qdrant.html",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "",
    "text": "While building a real-estate search engine using RAG (Retrieval-Augmented Generation) across multiple collections, we hit an interesting problem: our top results were often too similar.\nExample scenario: - User query: ‚ÄúI want a unit in New Cairo‚Äù - Top 5 results: 3 units from Palm Hills, 1 from Sodic, 1 from Radix\nThe issue? Our agent‚Äôs responses became heavily skewed toward Palm Hills properties, leading customers to believe we were manipulating results to favor specific developers.\nThe solution: Diversification algorithms like MMR (Maximal Marginal Relevance) help balance relevance with variety.\nI found the amazing Pyversity - a lightweight Python library that implements multiple diversification strategies.\nIn this post, we‚Äôll explore: 1. What Pyversity offers and how it works 2. Qdrant‚Äôs built-in MMR capabilities 3. Combining Pyversity with Qdrant for flexible diversification"
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#why-diversify-search-results",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#why-diversify-search-results",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "",
    "text": "While building a real-estate search engine using RAG (Retrieval-Augmented Generation) across multiple collections, we hit an interesting problem: our top results were often too similar.\nExample scenario: - User query: ‚ÄúI want a unit in New Cairo‚Äù - Top 5 results: 3 units from Palm Hills, 1 from Sodic, 1 from Radix\nThe issue? Our agent‚Äôs responses became heavily skewed toward Palm Hills properties, leading customers to believe we were manipulating results to favor specific developers.\nThe solution: Diversification algorithms like MMR (Maximal Marginal Relevance) help balance relevance with variety.\nI found the amazing Pyversity - a lightweight Python library that implements multiple diversification strategies.\nIn this post, we‚Äôll explore: 1. What Pyversity offers and how it works 2. Qdrant‚Äôs built-in MMR capabilities 3. Combining Pyversity with Qdrant for flexible diversification"
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#meet-pyversity-your-diversification-toolkit",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#meet-pyversity-your-diversification-toolkit",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "Meet Pyversity: Your Diversification Toolkit",
    "text": "Meet Pyversity: Your Diversification Toolkit\nPyversity is a lightweight library that solves a common problem: search results that all look the same. It re-ranks your results to surface items that are relevant and different from each other.\nWhat makes it special? - Multiple strategies: MMR, MSD, DPP, COVER, and SSD - each with different strengths - Minimal dependencies: Just NumPy - Simple API: One function to rule them all\nLet‚Äôs see it in action with a quick example.\n\nimport numpy as np\nfrom pyversity import diversify, Strategy\n\n# Define embeddings and scores (e.g. cosine similarities of a query result)\nembeddings = np.random.randn(100, 256)\nscores = np.random.rand(100)\n\n# Diversify the result\ndiversified_result = diversify(\n    embeddings=embeddings,\n    scores=scores,\n    k=10, \n    strategy=Strategy.MMR,\n    diversity=0.5 # Diversity parameter (higher values prioritize diversity)\n)\n\n\nprint(\"Diversified Indices:\\n\", diversified_result.indices)\nprint(\"\\nSelection Scores:\\n\", diversified_result.selection_scores)\nprint(\"\\nStrategy Used:\", diversified_result.strategy)\n\nDiversified Indices:\n [66 16 20 34 54 89 53 81 24 42]\n\nSelection Scores:\n [0.4990284  0.49552712 0.49322212 0.4734265  0.44911325 0.44692624\n 0.4468549  0.43787128 0.4272018  0.4173287 ]\n\nStrategy Used: Strategy.MMR"
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#diversification-strategies",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#diversification-strategies",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "Diversification Strategies",
    "text": "Diversification Strategies\n\n\n\n\n\n\n\n\n\nStrategy\nWhat It Does\nTime Complexity\nBest For\n\n\n\n\nMMR\nBalances relevance with dissimilarity to already-selected items\nO(k¬∑n¬∑d)\nGeneral purpose - fast and effective\n\n\nMSD\nMaximizes distance from all previous selections\nO(k¬∑n¬∑d)\nBroader topic coverage\n\n\nDPP\nProbabilistic sampling with built-in ‚Äúrepulsion‚Äù\nO(k¬∑n¬∑d + n¬∑k¬≤)\nEliminating redundancy\n\n\nCOVER\nEnsures selections represent the full dataset structure\nO(k¬∑n¬≤)\nTopic clustering (slower for large datasets)\n\n\nSSD\nSequence-aware: rewards novelty relative to recent items\nO(k¬∑n¬∑d)\nContent feeds, infinite scroll, conversational RAG"
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#qdrant-mmr-in-action",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#qdrant-mmr-in-action",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "Qdrant MMR in Action",
    "text": "Qdrant MMR in Action\nQdrant has built-in MMR support that helps diversify visual search results.\nLet‚Äôs test it with a fashion dataset - we‚Äôll search for ‚Äúblack jacket‚Äù and compare standard search (which might return very similar items) against MMR search (which balances relevance with variety).\nWe‚Äôll use the DeepFashion dataset with CLIP embeddings for visual similarity.\nIn the end, we will use pyversity with Qdrant\n\nCreating Fashion Embedding\n\ndef fashion_search_standard(query_text, limit=5):\n    text_model = TextEmbedding(model_name=\"Qdrant/clip-ViT-B-32-text\")\n    query_embedding = list(text_model.embed([query_text]))[0]\n    \n    results = client.query_points(\n        collection_name=collection_name,\n        query=query_embedding.tolist(),\n        limit=limit,\n        with_payload=True\n    )\n    return results\n    \n\n\n\n\n\n\nSTANDARD FASHION SEARCH: 'black jacket'\n\n\n\n    \n        \n            Standard Search Results for \"black jacket\"\n        \n        \n    \n        \n            \n            \n                \n                    #1 ‚Ä¢ Score: 0.288\n                \n                \n                    a young man wearing a black jacket and tie\n                \n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n            \n            \n                \n                    #2 ‚Ä¢ Score: 0.287\n                \n                \n                    a black leather jacket on a white background\n                \n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n            \n            \n                \n                    #3 ‚Ä¢ Score: 0.287\n                \n                \n                    a black leather jacket on a white background\n                \n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n            \n            \n                \n                    #4 ‚Ä¢ Score: 0.283\n                \n                \n                    a man wearing a black jacket with a hood\n                \n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n            \n            \n                \n                    #5 ‚Ä¢ Score: 0.278\n                \n                \n                    a man wearing a black jacket and jeans\n                \n                \n                    Jackets & Vests\n                \n            \n        \n        \n\n\n\n\nStandard Qdrant Search Results\nNotice something? Most of these black jackets look very similar\nSame style, similar cuts, nearly identical designs.\nWhile they‚Äôre all highly relevant to our query, they don‚Äôt give users much variety to choose from. This is exactly the problem diversification solves. All scores ar around 0.288 to 0.278 very similar results\n\ndef fashion_search_mmr(query_text, limit=5, diversity=0.5):\n    text_model = TextEmbedding(model_name=\"Qdrant/clip-ViT-B-32-text\")\n    query_embedding = list(text_model.embed([query_text]))[0]\n    \n    results = client.query_points(\n        collection_name=collection_name,\n        query=models.NearestQuery(\n            nearest=query_embedding.tolist(),\n            mmr=models.Mmr(\n                diversity=diversity,  # 0.0 - relevance; 1.0 - diversity\n                candidates_limit=100  # num of candidates to preselect\n            )\n        ),\n        limit=limit,\n        with_payload=True\n    )\n    return results\n\n\n    \n        \n            MMR Search ‚Äì Diverse Black Jackets: \"black jacket\"\n        \n        \n    \n        \n\n            \n\n            \n                #1 ‚Ä¢ Score: 0.288\n                a young man wearing a black jacket and tie\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #2 ‚Ä¢ Score: 0.240\n                a man in a black shirt is looking at the camera\n                \n                    Tees & Tanks\n                \n            \n        \n        \n        \n\n            \n\n            \n                #3 ‚Ä¢ Score: 0.275\n                a man wearing a black jacket and plaid shirt\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #4 ‚Ä¢ Score: 0.275\n                a man in a blue jacket is posing for a picture\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #5 ‚Ä¢ Score: 0.242\n                a man wearing a hat and plaid pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #6 ‚Ä¢ Score: 0.254\n                a man in a black shirt and black pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n\n\n\n\nMMR Search - Diversity in Action\nLook at the difference! Instead of six nearly-identical black jackets, MMR gives us real variety: formal wear with ties, casual tees, layered looks, even a blue jacket and styled outfits with patterned pants.\nYes, some scores dropped slightly - but the browsing experience? Much better. Users can actually explore different styles instead of scrolling through clones."
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#pyversity-with-qdrant",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#pyversity-with-qdrant",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "Pyversity with Qdrant",
    "text": "Pyversity with Qdrant\nLet‚Äôs try to use the Pyversity algorhtims with Qdrant engine\n\ndef apply_pyversity(qdrant_results, strategy=Strategy.MMR, k=10, **strategy_kwargs):\n    \"\"\"Apply Pyversity diversification to Qdrant search results\"\"\"\n    embeddings = np.array([point.vector for point in qdrant_results.points])\n    scores = np.array([point.score for point in qdrant_results.points])\n    \n    diversified = diversify(\n        embeddings=embeddings,\n        scores=scores,\n        k=k,\n        strategy=strategy,\n        **strategy_kwargs\n    )\n    \n    # Return reordered results based on diversified indices\n    return [qdrant_results.points[i] for i in diversified.indices], diversified\n\n\n\ndef diversified_search(client, collection_name, query_embedding, \n                       strategy=Strategy.MMR, k=10, \n                       candidates_limit=100, **strategy_kwargs):\n    \"\"\"Search Qdrant and apply Pyversity diversification\"\"\"\n    results = client.query_points(\n        collection_name=collection_name,\n        query=query_embedding.tolist(),\n        limit=candidates_limit,\n        with_payload=True,\n        with_vectors=True\n    )\n    \n    # This should return the tuple from apply_pyversity\n    return apply_pyversity(results, strategy=strategy, k=k, **strategy_kwargs)\n\n\n\n\n============================================================\nTesting MMR Strategy\n============================================================\n\n\n\n    \n        \n            MMR Strategy: \"black jacket\"\n        \n        \n    \n        \n\n            \n\n            \n                #1 ‚Ä¢ Score: 0.288\n                a young man wearing a black jacket and tie\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #2 ‚Ä¢ Score: 0.240\n                a man in a black shirt is looking at the camera\n                \n                    Tees & Tanks\n                \n            \n        \n        \n        \n\n            \n\n            \n                #3 ‚Ä¢ Score: 0.275\n                a man wearing a black jacket and plaid shirt\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #4 ‚Ä¢ Score: 0.275\n                a man in a blue jacket is posing for a picture\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #5 ‚Ä¢ Score: 0.242\n                a man wearing a hat and plaid pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #6 ‚Ä¢ Score: 0.254\n                a man in a black shirt and black pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n\n\n\nDiversity Stats:\nStrategy: Strategy.MMR\nSelection Scores: [ 0.1440569  -0.21647353 -0.23149979 -0.23982394 -0.2528901  -0.2622754 ]\n\n============================================================\nTesting MSD Strategy\n============================================================\n\n\n\n    \n        \n            MSD Strategy: \"black jacket\"\n        \n        \n    \n        \n\n            \n\n            \n                #1 ‚Ä¢ Score: 0.288\n                a young man wearing a black jacket and tie\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #2 ‚Ä¢ Score: 0.240\n                a man in a black shirt is looking at the camera\n                \n                    Tees & Tanks\n                \n            \n        \n        \n        \n\n            \n\n            \n                #3 ‚Ä¢ Score: 0.278\n                a man wearing a black jacket and jeans\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #4 ‚Ä¢ Score: 0.246\n                a man sitting on top of a white cube\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #5 ‚Ä¢ Score: 0.242\n                a man wearing a baseball cap and a plaid shirt\n                \n                    Sweaters\n                \n            \n        \n        \n        \n\n            \n\n            \n                #6 ‚Ä¢ Score: 0.287\n                a black leather jacket on a white background\n                \n                    Jackets & Vests\n                \n            \n        \n        \n\n\n\nDiversity Stats:\nStrategy: Strategy.MSD\nSelection Scores: [0.1440569  0.28352648 0.45831633 0.5803725  0.7433619  0.9287865 ]\n\n============================================================\nTesting DPP Strategy\n============================================================\n\n\n\n    \n        \n            DPP Strategy: \"black jacket\"\n        \n        \n    \n        \n\n            \n\n            \n                #1 ‚Ä¢ Score: 0.288\n                a young man wearing a black jacket and tie\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #2 ‚Ä¢ Score: 0.287\n                a black leather jacket on a white background\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #3 ‚Ä¢ Score: 0.275\n                a man in a blue jacket is posing for a picture\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #4 ‚Ä¢ Score: 0.278\n                a man wearing a black jacket and jeans\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #5 ‚Ä¢ Score: 0.283\n                a man wearing a black jacket with a hood\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #6 ‚Ä¢ Score: 0.272\n                a man in a black jacket and black pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n\n\n\nDiversity Stats:\nStrategy: Strategy.DPP\nSelection Scores: [11.763905   4.50202    1.778986   1.6289598  1.1995786  1.063326 ]\n\n============================================================\nTesting COVER Strategy\n============================================================\n\n\n\n    \n        \n            COVER Strategy: \"black jacket\"\n        \n        \n    \n        \n\n            \n\n            \n                #1 ‚Ä¢ Score: 0.254\n                a man in a black jacket and red pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #2 ‚Ä¢ Score: 0.274\n                a man wearing a black jacket and a beanie\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #3 ‚Ä¢ Score: 0.277\n                a man in a black jacket and black pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #4 ‚Ä¢ Score: 0.266\n                a man in a white jacket and black pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #5 ‚Ä¢ Score: 0.271\n                a man in a black shirt and grey pants\n                \n                    Sweaters\n                \n            \n        \n        \n        \n\n            \n\n            \n                #6 ‚Ä¢ Score: 0.244\n                a man wearing a duffle coat and red pants\n                \n                    Jackets & Vests\n                \n            \n        \n        \n\n\n\nDiversity Stats:\nStrategy: Strategy.COVER\nSelection Scores: [45.971733  19.065933  14.6605215 12.34475   10.894392   9.850458 ]\n\n============================================================\nTesting SSD Strategy\n============================================================\n\n\n\n    \n        \n            SSD Strategy: \"black jacket\"\n        \n        \n    \n        \n\n            \n\n            \n                #1 ‚Ä¢ Score: 0.288\n                a young man wearing a black jacket and tie\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #2 ‚Ä¢ Score: 0.287\n                a black leather jacket on a white background\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #3 ‚Ä¢ Score: 0.287\n                a black leather jacket on a white background\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #4 ‚Ä¢ Score: 0.283\n                a man wearing a black jacket with a hood\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #5 ‚Ä¢ Score: 0.278\n                a man wearing a black jacket and jeans\n                \n                    Jackets & Vests\n                \n            \n        \n        \n        \n\n            \n\n            \n                #6 ‚Ä¢ Score: 0.275\n                a man in a blue jacket is posing for a picture\n                \n                    Jackets & Vests\n                \n            \n        \n        \n\n\n\nDiversity Stats:\nStrategy: Strategy.SSD\nSelection Scores: [1.939636  1.524907  1.3047718 1.2576772 1.1047928 1.0550355]"
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#comparing-diversification-strategies",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#comparing-diversification-strategies",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "Comparing Diversification Strategies",
    "text": "Comparing Diversification Strategies\nAfter testing all five strategies on our fashion search, here‚Äôs what we observed:\nMMR & MSD: Both provided good variety while maintaining relevance. MMR tends to be slightly faster and is a solid default choice. MSD pushes for even more spread across different styles.\nDPP: Offers probabilistic diversity with a natural balance. Great when you want to eliminate near-duplicates while keeping results feeling ‚Äúorganic.‚Äù\nCOVER: Ensures broad coverage across the dataset. Best when you need to represent different clusters or categories, though it‚Äôs slower on large datasets.\nSSD: Sequence-aware diversification. Perfect for feeds where users scroll through results over time - it avoids showing similar items close together.\n\nStart with MMR for general use. Experiment with others based on your specific needs."
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#the-diversity-vs.-relevance-trade-off",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#the-diversity-vs.-relevance-trade-off",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "The Diversity vs.¬†Relevance Trade-off",
    "text": "The Diversity vs.¬†Relevance Trade-off\nDiversification isn‚Äôt free - there‚Äôs always a balance:\nScore drops: Notice how diversified results sometimes have lower similarity scores? That‚Äôs expected. We‚Äôre trading pure relevance for variety.\nComputational cost: Fetching 100 candidates and diversifying to 10 is slower than just grabbing the top 10. But for most applications, the added latency (milliseconds) is worth the improved user experience.\nSweet spot: In our tests, fetching 100 candidates and diversifying to 5-10 results gave the best balance. Too few candidates limits diversity options; too many adds unnecessary overhead.\nThe payoff: Better user engagement, reduced bias, and more satisfied customers who feel they‚Äôre seeing real choices."
  },
  {
    "objectID": "blog/posts/minishlab/pyversity_qdrant.html#references",
    "href": "blog/posts/minishlab/pyversity_qdrant.html#references",
    "title": "Diversifying Search Results with Pyversity and Qdrant",
    "section": "References",
    "text": "References\n\nQdrant MMR\nPyversity"
  },
  {
    "objectID": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html",
    "href": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html",
    "title": "my dream job at Tarteel",
    "section": "",
    "text": "As a Muslim, my ultimate goal isn‚Äôt just to accumulate wealth or knowledge for their own sake. I‚Äôm guided by broader concepts like taqwa (God-consciousness), righteous deeds, and sincere intentions. With only one short life to live, I want to make the most of it in the best way possible.\nWorking at big tech companies as a programmer offers good financial rewards and significant technical growth, along with practical experience‚Äîthough it comes with its fair share of challenges. However, it also means operating under the umbrella of foreign companies with their own agendas and ideologies. Take the major players like Google, Facebook, X, and Amazon, for example.\nTheir leaders, in one way or another, have supported the occupation of Gaza, contributed to the suffering of children, and restricted our freedom of expression.\nOur accounts get banned, our voices silenced, and these companies provide both material and moral support to oppressive entities with every means at their disposal.\nI‚Äôm not denying that working for such companies might be permissible under certain Islamic legal perspectives, but personally, I have no desire to be part of them. So, where do I want to go instead? Do I even have rules? After all, I haven‚Äôt worked at a ‚Äúreal‚Äù company yet‚Äîonly freelance gigs and open-source projects.\nThe truth is, I do have specific criteria for the kind of work environment I want to invest my time in. Here‚Äôs what I‚Äôm looking for:\n\nA workplace that respects my faith, including what‚Äôs halal and haram, and honors religious practices.\nA team working on meaningful projects with real humanitarian impact‚Äîprojects that benefit society without involving anything forbidden, even if they‚Äôre not explicitly religious.\nA place that fosters my growth beyond just financial gain. As someone passionate about data science, I want to join a team grounded in strong scientific principles, up-to-date with advancements, and focused on innovation‚Äînot blind imitation or merely using what‚Äôs available.\nA supportive, ambitious team led by kind and fair management.\n\nThat‚Äôs when my eyes turned to Tarteel. I first came across it during high school, watching episodes featuring Hazem Al-Siddiq and Abdul Latif discussing the idea behind Tarteel and its early beginnings. Even now, after graduating, I‚Äôve kept up with the company‚Äôs progress.\nFrom what I can see, it embodies everything I‚Äôm looking for‚Äîat least on the surface‚Äîand I assume the best of the people working there. My dream for the next two years is to join the Tarteel team."
  },
  {
    "objectID": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#why-tarteel-not-fang",
    "href": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#why-tarteel-not-fang",
    "title": "my dream job at Tarteel",
    "section": "",
    "text": "As a Muslim, my ultimate goal isn‚Äôt just to accumulate wealth or knowledge for their own sake. I‚Äôm guided by broader concepts like taqwa (God-consciousness), righteous deeds, and sincere intentions. With only one short life to live, I want to make the most of it in the best way possible.\nWorking at big tech companies as a programmer offers good financial rewards and significant technical growth, along with practical experience‚Äîthough it comes with its fair share of challenges. However, it also means operating under the umbrella of foreign companies with their own agendas and ideologies. Take the major players like Google, Facebook, X, and Amazon, for example.\nTheir leaders, in one way or another, have supported the occupation of Gaza, contributed to the suffering of children, and restricted our freedom of expression.\nOur accounts get banned, our voices silenced, and these companies provide both material and moral support to oppressive entities with every means at their disposal.\nI‚Äôm not denying that working for such companies might be permissible under certain Islamic legal perspectives, but personally, I have no desire to be part of them. So, where do I want to go instead? Do I even have rules? After all, I haven‚Äôt worked at a ‚Äúreal‚Äù company yet‚Äîonly freelance gigs and open-source projects.\nThe truth is, I do have specific criteria for the kind of work environment I want to invest my time in. Here‚Äôs what I‚Äôm looking for:\n\nA workplace that respects my faith, including what‚Äôs halal and haram, and honors religious practices.\nA team working on meaningful projects with real humanitarian impact‚Äîprojects that benefit society without involving anything forbidden, even if they‚Äôre not explicitly religious.\nA place that fosters my growth beyond just financial gain. As someone passionate about data science, I want to join a team grounded in strong scientific principles, up-to-date with advancements, and focused on innovation‚Äînot blind imitation or merely using what‚Äôs available.\nA supportive, ambitious team led by kind and fair management.\n\nThat‚Äôs when my eyes turned to Tarteel. I first came across it during high school, watching episodes featuring Hazem Al-Siddiq and Abdul Latif discussing the idea behind Tarteel and its early beginnings. Even now, after graduating, I‚Äôve kept up with the company‚Äôs progress.\nFrom what I can see, it embodies everything I‚Äôm looking for‚Äîat least on the surface‚Äîand I assume the best of the people working there. My dream for the next two years is to join the Tarteel team."
  },
  {
    "objectID": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#tarteels-vision",
    "href": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#tarteels-vision",
    "title": "my dream job at Tarteel",
    "section": "Tarteel‚Äôs Vision",
    "text": "Tarteel‚Äôs Vision\nTarteel AI is the world‚Äôs leading app for Quran memorization and recitation. It‚Äôs a tool that supports millions of Muslims globally by providing features to help them memorize and connect with the Quran. When you read their application page, it‚Äôs genuinely inspiring:\n\nFully remote work‚Äîwork anytime, anywhere.\nA balance of dunya and akhira‚Äîan Islamic workweek, Islamic holidays, and a culture rooted in faith.\nUnlimited time off (with manager approval).\nYearly team retreats and off-sites.\nThe freedom to work in your thobe, abaya, or traditional clothing from the comfort of home.\nA chance to be part of a company leading AI and technology innovation in the Muslim community.\nAn opportunity to contribute to impactful projects that benefit Muslims worldwide."
  },
  {
    "objectID": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#machine-learning-engineer-at-tarteel",
    "href": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#machine-learning-engineer-at-tarteel",
    "title": "my dream job at Tarteel",
    "section": "Machine Learning Engineer at Tarteel",
    "text": "Machine Learning Engineer at Tarteel\nTarteel is always seeking talented individuals passionate about advancing the state of the Muslim ummah through their unique skills. They encourage applicants to share as much as possible about their interests and abilities.\nSo, here‚Äôs my story: I‚Äôve applied to Tarteel 4 times!\n\nThe first time was during my second year of college, seeking an internship. My skills were basic‚ÄîI had just started learning about deep learning‚Äîbut the advice they gave me was encouraging and kind.\nAfter graduation, I applied again but was rejected without explanation. I assume it‚Äôs because I was a fresh graduate, and they likely needed someone with experience in large-scale projects. That‚Äôs fair.\nSeven months later, just before Ramadan 2026, Tarteel announced internship opportunities for the first time. I applied but wasn‚Äôt accepted. The competition was tough, and I don‚Äôt think I was the strongest candidate at the time‚Äîno hard feelings!\nWhat now? I‚Äôm determined to prove I have the knowledge and skills to contribute. Here‚Äôs what I‚Äôm currently working on:\n\nArabic NLP, LLMs, and speech recognition with the Namma community, where I‚Äôm contributing to open-source projects and research papers.\nA remote research lab in Russia, which is accelerating my technical growth.\nPlans to join a company to learn about cloud deployment, model optimization, and GPU workloads.\nStudying Quranic sciences and Tajweed to deepen my connection to the field.\nBuilding small projects inspired by Tarteel‚Äôs vision to test my abilities and see where they take me."
  },
  {
    "objectID": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#skills-i-need-to-master",
    "href": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#skills-i-need-to-master",
    "title": "my dream job at Tarteel",
    "section": "Skills I Need to Master",
    "text": "Skills I Need to Master\nTo succeed, I‚Äôm focusing on these key areas:\n\nSpeech recognition and audio processing.\nNvidia NeMo frameworks.\nSLURM (for managing computing resources).\nS5 (data storage and retrieval).\nMonitoring and analyzing model performance for data-driven improvements."
  },
  {
    "objectID": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#my-current-plan",
    "href": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#my-current-plan",
    "title": "my dream job at Tarteel",
    "section": "My Current Plan",
    "text": "My Current Plan\nI‚Äôve started mastering these skills by taking courses and reading books on state-of-the-art (SOTA) speech recognition models. Soon, I‚Äôll share my progress, publish my work, and apply what I‚Äôve learned to Tarteel‚Äôs vision. And, of course, I‚Äôm making duaa for guidance and success ‚ù§Ô∏è."
  },
  {
    "objectID": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#other-resources",
    "href": "blog/posts/speech_recognition/my_dream_job_at_tarteel.html#other-resources",
    "title": "my dream job at Tarteel",
    "section": "Other Resources",
    "text": "Other Resources\n\nMy Blogs Related to Tarteel\n(To be added)\n\n\nSocial Media\n\nHugging Face\nLinkedIn\nTwitter\nGitHub"
  },
  {
    "objectID": "til/tils/2025-05-20-til.html",
    "href": "til/tils/2025-05-20-til.html",
    "title": "Domains Day: Connecting Railway with Vercel, Cloudflare, and Hostinger",
    "section": "",
    "text": "I decided to transfer all 11 of my domains from Hostinger to other providers. I consulted two friends‚Äîa team lead in Canada and an SEO specialist in Turkey‚Äîand both recommended Porkbun.\nI registered with Porkbun and was required to verify my identity. They offered multiple verification options, and I chose to use my government ID. However, I faced issues: I uploaded my ID about 10 times, and it failed every time, even though the verification platform supported my language. I reached out to their help center, and the fastest response came via email.\nIt took about 12 hours to receive a reply, which felt like a long time. The good news? They instantly verified my ID with no further issues. Later, when I asked another question, their response again took several hours, unlike Hostinger, which typically responds within 1 to 30 minutes (and at most within 2 hours). However, I found Hostinger‚Äôs customer service stricter and sometimes less friendly.\nI‚Äôll discuss my reasons for moving later, but for now, let‚Äôs focus on the process.\n\n\nI had never transferred a domain before, so I expected it to be challenging. However, Hostinger made the process straightforward without asking why I was transferring.\nHere‚Äôs how to do it:\n\nGo to your Hostinger dashboard.\nDisable the Privacy Protection (WHOIS Privacy Protection) button.\nDisable the Transfer Lock button. This may take up to 12 hours to update.\nObtain the Authorization Code (EPP code) from the dashboard and save it, as you‚Äôll need to provide it to Porkbun for the domain transfer.\n\nOn Porkbun‚Äôs website: - Enter your domain name in the Domain Name field under the transfer section. - Copy the authorization code from Hostinger and paste it into the Auth Code field. - Click Submit.\nThe transfer(s) will be added to your cart. From there, click Continue to Billing to pay for the transfer. It‚Äôs that simple!\nIf your domain is older than 60 days, the transfer typically takes 5 to 7 days. Some domains may transfer in as little as 2 days, but Hostinger will send a verification request via email to confirm the transfer.\nNote: If your domain is less than 60 days old, you‚Äôll need to wait until it passes the 60-day mark. There‚Äôs talk of this being reduced to 30 days, but as of this writing (May 2025), the 60-day rule applies, per ICANN regulations, not Hostinger or Porkbun.\n\n\n\nConnecting a domain to Vercel is straightforward. Follow the instructions provided by Vercel, which are similar to those for any registrar. Add the necessary DNS records in Porkbun‚Äôs DNS Management section, accessible from the domain management dashboard under your account menu.\nConnecting to Railway was trickier. I needed an intermediary, and I chose Cloudflare to manage my Porkbun domain‚Äôs DNS. Here‚Äôs how it worked:\n\nConfigure Cloudflare to manage your Porkbun domain.\nAdd the necessary Railway DNS records to Cloudflare.\nWait approximately 1 to 2 days for the DNS changes to propagate.\n\nOnce the DNS updates are complete, your domain should work seamlessly with Railway."
  },
  {
    "objectID": "til/tils/2025-05-20-til.html#moving-my-domains",
    "href": "til/tils/2025-05-20-til.html#moving-my-domains",
    "title": "Domains Day: Connecting Railway with Vercel, Cloudflare, and Hostinger",
    "section": "",
    "text": "I decided to transfer all 11 of my domains from Hostinger to other providers. I consulted two friends‚Äîa team lead in Canada and an SEO specialist in Turkey‚Äîand both recommended Porkbun.\nI registered with Porkbun and was required to verify my identity. They offered multiple verification options, and I chose to use my government ID. However, I faced issues: I uploaded my ID about 10 times, and it failed every time, even though the verification platform supported my language. I reached out to their help center, and the fastest response came via email.\nIt took about 12 hours to receive a reply, which felt like a long time. The good news? They instantly verified my ID with no further issues. Later, when I asked another question, their response again took several hours, unlike Hostinger, which typically responds within 1 to 30 minutes (and at most within 2 hours). However, I found Hostinger‚Äôs customer service stricter and sometimes less friendly.\nI‚Äôll discuss my reasons for moving later, but for now, let‚Äôs focus on the process.\n\n\nI had never transferred a domain before, so I expected it to be challenging. However, Hostinger made the process straightforward without asking why I was transferring.\nHere‚Äôs how to do it:\n\nGo to your Hostinger dashboard.\nDisable the Privacy Protection (WHOIS Privacy Protection) button.\nDisable the Transfer Lock button. This may take up to 12 hours to update.\nObtain the Authorization Code (EPP code) from the dashboard and save it, as you‚Äôll need to provide it to Porkbun for the domain transfer.\n\nOn Porkbun‚Äôs website: - Enter your domain name in the Domain Name field under the transfer section. - Copy the authorization code from Hostinger and paste it into the Auth Code field. - Click Submit.\nThe transfer(s) will be added to your cart. From there, click Continue to Billing to pay for the transfer. It‚Äôs that simple!\nIf your domain is older than 60 days, the transfer typically takes 5 to 7 days. Some domains may transfer in as little as 2 days, but Hostinger will send a verification request via email to confirm the transfer.\nNote: If your domain is less than 60 days old, you‚Äôll need to wait until it passes the 60-day mark. There‚Äôs talk of this being reduced to 30 days, but as of this writing (May 2025), the 60-day rule applies, per ICANN regulations, not Hostinger or Porkbun.\n\n\n\nConnecting a domain to Vercel is straightforward. Follow the instructions provided by Vercel, which are similar to those for any registrar. Add the necessary DNS records in Porkbun‚Äôs DNS Management section, accessible from the domain management dashboard under your account menu.\nConnecting to Railway was trickier. I needed an intermediary, and I chose Cloudflare to manage my Porkbun domain‚Äôs DNS. Here‚Äôs how it worked:\n\nConfigure Cloudflare to manage your Porkbun domain.\nAdd the necessary Railway DNS records to Cloudflare.\nWait approximately 1 to 2 days for the DNS changes to propagate.\n\nOnce the DNS updates are complete, your domain should work seamlessly with Railway."
  },
  {
    "objectID": "til/tils/2025-05-17-til.html",
    "href": "til/tils/2025-05-17-til.html",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "",
    "text": "It helps you overcome the perfacationsim in writting. you don‚Äôt need to create great article in depth about things you want to share or learn about..etc, all what you want it to write a thing you were trying to learn or solve today and how you solve it\nwhich will help me more focused and make the process of learning more easier and useful for me and others"
  },
  {
    "objectID": "til/tils/2025-05-17-til.html#why-til",
    "href": "til/tils/2025-05-17-til.html#why-til",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "",
    "text": "It helps you overcome the perfacationsim in writting. you don‚Äôt need to create great article in depth about things you want to share or learn about..etc, all what you want it to write a thing you were trying to learn or solve today and how you solve it\nwhich will help me more focused and make the process of learning more easier and useful for me and others"
  },
  {
    "objectID": "til/tils/2025-05-17-til.html#create-your-own-gravitey",
    "href": "til/tils/2025-05-17-til.html#create-your-own-gravitey",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "create your own gravitey",
    "text": "create your own gravitey\nsometimes you want to reach and communicate with people in the same space of problems you are solving, search engines are very bad in provide the information you want..this is related to how these engines work and other SEO stuff. but for me, i can‚Äôt reach people and help them or get benefit from them because they simple don‚Äôt know about me!!\nTIL will decreases this spaces and daily TIl about the things i am learning which are alot will start to give me nice SEO and unique because i am talking about things i don‚Äôt know and i am interested in and there will be much people in the same boat this will increase my X account and linkedin and this is very useful in the current time."
  },
  {
    "objectID": "til/tils/2025-05-17-til.html#tils-level-up",
    "href": "til/tils/2025-05-17-til.html#tils-level-up",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "TILs level up",
    "text": "TILs level up\nI also want to think in way to extract more crafted blogs from my TILs. but just start making it habbit and will see who will it comes in the end.\ninitial thoughts: 1. weekly recap from my TILs and SEO optimization for the keywords that is increasing and i am interested in 2. ML to extract related stuff, for example i will want to take about the folloinwg topics: - Late interaciton (Pylate, Colbertv2, ColPali) - Searching - Model2vec - Visino Language models..etc collecting them and start writing about them and adding internal links for them will be very useful to improve my blog system"
  },
  {
    "objectID": "til/tils/2025-05-17-til.html#things-i-learned-the-last-2-days",
    "href": "til/tils/2025-05-17-til.html#things-i-learned-the-last-2-days",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "Things i learned the last 2 days",
    "text": "Things i learned the last 2 days\n\nThe best way to increase traffic is comment with valuble knowledge.\nI was scorlling on X and found some popular account tweets about Harvard CS197 AI Research and i had create a review year ago about it I add the link in the comment and just slept. Boom i found reply analytics links opened wihtout annoying anyone!! - 501 Impressions - 77 Engagements - 2 profile visits - 74 clicks"
  },
  {
    "objectID": "til/tils/2025-05-17-til.html#what-is-palid-index",
    "href": "til/tils/2025-05-17-til.html#what-is-palid-index",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "What is PALID index?",
    "text": "What is PALID index?\nPLAID index is for indexing very large datasets with Later interaction models like (Colbertv2 & ColPali) IT Solves the storage footprint and allow you to scale to infinity\nThey swapped the faiss from facebook what is nice thing because i have multiple bad time to install it especially the GPU version.\nand used fastkeamns from the amazing @bclaive which i really like his work on embeddings\nIt‚Äôs replacement for Voyager-based HNSW index which was very bad for scaling Late-Interaction retrieval models"
  },
  {
    "objectID": "til/tils/2025-05-17-til.html#prime-intellect-vs-gpuvec",
    "href": "til/tils/2025-05-17-til.html#prime-intellect-vs-gpuvec",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "Prime Intellect VS Gpuvec",
    "text": "Prime Intellect VS Gpuvec\nI was creating a website to find and compare the cloud compute instances from all cloud providers in easy and interactive way.\nI started to work on it the last month, but stoped for other work.\nsuddenly i found this website which is called Prime intellect.\nAnd i just want to say,woooooow. it‚Äôs a piece of art. The design and information on it and how fast, accurate is very embrassing for my poor gpuvec.com\nshould i continue improve my website?\nActually yes, we share similar goals but there is multiple chances to compete or even collaborite!! who knows!\nThey are more than just listing and compare prices, then enable you to use these GPUs from their website.\nAlso they create decentralized models and have a mutliple expirened engineers."
  },
  {
    "objectID": "til/tils/2025-05-17-til.html#references",
    "href": "til/tils/2025-05-17-til.html#references",
    "title": "TIL ? Tody I lernt to create TIL",
    "section": "References",
    "text": "References\n\nAntoine tweet\nbetatim TIL\nother TILs"
  },
  {
    "objectID": "til/tils/2025-05-28-til.html",
    "href": "til/tils/2025-05-28-til.html",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: What is PyLate and what does it do? A: PyLate is a Python library for vector retrieval and search, specifically designed for ColBERT models. It provides tools for indexing documents, encoding queries, and performing similarity search.\n\n\n\nQ: How does ColBERT work? A: ColBERT (Contextualized Late Interaction over BERT) creates dense vector representations for documents and queries, then uses late interaction (token-level matching) for retrieval instead of single vector similarity.\n\n\n\n\n\n\nQ: What does triplet format look like? A: Each row contains: - query: The search query - positive: One relevant document\n- negative1, negative2, ‚Ä¶: Multiple irrelevant documents\nPros: Good for training with hard negatives Cons: No separate corpus, harder to evaluate\n\n\n\nQ: What does structured format contain? A: Three separate components: - corpus: All documents with IDs - queries: All queries with IDs - qrels: Relevance judgments (query-doc pairs)\nPros: Standard IR evaluation format, works with PyLate directly Cons: More complex structure\n\n\n\nQ: How does passage ranking format work? A: Each row has: - query_id, query: Query information - positive_passages: List of relevant documents - negative_passages: List of irrelevant documents\nPros: Multiple positives/negatives per query, rich annotations Cons: Requires extraction to create corpus\n\n\n\n\n\n\nQ: How do you handle large datasets efficiently? A: Stream processing with direct file writing:\nwith open('corpus.jsonl', 'w') as f:\n    for el in dataset['corpus']:\n        if el['corpus-id'] and el['text']:\n            json.dump({\"_id\": el['corpus-id'], \"text\": el['text']}, f)\n            f.write('\\n')\nPros: Low memory usage, handles any dataset size Cons: Requires file I/O, slightly slower\n\n\n\nQ: What files does BEIR datasets is ? A: - corpus.jsonl: {\"_id\": \"doc1\", \"text\": \"document text\"} - queries.jsonl: {\"_id\": \"q1\", \"text\": \"query text\"} - qrels/split.tsv: query_id\\tdoc_id\\tscore\nCritical: File names and folder structure must match exactly\n\n\n\nQ: How do you convert without files? A: Transform to PyLate‚Äôs expected return format:\ndocuments = [{\"id\": doc_id, \"text\": text} for doc_id, text in corpus.items()]\nqueries = list(queries.values())\n# qrels stays as dictionary\nPros: Faster, no file operations Cons: Must match exact format, harder to debug\n\n\n\n\n\n\nQ: When do you use ranx for evaluation? A: When you have non-standard formats or want custom metrics:\nqrels = Qrels(qrels_dict)\nrun = Run(run_dict)\nmetrics = evaluate(qrels, run, [\"ndcg@5\", \"map@5\"])\nPros: Flexible, works with any format Cons: Manual setup required\n\n\n\nQ: When do you use PyLate‚Äôs evaluation? A: When data is in standard BEIR format with proper file structure\nPros: Standardized, less code Cons: Strict format requirements\n\n\n\n\n\n\nQ: What is PLAID indexing? A: PyLate‚Äôs efficient indexing method for ColBERT embeddings, supporting fast similarity search\nKey Parameters: - index_folder: Where to store index - index_name: Identifier for the index\n- override=True: Overwrites existing index\n\n\n\nQ: How do you prepare documents for indexing? A: 1. Extract unique documents from all sources 2. Create document IDs and embeddings 3. Add to index with add_documents()\nImportant: Use is_query=False for documents, is_query=True for queries\n\n\n\n\n\n\nQ: What are common file format mistakes? A: - Wrong file extensions (.csv instead of .tsv) - Incorrect folder structure (missing qrels folder) - Wrong field names (id vs _id)\n\n\n\nQ: How do you handle variable-length lists? A: Use nested loops for negative passages:\nfor row in dataset:\n    for neg_doc in row['negative_passages']:\n        # process each negative document\n\n\n\nQ: How do you avoid memory issues? A: - Process datasets in chunks - Use generators instead of lists - Write to files incrementally - Use dictionaries to avoid duplicates\n\n\n\n\n\n\nQ: How do you optimize encoding speed? A: Use appropriate batch sizes: - Larger batches: Faster but more memory - Smaller batches: Slower but memory-safe - Typical: batch_size=32 or batch_size=64\n\n\n\nQ: How do you manage multiple indexes? A: Use descriptive names and separate folders: - index_folder=\"arabic_index\" - index_name=\"gte-multilingual-base\"\n\n\n\n\n\n\nQ: What metrics should you track? A: - NDCG@k: Normalized discounted cumulative gain - MAP@k: Mean average precision\n- Recall@k: Proportion of relevant docs retrieved - Precision@k: Proportion of retrieved docs that are relevant\n\n\n\nQ: What makes good retrieval performance? A: - NDCG@5 &gt; 0.7: Excellent - NDCG@5 &gt; 0.5: Good\n- NDCG@5 &gt; 0.3: Acceptable - NDCG@5 &lt; 0.3: Needs improvement\nThis comprehensive guide covers all the key concepts, trade-offs, and practical considerations for working with PyLate and ColBERT evaluation pipelines."
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#core-concepts",
    "href": "til/tils/2025-05-28-til.html#core-concepts",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: What is PyLate and what does it do? A: PyLate is a Python library for vector retrieval and search, specifically designed for ColBERT models. It provides tools for indexing documents, encoding queries, and performing similarity search.\n\n\n\nQ: How does ColBERT work? A: ColBERT (Contextualized Late Interaction over BERT) creates dense vector representations for documents and queries, then uses late interaction (token-level matching) for retrieval instead of single vector similarity."
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#dataset-formats",
    "href": "til/tils/2025-05-28-til.html#dataset-formats",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: What does triplet format look like? A: Each row contains: - query: The search query - positive: One relevant document\n- negative1, negative2, ‚Ä¶: Multiple irrelevant documents\nPros: Good for training with hard negatives Cons: No separate corpus, harder to evaluate\n\n\n\nQ: What does structured format contain? A: Three separate components: - corpus: All documents with IDs - queries: All queries with IDs - qrels: Relevance judgments (query-doc pairs)\nPros: Standard IR evaluation format, works with PyLate directly Cons: More complex structure\n\n\n\nQ: How does passage ranking format work? A: Each row has: - query_id, query: Query information - positive_passages: List of relevant documents - negative_passages: List of irrelevant documents\nPros: Multiple positives/negatives per query, rich annotations Cons: Requires extraction to create corpus"
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#data-conversion-strategies",
    "href": "til/tils/2025-05-28-til.html#data-conversion-strategies",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: How do you handle large datasets efficiently? A: Stream processing with direct file writing:\nwith open('corpus.jsonl', 'w') as f:\n    for el in dataset['corpus']:\n        if el['corpus-id'] and el['text']:\n            json.dump({\"_id\": el['corpus-id'], \"text\": el['text']}, f)\n            f.write('\\n')\nPros: Low memory usage, handles any dataset size Cons: Requires file I/O, slightly slower\n\n\n\nQ: What files does BEIR datasets is ? A: - corpus.jsonl: {\"_id\": \"doc1\", \"text\": \"document text\"} - queries.jsonl: {\"_id\": \"q1\", \"text\": \"query text\"} - qrels/split.tsv: query_id\\tdoc_id\\tscore\nCritical: File names and folder structure must match exactly\n\n\n\nQ: How do you convert without files? A: Transform to PyLate‚Äôs expected return format:\ndocuments = [{\"id\": doc_id, \"text\": text} for doc_id, text in corpus.items()]\nqueries = list(queries.values())\n# qrels stays as dictionary\nPros: Faster, no file operations Cons: Must match exact format, harder to debug"
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#evaluation-approaches",
    "href": "til/tils/2025-05-28-til.html#evaluation-approaches",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: When do you use ranx for evaluation? A: When you have non-standard formats or want custom metrics:\nqrels = Qrels(qrels_dict)\nrun = Run(run_dict)\nmetrics = evaluate(qrels, run, [\"ndcg@5\", \"map@5\"])\nPros: Flexible, works with any format Cons: Manual setup required\n\n\n\nQ: When do you use PyLate‚Äôs evaluation? A: When data is in standard BEIR format with proper file structure\nPros: Standardized, less code Cons: Strict format requirements"
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#indexing-strategies",
    "href": "til/tils/2025-05-28-til.html#indexing-strategies",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: What is PLAID indexing? A: PyLate‚Äôs efficient indexing method for ColBERT embeddings, supporting fast similarity search\nKey Parameters: - index_folder: Where to store index - index_name: Identifier for the index\n- override=True: Overwrites existing index\n\n\n\nQ: How do you prepare documents for indexing? A: 1. Extract unique documents from all sources 2. Create document IDs and embeddings 3. Add to index with add_documents()\nImportant: Use is_query=False for documents, is_query=True for queries"
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#common-pitfalls-solutions",
    "href": "til/tils/2025-05-28-til.html#common-pitfalls-solutions",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: What are common file format mistakes? A: - Wrong file extensions (.csv instead of .tsv) - Incorrect folder structure (missing qrels folder) - Wrong field names (id vs _id)\n\n\n\nQ: How do you handle variable-length lists? A: Use nested loops for negative passages:\nfor row in dataset:\n    for neg_doc in row['negative_passages']:\n        # process each negative document\n\n\n\nQ: How do you avoid memory issues? A: - Process datasets in chunks - Use generators instead of lists - Write to files incrementally - Use dictionaries to avoid duplicates"
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#performance-considerations",
    "href": "til/tils/2025-05-28-til.html#performance-considerations",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: How do you optimize encoding speed? A: Use appropriate batch sizes: - Larger batches: Faster but more memory - Smaller batches: Slower but memory-safe - Typical: batch_size=32 or batch_size=64\n\n\n\nQ: How do you manage multiple indexes? A: Use descriptive names and separate folders: - index_folder=\"arabic_index\" - index_name=\"gte-multilingual-base\""
  },
  {
    "objectID": "til/tils/2025-05-28-til.html#evaluation-metrics",
    "href": "til/tils/2025-05-28-til.html#evaluation-metrics",
    "title": "Pylate Day 1",
    "section": "",
    "text": "Q: What metrics should you track? A: - NDCG@k: Normalized discounted cumulative gain - MAP@k: Mean average precision\n- Recall@k: Proportion of relevant docs retrieved - Precision@k: Proportion of retrieved docs that are relevant\n\n\n\nQ: What makes good retrieval performance? A: - NDCG@5 &gt; 0.7: Excellent - NDCG@5 &gt; 0.5: Good\n- NDCG@5 &gt; 0.3: Acceptable - NDCG@5 &lt; 0.3: Needs improvement\nThis comprehensive guide covers all the key concepts, trade-offs, and practical considerations for working with PyLate and ColBERT evaluation pipelines."
  },
  {
    "objectID": "til/tils/2025-05-21-til.html",
    "href": "til/tils/2025-05-21-til.html",
    "title": "ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©",
    "section": "",
    "text": "ŸÅŸä ÿßŸÑŸàŸÇÿ™ ÿßŸÑÿ≠ÿßŸÑŸä .. ÿ£ŸÜÿß ÿßŸÇŸàŸÖ ÿ®ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ŸàŸÖŸÜŸáÿß ÿßŸÑŸàÿßÿπÿØ ÿßŸÑÿ∞Ÿä ÿ≥ŸäŸÉŸàŸÜ ÿ≥ÿ®ÿ® ŸÅŸä ÿ•ÿØÿÆÿßŸÑ ÿØÿÆŸÑ ŸÖÿßÿØŸä ŸÉÿ®Ÿäÿ± Ÿà ÿπŸÑŸÖŸä ÿ•ŸÜ ÿ¥ÿßÿ° ÿßŸÑŸÑŸá.\nÿ≠ÿßŸÑŸäÿß ÿ£ÿπŸÖŸÑ ÿπŸÑŸä ÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑŸÖÿßÿ≥ÿ™ÿ± + ÿπÿ∂Ÿà ŸÅÿπÿßŸÑ ŸÅŸä ŸÖÿ¨ÿ™ŸÖÿπŸäŸÜ ŸÑÿ™ÿ∑ŸàŸäÿ± ÿßŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ŸàÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿßŸÑÿπÿßŸÑŸÖ ÿßŸÑÿπÿ±ÿ®Ÿä ŸàÿßŸÑÿ•ÿ≥ŸÑÿßŸÖŸä ŸàŸÑŸÑŸá ÿßŸÑÿ≠ŸÖÿØ ŸàÿßŸÑŸÅÿ∂ŸÑ Ÿàÿ≠ÿØŸá + ÿ£ÿπŸÖŸÑ ŸÅŸä ŸÖÿπŸÖŸÑ ÿ®ÿßÿ≠ÿ´Ÿä ÿ™ÿßÿ®ÿπ ŸÑÿßÿ≠ÿØ ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ÿßŸÑŸÖŸÖŸäÿ≤ÿ© ÿ¨ÿØÿß Ÿà ŸÑÿØŸä ÿ£ÿπŸÖÿßŸÑ ÿ®ÿßÿ≠ÿ´ŸäŸá ŸàŸÖÿ¥ÿßÿ±Ÿäÿπ ÿÆÿßÿµŸá ŸÖŸÜ ŸÜŸàÿßÿ≠Ÿä ŸÖÿ™ÿπÿØÿØÿ©.\nÿ£ÿ≥ÿ™ÿ¥ÿπÿ± ÿ≠ÿßŸÑŸäÿß ŸÉÿ´ÿ±ÿ© ÿßŸÑŸÖŸáÿßŸÖ ŸàÿßŸÑÿ™ÿ¥ÿ™ÿ™ ÿßŸÑŸÉÿ®Ÿäÿ± Ÿà ŸÇŸÑÿ© ÿßŸÑŸàŸÇÿ™ ŸàÿßŸÑŸÖÿ¨ŸáŸàÿØ ŸàÿßŸÑŸÉÿ´Ÿäÿ± ..ŸÑŸÉŸÜ Ÿáÿ∞ÿß ŸÑŸäÿ≥ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©. ŸÖÿß ÿ£ÿ≥ÿ™ÿ¥ÿπÿ±Ÿá ŸáŸà ÿ≤ŸäÿßÿØÿ© ÿßŸÑÿ•ÿπÿ¨ÿßÿ® ÿ®ÿßŸÑŸÜŸÅÿ≥ ŸàÿßŸÑÿ®ÿπÿØ ÿπŸÜ ÿßŸÑÿπÿ®ÿßÿØÿ© ŸÖŸÜ ÿ£ÿ¨ŸÑ ŸÑÿ∞ÿ© ÿßŸÑÿπŸÑŸÖ Ÿà ÿ≠ÿ∏ ÿßŸÑŸÜŸÅÿ≥.\nŸà ŸÖŸÜ ÿØÿßÿÆŸÑŸä ŸÑÿß ÿ£ŸÇŸÜÿπ ÿ®ŸÉŸÑ ŸÖÿß ÿ£ŸÇÿØŸÖ ..Ÿàÿßÿ±Ÿä ÿßŸÜŸá ŸáŸÜÿßŸÉ ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑŸÖÿπÿ±ŸÅÿ© Ÿäÿ¨ÿ® ÿ™ÿ≠ÿµŸÑŸäŸáÿß Ÿà ÿπÿØŸÖ ÿßŸÑÿ±ÿ∂ÿß ÿ®ŸÉŸàŸÜŸä ŸÖÿ¨ÿ±ÿØ ŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ŸàŸÖÿπÿØŸÑ ŸÑŸÖÿß ÿ£ÿ≥ÿ™ŸÇÿ®ŸÑŸá. ŸÖÿ¨ÿßŸÑ ÿØÿ±ÿßÿ≥ÿ™Ÿä ŸáŸà ÿßŸÑÿ∞ŸÉÿßÿ° ŸàÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä ÿ®ÿ™ÿÆÿµÿµÿßÿ™Ÿá Ÿà ÿπŸÑŸàŸÖ ÿßŸÑÿ≠ÿßÿ≥ÿ®.\nŸÖÿß Ÿäÿ≤ÿπÿ¨ŸÜŸä ÿßŸÑŸÉÿ´Ÿäÿ± ..ŸÖŸÜŸáÿß ŸÑŸÖÿßÿ∞ÿß ÿ£ŸÇŸàŸÖ ÿ®ÿßÿ≥ÿ™ŸÇÿ®ÿßŸÑ ÿßŸÑÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑÿÆÿßÿ±ÿ¨ ŸàŸÑÿ≥ÿ™ ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ŸÖÿ¨ÿ±ÿØ ÿßŸÑÿ¥ÿ±Ÿàÿ≠ÿßÿ™ ÿßŸÑÿ£ÿ¨ŸÜÿ®Ÿäÿ© Ÿà ÿßŸÑÿ£Ÿàÿ±ÿßŸÇ ŸàÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ÿßŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿ© ŸàŸÉŸÑ Ÿáÿ∞ÿß ŸàŸÑŸÉŸÜ ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿßŸÑÿ±ŸäÿßÿØÿ© ŸÅŸä ÿßŸÑÿπŸÑŸÖ ÿ∞ÿßÿ™Ÿá. ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿ£ŸÖÿ´ÿßŸÑ ÿ¨ŸäŸÅÿ±Ÿä ŸáŸäŸÜÿ™ŸàŸÜ ŸàŸÖÿß ÿ®ÿπÿØŸá ..ÿßŸÑÿ±ÿ∫ÿ®ÿ© ŸÅŸä ÿßŸÑŸàÿµŸàŸÑ ÿßŸÑŸä ÿ≠ÿßŸÅÿ© ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑÿ•ÿ®ÿØÿßÿπ ŸàŸÑŸäÿ≥ ŸÖÿ¨ÿ±ÿØ ÿßŸÑÿ™ÿπÿØŸäŸÑ ŸàŸÅŸáŸÖ ŸÖÿß ŸäÿµÿØÿ±ŸàŸÜ.\nŸáŸÑ ÿ£ŸÉÿ™ŸÅŸä ÿ®Ÿáÿ∞ÿß !\nŸÅŸä ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÑÿß ÿßÿ™ÿ∞ŸÉÿ± ÿπŸÜÿØŸÖÿß ÿ™ŸÖ ÿ•ÿ∑ŸÑÿßŸÇ deepseek ŸàŸÇÿ±ÿßÿ™ ÿπŸÜ ÿßŸÑÿ¥ÿ±ŸÉÿ© ÿßŸÑÿ™Ÿä ÿ™ŸÇŸÅ Ÿàÿ±ÿßÿ¶Ÿáÿß..ŸÑŸÖÿßÿ∞ÿß ŸÑŸÖ ÿ™ŸÉÿ±ÿ± ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿπÿ±ÿ®Ÿäÿ© ÿ•ÿ≥ŸÑÿßŸÖŸäÿ© ÿÆÿßŸÑÿµÿ©! ŸÑŸäÿ≥ ŸÖÿ≥ÿ™ÿ≠ŸäŸÑ ÿ™ŸÇŸÜŸäÿß ŸàŸÜÿ≠ŸÜ ÿ£ŸàŸÑŸä ÿ®ŸÑÿ∫ÿ™ŸÜÿß Ÿàÿ™ÿ±ÿßÿ´ŸÜÿß ŸÖŸÜ ÿ∫Ÿäÿ±ŸÜÿß ŸÖŸÜ ÿßŸÑÿ¥ÿπŸàÿ® ÿÆÿµŸàÿµÿß ..ÿ£ŸÜ ÿ™ŸÉŸàŸÜ Ÿáÿ∞Ÿá ÿßŸÑÿ¥ÿπŸàÿ® ŸÑÿØŸäŸáÿß ŸÉÿ±ÿßŸáŸäÿ© ŸÖÿ™ÿ¥ÿπÿ®Ÿá ÿÆÿßÿµÿ© ŸÑÿØŸäŸÜŸÉ Ÿàÿ¥ÿπÿ®ŸÉ ŸàŸÑŸÜÿß ŸÅŸä ŸÅŸÑÿ≥ÿ∑ŸäŸÜ ÿπÿ®ÿ±ÿ© ŸÅŸäŸÖÿß Ÿäÿ≠ÿØÿ´ ŸÅŸäŸáÿß ŸÖŸÜ ÿ™ŸÜŸÉŸäŸÑ Ÿà ÿ¨ÿ±ÿßÿ¶ŸÖ ŸÑÿß ÿßÿ≠ÿ® ÿ≠ÿ™Ÿä ÿßŸÑÿ™ŸÅŸÉÿ± ŸÅŸäŸáÿß. ŸÑŸÉŸÜ ŸÖÿß Ÿäÿ≤ŸäÿØ ÿßŸÑÿ≠ÿ≤ŸÜ ŸàÿßŸÑÿ∂ÿπŸÅ ŸàÿßŸÑŸáŸÖ ŸàÿßŸÑÿ∫ŸÖÿ© ..ÿ£ŸÜ ÿ™ÿ¨ÿØ ŸÖŸÜ ÿßŸÑÿ±ŸäÿßÿØÿ© ŸÅŸä ŸÖÿ¨ÿßŸÑŸÉ Ÿà ÿ™ÿÆÿµÿµŸÉ ÿ£ÿ∫ŸÑÿ®ŸáŸÖ ŸÖŸÜ ŸáŸàŸÑÿßÿ° ÿßŸÑÿµŸÜŸÅ ÿßŸÑÿ∞Ÿä ŸäŸÇÿ™ŸÑ ÿ•ÿÆŸàÿ™ŸÉ ÿ®ÿØŸÖ ÿ®ÿßÿ±ÿØ!\nŸÉŸäŸÅ ÿ™ÿ≥ÿπÿØ ŸÜŸÅÿ≥ŸÉ ŸàÿßŸÜÿ™ ÿ™ÿßÿ®ÿπ ŸÑŸáŸàŸÑÿßÿ° ÿ™ŸÜÿ™ÿ∏ÿ± ŸÖŸÜŸáŸÖ ÿ£ŸÜ Ÿäÿπÿ∑ŸàŸÉ ÿ®ÿπÿ∂ ÿßŸÑŸÅÿ™ÿ™ÿßÿ™ ŸÖŸÜ ÿßŸÑÿπŸÑŸÖ ŸÑÿ™ÿ∞Ÿáÿ® ŸÑÿ™ŸÜÿ™ŸÅÿÆ ÿ®Ÿá ŸÜŸÅÿ≥ŸÉ Ÿàÿ™ÿ∏ŸÜ ÿ£ŸÜ ŸÑÿØŸäŸÉ ÿ¥Ÿä ŸÖŸÜ ÿπŸÑŸÖ ŸàŸáŸà ŸÅÿ™ÿßÿ™.\nÿ®ÿØÿßŸäÿ© ŸÖŸÜ ÿßŸÑÿ®ÿßÿ≠ÿ´ŸäŸÜ ŸÑÿ£ÿµÿ≠ÿßÿ® ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ŸÑŸÑŸÖŸàÿßŸÇÿπ ÿßŸÑÿ™Ÿä ÿ£ŸÇŸàŸÖ ÿ®ÿßŸÑÿßÿ≥ÿ™ÿ∂ÿßŸÅÿ© ÿπŸÑŸäŸáÿß ÿ•ŸÑŸä ÿßŸÑŸÉŸàÿ±ÿ≥ÿßÿ™ Ÿà ŸÖÿ¨ÿ™ŸÖÿπÿßÿ™ ÿßŸÑÿ™ŸÇŸÜŸäÿ©..ÿ®ŸÑ ÿ™ÿ≤ŸäÿØ ÿßŸÑÿ≠ÿ≥ÿ±ÿ© ÿπŸÜÿØŸä ÿ®ÿ≠ÿ´Ÿä ŸÅŸä ÿ®ŸäÿßŸÜÿßÿ™ ŸÑÿ™ÿ∑ŸàŸäÿ± ŸÜŸÖŸàÿ∞ÿ¨ ÿµÿ∫Ÿäÿ± ŸÑŸÖŸáŸÖÿ© ŸÖŸÜ ŸÖŸáÿßŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ£ÿ¨ÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ£ŸäŸÜ !ŸàŸÖŸÜ ŸäÿπŸÖŸÑ ÿπŸÑŸäŸáÿß !\n\n\n\nÿßŸÑÿ¥ÿπŸàÿ± ÿ®ÿßŸÑÿπÿ¨ÿ≤\n\n\nŸäŸÇŸàŸÖŸàŸÜ ÿ®ÿ™ÿ¨ŸÖŸäÿπ Ÿà ÿ™ÿ∑ŸàŸäÿ± ŸÜŸÖÿßÿ∞ÿ¨ ÿ™ÿÆÿØŸÖ ŸÅŸáŸÖ ÿßŸÑŸÑŸáÿ¨ÿ© ÿßŸÑÿ¥ÿßŸÖŸäÿ© ÿ™ÿ≥ÿßÿπÿØŸáŸÖ ŸÅŸä ŸÉŸÑ ÿ£ÿπŸÖÿßŸÑŸáŸÖ..ŸàŸÑŸäÿ≥ Ÿáÿ∞ÿß ŸàŸÇÿ™ ÿßŸÑÿ≠ÿØŸäÿ´..\nÿßŸÑÿπŸàÿßÿ¶ŸÇ ŸÉÿ´Ÿäÿ± ŸÖÿßÿØŸäÿ© Ÿà ŸÖÿπÿ±ŸÅŸäÿ© ŸàŸÉÿ´Ÿäÿ± ŸÑŸÉŸÜ ÿ≥ŸÇŸÅ ÿßŸÑŸÖŸÖŸÉŸÜ ŸÖÿ∞ŸáŸÑ..Ÿà ŸáŸÜÿßŸÉ ÿ£ŸÖŸÑ Ÿà ÿ•ŸÜ ŸÑŸÖ ŸäŸÉŸÜ ŸäŸÉŸÅŸä ÿ£ŸÜ ÿ™ŸÖŸàÿ™ ŸàÿßŸÜÿ™ ÿ™ÿ≠ÿßŸàŸÑ Ÿàÿ™ŸÜŸÉÿ± ÿ®ŸÇŸÑÿ®ŸÉ ŸàŸáÿ∞ÿß ÿ£ÿ∂ÿπŸÅ ÿßŸÑÿ•ŸäŸÖÿßŸÜ."
  },
  {
    "objectID": "til/tils/2025-05-21-til.html#ÿßŸÑÿ≥ÿπŸä-ÿßŸÑŸä-ÿßŸÑŸÉŸÖÿßŸÑ",
    "href": "til/tils/2025-05-21-til.html#ÿßŸÑÿ≥ÿπŸä-ÿßŸÑŸä-ÿßŸÑŸÉŸÖÿßŸÑ",
    "title": "ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©",
    "section": "",
    "text": "ŸÅŸä ÿßŸÑŸàŸÇÿ™ ÿßŸÑÿ≠ÿßŸÑŸä .. ÿ£ŸÜÿß ÿßŸÇŸàŸÖ ÿ®ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ŸàŸÖŸÜŸáÿß ÿßŸÑŸàÿßÿπÿØ ÿßŸÑÿ∞Ÿä ÿ≥ŸäŸÉŸàŸÜ ÿ≥ÿ®ÿ® ŸÅŸä ÿ•ÿØÿÆÿßŸÑ ÿØÿÆŸÑ ŸÖÿßÿØŸä ŸÉÿ®Ÿäÿ± Ÿà ÿπŸÑŸÖŸä ÿ•ŸÜ ÿ¥ÿßÿ° ÿßŸÑŸÑŸá.\nÿ≠ÿßŸÑŸäÿß ÿ£ÿπŸÖŸÑ ÿπŸÑŸä ÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑŸÖÿßÿ≥ÿ™ÿ± + ÿπÿ∂Ÿà ŸÅÿπÿßŸÑ ŸÅŸä ŸÖÿ¨ÿ™ŸÖÿπŸäŸÜ ŸÑÿ™ÿ∑ŸàŸäÿ± ÿßŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿßÿ™ ŸàÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä ŸÅŸä ÿßŸÑÿπÿßŸÑŸÖ ÿßŸÑÿπÿ±ÿ®Ÿä ŸàÿßŸÑÿ•ÿ≥ŸÑÿßŸÖŸä ŸàŸÑŸÑŸá ÿßŸÑÿ≠ŸÖÿØ ŸàÿßŸÑŸÅÿ∂ŸÑ Ÿàÿ≠ÿØŸá + ÿ£ÿπŸÖŸÑ ŸÅŸä ŸÖÿπŸÖŸÑ ÿ®ÿßÿ≠ÿ´Ÿä ÿ™ÿßÿ®ÿπ ŸÑÿßÿ≠ÿØ ÿßŸÑÿ£ÿ¥ÿÆÿßÿµ ÿßŸÑŸÖŸÖŸäÿ≤ÿ© ÿ¨ÿØÿß Ÿà ŸÑÿØŸä ÿ£ÿπŸÖÿßŸÑ ÿ®ÿßÿ≠ÿ´ŸäŸá ŸàŸÖÿ¥ÿßÿ±Ÿäÿπ ÿÆÿßÿµŸá ŸÖŸÜ ŸÜŸàÿßÿ≠Ÿä ŸÖÿ™ÿπÿØÿØÿ©.\nÿ£ÿ≥ÿ™ÿ¥ÿπÿ± ÿ≠ÿßŸÑŸäÿß ŸÉÿ´ÿ±ÿ© ÿßŸÑŸÖŸáÿßŸÖ ŸàÿßŸÑÿ™ÿ¥ÿ™ÿ™ ÿßŸÑŸÉÿ®Ÿäÿ± Ÿà ŸÇŸÑÿ© ÿßŸÑŸàŸÇÿ™ ŸàÿßŸÑŸÖÿ¨ŸáŸàÿØ ŸàÿßŸÑŸÉÿ´Ÿäÿ± ..ŸÑŸÉŸÜ Ÿáÿ∞ÿß ŸÑŸäÿ≥ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ©. ŸÖÿß ÿ£ÿ≥ÿ™ÿ¥ÿπÿ±Ÿá ŸáŸà ÿ≤ŸäÿßÿØÿ© ÿßŸÑÿ•ÿπÿ¨ÿßÿ® ÿ®ÿßŸÑŸÜŸÅÿ≥ ŸàÿßŸÑÿ®ÿπÿØ ÿπŸÜ ÿßŸÑÿπÿ®ÿßÿØÿ© ŸÖŸÜ ÿ£ÿ¨ŸÑ ŸÑÿ∞ÿ© ÿßŸÑÿπŸÑŸÖ Ÿà ÿ≠ÿ∏ ÿßŸÑŸÜŸÅÿ≥.\nŸà ŸÖŸÜ ÿØÿßÿÆŸÑŸä ŸÑÿß ÿ£ŸÇŸÜÿπ ÿ®ŸÉŸÑ ŸÖÿß ÿ£ŸÇÿØŸÖ ..Ÿàÿßÿ±Ÿä ÿßŸÜŸá ŸáŸÜÿßŸÉ ÿßŸÑŸÖÿ≤ŸäÿØ ŸÖŸÜ ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑŸÖÿπÿ±ŸÅÿ© Ÿäÿ¨ÿ® ÿ™ÿ≠ÿµŸÑŸäŸáÿß Ÿà ÿπÿØŸÖ ÿßŸÑÿ±ÿ∂ÿß ÿ®ŸÉŸàŸÜŸä ŸÖÿ¨ÿ±ÿØ ŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ŸàŸÖÿπÿØŸÑ ŸÑŸÖÿß ÿ£ÿ≥ÿ™ŸÇÿ®ŸÑŸá. ŸÖÿ¨ÿßŸÑ ÿØÿ±ÿßÿ≥ÿ™Ÿä ŸáŸà ÿßŸÑÿ∞ŸÉÿßÿ° ŸàÿßŸÑÿ•ÿµÿ∑ŸÜÿßÿπŸä ÿ®ÿ™ÿÆÿµÿµÿßÿ™Ÿá Ÿà ÿπŸÑŸàŸÖ ÿßŸÑÿ≠ÿßÿ≥ÿ®.\nŸÖÿß Ÿäÿ≤ÿπÿ¨ŸÜŸä ÿßŸÑŸÉÿ´Ÿäÿ± ..ŸÖŸÜŸáÿß ŸÑŸÖÿßÿ∞ÿß ÿ£ŸÇŸàŸÖ ÿ®ÿßÿ≥ÿ™ŸÇÿ®ÿßŸÑ ÿßŸÑÿπŸÑŸÖ ŸÖŸÜ ÿßŸÑÿÆÿßÿ±ÿ¨ ŸàŸÑÿ≥ÿ™ ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ŸÖÿ¨ÿ±ÿØ ÿßŸÑÿ¥ÿ±Ÿàÿ≠ÿßÿ™ ÿßŸÑÿ£ÿ¨ŸÜÿ®Ÿäÿ© Ÿà ÿßŸÑÿ£Ÿàÿ±ÿßŸÇ ŸàÿßŸÑŸÖÿ¥ÿßÿ±Ÿäÿπ ÿßŸÑÿ®ÿ±ŸÖÿ¨Ÿäÿ© ŸàŸÉŸÑ Ÿáÿ∞ÿß ŸàŸÑŸÉŸÜ ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿßŸÑÿ±ŸäÿßÿØÿ© ŸÅŸä ÿßŸÑÿπŸÑŸÖ ÿ∞ÿßÿ™Ÿá. ÿ£ÿ™ÿ≠ÿØÿ´ ÿπŸÜ ÿ£ŸÖÿ´ÿßŸÑ ÿ¨ŸäŸÅÿ±Ÿä ŸáŸäŸÜÿ™ŸàŸÜ ŸàŸÖÿß ÿ®ÿπÿØŸá ..ÿßŸÑÿ±ÿ∫ÿ®ÿ© ŸÅŸä ÿßŸÑŸàÿµŸàŸÑ ÿßŸÑŸä ÿ≠ÿßŸÅÿ© ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑÿ•ÿ®ÿØÿßÿπ ŸàŸÑŸäÿ≥ ŸÖÿ¨ÿ±ÿØ ÿßŸÑÿ™ÿπÿØŸäŸÑ ŸàŸÅŸáŸÖ ŸÖÿß ŸäÿµÿØÿ±ŸàŸÜ.\nŸáŸÑ ÿ£ŸÉÿ™ŸÅŸä ÿ®Ÿáÿ∞ÿß !\nŸÅŸä ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÑÿß ÿßÿ™ÿ∞ŸÉÿ± ÿπŸÜÿØŸÖÿß ÿ™ŸÖ ÿ•ÿ∑ŸÑÿßŸÇ deepseek ŸàŸÇÿ±ÿßÿ™ ÿπŸÜ ÿßŸÑÿ¥ÿ±ŸÉÿ© ÿßŸÑÿ™Ÿä ÿ™ŸÇŸÅ Ÿàÿ±ÿßÿ¶Ÿáÿß..ŸÑŸÖÿßÿ∞ÿß ŸÑŸÖ ÿ™ŸÉÿ±ÿ± ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿπÿ±ÿ®Ÿäÿ© ÿ•ÿ≥ŸÑÿßŸÖŸäÿ© ÿÆÿßŸÑÿµÿ©! ŸÑŸäÿ≥ ŸÖÿ≥ÿ™ÿ≠ŸäŸÑ ÿ™ŸÇŸÜŸäÿß ŸàŸÜÿ≠ŸÜ ÿ£ŸàŸÑŸä ÿ®ŸÑÿ∫ÿ™ŸÜÿß Ÿàÿ™ÿ±ÿßÿ´ŸÜÿß ŸÖŸÜ ÿ∫Ÿäÿ±ŸÜÿß ŸÖŸÜ ÿßŸÑÿ¥ÿπŸàÿ® ÿÆÿµŸàÿµÿß ..ÿ£ŸÜ ÿ™ŸÉŸàŸÜ Ÿáÿ∞Ÿá ÿßŸÑÿ¥ÿπŸàÿ® ŸÑÿØŸäŸáÿß ŸÉÿ±ÿßŸáŸäÿ© ŸÖÿ™ÿ¥ÿπÿ®Ÿá ÿÆÿßÿµÿ© ŸÑÿØŸäŸÜŸÉ Ÿàÿ¥ÿπÿ®ŸÉ ŸàŸÑŸÜÿß ŸÅŸä ŸÅŸÑÿ≥ÿ∑ŸäŸÜ ÿπÿ®ÿ±ÿ© ŸÅŸäŸÖÿß Ÿäÿ≠ÿØÿ´ ŸÅŸäŸáÿß ŸÖŸÜ ÿ™ŸÜŸÉŸäŸÑ Ÿà ÿ¨ÿ±ÿßÿ¶ŸÖ ŸÑÿß ÿßÿ≠ÿ® ÿ≠ÿ™Ÿä ÿßŸÑÿ™ŸÅŸÉÿ± ŸÅŸäŸáÿß. ŸÑŸÉŸÜ ŸÖÿß Ÿäÿ≤ŸäÿØ ÿßŸÑÿ≠ÿ≤ŸÜ ŸàÿßŸÑÿ∂ÿπŸÅ ŸàÿßŸÑŸáŸÖ ŸàÿßŸÑÿ∫ŸÖÿ© ..ÿ£ŸÜ ÿ™ÿ¨ÿØ ŸÖŸÜ ÿßŸÑÿ±ŸäÿßÿØÿ© ŸÅŸä ŸÖÿ¨ÿßŸÑŸÉ Ÿà ÿ™ÿÆÿµÿµŸÉ ÿ£ÿ∫ŸÑÿ®ŸáŸÖ ŸÖŸÜ ŸáŸàŸÑÿßÿ° ÿßŸÑÿµŸÜŸÅ ÿßŸÑÿ∞Ÿä ŸäŸÇÿ™ŸÑ ÿ•ÿÆŸàÿ™ŸÉ ÿ®ÿØŸÖ ÿ®ÿßÿ±ÿØ!\nŸÉŸäŸÅ ÿ™ÿ≥ÿπÿØ ŸÜŸÅÿ≥ŸÉ ŸàÿßŸÜÿ™ ÿ™ÿßÿ®ÿπ ŸÑŸáŸàŸÑÿßÿ° ÿ™ŸÜÿ™ÿ∏ÿ± ŸÖŸÜŸáŸÖ ÿ£ŸÜ Ÿäÿπÿ∑ŸàŸÉ ÿ®ÿπÿ∂ ÿßŸÑŸÅÿ™ÿ™ÿßÿ™ ŸÖŸÜ ÿßŸÑÿπŸÑŸÖ ŸÑÿ™ÿ∞Ÿáÿ® ŸÑÿ™ŸÜÿ™ŸÅÿÆ ÿ®Ÿá ŸÜŸÅÿ≥ŸÉ Ÿàÿ™ÿ∏ŸÜ ÿ£ŸÜ ŸÑÿØŸäŸÉ ÿ¥Ÿä ŸÖŸÜ ÿπŸÑŸÖ ŸàŸáŸà ŸÅÿ™ÿßÿ™.\nÿ®ÿØÿßŸäÿ© ŸÖŸÜ ÿßŸÑÿ®ÿßÿ≠ÿ´ŸäŸÜ ŸÑÿ£ÿµÿ≠ÿßÿ® ÿßŸÑÿ¥ÿ±ŸÉÿßÿ™ ŸÑŸÑŸÖŸàÿßŸÇÿπ ÿßŸÑÿ™Ÿä ÿ£ŸÇŸàŸÖ ÿ®ÿßŸÑÿßÿ≥ÿ™ÿ∂ÿßŸÅÿ© ÿπŸÑŸäŸáÿß ÿ•ŸÑŸä ÿßŸÑŸÉŸàÿ±ÿ≥ÿßÿ™ Ÿà ŸÖÿ¨ÿ™ŸÖÿπÿßÿ™ ÿßŸÑÿ™ŸÇŸÜŸäÿ©..ÿ®ŸÑ ÿ™ÿ≤ŸäÿØ ÿßŸÑÿ≠ÿ≥ÿ±ÿ© ÿπŸÜÿØŸä ÿ®ÿ≠ÿ´Ÿä ŸÅŸä ÿ®ŸäÿßŸÜÿßÿ™ ŸÑÿ™ÿ∑ŸàŸäÿ± ŸÜŸÖŸàÿ∞ÿ¨ ÿµÿ∫Ÿäÿ± ŸÑŸÖŸáŸÖÿ© ŸÖŸÜ ŸÖŸáÿßŸÖ ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ£ÿ¨ÿØ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™ ÿ£ŸäŸÜ !ŸàŸÖŸÜ ŸäÿπŸÖŸÑ ÿπŸÑŸäŸáÿß !\n\n\n\nÿßŸÑÿ¥ÿπŸàÿ± ÿ®ÿßŸÑÿπÿ¨ÿ≤\n\n\nŸäŸÇŸàŸÖŸàŸÜ ÿ®ÿ™ÿ¨ŸÖŸäÿπ Ÿà ÿ™ÿ∑ŸàŸäÿ± ŸÜŸÖÿßÿ∞ÿ¨ ÿ™ÿÆÿØŸÖ ŸÅŸáŸÖ ÿßŸÑŸÑŸáÿ¨ÿ© ÿßŸÑÿ¥ÿßŸÖŸäÿ© ÿ™ÿ≥ÿßÿπÿØŸáŸÖ ŸÅŸä ŸÉŸÑ ÿ£ÿπŸÖÿßŸÑŸáŸÖ..ŸàŸÑŸäÿ≥ Ÿáÿ∞ÿß ŸàŸÇÿ™ ÿßŸÑÿ≠ÿØŸäÿ´..\nÿßŸÑÿπŸàÿßÿ¶ŸÇ ŸÉÿ´Ÿäÿ± ŸÖÿßÿØŸäÿ© Ÿà ŸÖÿπÿ±ŸÅŸäÿ© ŸàŸÉÿ´Ÿäÿ± ŸÑŸÉŸÜ ÿ≥ŸÇŸÅ ÿßŸÑŸÖŸÖŸÉŸÜ ŸÖÿ∞ŸáŸÑ..Ÿà ŸáŸÜÿßŸÉ ÿ£ŸÖŸÑ Ÿà ÿ•ŸÜ ŸÑŸÖ ŸäŸÉŸÜ ŸäŸÉŸÅŸä ÿ£ŸÜ ÿ™ŸÖŸàÿ™ ŸàÿßŸÜÿ™ ÿ™ÿ≠ÿßŸàŸÑ Ÿàÿ™ŸÜŸÉÿ± ÿ®ŸÇŸÑÿ®ŸÉ ŸàŸáÿ∞ÿß ÿ£ÿ∂ÿπŸÅ ÿßŸÑÿ•ŸäŸÖÿßŸÜ."
  },
  {
    "objectID": "til/tils/2025-05-21-til.html#ÿßŸÑÿ®ÿØÿßŸäÿ©",
    "href": "til/tils/2025-05-21-til.html#ÿßŸÑÿ®ÿØÿßŸäÿ©",
    "title": "ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©",
    "section": "ÿßŸÑÿ®ÿØÿßŸäÿ©",
    "text": "ÿßŸÑÿ®ÿØÿßŸäÿ©\nŸÑÿØŸä ŸÖŸÜ ÿßŸÑÿπŸÖÿ± ÿßŸÑÿ¢ŸÜ 22 ÿπÿßŸÖ ŸÑÿØŸä ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÜÿØŸÖ ŸàÿßŸÑÿ≠ÿ≥ÿ±ÿ© ÿπŸÑŸä ÿßŸÑÿπŸÖÿ± ÿßŸÑŸÅÿßÿ¶ÿ™ ŸÅŸä ÿ∫Ÿäÿ± ÿßŸÑÿ∑ÿßÿπÿ© ŸàÿßŸÑÿπŸÖŸÑ ÿßŸÑÿµÿßŸÑÿ≠ ŸàŸàÿØÿØÿ™ ŸÑŸà ÿπŸÜÿØŸä ŸÅÿ±ÿµÿ© ŸÅŸä ÿßŸÑÿ±ÿ¨Ÿàÿπ ŸÑŸÑÿÆŸÑŸÅ ŸÉÿ´Ÿäÿ±ÿß ŸàÿßŸÑÿ®ÿØÿßŸäÿ© ŸÖÿ¨ÿØÿØÿß..ŸÑŸÉŸÜŸÜÿß ŸÑÿ≥ŸÜÿß ŸÅŸä ŸÅŸäŸÑŸÖ ÿ£ŸÜŸÖŸä ÿ®ŸÑ ŸàÿßŸÇÿπ‚Ä¶ÿπÿ≤ÿßÿ¶Ÿä ÿ•ŸÜŸÉ ÿ•ŸÜ ÿ™ÿ≥ÿ™ÿØÿ±ŸÉÿå ÿ™ÿ≥ÿ™ÿØÿ±ŸÉ ÿπŸÜÿØ ÿ±ÿ® ŸÉÿ±ŸäŸÖ ŸÇÿßÿØÿ± ÿπŸÑŸä ŸÉŸÑ ÿ¥ÿ¶. Ÿäÿ®ÿØŸÑ ŸÑŸÉ ÿ≥Ÿäÿ¶ÿßÿ™ŸÉ.\nÿ£ÿπÿßŸÜŸä ŸÖŸÜ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿπÿ≥ÿ± ÿßŸÑŸÅŸáŸÖ ŸÅŸä ŸÉŸÑ ÿ¥ÿ¶ ÿ™ŸÇÿ±Ÿäÿ®ÿß..ÿÆÿµŸàÿµÿß ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÑÿØŸä ÿπÿ≥ÿ± ŸÇÿ±ÿßÿ°ÿ© Ÿà ŸÉÿ™ÿßÿ®ÿ© Ÿà ÿßŸÑŸä ÿßŸÑÿµŸÅ ÿßŸÑÿ´ÿßŸÑÿ´ ÿßŸÑÿ´ÿßŸÜŸàŸä ŸÑÿØŸä ŸÖÿ¥ÿßŸÉŸÑ ŸÅÿßÿØÿ≠Ÿá ŸÅŸä ÿßŸÑŸÉÿ™ÿßÿ®ÿ©..ÿßŸÑÿ• ÿ£ŸÜŸÜŸä ŸÉŸÜÿ™ ÿßÿ≠ÿ® ÿßŸÑÿ±Ÿäÿßÿ∂Ÿäÿßÿ™ ÿ®ÿ±ÿ∫ŸÖ ŸÅÿ¥ŸÑŸä ŸÅŸäŸáÿß ..Ÿàÿßÿ≠ÿ® ÿßŸÑÿ•ŸÜÿ¨ŸäŸÑŸäÿ≤Ÿä ŸàÿßŸÑÿ≠ÿßŸÑ ÿ£ÿ≠ÿ≥ŸÜ ŸÖŸÜ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿ®ŸÉÿ´Ÿäÿ± ..ÿßÿ≠ÿ®ŸáŸÖ ŸàŸÑŸÉŸÜŸáŸÖ ŸÑÿß Ÿäÿ≠ÿ®ŸàŸÜŸä ŸàÿßŸÑÿ≠ŸÖÿØ ŸÑŸÑŸá.\nÿ®ÿØÿßÿ™ ÿ£ÿ≠ÿßŸàŸÑ ÿ¨ÿßŸáÿØÿß ŸÅŸä ÿßŸÑÿµŸÅ ÿßŸÑÿ´ÿßŸÜŸä ÿßŸÑÿ´ÿßŸÜŸàŸä ŸÖÿ≠ÿßŸàŸÑÿßÿ™ ÿ™ÿπÿ™ÿ®ÿ± ÿ¨ÿßÿØŸá ÿßŸÑŸä ÿßŸÑÿ´ÿßŸÑÿ´ ÿßŸÑÿ´ÿßŸÜŸàŸä ŸàŸÉŸÜÿ™ ŸÅÿßÿ¥ŸÑŸá Ÿàÿ™ÿ¨ÿßŸàÿ≤ÿ™ ÿßŸÑÿßŸÖÿ™ÿ≠ÿßŸÜÿßÿ™ ÿ®ÿßŸÑÿ∫ÿ¥ ŸàÿØÿÆŸÑÿ™ ÿßŸÑÿ¨ÿßŸÖÿπÿ© ŸàŸÑÿß ÿßÿ≥ÿ™ÿ≠ŸÇ Ÿáÿ∞ÿß ÿßŸÑŸÖŸÉÿßŸÜ ŸàŸÑÿß ÿ∞ŸÑŸÉ ÿßŸÑŸÖÿ¨ŸÖŸàÿπ.\nŸÅŸä ŸÉŸÑ ÿ™ŸÑŸÉ ÿßŸÑÿ≥ŸÜŸàÿßÿ™ ÿßŸÑŸÅÿßÿ¶ÿ™Ÿá ŸÉŸÜÿ™ ÿ™ÿπŸäÿ¥ ŸÅŸä ÿπÿßŸÑŸÖ ÿßŸÑŸÖŸÇÿßÿ±ÿßŸÜÿßÿ™ Ÿàÿ™ŸÜÿ™ÿ∏ÿ± ŸÖŸÜ ÿßŸÑÿ£ŸáŸÑ Ÿà ÿßŸÑÿ£ÿµÿ≠ÿßÿ® ÿßŸÑÿ•ÿπÿ™ÿ±ÿßŸÅ ŸàÿßŸÑÿ™ŸÇÿØŸäÿ± ..ÿ®ÿ±ÿ∫ŸÖ ŸÉŸÑ Ÿáÿ∞ÿß ŸÅŸÉŸÜÿ™ ÿ£ÿ™ŸÑŸÇŸä ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿ≠ÿ® ŸàÿßŸÑÿ•ŸäŸÖÿßŸÜ ÿ®Ÿä ŸÖŸÜ ŸÉŸÑ ŸÖŸÜ ÿØÿ±ÿ≥ ŸÑŸä ÿ™ŸÇÿ±Ÿäÿ®ÿß. ŸÅÿ¨ÿ≤ÿßŸáŸÖ ÿßŸÑŸÑŸá ÿÆŸäÿ±ÿß.\nŸÖŸÜ ÿØÿßÿÆŸÑŸä ŸÑÿ£ ÿßŸÅŸÉÿ± ŸÅŸä Ÿáÿ∞Ÿá ÿßŸÑÿ£ŸÅŸÉÿßÿ± ŸÉÿ´Ÿäÿ±ÿß..ŸÑŸÉŸÜŸä ŸÅŸä ÿ®ÿØÿßŸäÿ© ÿßŸÑÿ¨ÿßŸÖÿπÿ© ÿ™ÿ®ÿØŸÑ ÿßŸÑÿ≠ÿßŸÑ Ÿà ÿ£ÿµÿ®ÿ≠ ŸÉŸÑ ŸàŸÇÿ™Ÿä ÿ™ÿπŸÑŸÖ ŸàÿØÿ±ÿßÿ≥ÿ© ÿßŸÑŸä ÿ£ŸÜ ÿ™ÿÆÿ±ÿ¨ÿ™ ÿßŸÑÿπÿßŸÖ ÿßŸÑŸÅÿßÿ¶ÿ™ Ÿà ŸÖÿ±ÿ±ÿ™ ÿ®ŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿµÿπÿßÿ® Ÿàÿ™ÿ¨ÿßŸàÿ≤ÿ™Ÿáÿß Ÿà ÿßŸÑÿ≠ŸÖÿØ ŸÑŸÑŸá Ÿà ÿßŸÑŸä ÿßŸÑÿ£ŸÜ ÿ£ŸÇÿ™ÿ±ÿ® ŸÖŸÜ ÿßŸÑŸÑÿ≠ÿ∏ÿ© ÿßŸÑÿ™Ÿä ÿ≥Ÿäÿ™ÿ∫Ÿäÿ± ŸÅŸäŸáÿß ŸÉŸÑ ÿ¥ÿ¶ ŸàŸäÿ™ÿ®ÿØŸÑ ŸÉŸÑ ÿßŸÑÿ≠ÿßŸÑ..ŸÖŸÜ ŸÅÿ±ÿµ ÿßŸÑÿ≥ŸÅÿ± ŸàÿßŸÑŸÖŸÜÿ≠ Ÿà ŸÜÿ¨ÿßÿ≠ ÿßŸÑÿ£ÿπŸÖÿßŸÑ ŸàÿßŸÑÿ≠ÿ±Ÿäÿ© ÿßŸÑŸÖÿßÿØÿ© Ÿà ÿßŸÑŸÉÿ´Ÿäÿ± ÿ´ŸÖ ŸÇÿ®ŸÑŸáÿß ŸäŸàŸÖ ÿßŸÑÿ≠ÿµÿßÿØ ÿ£Ÿà ŸäŸàŸÖŸáÿß ŸÖÿ´ŸÑ ÿ£ÿÆÿ± ŸÖÿ±Ÿá..ÿ£ŸÅŸÇÿØ ŸÉŸÑ Ÿáÿ∞ÿß Ÿà ÿ£ÿ®ÿØÿß ŸÖŸÜ ÿ¨ÿØŸäÿØ..ÿ™ÿ¥ÿπÿ± ÿ®ÿßŸÑÿ≠ÿ≤ŸÜ ŸÉÿ´Ÿäÿ±ÿß..ŸÑŸÉŸÜ ÿ®ÿπÿØ ŸÅÿ™ÿ±ÿ© ÿ™ÿ¨ÿØ ÿ±ÿ≠ŸÖÿßÿ™ ÿ±ÿ®ŸÉ Ÿà ÿ™ŸÇÿØŸäÿ±Ÿá ŸÅŸä ŸÉŸÑ Ÿáÿ∞ÿß Ÿà ŸáŸÜÿßŸÉ ÿ£ŸàŸÇÿßÿ™ ŸÑÿß ÿ™ÿπÿ±ŸÅ ŸÖÿßŸáŸä ÿßŸÑÿ≠ŸÉŸÖÿ© ŸÑŸÉŸÜ ÿ™ÿ®ÿØÿß ŸÅŸä ÿ±ÿ§Ÿäÿ© ÿ™ŸÇÿµŸäÿ±ŸÉ Ÿà ÿ™ÿπŸäÿØ ÿ≠ÿ≥ÿßÿ®ÿßÿ™ Ÿàÿ™ÿ™Ÿàÿ¨Ÿá ÿßŸÑŸä ÿßŸÑŸÑŸá ŸÖÿ¨ÿØÿØÿß."
  },
  {
    "objectID": "til/tils/2025-05-21-til.html#ÿßŸÑÿ™ÿ≠ÿ±ÿ±-ŸÖŸÜ-ÿßŸÑÿØŸÜÿ≥",
    "href": "til/tils/2025-05-21-til.html#ÿßŸÑÿ™ÿ≠ÿ±ÿ±-ŸÖŸÜ-ÿßŸÑÿØŸÜÿ≥",
    "title": "ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©",
    "section": "ÿßŸÑÿ™ÿ≠ÿ±ÿ± ŸÖŸÜ ÿßŸÑÿØŸÜÿ≥",
    "text": "ÿßŸÑÿ™ÿ≠ÿ±ÿ± ŸÖŸÜ ÿßŸÑÿØŸÜÿ≥\nÿ®ÿπÿØ Ÿáÿ∞Ÿá ÿßŸÑÿ≥ŸÜŸäŸÜ ÿ™ŸÜÿ∏ÿ± ŸÑŸÜŸÅÿ≥ŸÉ Ÿà ÿ™ÿ®ÿØÿß ŸÅŸä ÿßŸÑÿ∫Ÿàÿµ ŸÅŸä ÿ£ÿπŸÖÿßŸÉ ÿßŸÑÿ∞ÿßÿ™ ŸÑŸÖÿßÿ∞ÿß ÿ£ŸÇŸàŸÖ ÿ®Ÿáÿ∞ÿß ŸàŸÖÿßŸáŸä ÿßŸÑÿ±ÿ∫ÿ®ÿ© ŸàÿßŸÑŸáÿØŸÅ !\nÿ™ÿ¨ÿØ ÿ£ŸÜŸÉ ÿ™ŸÖ ÿ≠ÿ®ÿ≥ŸÉ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÖÿπÿ™ŸÇÿØÿßÿ™ Ÿà ÿ£ŸÅŸÉÿßÿ± ÿ≥ÿßŸÖÿ© Ÿà ŸÅÿßÿ≥ÿØÿ© ÿ∑ŸäŸÑÿ© ÿ≠Ÿäÿßÿ™ŸÉ Ÿà ÿßŸÑŸÇŸÑŸäŸÑ ÿßŸÑŸÇŸÑŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿßŸÑÿµÿßŸÑÿ≠ÿ© ŸÖŸÜ ÿßŸÑÿ™ÿ±ÿ®Ÿäÿ© Ÿà ÿßŸÑŸÖÿ¨ÿ™ŸÖÿπ‚Ä¶ÿ™ÿ£ÿ™Ÿä Ÿáÿ∞Ÿá ÿßŸÑÿ£ŸÅŸÉÿßÿ± ÿ®ÿπÿØ ÿ£ŸÜ ÿ™ŸÅŸÉŸÉÿ™ ÿßŸÑÿ≠Ÿäÿßÿ© Ÿàÿ™ÿ®ÿØŸÑÿ™ ŸàŸáŸÜÿßŸÉ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑŸÖŸàÿ™Ÿä ŸÅŸä ÿ≠Ÿäÿßÿ™ŸÉ Ÿàÿ£ŸÜÿ™ ŸÖÿßÿ≤ŸÑÿ™\nÿ™ÿπŸäÿ¥ ŸÅŸä ÿ≥ÿπŸäŸÉ ŸÑŸÑÿßÿπÿ™ÿ±ÿßŸÅ ÿ®ŸÉ‚Ä¶ÿ™ÿπŸäÿ¥ ÿ£ÿ≥Ÿäÿ± ŸÑŸÑŸÖÿßÿ∂Ÿä ŸÅÿ™ÿ∏ŸÑŸÖ ÿ®ÿ∞ŸÑŸÉ ÿßŸÑÿ≠ÿßÿ∂ÿ± ŸàÿßŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑ."
  },
  {
    "objectID": "til/tils/2025-05-21-til.html#ÿßŸÑÿ£ŸÜÿßŸÜŸäÿ©-ŸàŸÑÿ∞ÿ©-ÿßŸÑÿπŸÑŸÖ",
    "href": "til/tils/2025-05-21-til.html#ÿßŸÑÿ£ŸÜÿßŸÜŸäÿ©-ŸàŸÑÿ∞ÿ©-ÿßŸÑÿπŸÑŸÖ",
    "title": "ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©",
    "section": "ÿßŸÑÿ£ŸÜÿßŸÜŸäÿ© ŸàŸÑÿ∞ÿ© ÿßŸÑÿπŸÑŸÖ",
    "text": "ÿßŸÑÿ£ŸÜÿßŸÜŸäÿ© ŸàŸÑÿ∞ÿ© ÿßŸÑÿπŸÑŸÖ\nŸÉÿßŸÜ ŸáŸÜÿßŸÉ ÿ£ŸàŸÇÿßÿ™ Ÿäÿ¨ÿ® ÿ£ŸÜ ÿßÿÆÿ™ÿßÿ± ÿßŸÑŸÖÿßŸÑ ÿ£ŸÖ ÿßŸÑÿπŸÑŸÖ!ŸàŸÉŸÜÿ™ ÿ®ŸÉŸÑ ÿ®ÿ≥ÿßÿ∑ÿ© ÿßŸÑÿπŸÑŸÖ ..ŸÅÿßŸÑŸÖÿßŸÑ ÿ≥Ÿäÿ£ÿ™Ÿä ŸÖÿ≥ÿ™ŸÇÿ®ŸÑÿß ÿ®ÿπÿØ ÿßŸÑÿπŸÑŸÖ ..ŸàŸáÿ∞ÿß ŸÑŸäÿ≥ ÿµÿ≠Ÿäÿ≠ÿß 100% ŸàŸÑŸÉŸÜ ÿßŸÑŸàÿßŸÇÿπ ŸÖÿÆÿ™ŸÑŸÅ..\nŸÑŸÖÿßÿ∞ÿß ÿ™ÿ±ŸäÿØ ÿßŸÑÿπŸÑŸÖ!! ÿ£ŸÇŸàŸÖ ÿ®ÿ≥ÿ±ÿØ ÿßŸÑŸÖÿßÿ¶ÿßÿ™ ŸÖŸÜ ÿßŸÑÿ¥ÿπÿßÿ±ÿßÿ™ ÿßŸÑÿ¨ÿ∞ÿßÿ®ÿ© ÿπŸÜ ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑÿ™ÿπŸÑŸÖ ŸàÿßŸÑŸáŸÖÿ© Ÿàÿ±ŸÅÿπ ÿßŸÑÿ≠ÿ±ÿ¨ ÿπŸÜ ÿßŸÑÿ£ŸÖÿ© ŸàÿßŸÑÿ´ÿ∫ÿ± ŸàŸÉŸÑÿßŸÖ Ÿäÿ¨ÿπŸÑŸÉ ÿ™ŸÇŸàŸÑ ŸäÿßŸá ÿ®ÿßÿ±ŸÉ ÿßŸÑŸÑŸá ŸÅŸäŸÉ‚Ä¶\nŸÖÿπÿ∏ŸÖŸá ŸÉŸÑÿßŸÖ ..ŸÑÿ≠ÿ∏ÿßÿ™ ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸáŸä ÿßŸÑŸÖÿ≠ŸÜ ..ÿßŸÑŸÑÿ≠ÿ∏ÿ© ÿßŸÑÿ™Ÿä ÿ≥ŸàŸÅ ÿ™ÿ™ÿÆŸÑŸä ÿπŸÜ ÿπŸÖŸÑ ŸÖÿπŸäŸÜ Ÿàÿ≥ÿπŸä Ÿà ŸÑŸÜ Ÿäÿ∞ŸÉÿ± ÿßÿ≥ŸÖŸÉ ŸàŸÑŸÉŸÜŸá ÿ≥ŸäÿÆÿ±ÿ¨ ÿ®ÿßÿ≥ŸÖ ŸÉŸÑŸä ŸàŸÑŸäÿ≥ ÿßÿ≥ŸÖ ŸäÿÆÿµŸÉ ŸÅÿ™ÿ¥ÿπÿ± ŸÖŸÜ ÿØÿßÿÆŸÑŸÉ ŸÖÿßÿ∞ÿß ŸÑŸà ŸÉŸÜÿ™ ÿßŸÜÿß ŸÖŸÜ ŸÇÿßŸÖ ÿ®Ÿá Ÿàÿ≠ÿØŸä Ÿàÿ™ŸÖ ÿ∞ŸÉÿ±Ÿä ÿßÿ≥ŸÖŸä Ÿàÿ≠ÿØŸä ÿπŸÑŸä ŸÖŸÜÿµÿßÿ™Ÿä ÿ≥ŸàŸÅ ÿ£ÿµÿ®ÿ≠ ŸÖÿπÿ±ŸàŸÅÿß ŸÅŸä ŸÖÿ¨ÿßŸÑŸä Ÿà ÿßÿ≠ÿµŸÑ ÿπŸÑŸä ŸÅÿ±ÿµÿ© ÿπŸÖŸÑ ÿ¨ŸäÿØÿ©‚Ä¶.\nŸÑŸÜ ÿ£ÿÆÿ®ÿ± Ÿáÿ∞ÿß ŸÉŸäŸÅŸäÿ© ÿπŸÖŸÑ ÿßŸÑŸÜŸÖŸàÿ∞ÿ¨ Ÿáÿ∞ÿß ÿßŸà ÿ£ŸÜ ŸáŸÜÿßŸÉ ÿ∑ÿ±ŸäŸÇÿ© ÿ£ÿ≥ŸáŸÑ ÿßŸÑŸä ÿßŸÜ ÿßŸÇŸàŸÖ ÿßŸÜÿß ÿ®Ÿáÿß ÿ≠ÿ™Ÿä ŸäŸÉŸàŸÜ ŸÑŸä ÿßŸÑÿ≥ÿ®ŸÇ!\nŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ŸÑÿ≠ÿ∏ÿßÿ™ ÿßŸÑÿßŸÜÿßŸÜŸäÿ© Ÿàÿ≠ÿ® ÿßŸÑÿ∞ÿßÿ™ ŸàŸÑÿ∞ÿ© ÿßŸÑÿπŸÑŸÖ ÿ™ÿ£ÿ™Ÿä ÿπŸÑŸä ÿ≠ÿ≥ÿßÿ® ÿßŸÑÿ∫ÿßŸäÿ© ÿßŸÑÿßŸàŸÑŸä Ÿà ŸÖÿ±ÿ∂ÿßÿ© ÿßŸÑŸÑŸá ÿå Ÿà ÿ≠ÿ≥ŸÜ ÿßŸÑÿπŸÑŸÖ ŸàÿßŸÑÿ•ÿÆŸÑÿßÿµ ŸÅŸä ÿßŸÑÿπŸÖŸÑ ŸàÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿ´ŸÖÿ±ÿßÿ™ ÿßŸÑÿ™Ÿä ÿ£ÿ∂ŸäÿπŸáÿß ŸÅÿ£ÿµÿ®ÿ≠ ÿπÿ®ÿØÿß ŸÑŸÑÿπÿ®ÿßÿØÿ© (ÿ∑ŸÑÿ® ÿßŸÑÿπŸÑŸÖ ) ŸàŸÑÿ≥ÿ™ ÿπÿ®ÿØÿß ŸÑŸÑŸá."
  },
  {
    "objectID": "til/tils/2025-05-21-til.html#ŸáŸÑ-Ÿáÿ∞ÿß-ŸáŸà-ÿßŸÑÿ≠ŸÇ",
    "href": "til/tils/2025-05-21-til.html#ŸáŸÑ-Ÿáÿ∞ÿß-ŸáŸà-ÿßŸÑÿ≠ŸÇ",
    "title": "ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©",
    "section": "ŸáŸÑ Ÿáÿ∞ÿß ŸáŸà ÿßŸÑÿ≠ŸÇÿü",
    "text": "ŸáŸÑ Ÿáÿ∞ÿß ŸáŸà ÿßŸÑÿ≠ŸÇÿü\nÿßŸÑÿ≠ŸÖÿØ ŸÑŸÑŸá ÿßŸÑÿ∞Ÿä ÿ£ÿ±ÿßŸÜŸä ÿ®ÿπÿ∂ ŸÖŸÜ ÿ£ÿØŸÜÿßÿ≥ ÿßŸÑŸÇŸÑÿ® ŸàŸÅÿ≥ÿßÿØ ÿßŸÑŸÜŸäÿ©ÿå ŸáŸÑ Ÿáÿ∞ÿß ŸáŸà ÿßŸÑÿ≠ŸÇ! ÿ®ÿßŸÑÿ™ÿßŸÉŸäÿØ ŸÑÿß.\nŸÖÿßŸáŸà ÿßŸÑÿ≠ŸÇ ÿ•ÿ∞ÿß‚Ä¶ŸáŸÜÿßŸÉ ÿßŸÑŸÉÿ´Ÿäÿ± ŸÖŸÜ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿßÿ™ ŸÑŸÉŸÜ ŸÖÿß Ÿäÿ≠ÿ∂ÿ± ŸÅŸä ŸÇŸÑÿ®Ÿä ÿ≠ÿßŸÑŸäÿß ÿ®ÿπÿØ ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸä ŸÉÿ´Ÿäÿ± ŸÖŸÜ ŸÖÿß ÿ£ÿ≠ÿ® ŸÖŸÜ ÿπŸÑŸÖ ŸàŸÖÿßŸÑ Ÿà ÿπŸÑÿßŸÇÿßÿ™ Ÿà ÿ∫Ÿäÿ±Ÿá..ÿ£ÿ¨ÿØ ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ÿßŸÑŸÇÿ±ÿßŸÜŸäÿ© ŸáŸä ÿßŸÑÿ•ÿ¨ÿßÿ®ÿ© ÿßŸÑŸàÿ≠ŸäÿØŸá ÿßŸÑÿ¥ÿßŸÅŸäŸá ŸÑÿ™ÿπÿ®ÿ± ÿπŸÜ ŸÖÿß ÿ£ŸÖÿ± ÿ®Ÿá ŸÖŸÜ ÿ£ÿ≤ŸÖÿ© ŸáŸàŸäÿ© ÿ≠ŸÇŸäŸÇÿ©.\n\n{ ŸÇŸèŸÑŸí ŸáŸéŸÑŸí ŸÜŸèŸÜŸéÿ®ŸêŸëÿ¶ŸèŸÉŸèŸÖŸí ÿ®ŸêÿßŸÑÿ£ŸéÿÆŸíÿ≥Ÿéÿ±ŸêŸäŸÜŸé ÿ£ŸéÿπŸíŸÖŸéÿßŸÑÿß * ÿßŸÑŸéŸëÿ∞ŸêŸäŸÜŸé ÿ∂ŸéŸÑŸéŸë ÿ≥ŸéÿπŸíŸäŸèŸáŸèŸÖŸí ŸÅŸêŸä ÿßŸÑŸíÿ≠ŸéŸäŸéÿßÿ©Ÿê ÿßŸÑÿØŸèŸëŸÜŸíŸäŸéÿß ŸàŸéŸáŸèŸÖŸí ŸäŸéÿ≠Ÿíÿ≥Ÿéÿ®ŸèŸàŸÜŸé ÿ£ŸéŸÜŸéŸëŸáŸèŸÖŸí ŸäŸèÿ≠Ÿíÿ≥ŸêŸÜŸèŸàŸÜŸé ÿµŸèŸÜŸíÿπŸãÿß } ÿ≥Ÿàÿ±ÿ© ÿßŸÑŸÉŸáŸÅ.\nÿ≥Ÿàÿ±ÿ© ÿßŸÑÿ≠ÿØŸäÿØ \n\nÿ£ÿ±ŸíŸàŸéŸâ. ¬∑ ÿ≥Ÿàÿ±ÿ© ÿßŸÑÿ≠ÿØŸäÿØ - ÿßŸÑÿ®ÿ±ÿßÿ° ÿ®ÿµŸÅÿ±\n\n\nŸàŸÑŸäÿ≥ ÿπŸÜÿØ ŸÖÿß ŸäŸÇÿßŸÑ ÿ®ÿπÿØ ÿ≥Ÿàÿ±ÿ© ÿßŸÑÿ≠ÿØŸäÿØ ŸàŸÖÿßŸÅŸäŸáÿß ŸÖŸÜ ÿÆÿ∑ÿßÿ® Ÿäÿ≠ÿ±ŸÉ ÿßŸÑÿµÿÆÿ± Ÿà Ÿäÿ¥ŸÅŸä ÿßŸÑÿµÿØÿ± Ÿà ŸäÿπŸÑŸä ÿßŸÑŸÑŸáŸÖÿ© ŸàŸäÿπÿ∑Ÿä ŸÑŸÑÿπÿ®ÿØ ÿßŸÑŸÜÿ∏ÿßÿ±ÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÑÿ±ÿ§Ÿäÿ© ÿßŸÑÿ≠ŸÇ."
  },
  {
    "objectID": "til/tils/2025-05-21-til.html#ÿ∑ŸÑÿ®-ÿßŸÑÿ™ŸàŸÅŸäŸÇ-Ÿà-ÿßŸÑÿµŸÑÿßÿ≠",
    "href": "til/tils/2025-05-21-til.html#ÿ∑ŸÑÿ®-ÿßŸÑÿ™ŸàŸÅŸäŸÇ-Ÿà-ÿßŸÑÿµŸÑÿßÿ≠",
    "title": "ÿßŸÑÿ®ŸàÿµŸÑÿ© ÿßŸÑÿ≠ŸÇŸäŸÇÿ©",
    "section": "ÿ∑ŸÑÿ® ÿßŸÑÿ™ŸàŸÅŸäŸÇ Ÿà ÿßŸÑÿµŸÑÿßÿ≠",
    "text": "ÿ∑ŸÑÿ® ÿßŸÑÿ™ŸàŸÅŸäŸÇ Ÿà ÿßŸÑÿµŸÑÿßÿ≠\nŸÅŸä ÿßŸÑÿ≠ŸÇŸäŸÇÿ© ŸÉŸÑ ŸÖÿß ŸÅŸä ÿßŸÑÿ£ÿπŸÑŸä ŸáŸà ÿ™ŸÖŸáŸäÿØ ÿ£ŸÜ ŸÉŸÑ ÿ£ŸÖÿßŸÑŸä Ÿà ÿ∑ŸÖŸàÿ≠ÿßÿ™Ÿä ŸáŸä ÿ±ÿ∫ÿ®ÿ© ŸÅŸä ÿßŸÑŸÖŸÜÿßŸÅÿ≥ÿ© Ÿà ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸä ÿßŸÑÿ™ŸÇÿØŸäÿ± ŸàÿßŸÑÿ±ŸÅÿπÿ© ŸÅŸä ÿßŸÑÿØŸäŸÜÿß‚Ä¶ŸàŸáÿ∞ÿß ÿÆÿ≥ÿ±ÿßŸÜ ŸÖÿ®ŸäŸÜ.\nÿ£ÿ±ÿ∫ÿ® ŸÅÿπŸÑÿß ÿ£ŸÜ ÿ™ŸÉŸàŸÜ ÿ™ÿ™ÿ≠ŸàŸÑ Ÿáÿ∞Ÿá ÿßŸÑÿ±ÿ∫ÿ®ÿ© ÿßŸÑŸä ÿ±ÿ∫ÿ®ÿ© ŸÅŸäŸÖÿß ÿπŸÜÿØ ÿßŸÑŸÑŸá Ÿà ŸÖÿ≠ÿ®ÿ™ÿ© Ÿà ÿ±ÿ∂ÿßŸá ŸÅŸáÿ∞ÿß ŸáŸà ÿßŸÑÿ™ŸàŸÅŸäŸÇ Ÿà ÿ£ŸÜ ÿ™ÿ±ÿ™ŸÅÿπ ÿØÿ±ÿ¨ÿßÿ™Ÿä ŸÅŸä ÿßŸÑÿØŸÜŸäÿß ÿ®ÿ£ŸÉÿ®ÿ± ŸÇÿØÿ± ŸÇÿ®ŸÑ ŸÅŸàÿßÿ™ ÿßŸÑÿ£ŸàÿßŸÜ ÿπŸÜÿØŸÖÿß ÿ™ŸÜŸÇŸÑÿ® ŸÉŸÑ ÿ£ÿπŸÖÿßŸÑŸä ÿßŸÑŸä ÿ≠ÿ≥ÿ±ÿ© Ÿà ŸÇÿ®ŸÑ ÿ£ŸÜ Ÿäÿ∂ŸÑ ÿ≥ÿπŸä Ÿà ÿ£ŸÜÿß ÿ£ÿ≠ÿ≥ÿ® ÿ£ŸÜŸä ÿßÿ≠ÿ≥ŸÜ ÿßŸÑÿπŸÖŸÑ.\nÿ®ÿπÿØ ŸÉŸÑ ÿßŸÑŸÖÿµÿßÿπÿ® ÿßŸÑÿ™Ÿä ÿ™ŸÇÿßÿ®ŸÑŸÜŸä ŸÖŸÜ ÿ≠ÿßÿ¨ÿ© ŸÖÿßÿØÿ© Ÿàÿ≠ÿßÿ¨ÿ© ŸÑŸÑŸÅŸáŸÖ ŸàÿßŸÑŸàŸÇÿ™ ŸàÿßŸÑÿ™ŸàŸÅŸäŸÇ ŸàÿßŸÑÿπŸÑŸÖ Ÿà ÿ∫Ÿäÿ± Ÿáÿ∞ÿß..ÿ£ÿ¨ÿØ ÿ£ŸÜ ÿßŸÑÿßŸÖÿ± ŸÉŸÑŸá ÿ®ŸäÿØ ÿßŸÑŸÑŸá Ÿà ŸÇÿØÿ±ÿ™Ÿá.\nŸÅŸÑÿß ÿ≠ŸàŸÑ ŸàŸÑÿß ŸÇŸàÿ© ÿßŸÑÿ•ÿ®ÿßŸÑŸÑŸá Ÿà ÿ≠ÿ≥ÿ®Ÿä ÿßŸÑŸÑŸá ŸàŸÜÿπŸÖ ÿßŸÑŸàŸÉŸäŸÑ.\nŸäÿ¨ÿ® ÿπŸÑŸä ÿ™ŸÇÿ®ŸÑ ÿßŸÑŸÖÿ≠ÿØŸàÿØŸäÿ© Ÿà ÿßŸÑÿ∂ÿπŸÅ Ÿà ÿßŸÑŸÑÿ¨Ÿàÿ° ÿßŸÑŸä ŸÖŸÜ ÿ®ŸäÿØŸá ŸÖŸÑŸÉŸàÿ™ ÿßŸÑÿ≥ŸÖŸàÿßÿ™ Ÿà ÿßŸÑÿ£ÿ±ÿ∂ ÿßŸÑŸÇÿßÿØÿ± ÿπŸÑŸä ŸÉŸÑ ÿ¥ÿ¶. ÿ≥ÿ®ÿ≠ÿßŸÜ ÿ±ÿ®Ÿä Ÿà ÿ™ÿπÿßŸÑŸä Ÿà ÿµŸÑŸä ÿßŸÑŸÑŸá Ÿàÿ≥ŸÑŸÖ ÿπŸÑŸä ÿ≥ŸäÿØŸÜÿß ŸÖÿ≠ŸÖÿØ."
  },
  {
    "objectID": "til/tils/2025-05-18-til.html",
    "href": "til/tils/2025-05-18-til.html",
    "title": "Explore the Qdrant Blog core concepts | Part 1",
    "section": "",
    "text": "I will divide the blogs into 3 types:\n\nStartups using Qdrant: why and comparision you get read nice usecases with some numbers of comparision and how qdrant is amazing\nStartup using Qdrant++: The same but with code snippets and System Design discussion..very useful for me as a developer\nQdrant releases: New features in Qdrant and how to use them.\n\nRemember this when i will build Agentic RAG in the new job\nusers tend to ask more structured, analytical questions when they know a database is involved‚Äîqueries better suited to SQL than vector search. This prompted the team to pair Qdrant with a text-to-SQL system, blending unstructured and structured query capabilities for a more versatile agent.\n\n\nSuperlinked enhances search by embedding each attribute (text, numbers, categories) into specialized spaces, enabling nuanced, multi-attribute queries.\nAn LLM interprets user intent, assigning weights to preferences (e.g., price, rating), allowing flexible, business-driven ranking without system redesign.\nHard filters narrow results, while weighted nearest neighbor search ranks them by user preferences.\nThis unified approach supports multimodal search‚Äîcombining semantic text, scaled numerical, and categorical data‚Äîpreserving relationships and preference strengths.\nUnlike traditional systems that separate or flatten data, Superlinked enables simultaneous, weighted consideration of all attributes, solving challenges like reconciling\nresults across types and capturing nuanced user intent.\n\n\n\nQdrant‚Äôs native support for Reciprocal Rank Fusion (RRF) streamlined their retriever implementations, reducing hybrid search code by 80%. The multi-vector capabilities also enabled more sophisticated retrieval methods that better captured semantic relationships.\n\n\n\nHere is summary of these new features\n\n\nYou can Index over all majro GPU vendors including NVIDIA,AMD and Intel that support Vulkan API to get speeds up to 10x faster than CPU-based methods*\nAs of right now this solution supports only on-premises deployments, but they will introduce support for Qdrant Cloud shortly.\nAdditional benefits:\n\nMulti-GPU support\nGPU indexing supports all quantization options and datatypes in Qdrant\n\n\n\n\nStrict Mode enforces operational controls in distributed Qdrant deployments. It limits resource-intensive operations (like unindexed filtering and large batch sizes), sets boundaries on search parameters, and adds safeguards for payload sizes and timeouts. This prevents system overload, solves the ‚Äúnoisy neighbor‚Äù problem, and ensures reliable performance‚Äîespecially in multi-tenant or serverless environments.\n\n\n\nMake search lighter on memory wihtout sacrificing speed with Delta Encoding.\nDelta Encoding is a clever way to compress data by storing only the differences (or ‚Äúdeltas‚Äù) between values. It‚Äôs commonly used in search engines (for the classical inverted index) to save space and improve performance. I think i have read this with Colbertv2 using similar techniques to reduce the siz  it‚Äôs called residual compression mechanism needs more searching\nIt‚Äôs now used for HNSW graph structure that powers Qdrant‚Äôs search."
  },
  {
    "objectID": "til/tils/2025-05-18-til.html#overview-of-qdrant-features-and-concepts",
    "href": "til/tils/2025-05-18-til.html#overview-of-qdrant-features-and-concepts",
    "title": "Explore the Qdrant Blog core concepts | Part 1",
    "section": "",
    "text": "I will divide the blogs into 3 types:\n\nStartups using Qdrant: why and comparision you get read nice usecases with some numbers of comparision and how qdrant is amazing\nStartup using Qdrant++: The same but with code snippets and System Design discussion..very useful for me as a developer\nQdrant releases: New features in Qdrant and how to use them.\n\nRemember this when i will build Agentic RAG in the new job\nusers tend to ask more structured, analytical questions when they know a database is involved‚Äîqueries better suited to SQL than vector search. This prompted the team to pair Qdrant with a text-to-SQL system, blending unstructured and structured query capabilities for a more versatile agent.\n\n\nSuperlinked enhances search by embedding each attribute (text, numbers, categories) into specialized spaces, enabling nuanced, multi-attribute queries.\nAn LLM interprets user intent, assigning weights to preferences (e.g., price, rating), allowing flexible, business-driven ranking without system redesign.\nHard filters narrow results, while weighted nearest neighbor search ranks them by user preferences.\nThis unified approach supports multimodal search‚Äîcombining semantic text, scaled numerical, and categorical data‚Äîpreserving relationships and preference strengths.\nUnlike traditional systems that separate or flatten data, Superlinked enables simultaneous, weighted consideration of all attributes, solving challenges like reconciling\nresults across types and capturing nuanced user intent.\n\n\n\nQdrant‚Äôs native support for Reciprocal Rank Fusion (RRF) streamlined their retriever implementations, reducing hybrid search code by 80%. The multi-vector capabilities also enabled more sophisticated retrieval methods that better captured semantic relationships.\n\n\n\nHere is summary of these new features\n\n\nYou can Index over all majro GPU vendors including NVIDIA,AMD and Intel that support Vulkan API to get speeds up to 10x faster than CPU-based methods*\nAs of right now this solution supports only on-premises deployments, but they will introduce support for Qdrant Cloud shortly.\nAdditional benefits:\n\nMulti-GPU support\nGPU indexing supports all quantization options and datatypes in Qdrant\n\n\n\n\nStrict Mode enforces operational controls in distributed Qdrant deployments. It limits resource-intensive operations (like unindexed filtering and large batch sizes), sets boundaries on search parameters, and adds safeguards for payload sizes and timeouts. This prevents system overload, solves the ‚Äúnoisy neighbor‚Äù problem, and ensures reliable performance‚Äîespecially in multi-tenant or serverless environments.\n\n\n\nMake search lighter on memory wihtout sacrificing speed with Delta Encoding.\nDelta Encoding is a clever way to compress data by storing only the differences (or ‚Äúdeltas‚Äù) between values. It‚Äôs commonly used in search engines (for the classical inverted index) to save space and improve performance. I think i have read this with Colbertv2 using similar techniques to reduce the siz  it‚Äôs called residual compression mechanism needs more searching\nIt‚Äôs now used for HNSW graph structure that powers Qdrant‚Äôs search."
  },
  {
    "objectID": "til/tils/2025-05-18-til.html#static-embedding-with-qdrant-and-model2vec",
    "href": "til/tils/2025-05-18-til.html#static-embedding-with-qdrant-and-model2vec",
    "title": "Explore the Qdrant Blog core concepts | Part 1",
    "section": "Static Embedding with Qdrant and Model2vec",
    "text": "Static Embedding with Qdrant and Model2vec\nStatic embedding from minishLab reduce the model size with 15x reduction and up to 500x speed increase while the maintain more than 85% of the performance levels. it‚Äôs like our zaraah model for arabic.\nStatic embedding are dense embedding so you can also use with qdrant collections. The retrieval is not going to be any faster becuase static embeddings. but the speedup is in creating the vectors from your data and encoding the queries.\nIf you want to make the retrieval faster use the following: 1. Matryoshka Embeddings 2. Quantization methods like (Scalar and Binary Quantization) ### When to use Static Embeddings ?\n\nMobile applications - although many smartphones have powerful CPUs or even GPUs, the battery life is still a concern, and the static embeddings might be a good compromise between the quality and the power consumption. Moreover, the static embeddings can be used in the applications that require offline mode.\nWeb browser extensions - running a transformer-based model in a web browser is usually not quite an option, but static embeddings might be a good choice, as they have fewer parameters and are faster to encode.\nEmbedded systems - the static embeddings might be a good choice for the devices with limited computational power, such as IoT devices or microcontrollers.\n\n\nReferences:\nThere is more text in here from Qdrant not me..you can continue reading here\n\nHotel Search\nQdrant Blog\nStatic Embedding"
  },
  {
    "objectID": "oss/opensource.html",
    "href": "oss/opensource.html",
    "title": " Open Source",
    "section": "",
    "text": "My open source work has been focused on developer tools and infrastructure. I‚Äôve contributed to projects such as fastai, Metaflow, Kubeflow, Jupyter, and Great Expectations, as well as many others. I list some of these below:"
  },
  {
    "objectID": "oss/opensource.html#fastai",
    "href": "oss/opensource.html#fastai",
    "title": " Open Source",
    "section": " fastai",
    "text": "fastai\nI maintain and contribute to a variety of fastai projects. Below are the projects I‚Äôve been very involved in:\n\n\n\n\n\n\nProject\n\n\n\nDescription\n\n\n\nRole\n\n\n\nOther References\n\n\n\n\n\n\n\n\nfastpages \n\n\nAn easy to use blogging platform for Jupyter Notebooks. \n\n\nCreator\n\n\nBlog, Talk\n\n\n\n\n\n\nnbdev \n\n\nWrite, test, document, and distribute software packages and technical articles all in one place, your notebook. \n\n\nCore Contributor\n\n\nBlog, Talk\n\n\n\n\n\n\nfastcore \n\n\nA Python language extension for exploratory and literate programming. \n\n\nCore Contributor\n\n\nBlog\n\n\n\n\n\n\nghapi \n\n\nA Python client for the GitHub API \n\n\nCore Contributor\n\n\n Blog\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "oss/opensource.html#metaflow",
    "href": "oss/opensource.html#metaflow",
    "title": " Open Source",
    "section": " Metaflow",
    "text": "Metaflow\nI created notebook cards: A tool that allows you to use notebooks to generate reports, visualizations and diagnostics in Metaflow production workflows. Blog"
  },
  {
    "objectID": "oss/opensource.html#kubeflow",
    "href": "oss/opensource.html#kubeflow",
    "title": " Open Source",
    "section": " Kubeflow",
    "text": "Kubeflow\nI‚Äôve worked on several projects related to Kubeflow, mainly around examples and documentation:\n\n\n\n\n\n\nProject\n\n\n\nDescription\n\n\n\nRole\n\n\n\nOther References\n\n\n\n\n\n\n\n\nGitHub Issue Summarization\n\n\nAn end-to-end example of using Kubeflow to summarize GitHub Issues. Became one of the most popular tutorials of Kubeflow. \n\n\nAuthor\n\n\nInterview with Jeremy Lewi\n\n\n\n\n\n\nkubeflow/codei-intelligence\n\n\nVarious tutorials and applied examples of Kubeflow. \n\n\nCore Contributor\n\n\nTalk\n\n\n\n\n\n\nThe Kubeflow Blog\n\n\nI used fastpages to create the official Kubeflow blog. \n\n\nCore Contributor\n\n\nSite\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "oss/opensource.html#jupyter",
    "href": "oss/opensource.html#jupyter",
    "title": " Open Source",
    "section": " Jupyter",
    "text": "Jupyter\nI created the Repo2Docker GitHub Action, which allows you to trigger repo2docker to build a Jupyter enabled Docker images from your GitHub repository. This Action allows you to pre-cache images for your own BinderHub cluster or for mybinder.org.\nThis project was accepted into the official JupyterHub GitHub org."
  },
  {
    "objectID": "oss/opensource.html#great-expectations",
    "href": "oss/opensource.html#great-expectations",
    "title": " Open Source",
    "section": " Great Expectations",
    "text": "Great Expectations\nI developed the Great Expectations GitHub Action that allows you to use Great Expectations in CI/CD Workflows. Blog."
  },
  {
    "objectID": "oss/opensource.html#other",
    "href": "oss/opensource.html#other",
    "title": " Open Source",
    "section": " Other",
    "text": "Other\nI worked as a staff machine learning engineer at GitHub from 2017 - 2022. I led or created the following open source projects that explored the intersection of machine learning, data and the developer workflow:\n\n\n\n\n\n\nProject\n\n\n\nDescription\n\n\n\nRole\n\n\n\nOther References\n\n\n\n\n\n\n\n\nCode Search Net \n\n\nDatasets, tools, and benchmarks for representation learning of code. This was a big part of the inspiration for GitHub‚Äôs eventual work on CoPilot. \n\n\nLead\n\n\n Blog, Paper\n\n\n\n\n\n\nMachine Learning Ops\n\n\nA collection of resources on how to facilitate Machine Learning Ops with GitHub. This project explored integrations with a wide variety of data science tools with GitHub Actions. \n\n\nCreator\n\n\nBlog\n\n\n\n\n\n\nIssue Label Bot\n\n\nA GitHub App powered by machine learning that auto-labels issues. \n\n\nCreator\n\n\nBlog, Talk\n\n\n\n\n\n\nCovid19-dashboard \n\n\nA demonstration of how to use GitHub Actions, Jupyter Notebooks and fastpages to create interactive dashboards that update daily.\n\n\n\nCreator\n\n\nNews Article\n\n\n\n\n\n\nNo matching items"
  }
]